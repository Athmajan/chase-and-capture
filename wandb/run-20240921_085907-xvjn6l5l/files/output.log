Episode 10: Avg Loss = 0.0
Model saved with loss 0.0 at episode 10
Traceback (most recent call last):
  File "/Users/athmajanvivekananthan/WCE/JEPA - MARL/multi-agent/PPO/bert_marl/mode20-dqn/dqn_seq.py", line 272, in <module>
    if i ==1 :
  File "/Users/athmajanvivekananthan/WCE/JEPA - MARL/multi-agent/PPO/bert_marl/mode20-dqn/src/agent_seq_rollout.py", line 69, in act
    best_action, action_q_values = self.act_with_info(obs, prev_actions)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/athmajanvivekananthan/WCE/JEPA - MARL/multi-agent/PPO/bert_marl/mode20-dqn/src/agent_seq_rollout.py", line 127, in act_with_info
    res = self._simulate_action_par(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/athmajanvivekananthan/WCE/JEPA - MARL/multi-agent/PPO/bert_marl/mode20-dqn/src/agent_seq_rollout.py", line 228, in _simulate_action_par
    sim_best_action = agent.act(sim_obs, prev_actions=sim_prev_actions)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/athmajanvivekananthan/WCE/JEPA - MARL/multi-agent/PPO/bert_marl/mode20-dqn/src/agent_rule_based.py", line 45, in act
    best_action, action_distances = self.act_with_info(obs)
                                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/athmajanvivekananthan/WCE/JEPA - MARL/multi-agent/PPO/bert_marl/mode20-dqn/src/agent_rule_based.py", line 56, in act_with_info
    arrSortedActDist = np.array(action_distances, dtype=np.float32)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt