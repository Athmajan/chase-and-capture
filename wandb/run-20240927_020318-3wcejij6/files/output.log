Epoch: 0, Batch Gradient Norm: 5.961190507136447
Epoch: 0, Batch Gradient Norm after: 5.961190507136447
Epoch 1/10000, Prediction Accuracy = 19.923076923076923%, Loss = 0.17359568579838827
Epoch: 1, Batch Gradient Norm: 4.194169553844839
Epoch: 1, Batch Gradient Norm after: 4.194169553844839
Epoch 2/10000, Prediction Accuracy = 23.48846153846154%, Loss = 0.0921199768781662
Epoch: 2, Batch Gradient Norm: 2.963594444807087
Epoch: 2, Batch Gradient Norm after: 2.963594444807087
Epoch 3/10000, Prediction Accuracy = 25.273076923076925%, Loss = 0.05874721992474336
Epoch: 3, Batch Gradient Norm: 2.018244159104542
Epoch: 3, Batch Gradient Norm after: 2.018244159104542
Epoch 4/10000, Prediction Accuracy = 26.599999999999998%, Loss = 0.041316116658540875
Epoch: 4, Batch Gradient Norm: 1.2866450970747365
Epoch: 4, Batch Gradient Norm after: 1.2866450970747365
Epoch 5/10000, Prediction Accuracy = 27.96923076923077%, Loss = 0.032172611269813314
Epoch: 5, Batch Gradient Norm: 0.7831514847019427
Epoch: 5, Batch Gradient Norm after: 0.7831514847019427
Epoch 6/10000, Prediction Accuracy = 30.315384615384616%, Loss = 0.02777489174443942
Epoch: 6, Batch Gradient Norm: 0.48593878591225864
Epoch: 6, Batch Gradient Norm after: 0.48593878591225864
Epoch 7/10000, Prediction Accuracy = 31.823076923076925%, Loss = 0.025669705839111254
Epoch: 7, Batch Gradient Norm: 0.32644568906920907
Epoch: 7, Batch Gradient Norm after: 0.32644568906920907
Epoch 8/10000, Prediction Accuracy = 33.10000000000001%, Loss = 0.024457436341505785
Epoch: 8, Batch Gradient Norm: 0.28818244984985003
Epoch: 8, Batch Gradient Norm after: 0.28818244984985003
Epoch 9/10000, Prediction Accuracy = 33.669230769230765%, Loss = 0.023753015611034173
Epoch: 9, Batch Gradient Norm: 0.26538857709268227
Epoch: 9, Batch Gradient Norm after: 0.26538857709268227
Epoch 10/10000, Prediction Accuracy = 34.4923076923077%, Loss = 0.023218496774251644
Epoch: 10, Batch Gradient Norm: 0.25573803993904753
Epoch: 10, Batch Gradient Norm after: 0.25573803993904753
Epoch 11/10000, Prediction Accuracy = 35.05769230769231%, Loss = 0.022751099071823634
Epoch: 11, Batch Gradient Norm: 0.23377958553509426
Epoch: 11, Batch Gradient Norm after: 0.23377958553509426
Epoch 12/10000, Prediction Accuracy = 35.669230769230765%, Loss = 0.022326953136003934
Epoch: 12, Batch Gradient Norm: 0.2571402213522734
Epoch: 12, Batch Gradient Norm after: 0.2571402213522734
Epoch 13/10000, Prediction Accuracy = 36.05%, Loss = 0.022040589784200374
Epoch: 13, Batch Gradient Norm: 0.24969528660109444
Epoch: 13, Batch Gradient Norm after: 0.24969528660109444
Epoch 14/10000, Prediction Accuracy = 36.526923076923076%, Loss = 0.021735462718285047
Epoch: 14, Batch Gradient Norm: 0.24483778901022013
Epoch: 14, Batch Gradient Norm after: 0.24483778901022013
Epoch 15/10000, Prediction Accuracy = 37.08076923076923%, Loss = 0.021477508860138748
Epoch: 15, Batch Gradient Norm: 0.24239149687871817
Epoch: 15, Batch Gradient Norm after: 0.24239149687871817
Epoch 16/10000, Prediction Accuracy = 37.68076923076923%, Loss = 0.0212759763862078
Epoch: 16, Batch Gradient Norm: 0.22997632918275626
Epoch: 16, Batch Gradient Norm after: 0.22997632918275626
Epoch 17/10000, Prediction Accuracy = 37.65769230769231%, Loss = 0.021002580483372394
Epoch: 17, Batch Gradient Norm: 0.23594776026423456
Epoch: 17, Batch Gradient Norm after: 0.23594776026423456
Epoch 18/10000, Prediction Accuracy = 38.14615384615385%, Loss = 0.020852368754836228
Epoch: 18, Batch Gradient Norm: 0.2647897005788948
Epoch: 18, Batch Gradient Norm after: 0.2647897005788948
Epoch 19/10000, Prediction Accuracy = 38.4076923076923%, Loss = 0.020705291284964636
Epoch: 19, Batch Gradient Norm: 0.24242296419314038
Epoch: 19, Batch Gradient Norm after: 0.24242296419314038
Epoch 20/10000, Prediction Accuracy = 38.53846153846154%, Loss = 0.020537621843127105
Epoch: 20, Batch Gradient Norm: 0.24787597791318156
Epoch: 20, Batch Gradient Norm after: 0.24787597791318156
Epoch 21/10000, Prediction Accuracy = 39.13076923076923%, Loss = 0.02040822058916092
Epoch: 21, Batch Gradient Norm: 0.24224150134224162
Epoch: 21, Batch Gradient Norm after: 0.24224150134224162
Epoch 22/10000, Prediction Accuracy = 39.23461538461539%, Loss = 0.020242645763433896
Epoch: 22, Batch Gradient Norm: 0.24895225895496761
Epoch: 22, Batch Gradient Norm after: 0.24895225895496761
Epoch 23/10000, Prediction Accuracy = 39.599999999999994%, Loss = 0.020105511093368895
Epoch: 23, Batch Gradient Norm: 0.22879584123817748
Epoch: 23, Batch Gradient Norm after: 0.22879584123817748
Epoch 24/10000, Prediction Accuracy = 39.95769230769231%, Loss = 0.01994616538286209
Epoch: 24, Batch Gradient Norm: 0.2451925750522329
Epoch: 24, Batch Gradient Norm after: 0.2451925750522329
Epoch 25/10000, Prediction Accuracy = 40.10384615384615%, Loss = 0.019880838835468657
Epoch: 25, Batch Gradient Norm: 0.23557342271625337
Epoch: 25, Batch Gradient Norm after: 0.23557342271625337
Epoch 26/10000, Prediction Accuracy = 40.62692307692308%, Loss = 0.019732219381974295
Epoch: 26, Batch Gradient Norm: 0.23720939577000294
Epoch: 26, Batch Gradient Norm after: 0.23720939577000294
Epoch 27/10000, Prediction Accuracy = 40.31153846153847%, Loss = 0.01960263616190507
Epoch: 27, Batch Gradient Norm: 0.23010838976190176
Epoch: 27, Batch Gradient Norm after: 0.23010838976190176
Epoch 28/10000, Prediction Accuracy = 40.95384615384615%, Loss = 0.019550650738752805
Epoch: 28, Batch Gradient Norm: 0.2417608182607712
Epoch: 28, Batch Gradient Norm after: 0.2417608182607712
Epoch 29/10000, Prediction Accuracy = 40.92692307692308%, Loss = 0.01944837962778715
Epoch: 29, Batch Gradient Norm: 0.23809391777855357
Epoch: 29, Batch Gradient Norm after: 0.23809391777855357
Epoch 30/10000, Prediction Accuracy = 41.17307692307692%, Loss = 0.019361739978194237
Epoch: 30, Batch Gradient Norm: 0.23365391856991474
Epoch: 30, Batch Gradient Norm after: 0.23365391856991474
Epoch 31/10000, Prediction Accuracy = 41.41153846153846%, Loss = 0.019255133918844737
Epoch: 31, Batch Gradient Norm: 0.2488523405376157
Epoch: 31, Batch Gradient Norm after: 0.2488523405376157
Epoch 32/10000, Prediction Accuracy = 41.176923076923075%, Loss = 0.019181642681360245
Epoch: 32, Batch Gradient Norm: 0.23607312542205572
Epoch: 32, Batch Gradient Norm after: 0.23607312542205572
Epoch 33/10000, Prediction Accuracy = 41.57692307692309%, Loss = 0.019096101132723
Epoch: 33, Batch Gradient Norm: 0.25157846674759204
Epoch: 33, Batch Gradient Norm after: 0.25157846674759204
Epoch 34/10000, Prediction Accuracy = 41.71923076923077%, Loss = 0.01901692495896266
Epoch: 34, Batch Gradient Norm: 0.24560360353335006
Epoch: 34, Batch Gradient Norm after: 0.24560360353335006
Epoch 35/10000, Prediction Accuracy = 41.91538461538461%, Loss = 0.018920455271234878
Epoch: 35, Batch Gradient Norm: 0.2441996929720831
Epoch: 35, Batch Gradient Norm after: 0.2441996929720831
Epoch 36/10000, Prediction Accuracy = 41.96923076923076%, Loss = 0.018842375192504663
Epoch: 36, Batch Gradient Norm: 0.24528619637973095
Epoch: 36, Batch Gradient Norm after: 0.24528619637973095
Epoch 37/10000, Prediction Accuracy = 42.23846153846154%, Loss = 0.01876026649887745
Epoch: 37, Batch Gradient Norm: 0.24530586516475295
Epoch: 37, Batch Gradient Norm after: 0.24530586516475295
Epoch 38/10000, Prediction Accuracy = 42.17692307692308%, Loss = 0.01870550186588214
Epoch: 38, Batch Gradient Norm: 0.25258350747629316
Epoch: 38, Batch Gradient Norm after: 0.25258350747629316
Epoch 39/10000, Prediction Accuracy = 42.54615384615385%, Loss = 0.018660883490855876
Epoch: 39, Batch Gradient Norm: 0.2591527254725554
Epoch: 39, Batch Gradient Norm after: 0.2591527254725554
Epoch 40/10000, Prediction Accuracy = 42.611538461538466%, Loss = 0.018618197968372933
Epoch: 40, Batch Gradient Norm: 0.24574745927304856
Epoch: 40, Batch Gradient Norm after: 0.24574745927304856
Epoch 41/10000, Prediction Accuracy = 42.915384615384625%, Loss = 0.018489012494683266
Epoch: 41, Batch Gradient Norm: 0.24122455982514412
Epoch: 41, Batch Gradient Norm after: 0.24122455982514412
Epoch 42/10000, Prediction Accuracy = 42.76538461538462%, Loss = 0.018421047295515355
Epoch: 42, Batch Gradient Norm: 0.2503650206887337
Epoch: 42, Batch Gradient Norm after: 0.2503650206887337
Epoch 43/10000, Prediction Accuracy = 42.93076923076923%, Loss = 0.018383495939465668
Epoch: 43, Batch Gradient Norm: 0.2400938859669678
Epoch: 43, Batch Gradient Norm after: 0.2400938859669678
Epoch 44/10000, Prediction Accuracy = 43.099999999999994%, Loss = 0.018291364495570842
Epoch: 44, Batch Gradient Norm: 0.25078007224170323
Epoch: 44, Batch Gradient Norm after: 0.25078007224170323
Epoch 45/10000, Prediction Accuracy = 43.23846153846154%, Loss = 0.018257385263076194
Epoch: 45, Batch Gradient Norm: 0.24901735693270544
Epoch: 45, Batch Gradient Norm after: 0.24901735693270544
Epoch 46/10000, Prediction Accuracy = 43.3%, Loss = 0.018223138382801644
Epoch: 46, Batch Gradient Norm: 0.2619859327415664
Epoch: 46, Batch Gradient Norm after: 0.2619859327415664
Epoch 47/10000, Prediction Accuracy = 43.28461538461538%, Loss = 0.018168177312383287
Epoch: 47, Batch Gradient Norm: 0.2594897026237448
Epoch: 47, Batch Gradient Norm after: 0.2594897026237448
Epoch 48/10000, Prediction Accuracy = 43.46923076923077%, Loss = 0.018148408343012516
Epoch: 48, Batch Gradient Norm: 0.24991282152409114
Epoch: 48, Batch Gradient Norm after: 0.24991282152409114
Epoch 49/10000, Prediction Accuracy = 43.64999999999999%, Loss = 0.01803241612819525
Epoch: 49, Batch Gradient Norm: 0.2640764345207376
Epoch: 49, Batch Gradient Norm after: 0.2640764345207376
Epoch 50/10000, Prediction Accuracy = 43.91538461538461%, Loss = 0.01800542353437497
Epoch: 50, Batch Gradient Norm: 0.267464408916347
Epoch: 50, Batch Gradient Norm after: 0.267464408916347
Epoch 51/10000, Prediction Accuracy = 44.01538461538461%, Loss = 0.01796930942397851
Epoch: 51, Batch Gradient Norm: 0.28060030636159067
Epoch: 51, Batch Gradient Norm after: 0.28060030636159067
Epoch 52/10000, Prediction Accuracy = 44.11923076923077%, Loss = 0.017895809589670256
Epoch: 52, Batch Gradient Norm: 0.24390826486036515
Epoch: 52, Batch Gradient Norm after: 0.24390826486036515
Epoch 53/10000, Prediction Accuracy = 44.18076923076922%, Loss = 0.01782507191483791
Epoch: 53, Batch Gradient Norm: 0.25079110101222724
Epoch: 53, Batch Gradient Norm after: 0.25079110101222724
Epoch 54/10000, Prediction Accuracy = 44.44615384615385%, Loss = 0.017771177996809665
Epoch: 54, Batch Gradient Norm: 0.26542158972885643
Epoch: 54, Batch Gradient Norm after: 0.26542158972885643
Epoch 55/10000, Prediction Accuracy = 44.27307692307692%, Loss = 0.017741248154869445
Epoch: 55, Batch Gradient Norm: 0.27267954531701133
Epoch: 55, Batch Gradient Norm after: 0.27267954531701133
Epoch 56/10000, Prediction Accuracy = 43.896153846153844%, Loss = 0.017744853949317567
Epoch: 56, Batch Gradient Norm: 0.2710528932715367
Epoch: 56, Batch Gradient Norm after: 0.2710528932715367
Epoch 57/10000, Prediction Accuracy = 44.684615384615384%, Loss = 0.01767976782642878
Epoch: 57, Batch Gradient Norm: 0.26776789560621717
Epoch: 57, Batch Gradient Norm after: 0.26776789560621717
Epoch 58/10000, Prediction Accuracy = 44.72692307692307%, Loss = 0.017615434785301868
Epoch: 58, Batch Gradient Norm: 0.25328345186866774
Epoch: 58, Batch Gradient Norm after: 0.25328345186866774
Epoch 59/10000, Prediction Accuracy = 44.61923076923077%, Loss = 0.017545351615318887
Epoch: 59, Batch Gradient Norm: 0.26332392828524065
Epoch: 59, Batch Gradient Norm after: 0.26332392828524065
Epoch 60/10000, Prediction Accuracy = 44.87692307692308%, Loss = 0.01751222977271447
Epoch: 60, Batch Gradient Norm: 0.2646703148448543
Epoch: 60, Batch Gradient Norm after: 0.2646703148448543
Epoch 61/10000, Prediction Accuracy = 44.79615384615385%, Loss = 0.017407923936843872
Epoch: 61, Batch Gradient Norm: 0.29003123723887236
Epoch: 61, Batch Gradient Norm after: 0.29003123723887236
Epoch 62/10000, Prediction Accuracy = 44.79230769230769%, Loss = 0.017437264179954164
Epoch: 62, Batch Gradient Norm: 0.28293873526927643
Epoch: 62, Batch Gradient Norm after: 0.28293873526927643
Epoch 63/10000, Prediction Accuracy = 45.092307692307685%, Loss = 0.017394065427092407
Epoch: 63, Batch Gradient Norm: 0.2705754248553498
Epoch: 63, Batch Gradient Norm after: 0.2705754248553498
Epoch 64/10000, Prediction Accuracy = 45.11538461538461%, Loss = 0.017314532914986976
Epoch: 64, Batch Gradient Norm: 0.2938503256215441
Epoch: 64, Batch Gradient Norm after: 0.2938503256215441
Epoch 65/10000, Prediction Accuracy = 44.96923076923077%, Loss = 0.017318916148864306
Epoch: 65, Batch Gradient Norm: 0.29469989175308176
Epoch: 65, Batch Gradient Norm after: 0.29469989175308176
Epoch 66/10000, Prediction Accuracy = 45.28076923076924%, Loss = 0.01723495598595876
Epoch: 66, Batch Gradient Norm: 0.28955343311173576
Epoch: 66, Batch Gradient Norm after: 0.28955343311173576
Epoch 67/10000, Prediction Accuracy = 45.25769230769231%, Loss = 0.017221026552411225
Epoch: 67, Batch Gradient Norm: 0.2875713714266944
Epoch: 67, Batch Gradient Norm after: 0.2875713714266944
Epoch 68/10000, Prediction Accuracy = 45.457692307692305%, Loss = 0.017169213782136258
Epoch: 68, Batch Gradient Norm: 0.27209734519358775
Epoch: 68, Batch Gradient Norm after: 0.27209734519358775
Epoch 69/10000, Prediction Accuracy = 45.73461538461538%, Loss = 0.017127456573339608
Epoch: 69, Batch Gradient Norm: 0.2736821341431463
Epoch: 69, Batch Gradient Norm after: 0.2736821341431463
Epoch 70/10000, Prediction Accuracy = 45.56153846153846%, Loss = 0.017030504460518178
Epoch: 70, Batch Gradient Norm: 0.29522979063130383
Epoch: 70, Batch Gradient Norm after: 0.29522979063130383
Epoch 71/10000, Prediction Accuracy = 45.76538461538462%, Loss = 0.017045778007461473
Epoch: 71, Batch Gradient Norm: 0.2987033606077493
Epoch: 71, Batch Gradient Norm after: 0.2987033606077493
Epoch 72/10000, Prediction Accuracy = 45.723076923076924%, Loss = 0.01704365573823452
Epoch: 72, Batch Gradient Norm: 0.3053384738947003
Epoch: 72, Batch Gradient Norm after: 0.3053384738947003
Epoch 73/10000, Prediction Accuracy = 45.7%, Loss = 0.017018895596265793
Epoch: 73, Batch Gradient Norm: 0.2942669918542513
Epoch: 73, Batch Gradient Norm after: 0.2942669918542513
Epoch 74/10000, Prediction Accuracy = 45.73076923076923%, Loss = 0.016958186546197303
Epoch: 74, Batch Gradient Norm: 0.29615188001831766
Epoch: 74, Batch Gradient Norm after: 0.29615188001831766
Epoch 75/10000, Prediction Accuracy = 46.21923076923077%, Loss = 0.016842367127537727
Epoch: 75, Batch Gradient Norm: 0.3177908747477378
Epoch: 75, Batch Gradient Norm after: 0.3177908747477378
Epoch 76/10000, Prediction Accuracy = 46.05769230769231%, Loss = 0.016919139915933974
Epoch: 76, Batch Gradient Norm: 0.2952387111113855
Epoch: 76, Batch Gradient Norm after: 0.2952387111113855
Epoch 77/10000, Prediction Accuracy = 46.17692307692307%, Loss = 0.016791530813162144
Epoch: 77, Batch Gradient Norm: 0.2917213794993785
Epoch: 77, Batch Gradient Norm after: 0.2917213794993785
Epoch 78/10000, Prediction Accuracy = 46.03461538461538%, Loss = 0.01674868481663557
Epoch: 78, Batch Gradient Norm: 0.32470632011581835
Epoch: 78, Batch Gradient Norm after: 0.32470632011581835
Epoch 79/10000, Prediction Accuracy = 46.28461538461538%, Loss = 0.01680624012190562
Epoch: 79, Batch Gradient Norm: 0.31753951060313806
Epoch: 79, Batch Gradient Norm after: 0.31753951060313806
Epoch 80/10000, Prediction Accuracy = 46.36538461538461%, Loss = 0.016728324815630913
Epoch: 80, Batch Gradient Norm: 0.31873985697803553
Epoch: 80, Batch Gradient Norm after: 0.31873985697803553
Epoch 81/10000, Prediction Accuracy = 46.38461538461539%, Loss = 0.016673076468018386
Epoch: 81, Batch Gradient Norm: 0.3140010439453783
Epoch: 81, Batch Gradient Norm after: 0.3140010439453783
Epoch 82/10000, Prediction Accuracy = 46.61538461538461%, Loss = 0.016583825533206645
Epoch: 82, Batch Gradient Norm: 0.32551837520918697
Epoch: 82, Batch Gradient Norm after: 0.32551837520918697
Epoch 83/10000, Prediction Accuracy = 46.49230769230769%, Loss = 0.016638570393507298
Epoch: 83, Batch Gradient Norm: 0.32073421203282865
Epoch: 83, Batch Gradient Norm after: 0.32073421203282865
Epoch 84/10000, Prediction Accuracy = 46.76538461538462%, Loss = 0.01650334780032818
Epoch: 84, Batch Gradient Norm: 0.3348595860820388
Epoch: 84, Batch Gradient Norm after: 0.3348595860820388
Epoch 85/10000, Prediction Accuracy = 46.573076923076925%, Loss = 0.016551402755654775
Epoch: 85, Batch Gradient Norm: 0.3428784225569492
Epoch: 85, Batch Gradient Norm after: 0.3428784225569492
Epoch 86/10000, Prediction Accuracy = 46.54615384615385%, Loss = 0.016520444303750992
Epoch: 86, Batch Gradient Norm: 0.3279557764894628
Epoch: 86, Batch Gradient Norm after: 0.3279557764894628
Epoch 87/10000, Prediction Accuracy = 46.94230769230769%, Loss = 0.016449793313558284
Epoch: 87, Batch Gradient Norm: 0.3402253068310988
Epoch: 87, Batch Gradient Norm after: 0.3402253068310988
Epoch 88/10000, Prediction Accuracy = 46.75384615384615%, Loss = 0.016464533284306526
Epoch: 88, Batch Gradient Norm: 0.3534396853262352
Epoch: 88, Batch Gradient Norm after: 0.3534396853262352
Epoch 89/10000, Prediction Accuracy = 46.657692307692315%, Loss = 0.016438406247359056
Epoch: 89, Batch Gradient Norm: 0.3400796285936227
Epoch: 89, Batch Gradient Norm after: 0.3400796285936227
Epoch 90/10000, Prediction Accuracy = 47.00384615384615%, Loss = 0.016344745213595722
Epoch: 90, Batch Gradient Norm: 0.3601873786371462
Epoch: 90, Batch Gradient Norm after: 0.3601873786371462
Epoch 91/10000, Prediction Accuracy = 46.83846153846154%, Loss = 0.016370457525436696
Epoch: 91, Batch Gradient Norm: 0.3450678120226299
Epoch: 91, Batch Gradient Norm after: 0.3450678120226299
Epoch 92/10000, Prediction Accuracy = 47.146153846153844%, Loss = 0.016292824051701106
Epoch: 92, Batch Gradient Norm: 0.34334290740728046
Epoch: 92, Batch Gradient Norm after: 0.34334290740728046
Epoch 93/10000, Prediction Accuracy = 47.2%, Loss = 0.016241485396256812
Epoch: 93, Batch Gradient Norm: 0.33499421541683716
Epoch: 93, Batch Gradient Norm after: 0.33499421541683716
Epoch 94/10000, Prediction Accuracy = 47.41923076923077%, Loss = 0.016182796886334054
Epoch: 94, Batch Gradient Norm: 0.34776961562335085
Epoch: 94, Batch Gradient Norm after: 0.34776961562335085
Epoch 95/10000, Prediction Accuracy = 47.15384615384616%, Loss = 0.016166735153931838
Epoch: 95, Batch Gradient Norm: 0.35353290716946084
Epoch: 95, Batch Gradient Norm after: 0.35353290716946084
Epoch 96/10000, Prediction Accuracy = 47.2%, Loss = 0.016162324553498857
Epoch: 96, Batch Gradient Norm: 0.3830097927146123
Epoch: 96, Batch Gradient Norm after: 0.3830097927146123
Epoch 97/10000, Prediction Accuracy = 47.26538461538462%, Loss = 0.016154261879049815
Epoch: 97, Batch Gradient Norm: 0.363570637862607
Epoch: 97, Batch Gradient Norm after: 0.363570637862607
Epoch 98/10000, Prediction Accuracy = 47.157692307692315%, Loss = 0.016135204440126054
Epoch: 98, Batch Gradient Norm: 0.37292342144965024
Epoch: 98, Batch Gradient Norm after: 0.37292342144965024
Epoch 99/10000, Prediction Accuracy = 47.49615384615384%, Loss = 0.016106624227876846
Epoch: 99, Batch Gradient Norm: 0.39591698064559167
Epoch: 99, Batch Gradient Norm after: 0.39591698064559167
Epoch 100/10000, Prediction Accuracy = 47.56153846153846%, Loss = 0.01611229182722477
Epoch: 100, Batch Gradient Norm: 0.40007174244406984
Epoch: 100, Batch Gradient Norm after: 0.40007174244406984
Epoch 101/10000, Prediction Accuracy = 47.41538461538461%, Loss = 0.016044603660702705
Epoch: 101, Batch Gradient Norm: 0.3727000267331329
Epoch: 101, Batch Gradient Norm after: 0.3727000267331329
Epoch 102/10000, Prediction Accuracy = 47.68846153846154%, Loss = 0.015960160929423112
Epoch: 102, Batch Gradient Norm: 0.3880682332948985
Epoch: 102, Batch Gradient Norm after: 0.3880682332948985
Epoch 103/10000, Prediction Accuracy = 47.776923076923076%, Loss = 0.015975241406032674
Epoch: 103, Batch Gradient Norm: 0.398417042543879
Epoch: 103, Batch Gradient Norm after: 0.398417042543879
Epoch 104/10000, Prediction Accuracy = 47.76153846153846%, Loss = 0.01591622170347434
Epoch: 104, Batch Gradient Norm: 0.40319734771473204
Epoch: 104, Batch Gradient Norm after: 0.40319734771473204
Epoch 105/10000, Prediction Accuracy = 47.66923076923077%, Loss = 0.01587955582027252
Epoch: 105, Batch Gradient Norm: 0.3860211988864694
Epoch: 105, Batch Gradient Norm after: 0.3860211988864694
Epoch 106/10000, Prediction Accuracy = 47.94615384615384%, Loss = 0.015855498468646638
Epoch: 106, Batch Gradient Norm: 0.3825687796443569
Epoch: 106, Batch Gradient Norm after: 0.3825687796443569
Epoch 107/10000, Prediction Accuracy = 48.323076923076925%, Loss = 0.01580101581147084
Epoch: 107, Batch Gradient Norm: 0.37999768121166777
Epoch: 107, Batch Gradient Norm after: 0.37999768121166777
Epoch 108/10000, Prediction Accuracy = 48.065384615384616%, Loss = 0.015772834062003173
Epoch: 108, Batch Gradient Norm: 0.3649268347204923
Epoch: 108, Batch Gradient Norm after: 0.3649268347204923
Epoch 109/10000, Prediction Accuracy = 48.42307692307692%, Loss = 0.015674224553199913
Epoch: 109, Batch Gradient Norm: 0.3864293785991938
Epoch: 109, Batch Gradient Norm after: 0.3864293785991938
Epoch 110/10000, Prediction Accuracy = 47.911538461538456%, Loss = 0.015733488118992403
Epoch: 110, Batch Gradient Norm: 0.43196956878974324
Epoch: 110, Batch Gradient Norm after: 0.43196956878974324
Epoch 111/10000, Prediction Accuracy = 48.05384615384615%, Loss = 0.01577754898999746
Epoch: 111, Batch Gradient Norm: 0.40588530034240716
Epoch: 111, Batch Gradient Norm after: 0.40588530034240716
Epoch 112/10000, Prediction Accuracy = 48.11153846153846%, Loss = 0.015647256173766576
Epoch: 112, Batch Gradient Norm: 0.38106777731088787
Epoch: 112, Batch Gradient Norm after: 0.38106777731088787
Epoch 113/10000, Prediction Accuracy = 48.53846153846155%, Loss = 0.015595526434481144
Epoch: 113, Batch Gradient Norm: 0.42945580226087676
Epoch: 113, Batch Gradient Norm after: 0.42945580226087676
Epoch 114/10000, Prediction Accuracy = 48.33461538461539%, Loss = 0.015602360049692484
Epoch: 114, Batch Gradient Norm: 0.4353857083694421
Epoch: 114, Batch Gradient Norm after: 0.4353857083694421
Epoch 115/10000, Prediction Accuracy = 48.35769230769232%, Loss = 0.015565139026595997
Epoch: 115, Batch Gradient Norm: 0.43706372622489503
Epoch: 115, Batch Gradient Norm after: 0.43706372622489503
Epoch 116/10000, Prediction Accuracy = 48.46153846153847%, Loss = 0.015584908067606963
Epoch: 116, Batch Gradient Norm: 0.4073473172173283
Epoch: 116, Batch Gradient Norm after: 0.4073473172173283
Epoch 117/10000, Prediction Accuracy = 48.619230769230775%, Loss = 0.015478750260976644
Epoch: 117, Batch Gradient Norm: 0.43683641478876023
Epoch: 117, Batch Gradient Norm after: 0.43683641478876023
Epoch 118/10000, Prediction Accuracy = 48.43846153846154%, Loss = 0.01549956238327118
Epoch: 118, Batch Gradient Norm: 0.43877567493883896
Epoch: 118, Batch Gradient Norm after: 0.43877567493883896
Epoch 119/10000, Prediction Accuracy = 48.56153846153846%, Loss = 0.015461281586724978
Epoch: 119, Batch Gradient Norm: 0.440377007916932
Epoch: 119, Batch Gradient Norm after: 0.440377007916932
Epoch 120/10000, Prediction Accuracy = 48.32692307692308%, Loss = 0.015489409391123515
Epoch: 120, Batch Gradient Norm: 0.4136472570099892
Epoch: 120, Batch Gradient Norm after: 0.4136472570099892
Epoch 121/10000, Prediction Accuracy = 48.965384615384615%, Loss = 0.015367054380476475
Epoch: 121, Batch Gradient Norm: 0.4153134839949755
Epoch: 121, Batch Gradient Norm after: 0.4153134839949755
Epoch 122/10000, Prediction Accuracy = 48.78846153846154%, Loss = 0.015339234055807957
Epoch: 122, Batch Gradient Norm: 0.40745901461679723
Epoch: 122, Batch Gradient Norm after: 0.40745901461679723
Epoch 123/10000, Prediction Accuracy = 49.080769230769235%, Loss = 0.015273139597131656
Epoch: 123, Batch Gradient Norm: 0.4725893772750663
Epoch: 123, Batch Gradient Norm after: 0.4725893772750663
Epoch 124/10000, Prediction Accuracy = 48.71153846153847%, Loss = 0.015315204070737729
Epoch: 124, Batch Gradient Norm: 0.4982252087628425
Epoch: 124, Batch Gradient Norm after: 0.4982252087628425
Epoch 125/10000, Prediction Accuracy = 48.3076923076923%, Loss = 0.015330487718948951
Epoch: 125, Batch Gradient Norm: 0.4835238925261864
Epoch: 125, Batch Gradient Norm after: 0.4835238925261864
Epoch 126/10000, Prediction Accuracy = 48.934615384615384%, Loss = 0.015313229308678554
Epoch: 126, Batch Gradient Norm: 0.43370774915736626
Epoch: 126, Batch Gradient Norm after: 0.43370774915736626
Epoch 127/10000, Prediction Accuracy = 49.1923076923077%, Loss = 0.01517517463519023
Epoch: 127, Batch Gradient Norm: 0.43705755197375556
Epoch: 127, Batch Gradient Norm after: 0.43705755197375556
Epoch 128/10000, Prediction Accuracy = 49.04230769230768%, Loss = 0.015198989986227108
Epoch: 128, Batch Gradient Norm: 0.4611179792144322
Epoch: 128, Batch Gradient Norm after: 0.4611179792144322
Epoch 129/10000, Prediction Accuracy = 49.21538461538462%, Loss = 0.015190051725277534
Epoch: 129, Batch Gradient Norm: 0.4879195714981538
Epoch: 129, Batch Gradient Norm after: 0.4879195714981538
Epoch 130/10000, Prediction Accuracy = 48.765384615384626%, Loss = 0.015239543854617156
Epoch: 130, Batch Gradient Norm: 0.4970103812103291
Epoch: 130, Batch Gradient Norm after: 0.4970103812103291
Epoch 131/10000, Prediction Accuracy = 48.94615384615384%, Loss = 0.015267510396929888
Epoch: 131, Batch Gradient Norm: 0.47418204892239224
Epoch: 131, Batch Gradient Norm after: 0.47418204892239224
Epoch 132/10000, Prediction Accuracy = 49.23846153846154%, Loss = 0.015068826193992909
Epoch: 132, Batch Gradient Norm: 0.45306286558625614
Epoch: 132, Batch Gradient Norm after: 0.45306286558625614
Epoch 133/10000, Prediction Accuracy = 49.449999999999996%, Loss = 0.01500597925713429
Epoch: 133, Batch Gradient Norm: 0.4852533180501282
Epoch: 133, Batch Gradient Norm after: 0.4852533180501282
Epoch 134/10000, Prediction Accuracy = 49.31153846153846%, Loss = 0.015012750617013527
Epoch: 134, Batch Gradient Norm: 0.5076607191283901
Epoch: 134, Batch Gradient Norm after: 0.5076607191283901
Epoch 135/10000, Prediction Accuracy = 49.650000000000006%, Loss = 0.01506609906657384
Epoch: 135, Batch Gradient Norm: 0.466375784077154
Epoch: 135, Batch Gradient Norm after: 0.466375784077154
Epoch 136/10000, Prediction Accuracy = 49.64999999999999%, Loss = 0.014956088808293525
Epoch: 136, Batch Gradient Norm: 0.4954351845312486
Epoch: 136, Batch Gradient Norm after: 0.4954351845312486
Epoch 137/10000, Prediction Accuracy = 49.94615384615384%, Loss = 0.014934182668534609
Epoch: 137, Batch Gradient Norm: 0.4698984202713428
Epoch: 137, Batch Gradient Norm after: 0.4698984202713428
Epoch 138/10000, Prediction Accuracy = 49.58076923076922%, Loss = 0.014907920016692234
Epoch: 138, Batch Gradient Norm: 0.5205741365621491
Epoch: 138, Batch Gradient Norm after: 0.5205741365621491
Epoch 139/10000, Prediction Accuracy = 49.68846153846154%, Loss = 0.014943678218584795
Epoch: 139, Batch Gradient Norm: 0.5098220416119625
Epoch: 139, Batch Gradient Norm after: 0.5098220416119625
Epoch 140/10000, Prediction Accuracy = 49.45384615384615%, Loss = 0.014908461115108086
Epoch: 140, Batch Gradient Norm: 0.5755304043484365
Epoch: 140, Batch Gradient Norm after: 0.5755304043484365
Epoch 141/10000, Prediction Accuracy = 49.08846153846154%, Loss = 0.014986392612067552
Epoch: 141, Batch Gradient Norm: 0.5297108290214032
Epoch: 141, Batch Gradient Norm after: 0.5297108290214032
Epoch 142/10000, Prediction Accuracy = 49.7576923076923%, Loss = 0.014856390225199552
Epoch: 142, Batch Gradient Norm: 0.5093050614103023
Epoch: 142, Batch Gradient Norm after: 0.5093050614103023
Epoch 143/10000, Prediction Accuracy = 49.78846153846154%, Loss = 0.014816798484669281
Epoch: 143, Batch Gradient Norm: 0.48996398827663007
Epoch: 143, Batch Gradient Norm after: 0.48996398827663007
Epoch 144/10000, Prediction Accuracy = 50.26538461538461%, Loss = 0.014680722226890234
Epoch: 144, Batch Gradient Norm: 0.5481526635983901
Epoch: 144, Batch Gradient Norm after: 0.5481526635983901
Epoch 145/10000, Prediction Accuracy = 50.24230769230769%, Loss = 0.014753825246141506
Epoch: 145, Batch Gradient Norm: 0.548075767156017
Epoch: 145, Batch Gradient Norm after: 0.548075767156017
Epoch 146/10000, Prediction Accuracy = 50.05384615384614%, Loss = 0.014778614975512028
Epoch: 146, Batch Gradient Norm: 0.5947361907982776
Epoch: 146, Batch Gradient Norm after: 0.5947361907982776
Epoch 147/10000, Prediction Accuracy = 49.63846153846154%, Loss = 0.014790583330278214
Epoch: 147, Batch Gradient Norm: 0.6048070645786482
Epoch: 147, Batch Gradient Norm after: 0.6048070645786482
Epoch 148/10000, Prediction Accuracy = 49.93461538461539%, Loss = 0.014786972162815241
Epoch: 148, Batch Gradient Norm: 0.5527254291984337
Epoch: 148, Batch Gradient Norm after: 0.5527254291984337
Epoch 149/10000, Prediction Accuracy = 50.20000000000001%, Loss = 0.014688455642989049
Epoch: 149, Batch Gradient Norm: 0.542390290093461
Epoch: 149, Batch Gradient Norm after: 0.542390290093461
Epoch 150/10000, Prediction Accuracy = 50.19615384615384%, Loss = 0.014620712958276272
Epoch: 150, Batch Gradient Norm: 0.5430471549467737
Epoch: 150, Batch Gradient Norm after: 0.5430471549467737
Epoch 151/10000, Prediction Accuracy = 50.00769230769231%, Loss = 0.014594708927548848
Epoch: 151, Batch Gradient Norm: 0.5222546622882663
Epoch: 151, Batch Gradient Norm after: 0.5222546622882663
Epoch 152/10000, Prediction Accuracy = 50.23076923076923%, Loss = 0.014529489983732883
Epoch: 152, Batch Gradient Norm: 0.585948396866757
Epoch: 152, Batch Gradient Norm after: 0.585948396866757
Epoch 153/10000, Prediction Accuracy = 50.30769230769231%, Loss = 0.014549283740612177
Epoch: 153, Batch Gradient Norm: 0.5913427551307657
Epoch: 153, Batch Gradient Norm after: 0.5913427551307657
Epoch 154/10000, Prediction Accuracy = 50.08076923076923%, Loss = 0.014571868456326999
Epoch: 154, Batch Gradient Norm: 0.6107018877748918
Epoch: 154, Batch Gradient Norm after: 0.6107018877748918
Epoch 155/10000, Prediction Accuracy = 50.369230769230775%, Loss = 0.014595493387717467
Epoch: 155, Batch Gradient Norm: 0.5652288100865728
Epoch: 155, Batch Gradient Norm after: 0.5652288100865728
Epoch 156/10000, Prediction Accuracy = 50.715384615384615%, Loss = 0.014493240115161125
Epoch: 156, Batch Gradient Norm: 0.6336675965332805
Epoch: 156, Batch Gradient Norm after: 0.6336675965332805
Epoch 157/10000, Prediction Accuracy = 50.40384615384615%, Loss = 0.014583776203485636
Epoch: 157, Batch Gradient Norm: 0.601760970824963
Epoch: 157, Batch Gradient Norm after: 0.601760970824963
Epoch 158/10000, Prediction Accuracy = 50.3346153846154%, Loss = 0.014506755253443351
Epoch: 158, Batch Gradient Norm: 0.6176764053509343
Epoch: 158, Batch Gradient Norm after: 0.6176764053509343
Epoch 159/10000, Prediction Accuracy = 50.396153846153844%, Loss = 0.014446413645950647
Epoch: 159, Batch Gradient Norm: 0.6027617554182925
Epoch: 159, Batch Gradient Norm after: 0.6027617554182925
Epoch 160/10000, Prediction Accuracy = 51.03076923076923%, Loss = 0.014376315431526074
Epoch: 160, Batch Gradient Norm: 0.6319637757348894
Epoch: 160, Batch Gradient Norm after: 0.6319637757348894
Epoch 161/10000, Prediction Accuracy = 50.66153846153847%, Loss = 0.01446646244193499
Epoch: 161, Batch Gradient Norm: 0.6646641202492298
Epoch: 161, Batch Gradient Norm after: 0.6646641202492298
Epoch 162/10000, Prediction Accuracy = 50.2576923076923%, Loss = 0.014486684965399595
Epoch: 162, Batch Gradient Norm: 0.600759007229836
Epoch: 162, Batch Gradient Norm after: 0.600759007229836
Epoch 163/10000, Prediction Accuracy = 50.73846153846153%, Loss = 0.014375684782862663
Epoch: 163, Batch Gradient Norm: 0.557772816200809
Epoch: 163, Batch Gradient Norm after: 0.557772816200809
Epoch 164/10000, Prediction Accuracy = 51.026923076923076%, Loss = 0.014263160383472076
Epoch: 164, Batch Gradient Norm: 0.5971216737685535
Epoch: 164, Batch Gradient Norm after: 0.5971216737685535
Epoch 165/10000, Prediction Accuracy = 50.86923076923077%, Loss = 0.014234074892906042
Epoch: 165, Batch Gradient Norm: 0.6445114188381754
Epoch: 165, Batch Gradient Norm after: 0.6445114188381754
Epoch 166/10000, Prediction Accuracy = 51.06153846153846%, Loss = 0.01434701236967857
Epoch: 166, Batch Gradient Norm: 0.609162733727917
Epoch: 166, Batch Gradient Norm after: 0.609162733727917
Epoch 167/10000, Prediction Accuracy = 51.24615384615384%, Loss = 0.014267502137674736
Epoch: 167, Batch Gradient Norm: 0.5933935311794741
Epoch: 167, Batch Gradient Norm after: 0.5933935311794741
Epoch 168/10000, Prediction Accuracy = 50.89615384615384%, Loss = 0.014202958832566556
Epoch: 168, Batch Gradient Norm: 0.6483810105443644
Epoch: 168, Batch Gradient Norm after: 0.6483810105443644
Epoch 169/10000, Prediction Accuracy = 50.98846153846153%, Loss = 0.014180218800902367
Epoch: 169, Batch Gradient Norm: 0.6418196731081698
Epoch: 169, Batch Gradient Norm after: 0.6418196731081698
Epoch 170/10000, Prediction Accuracy = 51.04230769230769%, Loss = 0.01419984706892417
Epoch: 170, Batch Gradient Norm: 0.6280724479000056
Epoch: 170, Batch Gradient Norm after: 0.6280724479000056
Epoch 171/10000, Prediction Accuracy = 51.15384615384615%, Loss = 0.014168949296268133
Epoch: 171, Batch Gradient Norm: 0.5986384308801166
Epoch: 171, Batch Gradient Norm after: 0.5986384308801166
Epoch 172/10000, Prediction Accuracy = 51.088461538461544%, Loss = 0.014122783922805237
Epoch: 172, Batch Gradient Norm: 0.617045707105844
Epoch: 172, Batch Gradient Norm after: 0.617045707105844
Epoch 173/10000, Prediction Accuracy = 51.23846153846154%, Loss = 0.014071537325015435
Epoch: 173, Batch Gradient Norm: 0.6113550390177565
Epoch: 173, Batch Gradient Norm after: 0.6113550390177565
Epoch 174/10000, Prediction Accuracy = 51.54230769230768%, Loss = 0.014027381888948955
Epoch: 174, Batch Gradient Norm: 0.5979393185334692
Epoch: 174, Batch Gradient Norm after: 0.5979393185334692
Epoch 175/10000, Prediction Accuracy = 51.51538461538462%, Loss = 0.013960277733321372
Epoch: 175, Batch Gradient Norm: 0.6244479330874962
Epoch: 175, Batch Gradient Norm after: 0.6244479330874962
Epoch 176/10000, Prediction Accuracy = 51.55384615384616%, Loss = 0.014007903993702851
Epoch: 176, Batch Gradient Norm: 0.664232732031049
Epoch: 176, Batch Gradient Norm after: 0.664232732031049
Epoch 177/10000, Prediction Accuracy = 51.2423076923077%, Loss = 0.014006771218891326
Epoch: 177, Batch Gradient Norm: 0.6821601573163397
Epoch: 177, Batch Gradient Norm after: 0.6821601573163397
Epoch 178/10000, Prediction Accuracy = 51.31153846153846%, Loss = 0.014077464476800881
Epoch: 178, Batch Gradient Norm: 0.6293348179325654
Epoch: 178, Batch Gradient Norm after: 0.6293348179325654
Epoch 179/10000, Prediction Accuracy = 51.642307692307696%, Loss = 0.013983265783351202
Epoch: 179, Batch Gradient Norm: 0.6546214437380274
Epoch: 179, Batch Gradient Norm after: 0.6546214437380274
Epoch 180/10000, Prediction Accuracy = 51.61153846153846%, Loss = 0.013917466267370261
Epoch: 180, Batch Gradient Norm: 0.6400332304913721
Epoch: 180, Batch Gradient Norm after: 0.6400332304913721
Epoch 181/10000, Prediction Accuracy = 51.75769230769231%, Loss = 0.013867353447354756
Epoch: 181, Batch Gradient Norm: 0.6582197537146743
Epoch: 181, Batch Gradient Norm after: 0.6582197537146743
Epoch 182/10000, Prediction Accuracy = 51.81923076923077%, Loss = 0.013862590233866986
Epoch: 182, Batch Gradient Norm: 0.626261754320062
Epoch: 182, Batch Gradient Norm after: 0.626261754320062
Epoch 183/10000, Prediction Accuracy = 51.58846153846153%, Loss = 0.013853464275598526
Epoch: 183, Batch Gradient Norm: 0.6760116225158468
Epoch: 183, Batch Gradient Norm after: 0.6760116225158468
Epoch 184/10000, Prediction Accuracy = 51.638461538461556%, Loss = 0.01386013963761238
Epoch: 184, Batch Gradient Norm: 0.6657178431261266
Epoch: 184, Batch Gradient Norm after: 0.6657178431261266
Epoch 185/10000, Prediction Accuracy = 52.06153846153845%, Loss = 0.013807457012052719
Epoch: 185, Batch Gradient Norm: 0.6636938499401934
Epoch: 185, Batch Gradient Norm after: 0.6636938499401934
Epoch 186/10000, Prediction Accuracy = 51.75%, Loss = 0.01377081971328992
Epoch: 186, Batch Gradient Norm: 0.6626066729930863
Epoch: 186, Batch Gradient Norm after: 0.6626066729930863
Epoch 187/10000, Prediction Accuracy = 51.59615384615385%, Loss = 0.01374915256523169
Epoch: 187, Batch Gradient Norm: 0.7370884421657962
Epoch: 187, Batch Gradient Norm after: 0.7370884421657962
Epoch 188/10000, Prediction Accuracy = 51.53076923076924%, Loss = 0.013843070214184431
Epoch: 188, Batch Gradient Norm: 0.7257705617439489
Epoch: 188, Batch Gradient Norm after: 0.7257705617439489
Epoch 189/10000, Prediction Accuracy = 52.06923076923077%, Loss = 0.013821536030333776
Epoch: 189, Batch Gradient Norm: 0.685915247090053
Epoch: 189, Batch Gradient Norm after: 0.685915247090053
Epoch 190/10000, Prediction Accuracy = 51.8923076923077%, Loss = 0.013753686028604325
Epoch: 190, Batch Gradient Norm: 0.702036012208317
Epoch: 190, Batch Gradient Norm after: 0.702036012208317
Epoch 191/10000, Prediction Accuracy = 51.76923076923078%, Loss = 0.013725342300648872
Epoch: 191, Batch Gradient Norm: 0.6731926874564881
Epoch: 191, Batch Gradient Norm after: 0.6731926874564881
Epoch 192/10000, Prediction Accuracy = 52.169230769230765%, Loss = 0.013645963098567266
Epoch: 192, Batch Gradient Norm: 0.7285707634152915
Epoch: 192, Batch Gradient Norm after: 0.7285707634152915
Epoch 193/10000, Prediction Accuracy = 52.18461538461538%, Loss = 0.013639440401815452
Epoch: 193, Batch Gradient Norm: 0.7329896363829693
Epoch: 193, Batch Gradient Norm after: 0.7329896363829693
Epoch 194/10000, Prediction Accuracy = 52.39615384615384%, Loss = 0.013662970911424894
Epoch: 194, Batch Gradient Norm: 0.7365697243038313
Epoch: 194, Batch Gradient Norm after: 0.7365697243038313
Epoch 195/10000, Prediction Accuracy = 51.96153846153847%, Loss = 0.013710399731420554
Epoch: 195, Batch Gradient Norm: 0.673915365934329
Epoch: 195, Batch Gradient Norm after: 0.673915365934329
Epoch 196/10000, Prediction Accuracy = 52.29230769230769%, Loss = 0.013579527345987467
Epoch: 196, Batch Gradient Norm: 0.7807122439077988
Epoch: 196, Batch Gradient Norm after: 0.7807122439077988
Epoch 197/10000, Prediction Accuracy = 51.94615384615385%, Loss = 0.013676702689666014
Epoch: 197, Batch Gradient Norm: 0.7787144753891847
Epoch: 197, Batch Gradient Norm after: 0.7787144753891847
Epoch 198/10000, Prediction Accuracy = 52.31923076923078%, Loss = 0.01366553448427182
Epoch: 198, Batch Gradient Norm: 0.8202105085446976
Epoch: 198, Batch Gradient Norm after: 0.8202105085446976
Epoch 199/10000, Prediction Accuracy = 51.72692307692308%, Loss = 0.013672235708397169
Epoch: 199, Batch Gradient Norm: 0.8093643672654202
Epoch: 199, Batch Gradient Norm after: 0.8093643672654202
Epoch 200/10000, Prediction Accuracy = 51.99615384615384%, Loss = 0.013675096802986585
Epoch: 200, Batch Gradient Norm: 0.7840828389835531
Epoch: 200, Batch Gradient Norm after: 0.7840828389835531
Epoch 201/10000, Prediction Accuracy = 52.60769230769232%, Loss = 0.01351205288217618
Epoch: 201, Batch Gradient Norm: 0.7473039936849972
Epoch: 201, Batch Gradient Norm after: 0.7473039936849972
Epoch 202/10000, Prediction Accuracy = 52.5076923076923%, Loss = 0.013522172561631752
Epoch: 202, Batch Gradient Norm: 0.7461402506801916
Epoch: 202, Batch Gradient Norm after: 0.7461402506801916
Epoch 203/10000, Prediction Accuracy = 52.8%, Loss = 0.013509165352353683
Epoch: 203, Batch Gradient Norm: 0.751306873682994
Epoch: 203, Batch Gradient Norm after: 0.751306873682994
Epoch 204/10000, Prediction Accuracy = 52.46538461538463%, Loss = 0.013522505187071286
Epoch: 204, Batch Gradient Norm: 0.7514467606644933
Epoch: 204, Batch Gradient Norm after: 0.7514467606644933
Epoch 205/10000, Prediction Accuracy = 52.45384615384616%, Loss = 0.013395887226439439
Epoch: 205, Batch Gradient Norm: 0.7807945422124386
Epoch: 205, Batch Gradient Norm after: 0.7807945422124386
Epoch 206/10000, Prediction Accuracy = 52.80769230769231%, Loss = 0.013431054826539297
Epoch: 206, Batch Gradient Norm: 0.7481754913269872
Epoch: 206, Batch Gradient Norm after: 0.7481754913269872
Epoch 207/10000, Prediction Accuracy = 52.834615384615375%, Loss = 0.013357782593140235
Epoch: 207, Batch Gradient Norm: 0.74457911792837
Epoch: 207, Batch Gradient Norm after: 0.74457911792837
Epoch 208/10000, Prediction Accuracy = 52.67307692307692%, Loss = 0.013344427785621239
Epoch: 208, Batch Gradient Norm: 0.7135728195922602
Epoch: 208, Batch Gradient Norm after: 0.7135728195922602
Epoch 209/10000, Prediction Accuracy = 52.95384615384616%, Loss = 0.013249587697478441
Epoch: 209, Batch Gradient Norm: 0.7681022124974412
Epoch: 209, Batch Gradient Norm after: 0.7681022124974412
Epoch 210/10000, Prediction Accuracy = 53.06923076923077%, Loss = 0.013293429636038266
Epoch: 210, Batch Gradient Norm: 0.7830722670295711
Epoch: 210, Batch Gradient Norm after: 0.7830722670295711
Epoch 211/10000, Prediction Accuracy = 52.46923076923077%, Loss = 0.01330727174018438
Epoch: 211, Batch Gradient Norm: 0.7590209417098644
Epoch: 211, Batch Gradient Norm after: 0.7590209417098644
Epoch 212/10000, Prediction Accuracy = 52.74230769230769%, Loss = 0.013286907512408037
Epoch: 212, Batch Gradient Norm: 0.8199975456102457
Epoch: 212, Batch Gradient Norm after: 0.8199975456102457
Epoch 213/10000, Prediction Accuracy = 52.4423076923077%, Loss = 0.013373557908030657
Epoch: 213, Batch Gradient Norm: 0.7593313847745441
Epoch: 213, Batch Gradient Norm after: 0.7593313847745441
Epoch 214/10000, Prediction Accuracy = 53.08846153846154%, Loss = 0.013222746837597627
Epoch: 214, Batch Gradient Norm: 0.76384713446671
Epoch: 214, Batch Gradient Norm after: 0.76384713446671
Epoch 215/10000, Prediction Accuracy = 52.87692307692308%, Loss = 0.013188777992931696
Epoch: 215, Batch Gradient Norm: 0.7693763463664356
Epoch: 215, Batch Gradient Norm after: 0.7693763463664356
Epoch 216/10000, Prediction Accuracy = 53.11538461538461%, Loss = 0.013124351318065938
Epoch: 216, Batch Gradient Norm: 0.7460903404806475
Epoch: 216, Batch Gradient Norm after: 0.7460903404806475
Epoch 217/10000, Prediction Accuracy = 53.130769230769225%, Loss = 0.013145196538131971
Epoch: 217, Batch Gradient Norm: 0.8076843372510124
Epoch: 217, Batch Gradient Norm after: 0.8076843372510124
Epoch 218/10000, Prediction Accuracy = 53.11538461538461%, Loss = 0.013170195671801384
Epoch: 218, Batch Gradient Norm: 0.8527400012557655
Epoch: 218, Batch Gradient Norm after: 0.8527400012557655
Epoch 219/10000, Prediction Accuracy = 53.29615384615384%, Loss = 0.013193420635966154
Epoch: 219, Batch Gradient Norm: 0.8357934679579154
Epoch: 219, Batch Gradient Norm after: 0.8357934679579154
Epoch 220/10000, Prediction Accuracy = 52.97307692307693%, Loss = 0.013158223663385097
Epoch: 220, Batch Gradient Norm: 0.7645314032782597
Epoch: 220, Batch Gradient Norm after: 0.7645314032782597
Epoch 221/10000, Prediction Accuracy = 53.130769230769225%, Loss = 0.013088508079258295
Epoch: 221, Batch Gradient Norm: 0.7720476992213323
Epoch: 221, Batch Gradient Norm after: 0.7720476992213323
Epoch 222/10000, Prediction Accuracy = 53.33076923076923%, Loss = 0.013106312602758408
Epoch: 222, Batch Gradient Norm: 0.8232253914300159
Epoch: 222, Batch Gradient Norm after: 0.8232253914300159
Epoch 223/10000, Prediction Accuracy = 53.28846153846154%, Loss = 0.01313236398765674
Epoch: 223, Batch Gradient Norm: 0.8148176044716954
Epoch: 223, Batch Gradient Norm after: 0.8148176044716954
Epoch 224/10000, Prediction Accuracy = 53.11923076923077%, Loss = 0.013066314519024812
Epoch: 224, Batch Gradient Norm: 0.8001671946231775
Epoch: 224, Batch Gradient Norm after: 0.8001671946231775
Epoch 225/10000, Prediction Accuracy = 53.51538461538461%, Loss = 0.013027968171697397
Epoch: 225, Batch Gradient Norm: 0.8215496418749321
Epoch: 225, Batch Gradient Norm after: 0.8215496418749321
Epoch 226/10000, Prediction Accuracy = 53.396153846153844%, Loss = 0.012979446050639335
Epoch: 226, Batch Gradient Norm: 0.8203590877302263
Epoch: 226, Batch Gradient Norm after: 0.8203590877302263
Epoch 227/10000, Prediction Accuracy = 53.40384615384615%, Loss = 0.012981621333612846
Epoch: 227, Batch Gradient Norm: 0.8793568629194564
Epoch: 227, Batch Gradient Norm after: 0.8793568629194564
Epoch 228/10000, Prediction Accuracy = 53.43846153846153%, Loss = 0.013066355139017105
Epoch: 228, Batch Gradient Norm: 0.7872310603794327
Epoch: 228, Batch Gradient Norm after: 0.7872310603794327
Epoch 229/10000, Prediction Accuracy = 53.5923076923077%, Loss = 0.012922402614584336
Epoch: 229, Batch Gradient Norm: 0.8251579479313403
Epoch: 229, Batch Gradient Norm after: 0.8251579479313403
Epoch 230/10000, Prediction Accuracy = 53.630769230769225%, Loss = 0.012955983455937643
Epoch: 230, Batch Gradient Norm: 0.9158074512975972
Epoch: 230, Batch Gradient Norm after: 0.9158074512975972
Epoch 231/10000, Prediction Accuracy = 53.78076923076924%, Loss = 0.013023984117003588
Epoch: 231, Batch Gradient Norm: 0.8694820683252574
Epoch: 231, Batch Gradient Norm after: 0.8694820683252574
Epoch 232/10000, Prediction Accuracy = 53.38846153846154%, Loss = 0.01298042365278189
Epoch: 232, Batch Gradient Norm: 0.9227619098944273
Epoch: 232, Batch Gradient Norm after: 0.9227619098944273
Epoch 233/10000, Prediction Accuracy = 53.65384615384616%, Loss = 0.013002305291593075
Epoch: 233, Batch Gradient Norm: 0.8398229075860233
Epoch: 233, Batch Gradient Norm after: 0.8398229075860233
Epoch 234/10000, Prediction Accuracy = 53.849999999999994%, Loss = 0.012941195342976313
Epoch: 234, Batch Gradient Norm: 0.8327718606988181
Epoch: 234, Batch Gradient Norm after: 0.8327718606988181
Epoch 235/10000, Prediction Accuracy = 53.78846153846154%, Loss = 0.012856836932209821
Epoch: 235, Batch Gradient Norm: 0.863341558429945
Epoch: 235, Batch Gradient Norm after: 0.863341558429945
Epoch 236/10000, Prediction Accuracy = 53.2%, Loss = 0.012888740891447434
Epoch: 236, Batch Gradient Norm: 0.8692906944742986
Epoch: 236, Batch Gradient Norm after: 0.8692906944742986
Epoch 237/10000, Prediction Accuracy = 53.776923076923076%, Loss = 0.012816075808726825
Epoch: 237, Batch Gradient Norm: 0.8948451822511823
Epoch: 237, Batch Gradient Norm after: 0.8948451822511823
Epoch 238/10000, Prediction Accuracy = 53.56153846153846%, Loss = 0.012858521121625718
Epoch: 238, Batch Gradient Norm: 0.8615897032915073
Epoch: 238, Batch Gradient Norm after: 0.8615897032915073
Epoch 239/10000, Prediction Accuracy = 53.79615384615385%, Loss = 0.012816692989033002
Epoch: 239, Batch Gradient Norm: 0.856607943512963
Epoch: 239, Batch Gradient Norm after: 0.856607943512963
Epoch 240/10000, Prediction Accuracy = 53.60000000000001%, Loss = 0.01277305450863563
Epoch: 240, Batch Gradient Norm: 0.9315859817077685
Epoch: 240, Batch Gradient Norm after: 0.9315859817077685
Epoch 241/10000, Prediction Accuracy = 53.565384615384616%, Loss = 0.012900669342623306
Epoch: 241, Batch Gradient Norm: 0.9185169285790798
Epoch: 241, Batch Gradient Norm after: 0.9185169285790798
Epoch 242/10000, Prediction Accuracy = 53.44615384615384%, Loss = 0.012923219097921481
Epoch: 242, Batch Gradient Norm: 0.8550381137837875
Epoch: 242, Batch Gradient Norm after: 0.8550381137837875
Epoch 243/10000, Prediction Accuracy = 54.00384615384615%, Loss = 0.012705486411085496
Epoch: 243, Batch Gradient Norm: 0.8898615786429785
Epoch: 243, Batch Gradient Norm after: 0.8898615786429785
Epoch 244/10000, Prediction Accuracy = 53.77307692307693%, Loss = 0.012730382597790314
Epoch: 244, Batch Gradient Norm: 0.9234678225879415
Epoch: 244, Batch Gradient Norm after: 0.9234678225879415
Epoch 245/10000, Prediction Accuracy = 53.75%, Loss = 0.01276874176871318
Epoch: 245, Batch Gradient Norm: 0.8817949603010757
Epoch: 245, Batch Gradient Norm after: 0.8817949603010757
Epoch 246/10000, Prediction Accuracy = 54.20384615384616%, Loss = 0.012670777308253141
Epoch: 246, Batch Gradient Norm: 0.8609011228461467
Epoch: 246, Batch Gradient Norm after: 0.8609011228461467
Epoch 247/10000, Prediction Accuracy = 54.08076923076923%, Loss = 0.01263652777729126
Epoch: 247, Batch Gradient Norm: 0.8777433697332477
Epoch: 247, Batch Gradient Norm after: 0.8777433697332477
Epoch 248/10000, Prediction Accuracy = 54.23461538461538%, Loss = 0.012695739403940164
Epoch: 248, Batch Gradient Norm: 0.9458104556351407
Epoch: 248, Batch Gradient Norm after: 0.9458104556351407
Epoch 249/10000, Prediction Accuracy = 53.723076923076924%, Loss = 0.012763907917990135
Epoch: 249, Batch Gradient Norm: 0.9351846708883252
Epoch: 249, Batch Gradient Norm after: 0.9351846708883252
Epoch 250/10000, Prediction Accuracy = 54.2153846153846%, Loss = 0.01266403954762679
Epoch: 250, Batch Gradient Norm: 0.9325944436457215
Epoch: 250, Batch Gradient Norm after: 0.9325944436457215
Epoch 251/10000, Prediction Accuracy = 54.51923076923077%, Loss = 0.012602439866616176
Epoch: 251, Batch Gradient Norm: 0.8782827660198228
Epoch: 251, Batch Gradient Norm after: 0.8782827660198228
Epoch 252/10000, Prediction Accuracy = 54.426923076923075%, Loss = 0.01254309663692346
Epoch: 252, Batch Gradient Norm: 0.9637779899673267
Epoch: 252, Batch Gradient Norm after: 0.9637779899673267
Epoch 253/10000, Prediction Accuracy = 54.17307692307692%, Loss = 0.012608472329492752
Epoch: 253, Batch Gradient Norm: 1.0099510067200002
Epoch: 253, Batch Gradient Norm after: 1.0099510067200002
Epoch 254/10000, Prediction Accuracy = 53.892307692307696%, Loss = 0.012734764828704871
Epoch: 254, Batch Gradient Norm: 0.9228976429036285
Epoch: 254, Batch Gradient Norm after: 0.9228976429036285
Epoch 255/10000, Prediction Accuracy = 54.376923076923084%, Loss = 0.012549623918647949
Epoch: 255, Batch Gradient Norm: 0.9091875230523777
Epoch: 255, Batch Gradient Norm after: 0.9091875230523777
Epoch 256/10000, Prediction Accuracy = 54.03846153846154%, Loss = 0.012508439544874888
Epoch: 256, Batch Gradient Norm: 0.9908897854745089
Epoch: 256, Batch Gradient Norm after: 0.9908897854745089
Epoch 257/10000, Prediction Accuracy = 54.71153846153847%, Loss = 0.012555098662582727
Epoch: 257, Batch Gradient Norm: 0.9650870383202353
Epoch: 257, Batch Gradient Norm after: 0.9650870383202353
Epoch 258/10000, Prediction Accuracy = 54.292307692307695%, Loss = 0.012494227634026455
Epoch: 258, Batch Gradient Norm: 0.9244274509932255
Epoch: 258, Batch Gradient Norm after: 0.9244274509932255
Epoch 259/10000, Prediction Accuracy = 54.292307692307695%, Loss = 0.012484144992553271
Epoch: 259, Batch Gradient Norm: 1.0096114697052103
Epoch: 259, Batch Gradient Norm after: 1.0096114697052103
Epoch 260/10000, Prediction Accuracy = 54.31153846153847%, Loss = 0.01257880855924808
Epoch: 260, Batch Gradient Norm: 1.0577759125656054
Epoch: 260, Batch Gradient Norm after: 1.0577759125656054
Epoch 261/10000, Prediction Accuracy = 54.24615384615385%, Loss = 0.01254683553885955
Epoch: 261, Batch Gradient Norm: 0.9917466696360047
Epoch: 261, Batch Gradient Norm after: 0.9917466696360047
Epoch 262/10000, Prediction Accuracy = 54.353846153846156%, Loss = 0.012510914283876236
Epoch: 262, Batch Gradient Norm: 0.9523860659297861
Epoch: 262, Batch Gradient Norm after: 0.9523860659297861
Epoch 263/10000, Prediction Accuracy = 54.28846153846155%, Loss = 0.012434114415485125
Epoch: 263, Batch Gradient Norm: 1.0583711052351559
Epoch: 263, Batch Gradient Norm after: 1.0583711052351559
Epoch 264/10000, Prediction Accuracy = 54.607692307692304%, Loss = 0.012571251234756066
Epoch: 264, Batch Gradient Norm: 0.9562458877091269
Epoch: 264, Batch Gradient Norm after: 0.9562458877091269
Epoch 265/10000, Prediction Accuracy = 54.37692307692308%, Loss = 0.012448844499886036
Epoch: 265, Batch Gradient Norm: 1.0260305093242277
Epoch: 265, Batch Gradient Norm after: 1.0260305093242277
Epoch 266/10000, Prediction Accuracy = 54.473076923076924%, Loss = 0.012478922637036214
Epoch: 266, Batch Gradient Norm: 0.9315897525645103
Epoch: 266, Batch Gradient Norm after: 0.9315897525645103
Epoch 267/10000, Prediction Accuracy = 55.05384615384616%, Loss = 0.01230959680217963
Epoch: 267, Batch Gradient Norm: 0.9667426680563568
Epoch: 267, Batch Gradient Norm after: 0.9667426680563568
Epoch 268/10000, Prediction Accuracy = 54.89230769230768%, Loss = 0.012366889474483637
Epoch: 268, Batch Gradient Norm: 0.9347106630504399
Epoch: 268, Batch Gradient Norm after: 0.9347106630504399
Epoch 269/10000, Prediction Accuracy = 54.92307692307692%, Loss = 0.012273543156110324
Epoch: 269, Batch Gradient Norm: 0.9407350834371409
Epoch: 269, Batch Gradient Norm after: 0.9407350834371409
Epoch 270/10000, Prediction Accuracy = 54.434615384615384%, Loss = 0.0122760095132085
Epoch: 270, Batch Gradient Norm: 0.9645972089448299
Epoch: 270, Batch Gradient Norm after: 0.9645972089448299
Epoch 271/10000, Prediction Accuracy = 54.81153846153846%, Loss = 0.012238659967596714
Epoch: 271, Batch Gradient Norm: 0.9903546763581753
Epoch: 271, Batch Gradient Norm after: 0.9903546763581753
Epoch 272/10000, Prediction Accuracy = 54.699999999999996%, Loss = 0.012257453770591663
Epoch: 272, Batch Gradient Norm: 1.0899751819974772
Epoch: 272, Batch Gradient Norm after: 1.0899751819974772
Epoch 273/10000, Prediction Accuracy = 54.13846153846154%, Loss = 0.012434449834892383
Epoch: 273, Batch Gradient Norm: 1.1060636002808386
Epoch: 273, Batch Gradient Norm after: 1.1060636002808386
Epoch 274/10000, Prediction Accuracy = 54.45769230769231%, Loss = 0.012422728065687876
Epoch: 274, Batch Gradient Norm: 1.0837234169318528
Epoch: 274, Batch Gradient Norm after: 1.0837234169318528
Epoch 275/10000, Prediction Accuracy = 54.176923076923075%, Loss = 0.012426903757911462
Epoch: 275, Batch Gradient Norm: 1.0102433796007637
Epoch: 275, Batch Gradient Norm after: 1.0102433796007637
Epoch 276/10000, Prediction Accuracy = 54.77307692307693%, Loss = 0.012278955071591414
Epoch: 276, Batch Gradient Norm: 0.9921980749059532
Epoch: 276, Batch Gradient Norm after: 0.9921980749059532
Epoch 277/10000, Prediction Accuracy = 54.95384615384615%, Loss = 0.01221293554856227
Epoch: 277, Batch Gradient Norm: 1.0655038103383152
Epoch: 277, Batch Gradient Norm after: 1.0655038103383152
Epoch 278/10000, Prediction Accuracy = 54.776923076923076%, Loss = 0.012244918813499121
Epoch: 278, Batch Gradient Norm: 0.9542824419042599
Epoch: 278, Batch Gradient Norm after: 0.9542824419042599
Epoch 279/10000, Prediction Accuracy = 54.61923076923077%, Loss = 0.012167412214554273
Epoch: 279, Batch Gradient Norm: 0.9265558847557023
Epoch: 279, Batch Gradient Norm after: 0.9265558847557023
Epoch 280/10000, Prediction Accuracy = 55.20384615384615%, Loss = 0.012132285664287897
Epoch: 280, Batch Gradient Norm: 0.9528089137415282
Epoch: 280, Batch Gradient Norm after: 0.9528089137415282
Epoch 281/10000, Prediction Accuracy = 54.892307692307696%, Loss = 0.012127528755137553
Epoch: 281, Batch Gradient Norm: 1.0183635271189073
Epoch: 281, Batch Gradient Norm after: 1.0183635271189073
Epoch 282/10000, Prediction Accuracy = 54.93846153846153%, Loss = 0.012188717436331969
Epoch: 282, Batch Gradient Norm: 1.0614415877844745
Epoch: 282, Batch Gradient Norm after: 1.0614415877844745
Epoch 283/10000, Prediction Accuracy = 55.24615384615385%, Loss = 0.012225702046774901
Epoch: 283, Batch Gradient Norm: 1.0167876624957826
Epoch: 283, Batch Gradient Norm after: 1.0167876624957826
Epoch 284/10000, Prediction Accuracy = 55.03846153846153%, Loss = 0.012077471957756923
Epoch: 284, Batch Gradient Norm: 1.0646310546870645
Epoch: 284, Batch Gradient Norm after: 1.0646310546870645
Epoch 285/10000, Prediction Accuracy = 55.10769230769232%, Loss = 0.012223244214860292
Epoch: 285, Batch Gradient Norm: 1.013066524364085
Epoch: 285, Batch Gradient Norm after: 1.013066524364085
Epoch 286/10000, Prediction Accuracy = 55.0076923076923%, Loss = 0.012108726498599235
Epoch: 286, Batch Gradient Norm: 1.0022200347330459
Epoch: 286, Batch Gradient Norm after: 1.0022200347330459
Epoch 287/10000, Prediction Accuracy = 55.619230769230754%, Loss = 0.012050062203063415
Epoch: 287, Batch Gradient Norm: 0.9950565375378874
Epoch: 287, Batch Gradient Norm after: 0.9950565375378874
Epoch 288/10000, Prediction Accuracy = 55.361538461538444%, Loss = 0.011983737707711183
Epoch: 288, Batch Gradient Norm: 1.0958603757519831
Epoch: 288, Batch Gradient Norm after: 1.0958603757519831
Epoch 289/10000, Prediction Accuracy = 54.84615384615385%, Loss = 0.012133758873320542
Epoch: 289, Batch Gradient Norm: 1.1006066910835417
Epoch: 289, Batch Gradient Norm after: 1.1006066910835417
Epoch 290/10000, Prediction Accuracy = 54.94615384615384%, Loss = 0.012100475338789133
Epoch: 290, Batch Gradient Norm: 1.0153989974292474
Epoch: 290, Batch Gradient Norm after: 1.0153989974292474
Epoch 291/10000, Prediction Accuracy = 55.592307692307685%, Loss = 0.011950610348811517
Epoch: 291, Batch Gradient Norm: 1.1168628989765546
Epoch: 291, Batch Gradient Norm after: 1.1168628989765546
Epoch 292/10000, Prediction Accuracy = 55.04615384615384%, Loss = 0.012122363926699528
Epoch: 292, Batch Gradient Norm: 1.0809359884780254
Epoch: 292, Batch Gradient Norm after: 1.0809359884780254
Epoch 293/10000, Prediction Accuracy = 54.98461538461538%, Loss = 0.01202366379304574
Epoch: 293, Batch Gradient Norm: 1.016856479134524
Epoch: 293, Batch Gradient Norm after: 1.016856479134524
Epoch 294/10000, Prediction Accuracy = 55.565384615384616%, Loss = 0.011923636094881939
Epoch: 294, Batch Gradient Norm: 1.0302214028894074
Epoch: 294, Batch Gradient Norm after: 1.0302214028894074
Epoch 295/10000, Prediction Accuracy = 55.45%, Loss = 0.011957083757107075
Epoch: 295, Batch Gradient Norm: 1.218826094803539
Epoch: 295, Batch Gradient Norm after: 1.218826094803539
Epoch 296/10000, Prediction Accuracy = 55.03846153846155%, Loss = 0.012102432835560579
Epoch: 296, Batch Gradient Norm: 1.0913061454698154
Epoch: 296, Batch Gradient Norm after: 1.0913061454698154
Epoch 297/10000, Prediction Accuracy = 55.4076923076923%, Loss = 0.011958694801880764
Epoch: 297, Batch Gradient Norm: 1.0990873159537864
Epoch: 297, Batch Gradient Norm after: 1.0990873159537864
Epoch 298/10000, Prediction Accuracy = 55.17692307692309%, Loss = 0.011955650666585335
Epoch: 298, Batch Gradient Norm: 1.1023292686792163
Epoch: 298, Batch Gradient Norm after: 1.1023292686792163
Epoch 299/10000, Prediction Accuracy = 55.46923076923077%, Loss = 0.011939649398510273
Epoch: 299, Batch Gradient Norm: 1.1075227850614213
Epoch: 299, Batch Gradient Norm after: 1.1075227850614213
Epoch 300/10000, Prediction Accuracy = 55.415384615384625%, Loss = 0.011883812813231578
Epoch: 300, Batch Gradient Norm: 1.1809098699499005
Epoch: 300, Batch Gradient Norm after: 1.1809098699499005
Epoch 301/10000, Prediction Accuracy = 55.52692307692309%, Loss = 0.011972734991174478
Epoch: 301, Batch Gradient Norm: 1.0297197711362744
Epoch: 301, Batch Gradient Norm after: 1.0297197711362744
Epoch 302/10000, Prediction Accuracy = 55.88461538461539%, Loss = 0.011809046236941447
Epoch: 302, Batch Gradient Norm: 1.0241322839915596
Epoch: 302, Batch Gradient Norm after: 1.0241322839915596
Epoch 303/10000, Prediction Accuracy = 55.6653846153846%, Loss = 0.011841843621088909
Epoch: 303, Batch Gradient Norm: 1.04516728934737
Epoch: 303, Batch Gradient Norm after: 1.04516728934737
Epoch 304/10000, Prediction Accuracy = 55.63846153846154%, Loss = 0.0118485762952612
Epoch: 304, Batch Gradient Norm: 1.1458143758766188
Epoch: 304, Batch Gradient Norm after: 1.1458143758766188
Epoch 305/10000, Prediction Accuracy = 55.51538461538462%, Loss = 0.011907632032839151
Epoch: 305, Batch Gradient Norm: 1.146702940909688
Epoch: 305, Batch Gradient Norm after: 1.146702940909688
Epoch 306/10000, Prediction Accuracy = 55.59615384615385%, Loss = 0.011879152976549588
Epoch: 306, Batch Gradient Norm: 1.1702650140054243
Epoch: 306, Batch Gradient Norm after: 1.1702650140054243
Epoch 307/10000, Prediction Accuracy = 55.33846153846154%, Loss = 0.011873942943146596
Epoch: 307, Batch Gradient Norm: 1.1239200833453222
Epoch: 307, Batch Gradient Norm after: 1.1239200833453222
Epoch 308/10000, Prediction Accuracy = 55.85000000000001%, Loss = 0.011857225631292049
Epoch: 308, Batch Gradient Norm: 1.090481378342833
Epoch: 308, Batch Gradient Norm after: 1.090481378342833
Epoch 309/10000, Prediction Accuracy = 55.65384615384615%, Loss = 0.011746443808078766
Epoch: 309, Batch Gradient Norm: 1.1708236277922197
Epoch: 309, Batch Gradient Norm after: 1.1708236277922197
Epoch 310/10000, Prediction Accuracy = 55.81923076923078%, Loss = 0.01181780152882521
Epoch: 310, Batch Gradient Norm: 1.122602803887697
Epoch: 310, Batch Gradient Norm after: 1.122602803887697
Epoch 311/10000, Prediction Accuracy = 55.93846153846154%, Loss = 0.011734958164967023
Epoch: 311, Batch Gradient Norm: 1.138821488295041
Epoch: 311, Batch Gradient Norm after: 1.138821488295041
Epoch 312/10000, Prediction Accuracy = 55.99230769230768%, Loss = 0.011747291956383448
Epoch: 312, Batch Gradient Norm: 1.1160530454038395
Epoch: 312, Batch Gradient Norm after: 1.1160530454038395
Epoch 313/10000, Prediction Accuracy = 55.719230769230776%, Loss = 0.011775385230206527
Epoch: 313, Batch Gradient Norm: 1.142617060434795
Epoch: 313, Batch Gradient Norm after: 1.142617060434795
Epoch 314/10000, Prediction Accuracy = 56.2%, Loss = 0.011750567561158767
Epoch: 314, Batch Gradient Norm: 1.070125409108009
Epoch: 314, Batch Gradient Norm after: 1.070125409108009
Epoch 315/10000, Prediction Accuracy = 55.78076923076924%, Loss = 0.011677697085990356
Epoch: 315, Batch Gradient Norm: 1.0649069146159715
Epoch: 315, Batch Gradient Norm after: 1.0649069146159715
Epoch 316/10000, Prediction Accuracy = 56.06538461538461%, Loss = 0.011606423542476617
Epoch: 316, Batch Gradient Norm: 1.1501414381371813
Epoch: 316, Batch Gradient Norm after: 1.1501414381371813
Epoch 317/10000, Prediction Accuracy = 55.78076923076923%, Loss = 0.011720151640474796
Epoch: 317, Batch Gradient Norm: 1.151198025501332
Epoch: 317, Batch Gradient Norm after: 1.151198025501332
Epoch 318/10000, Prediction Accuracy = 55.842307692307685%, Loss = 0.011744090355932713
Epoch: 318, Batch Gradient Norm: 1.1669846918869915
Epoch: 318, Batch Gradient Norm after: 1.1669846918869915
Epoch 319/10000, Prediction Accuracy = 55.97692307692307%, Loss = 0.011737073126893777
Epoch: 319, Batch Gradient Norm: 1.2388673268969028
Epoch: 319, Batch Gradient Norm after: 1.2388673268969028
Epoch 320/10000, Prediction Accuracy = 55.57692307692308%, Loss = 0.011818106644428693
Epoch: 320, Batch Gradient Norm: 1.188119811513893
Epoch: 320, Batch Gradient Norm after: 1.188119811513893
Epoch 321/10000, Prediction Accuracy = 55.77307692307692%, Loss = 0.01173137672818624
Epoch: 321, Batch Gradient Norm: 1.1104052791705643
Epoch: 321, Batch Gradient Norm after: 1.1104052791705643
Epoch 322/10000, Prediction Accuracy = 55.81923076923077%, Loss = 0.011619907732193287
Epoch: 322, Batch Gradient Norm: 1.2338102887163376
Epoch: 322, Batch Gradient Norm after: 1.2338102887163376
Epoch 323/10000, Prediction Accuracy = 56.15384615384615%, Loss = 0.011663541484337587
Epoch: 323, Batch Gradient Norm: 1.234274955762637
Epoch: 323, Batch Gradient Norm after: 1.234274955762637
Epoch 324/10000, Prediction Accuracy = 56.13461538461539%, Loss = 0.011684300019763984
Epoch: 324, Batch Gradient Norm: 1.1351303776452792
Epoch: 324, Batch Gradient Norm after: 1.1351303776452792
Epoch 325/10000, Prediction Accuracy = 56.24230769230769%, Loss = 0.01153997195741305
Epoch: 325, Batch Gradient Norm: 1.1635600214290922
Epoch: 325, Batch Gradient Norm after: 1.1635600214290922
Epoch 326/10000, Prediction Accuracy = 56.376923076923084%, Loss = 0.011530080093787266
Epoch: 326, Batch Gradient Norm: 1.2569047210503002
Epoch: 326, Batch Gradient Norm after: 1.2569047210503002
Epoch 327/10000, Prediction Accuracy = 56.130769230769225%, Loss = 0.011639145131294545
Epoch: 327, Batch Gradient Norm: 1.3013979957931037
Epoch: 327, Batch Gradient Norm after: 1.3013979957931037
Epoch 328/10000, Prediction Accuracy = 55.576923076923066%, Loss = 0.011733449494036345
Epoch: 328, Batch Gradient Norm: 1.3001116196203295
Epoch: 328, Batch Gradient Norm after: 1.3001116196203295
Epoch 329/10000, Prediction Accuracy = 55.900000000000006%, Loss = 0.011654927395284176
Epoch: 329, Batch Gradient Norm: 1.1204981640938723
Epoch: 329, Batch Gradient Norm after: 1.1204981640938723
Epoch 330/10000, Prediction Accuracy = 56.91538461538461%, Loss = 0.011503148394135328
Epoch: 330, Batch Gradient Norm: 1.1307630053686752
Epoch: 330, Batch Gradient Norm after: 1.1307630053686752
Epoch 331/10000, Prediction Accuracy = 56.66538461538461%, Loss = 0.01145777808359036
Epoch: 331, Batch Gradient Norm: 1.173548243436743
Epoch: 331, Batch Gradient Norm after: 1.173548243436743
Epoch 332/10000, Prediction Accuracy = 56.01153846153846%, Loss = 0.011479445804770175
Epoch: 332, Batch Gradient Norm: 1.2993337079497767
Epoch: 332, Batch Gradient Norm after: 1.2993337079497767
Epoch 333/10000, Prediction Accuracy = 56.04615384615385%, Loss = 0.011586011315767582
Epoch: 333, Batch Gradient Norm: 1.2473427180743346
Epoch: 333, Batch Gradient Norm after: 1.2473427180743346
Epoch 334/10000, Prediction Accuracy = 56.41153846153846%, Loss = 0.011523086649294082
Epoch: 334, Batch Gradient Norm: 1.1828579976301654
Epoch: 334, Batch Gradient Norm after: 1.1828579976301654
Epoch 335/10000, Prediction Accuracy = 56.215384615384615%, Loss = 0.011489668861031532
Epoch: 335, Batch Gradient Norm: 1.1011502884287845
Epoch: 335, Batch Gradient Norm after: 1.1011502884287845
Epoch 336/10000, Prediction Accuracy = 56.41538461538461%, Loss = 0.011442724400414871
Epoch: 336, Batch Gradient Norm: 1.0918159388335362
Epoch: 336, Batch Gradient Norm after: 1.0918159388335362
Epoch 337/10000, Prediction Accuracy = 56.23076923076924%, Loss = 0.011433303356170654
Epoch: 337, Batch Gradient Norm: 1.253487318261385
Epoch: 337, Batch Gradient Norm after: 1.253487318261385
Epoch 338/10000, Prediction Accuracy = 55.66153846153846%, Loss = 0.011577292775305418
Epoch: 338, Batch Gradient Norm: 1.2314943611977633
Epoch: 338, Batch Gradient Norm after: 1.2314943611977633
Epoch 339/10000, Prediction Accuracy = 56.188461538461524%, Loss = 0.01149746890251453
Epoch: 339, Batch Gradient Norm: 1.226617040387955
Epoch: 339, Batch Gradient Norm after: 1.226617040387955
Epoch 340/10000, Prediction Accuracy = 56.26923076923078%, Loss = 0.01144264810360395
Epoch: 340, Batch Gradient Norm: 1.2085897194169357
Epoch: 340, Batch Gradient Norm after: 1.2085897194169357
Epoch 341/10000, Prediction Accuracy = 56.37692307692308%, Loss = 0.01131211156741931
Epoch: 341, Batch Gradient Norm: 1.10893313971626
Epoch: 341, Batch Gradient Norm after: 1.10893313971626
Epoch 342/10000, Prediction Accuracy = 56.93846153846154%, Loss = 0.011311645476290813
Epoch: 342, Batch Gradient Norm: 1.1933950451300985
Epoch: 342, Batch Gradient Norm after: 1.1933950451300985
Epoch 343/10000, Prediction Accuracy = 56.103846153846156%, Loss = 0.01146583087169207
Epoch: 343, Batch Gradient Norm: 1.2754741554366247
Epoch: 343, Batch Gradient Norm after: 1.2754741554366247
Epoch 344/10000, Prediction Accuracy = 56.3423076923077%, Loss = 0.011385545492745362
Epoch: 344, Batch Gradient Norm: 1.2145083346558017
Epoch: 344, Batch Gradient Norm after: 1.2145083346558017
Epoch 345/10000, Prediction Accuracy = 56.61538461538461%, Loss = 0.011352016089054255
Epoch: 345, Batch Gradient Norm: 1.2050964100972361
Epoch: 345, Batch Gradient Norm after: 1.2050964100972361
Epoch 346/10000, Prediction Accuracy = 56.5923076923077%, Loss = 0.011320369676328622
Epoch: 346, Batch Gradient Norm: 1.1571741115620677
Epoch: 346, Batch Gradient Norm after: 1.1571741115620677
Epoch 347/10000, Prediction Accuracy = 56.79615384615385%, Loss = 0.011306953688080493
Epoch: 347, Batch Gradient Norm: 1.286051164445427
Epoch: 347, Batch Gradient Norm after: 1.286051164445427
Epoch 348/10000, Prediction Accuracy = 56.076923076923066%, Loss = 0.01142125533750424
Epoch: 348, Batch Gradient Norm: 1.171080325985216
Epoch: 348, Batch Gradient Norm after: 1.171080325985216
Epoch 349/10000, Prediction Accuracy = 56.76923076923078%, Loss = 0.011249479407874437
Epoch: 349, Batch Gradient Norm: 1.1235252608395216
Epoch: 349, Batch Gradient Norm after: 1.1235252608395216
Epoch 350/10000, Prediction Accuracy = 56.73846153846154%, Loss = 0.011149987220191039
Epoch: 350, Batch Gradient Norm: 1.1580231393278526
Epoch: 350, Batch Gradient Norm after: 1.1580231393278526
Epoch 351/10000, Prediction Accuracy = 56.784615384615385%, Loss = 0.011193604853290778
Epoch: 351, Batch Gradient Norm: 1.2689510789858713
Epoch: 351, Batch Gradient Norm after: 1.2689510789858713
Epoch 352/10000, Prediction Accuracy = 57.173076923076934%, Loss = 0.011288955807685852
Epoch: 352, Batch Gradient Norm: 1.3093202787545262
Epoch: 352, Batch Gradient Norm after: 1.3093202787545262
Epoch 353/10000, Prediction Accuracy = 56.44615384615384%, Loss = 0.011351858265697956
Epoch: 353, Batch Gradient Norm: 1.1873584591390713
Epoch: 353, Batch Gradient Norm after: 1.1873584591390713
Epoch 354/10000, Prediction Accuracy = 56.842307692307685%, Loss = 0.011226402738919625
Epoch: 354, Batch Gradient Norm: 1.275291511177097
Epoch: 354, Batch Gradient Norm after: 1.275291511177097
Epoch 355/10000, Prediction Accuracy = 56.58076923076923%, Loss = 0.01129082776606083
Epoch: 355, Batch Gradient Norm: 1.2697510923524185
Epoch: 355, Batch Gradient Norm after: 1.2697510923524185
Epoch 356/10000, Prediction Accuracy = 56.71923076923077%, Loss = 0.011349509398524579
Epoch: 356, Batch Gradient Norm: 1.2685946993473058
Epoch: 356, Batch Gradient Norm after: 1.2685946993473058
Epoch 357/10000, Prediction Accuracy = 56.70769230769231%, Loss = 0.01131932781292842
Epoch: 357, Batch Gradient Norm: 1.2639898322150551
Epoch: 357, Batch Gradient Norm after: 1.2639898322150551
Epoch 358/10000, Prediction Accuracy = 56.84615384615385%, Loss = 0.01124979483966644
Epoch: 358, Batch Gradient Norm: 1.363160854400306
Epoch: 358, Batch Gradient Norm after: 1.363160854400306
Epoch 359/10000, Prediction Accuracy = 56.58076923076923%, Loss = 0.011329907279175062
Epoch: 359, Batch Gradient Norm: 1.3558314127055306
Epoch: 359, Batch Gradient Norm after: 1.3558314127055306
Epoch 360/10000, Prediction Accuracy = 56.69615384615384%, Loss = 0.011356029659509659
Epoch: 360, Batch Gradient Norm: 1.401452424299534
Epoch: 360, Batch Gradient Norm after: 1.401452424299534
Epoch 361/10000, Prediction Accuracy = 56.530769230769224%, Loss = 0.011393038627619926
Epoch: 361, Batch Gradient Norm: 1.3359664632380064
Epoch: 361, Batch Gradient Norm after: 1.3359664632380064
Epoch 362/10000, Prediction Accuracy = 56.611538461538466%, Loss = 0.011281276623216959
Epoch: 362, Batch Gradient Norm: 1.2921102790297228
Epoch: 362, Batch Gradient Norm after: 1.2921102790297228
Epoch 363/10000, Prediction Accuracy = 57.01923076923077%, Loss = 0.011209746822714806
Epoch: 363, Batch Gradient Norm: 1.2392764727618364
Epoch: 363, Batch Gradient Norm after: 1.2392764727618364
Epoch 364/10000, Prediction Accuracy = 56.430769230769215%, Loss = 0.01121869210440379
Epoch: 364, Batch Gradient Norm: 1.2586990633623232
Epoch: 364, Batch Gradient Norm after: 1.2586990633623232
Epoch 365/10000, Prediction Accuracy = 57.20384615384616%, Loss = 0.011142523815998664
Epoch: 365, Batch Gradient Norm: 1.2333994430950033
Epoch: 365, Batch Gradient Norm after: 1.2333994430950033
Epoch 366/10000, Prediction Accuracy = 56.73461538461539%, Loss = 0.011164607695088936
Epoch: 366, Batch Gradient Norm: 1.189770551372214
Epoch: 366, Batch Gradient Norm after: 1.189770551372214
Epoch 367/10000, Prediction Accuracy = 56.63846153846154%, Loss = 0.011114609929231497
Epoch: 367, Batch Gradient Norm: 1.366389776795314
Epoch: 367, Batch Gradient Norm after: 1.366389776795314
Epoch 368/10000, Prediction Accuracy = 56.83076923076923%, Loss = 0.011275222811561365
Epoch: 368, Batch Gradient Norm: 1.230782119386941
Epoch: 368, Batch Gradient Norm after: 1.230782119386941
Epoch 369/10000, Prediction Accuracy = 57.146153846153844%, Loss = 0.011034035553725867
Epoch: 369, Batch Gradient Norm: 1.30170032454081
Epoch: 369, Batch Gradient Norm after: 1.30170032454081
Epoch 370/10000, Prediction Accuracy = 57.111538461538466%, Loss = 0.01120166602329566
Epoch: 370, Batch Gradient Norm: 1.2588107590720152
Epoch: 370, Batch Gradient Norm after: 1.2588107590720152
Epoch 371/10000, Prediction Accuracy = 56.7423076923077%, Loss = 0.011163390743044706
Epoch: 371, Batch Gradient Norm: 1.2077403539730476
Epoch: 371, Batch Gradient Norm after: 1.2077403539730476
Epoch 372/10000, Prediction Accuracy = 57.01153846153847%, Loss = 0.011042441599644147
Epoch: 372, Batch Gradient Norm: 1.235585440610223
Epoch: 372, Batch Gradient Norm after: 1.235585440610223
Epoch 373/10000, Prediction Accuracy = 57.14230769230771%, Loss = 0.011035375870191134
Epoch: 373, Batch Gradient Norm: 1.235405141103693
Epoch: 373, Batch Gradient Norm after: 1.235405141103693
Epoch 374/10000, Prediction Accuracy = 57.32307692307692%, Loss = 0.011038483621982427
Epoch: 374, Batch Gradient Norm: 1.2454848830249858
Epoch: 374, Batch Gradient Norm after: 1.2454848830249858
Epoch 375/10000, Prediction Accuracy = 57.06923076923077%, Loss = 0.011033665675383348
Epoch: 375, Batch Gradient Norm: 1.2594227499088209
Epoch: 375, Batch Gradient Norm after: 1.2594227499088209
Epoch 376/10000, Prediction Accuracy = 57.25384615384615%, Loss = 0.011016324878885196
Epoch: 376, Batch Gradient Norm: 1.246204324673881
Epoch: 376, Batch Gradient Norm after: 1.246204324673881
Epoch 377/10000, Prediction Accuracy = 57.776923076923076%, Loss = 0.010970149260873977
Epoch: 377, Batch Gradient Norm: 1.2508231241978318
Epoch: 377, Batch Gradient Norm after: 1.2508231241978318
Epoch 378/10000, Prediction Accuracy = 56.957692307692305%, Loss = 0.010984305364008132
Epoch: 378, Batch Gradient Norm: 1.403525784128678
Epoch: 378, Batch Gradient Norm after: 1.403525784128678
Epoch 379/10000, Prediction Accuracy = 57.22692307692307%, Loss = 0.011138237439669095
Epoch: 379, Batch Gradient Norm: 1.196557139515165
Epoch: 379, Batch Gradient Norm after: 1.196557139515165
Epoch 380/10000, Prediction Accuracy = 57.48461538461539%, Loss = 0.010938543683061233
Epoch: 380, Batch Gradient Norm: 1.2748898909435178
Epoch: 380, Batch Gradient Norm after: 1.2748898909435178
Epoch 381/10000, Prediction Accuracy = 57.669230769230765%, Loss = 0.010943063678076634
Epoch: 381, Batch Gradient Norm: 1.2379136371388528
Epoch: 381, Batch Gradient Norm after: 1.2379136371388528
Epoch 382/10000, Prediction Accuracy = 57.51538461538461%, Loss = 0.010985016607894348
Epoch: 382, Batch Gradient Norm: 1.2600889771021044
Epoch: 382, Batch Gradient Norm after: 1.2600889771021044
Epoch 383/10000, Prediction Accuracy = 57.64999999999999%, Loss = 0.01103113921215901
Epoch: 383, Batch Gradient Norm: 1.2839420446524024
Epoch: 383, Batch Gradient Norm after: 1.2839420446524024
Epoch 384/10000, Prediction Accuracy = 56.973076923076924%, Loss = 0.011056478493488751
Epoch: 384, Batch Gradient Norm: 1.4889058976097467
Epoch: 384, Batch Gradient Norm after: 1.4889058976097467
Epoch 385/10000, Prediction Accuracy = 56.74230769230768%, Loss = 0.011285253728811558
Epoch: 385, Batch Gradient Norm: 1.4649176128923926
Epoch: 385, Batch Gradient Norm after: 1.4649176128923926
Epoch 386/10000, Prediction Accuracy = 56.80769230769231%, Loss = 0.011215642667733706
Epoch: 386, Batch Gradient Norm: 1.3804175796624951
Epoch: 386, Batch Gradient Norm after: 1.3804175796624951
Epoch 387/10000, Prediction Accuracy = 56.96153846153846%, Loss = 0.01112313661724329
Epoch: 387, Batch Gradient Norm: 1.1915027082611278
Epoch: 387, Batch Gradient Norm after: 1.1915027082611278
Epoch 388/10000, Prediction Accuracy = 57.25769230769232%, Loss = 0.010923124921436492
Epoch: 388, Batch Gradient Norm: 1.2269140160447651
Epoch: 388, Batch Gradient Norm after: 1.2269140160447651
Epoch 389/10000, Prediction Accuracy = 57.669230769230765%, Loss = 0.010835402573530491
Epoch: 389, Batch Gradient Norm: 1.3300841082294983
Epoch: 389, Batch Gradient Norm after: 1.3300841082294983
Epoch 390/10000, Prediction Accuracy = 57.49230769230769%, Loss = 0.01086335743849094
Epoch: 390, Batch Gradient Norm: 1.373221839467303
Epoch: 390, Batch Gradient Norm after: 1.373221839467303
Epoch 391/10000, Prediction Accuracy = 57.36923076923077%, Loss = 0.010947336800969563
Epoch: 391, Batch Gradient Norm: 1.4411257878820194
Epoch: 391, Batch Gradient Norm after: 1.4411257878820194
Epoch 392/10000, Prediction Accuracy = 57.03846153846154%, Loss = 0.011059923957173642
Epoch: 392, Batch Gradient Norm: 1.4687394303490502
Epoch: 392, Batch Gradient Norm after: 1.4687394303490502
Epoch 393/10000, Prediction Accuracy = 57.07307692307692%, Loss = 0.011111327876838354
Epoch: 393, Batch Gradient Norm: 1.326913469395066
Epoch: 393, Batch Gradient Norm after: 1.326913469395066
Epoch 394/10000, Prediction Accuracy = 57.380769230769246%, Loss = 0.011005694118256752
Epoch: 394, Batch Gradient Norm: 1.2568219359832498
Epoch: 394, Batch Gradient Norm after: 1.2568219359832498
Epoch 395/10000, Prediction Accuracy = 57.63076923076923%, Loss = 0.010839006648613857
Epoch: 395, Batch Gradient Norm: 1.2940675824008208
Epoch: 395, Batch Gradient Norm after: 1.2940675824008208
Epoch 396/10000, Prediction Accuracy = 57.39615384615385%, Loss = 0.010857191653205799
Epoch: 396, Batch Gradient Norm: 1.3740394419044146
Epoch: 396, Batch Gradient Norm after: 1.3740394419044146
Epoch 397/10000, Prediction Accuracy = 57.40384615384615%, Loss = 0.010890512727200985
Epoch: 397, Batch Gradient Norm: 1.3445300155812747
Epoch: 397, Batch Gradient Norm after: 1.3445300155812747
Epoch 398/10000, Prediction Accuracy = 57.638461538461534%, Loss = 0.010804443835065914
Epoch: 398, Batch Gradient Norm: 1.2759704662580833
Epoch: 398, Batch Gradient Norm after: 1.2759704662580833
Epoch 399/10000, Prediction Accuracy = 58.20384615384615%, Loss = 0.010750139848544048
Epoch: 399, Batch Gradient Norm: 1.242153191836099
Epoch: 399, Batch Gradient Norm after: 1.242153191836099
Epoch 400/10000, Prediction Accuracy = 57.83076923076923%, Loss = 0.01077138575223776
Epoch: 400, Batch Gradient Norm: 1.251278185765954
Epoch: 400, Batch Gradient Norm after: 1.251278185765954
Epoch 401/10000, Prediction Accuracy = 57.55%, Loss = 0.010743205578854451
Epoch: 401, Batch Gradient Norm: 1.3774644882693854
Epoch: 401, Batch Gradient Norm after: 1.3774644882693854
Epoch 402/10000, Prediction Accuracy = 57.657692307692315%, Loss = 0.010849590055071391
Epoch: 402, Batch Gradient Norm: 1.5142395883336273
Epoch: 402, Batch Gradient Norm after: 1.5142395883336273
Epoch 403/10000, Prediction Accuracy = 57.67692307692307%, Loss = 0.010918345803824754
Epoch: 403, Batch Gradient Norm: 1.4859175365017292
Epoch: 403, Batch Gradient Norm after: 1.4859175365017292
Epoch 404/10000, Prediction Accuracy = 57.09615384615385%, Loss = 0.010892785942325225
Epoch: 404, Batch Gradient Norm: 1.5110907258675998
Epoch: 404, Batch Gradient Norm after: 1.5110907258675998
Epoch 405/10000, Prediction Accuracy = 57.44230769230769%, Loss = 0.010982966981828213
Epoch: 405, Batch Gradient Norm: 1.4216068757223121
Epoch: 405, Batch Gradient Norm after: 1.4216068757223121
Epoch 406/10000, Prediction Accuracy = 57.75000000000001%, Loss = 0.01084423831735666
Epoch: 406, Batch Gradient Norm: 1.2633764585462433
Epoch: 406, Batch Gradient Norm after: 1.2633764585462433
Epoch 407/10000, Prediction Accuracy = 58.0923076923077%, Loss = 0.010694383786847958
Epoch: 407, Batch Gradient Norm: 1.4066430521532047
Epoch: 407, Batch Gradient Norm after: 1.4066430521532047
Epoch 408/10000, Prediction Accuracy = 57.184615384615384%, Loss = 0.010857692131629357
Epoch: 408, Batch Gradient Norm: 1.405201689272799
Epoch: 408, Batch Gradient Norm after: 1.405201689272799
Epoch 409/10000, Prediction Accuracy = 57.526923076923076%, Loss = 0.01084921143662471
Epoch: 409, Batch Gradient Norm: 1.3608548140854055
Epoch: 409, Batch Gradient Norm after: 1.3608548140854055
Epoch 410/10000, Prediction Accuracy = 57.99615384615385%, Loss = 0.010750211775302887
Epoch: 410, Batch Gradient Norm: 1.3740537170596085
Epoch: 410, Batch Gradient Norm after: 1.3740537170596085
Epoch 411/10000, Prediction Accuracy = 57.87307692307692%, Loss = 0.010750489094509529
Epoch: 411, Batch Gradient Norm: 1.4095614382373125
Epoch: 411, Batch Gradient Norm after: 1.4095614382373125
Epoch 412/10000, Prediction Accuracy = 57.82307692307692%, Loss = 0.010761892637954308
Epoch: 412, Batch Gradient Norm: 1.5172617139492144
Epoch: 412, Batch Gradient Norm after: 1.5172617139492144
Epoch 413/10000, Prediction Accuracy = 57.24230769230769%, Loss = 0.01090711777886519
Epoch: 413, Batch Gradient Norm: 1.471944676446667
Epoch: 413, Batch Gradient Norm after: 1.471944676446667
Epoch 414/10000, Prediction Accuracy = 57.62307692307692%, Loss = 0.010785786506648246
Epoch: 414, Batch Gradient Norm: 1.4037577472061311
Epoch: 414, Batch Gradient Norm after: 1.4037577472061311
Epoch 415/10000, Prediction Accuracy = 57.76538461538461%, Loss = 0.010725300615796676
Epoch: 415, Batch Gradient Norm: 1.371327014111862
Epoch: 415, Batch Gradient Norm after: 1.371327014111862
Epoch 416/10000, Prediction Accuracy = 57.696153846153834%, Loss = 0.010720324989121694
Epoch: 416, Batch Gradient Norm: 1.379630820485811
Epoch: 416, Batch Gradient Norm after: 1.379630820485811
Epoch 417/10000, Prediction Accuracy = 57.98461538461539%, Loss = 0.010762340747393094
Epoch: 417, Batch Gradient Norm: 1.3304834884493781
Epoch: 417, Batch Gradient Norm after: 1.3304834884493781
Epoch 418/10000, Prediction Accuracy = 58.088461538461544%, Loss = 0.010674642040752448
Epoch: 418, Batch Gradient Norm: 1.424229436658146
Epoch: 418, Batch Gradient Norm after: 1.424229436658146
Epoch 419/10000, Prediction Accuracy = 58.0%, Loss = 0.010757852274064835
Epoch: 419, Batch Gradient Norm: 1.3627851008563627
Epoch: 419, Batch Gradient Norm after: 1.3627851008563627
Epoch 420/10000, Prediction Accuracy = 57.657692307692315%, Loss = 0.010718894047805896
Epoch: 420, Batch Gradient Norm: 1.3316871397720886
Epoch: 420, Batch Gradient Norm after: 1.3316871397720886
Epoch 421/10000, Prediction Accuracy = 58.023076923076935%, Loss = 0.010672613190343747
Epoch: 421, Batch Gradient Norm: 1.334595603606246
Epoch: 421, Batch Gradient Norm after: 1.334595603606246
Epoch 422/10000, Prediction Accuracy = 58.31923076923076%, Loss = 0.010565196450513143
Epoch: 422, Batch Gradient Norm: 1.3534126159285103
Epoch: 422, Batch Gradient Norm after: 1.3534126159285103
Epoch 423/10000, Prediction Accuracy = 58.380769230769225%, Loss = 0.010606765890350709
Epoch: 423, Batch Gradient Norm: 1.4766400170453131
Epoch: 423, Batch Gradient Norm after: 1.4766400170453131
Epoch 424/10000, Prediction Accuracy = 57.707692307692305%, Loss = 0.010718252008350996
Epoch: 424, Batch Gradient Norm: 1.465190914387026
Epoch: 424, Batch Gradient Norm after: 1.465190914387026
Epoch 425/10000, Prediction Accuracy = 57.7%, Loss = 0.01070011013115828
Epoch: 425, Batch Gradient Norm: 1.3391298577615094
Epoch: 425, Batch Gradient Norm after: 1.3391298577615094
Epoch 426/10000, Prediction Accuracy = 58.361538461538466%, Loss = 0.01057178032799409
Epoch: 426, Batch Gradient Norm: 1.4009780438928936
Epoch: 426, Batch Gradient Norm after: 1.4009780438928936
Epoch 427/10000, Prediction Accuracy = 58.19615384615385%, Loss = 0.010611100767094355
Epoch: 427, Batch Gradient Norm: 1.5420227244281928
Epoch: 427, Batch Gradient Norm after: 1.5420227244281928
Epoch 428/10000, Prediction Accuracy = 57.776923076923076%, Loss = 0.010703111927096661
Epoch: 428, Batch Gradient Norm: 1.5294274434241262
Epoch: 428, Batch Gradient Norm after: 1.5294274434241262
Epoch 429/10000, Prediction Accuracy = 58.02307692307692%, Loss = 0.010818793151814204
Epoch: 429, Batch Gradient Norm: 1.5273312926688822
Epoch: 429, Batch Gradient Norm after: 1.5273312926688822
Epoch 430/10000, Prediction Accuracy = 57.93846153846154%, Loss = 0.0107718135158603
Epoch: 430, Batch Gradient Norm: 1.5781443614606046
Epoch: 430, Batch Gradient Norm after: 1.5781443614606046
Epoch 431/10000, Prediction Accuracy = 57.653846153846175%, Loss = 0.010805013517920788
Epoch: 431, Batch Gradient Norm: 1.398466063362025
Epoch: 431, Batch Gradient Norm after: 1.398466063362025
Epoch 432/10000, Prediction Accuracy = 58.092307692307685%, Loss = 0.01062768124617063
Epoch: 432, Batch Gradient Norm: 1.4642408298320415
Epoch: 432, Batch Gradient Norm after: 1.4642408298320415
Epoch 433/10000, Prediction Accuracy = 57.80384615384616%, Loss = 0.010699602345434519
Epoch: 433, Batch Gradient Norm: 1.4250736273994202
Epoch: 433, Batch Gradient Norm after: 1.4250736273994202
Epoch 434/10000, Prediction Accuracy = 58.25384615384616%, Loss = 0.010626945071495496
Epoch: 434, Batch Gradient Norm: 1.3614506117523484
Epoch: 434, Batch Gradient Norm after: 1.3614506117523484
Epoch 435/10000, Prediction Accuracy = 58.2423076923077%, Loss = 0.010600289616447229
Epoch: 435, Batch Gradient Norm: 1.4484011772059593
Epoch: 435, Batch Gradient Norm after: 1.4484011772059593
Epoch 436/10000, Prediction Accuracy = 57.973076923076924%, Loss = 0.010679397732019424
Epoch: 436, Batch Gradient Norm: 1.3664287023778119
Epoch: 436, Batch Gradient Norm after: 1.3664287023778119
Epoch 437/10000, Prediction Accuracy = 58.353846153846156%, Loss = 0.010538915745340861
Epoch: 437, Batch Gradient Norm: 1.3774819000304637
Epoch: 437, Batch Gradient Norm after: 1.3774819000304637
Epoch 438/10000, Prediction Accuracy = 58.19615384615384%, Loss = 0.010674427836560287
Epoch: 438, Batch Gradient Norm: 1.496536023880112
Epoch: 438, Batch Gradient Norm after: 1.496536023880112
Epoch 439/10000, Prediction Accuracy = 58.24999999999999%, Loss = 0.010667539488237638
Epoch: 439, Batch Gradient Norm: 1.3878498389807625
Epoch: 439, Batch Gradient Norm after: 1.3878498389807625
Epoch 440/10000, Prediction Accuracy = 58.57692307692308%, Loss = 0.010431886650621891
Epoch: 440, Batch Gradient Norm: 1.47540735111226
Epoch: 440, Batch Gradient Norm after: 1.47540735111226
Epoch 441/10000, Prediction Accuracy = 58.25384615384616%, Loss = 0.01059191358777193
Epoch: 441, Batch Gradient Norm: 1.3847977533265226
Epoch: 441, Batch Gradient Norm after: 1.3847977533265226
Epoch 442/10000, Prediction Accuracy = 58.338461538461544%, Loss = 0.010498202262589565
Epoch: 442, Batch Gradient Norm: 1.4324221035530227
Epoch: 442, Batch Gradient Norm after: 1.4324221035530227
Epoch 443/10000, Prediction Accuracy = 58.473076923076924%, Loss = 0.010588390609392753
Epoch: 443, Batch Gradient Norm: 1.4168264636816186
Epoch: 443, Batch Gradient Norm after: 1.4168264636816186
Epoch 444/10000, Prediction Accuracy = 57.900000000000006%, Loss = 0.010559021280362057
Epoch: 444, Batch Gradient Norm: 1.369780277565659
Epoch: 444, Batch Gradient Norm after: 1.369780277565659
Epoch 445/10000, Prediction Accuracy = 58.49615384615386%, Loss = 0.010465620228877434
Epoch: 445, Batch Gradient Norm: 1.5259380539936624
Epoch: 445, Batch Gradient Norm after: 1.5259380539936624
Epoch 446/10000, Prediction Accuracy = 57.93076923076923%, Loss = 0.01060344844769973
Epoch: 446, Batch Gradient Norm: 1.3540240112362456
Epoch: 446, Batch Gradient Norm after: 1.3540240112362456
Epoch 447/10000, Prediction Accuracy = 58.33461538461539%, Loss = 0.010394177972697295
Epoch: 447, Batch Gradient Norm: 1.295985707065786
Epoch: 447, Batch Gradient Norm after: 1.295985707065786
Epoch 448/10000, Prediction Accuracy = 58.81923076923078%, Loss = 0.01035833408912787
Epoch: 448, Batch Gradient Norm: 1.3514014638010603
Epoch: 448, Batch Gradient Norm after: 1.3514014638010603
Epoch 449/10000, Prediction Accuracy = 58.29615384615384%, Loss = 0.010391401055340584
Epoch: 449, Batch Gradient Norm: 1.452491231121145
Epoch: 449, Batch Gradient Norm after: 1.452491231121145
Epoch 450/10000, Prediction Accuracy = 58.419230769230765%, Loss = 0.010494898001735028
Epoch: 450, Batch Gradient Norm: 1.5216001600618387
Epoch: 450, Batch Gradient Norm after: 1.5216001600618387
Epoch 451/10000, Prediction Accuracy = 58.29615384615385%, Loss = 0.010510098833877306
Epoch: 451, Batch Gradient Norm: 1.3571791317967583
Epoch: 451, Batch Gradient Norm after: 1.3571791317967583
Epoch 452/10000, Prediction Accuracy = 58.603846153846156%, Loss = 0.010359869410212223
Epoch: 452, Batch Gradient Norm: 1.3943662098778555
Epoch: 452, Batch Gradient Norm after: 1.3943662098778555
Epoch 453/10000, Prediction Accuracy = 58.64615384615385%, Loss = 0.010358474002434658
Epoch: 453, Batch Gradient Norm: 1.425320835062378
Epoch: 453, Batch Gradient Norm after: 1.425320835062378
Epoch 454/10000, Prediction Accuracy = 58.723076923076924%, Loss = 0.010376614303543018
Epoch: 454, Batch Gradient Norm: 1.4885718120255873
Epoch: 454, Batch Gradient Norm after: 1.4885718120255873
Epoch 455/10000, Prediction Accuracy = 58.24999999999999%, Loss = 0.010494364927021356
Epoch: 455, Batch Gradient Norm: 1.6581978767689225
Epoch: 455, Batch Gradient Norm after: 1.6581978767689225
Epoch 456/10000, Prediction Accuracy = 58.411538461538456%, Loss = 0.010603184238649331
Epoch: 456, Batch Gradient Norm: 1.60134297856748
Epoch: 456, Batch Gradient Norm after: 1.60134297856748
Epoch 457/10000, Prediction Accuracy = 58.26153846153847%, Loss = 0.010567117625704179
Epoch: 457, Batch Gradient Norm: 1.4615263628254092
Epoch: 457, Batch Gradient Norm after: 1.4615263628254092
Epoch 458/10000, Prediction Accuracy = 58.47307692307691%, Loss = 0.010470636260624114
Epoch: 458, Batch Gradient Norm: 1.3172586012019423
Epoch: 458, Batch Gradient Norm after: 1.3172586012019423
Epoch 459/10000, Prediction Accuracy = 58.75769230769232%, Loss = 0.010418615232293423
Epoch: 459, Batch Gradient Norm: 1.3877190642911572
Epoch: 459, Batch Gradient Norm after: 1.3877190642911572
Epoch 460/10000, Prediction Accuracy = 58.73846153846153%, Loss = 0.010354849151693858
Epoch: 460, Batch Gradient Norm: 1.5228277268075376
Epoch: 460, Batch Gradient Norm after: 1.5228277268075376
Epoch 461/10000, Prediction Accuracy = 58.434615384615384%, Loss = 0.01052060193167283
Epoch: 461, Batch Gradient Norm: 1.4935750406102277
Epoch: 461, Batch Gradient Norm after: 1.4935750406102277
Epoch 462/10000, Prediction Accuracy = 58.51538461538462%, Loss = 0.010415764668813119
Epoch: 462, Batch Gradient Norm: 1.490208005369983
Epoch: 462, Batch Gradient Norm after: 1.490208005369983
Epoch 463/10000, Prediction Accuracy = 58.60000000000001%, Loss = 0.010439736052201344
Epoch: 463, Batch Gradient Norm: 1.312767101700087
Epoch: 463, Batch Gradient Norm after: 1.312767101700087
Epoch 464/10000, Prediction Accuracy = 58.86153846153846%, Loss = 0.010291735570018109
Epoch: 464, Batch Gradient Norm: 1.3907914041723497
Epoch: 464, Batch Gradient Norm after: 1.3907914041723497
Epoch 465/10000, Prediction Accuracy = 58.58461538461539%, Loss = 0.010342561353284579
Epoch: 465, Batch Gradient Norm: 1.4335466426136967
Epoch: 465, Batch Gradient Norm after: 1.4335466426136967
Epoch 466/10000, Prediction Accuracy = 58.33846153846153%, Loss = 0.010455702503140155
Epoch: 466, Batch Gradient Norm: 1.4545931140703052
Epoch: 466, Batch Gradient Norm after: 1.4545931140703052
Epoch 467/10000, Prediction Accuracy = 58.28846153846154%, Loss = 0.010467129114728708
Epoch: 467, Batch Gradient Norm: 1.4109978674776402
Epoch: 467, Batch Gradient Norm after: 1.4109978674776402
Epoch 468/10000, Prediction Accuracy = 58.73076923076923%, Loss = 0.0103292646459662
Epoch: 468, Batch Gradient Norm: 1.3636695070413167
Epoch: 468, Batch Gradient Norm after: 1.3636695070413167
Epoch 469/10000, Prediction Accuracy = 58.892307692307696%, Loss = 0.010309303895785259
Epoch: 469, Batch Gradient Norm: 1.310009402426403
Epoch: 469, Batch Gradient Norm after: 1.310009402426403
Epoch 470/10000, Prediction Accuracy = 58.9153846153846%, Loss = 0.010283054998860909
Epoch: 470, Batch Gradient Norm: 1.3576431961787012
Epoch: 470, Batch Gradient Norm after: 1.3576431961787012
Epoch 471/10000, Prediction Accuracy = 58.93076923076923%, Loss = 0.01020324187209973
Epoch: 471, Batch Gradient Norm: 1.495463498890142
Epoch: 471, Batch Gradient Norm after: 1.495463498890142
Epoch 472/10000, Prediction Accuracy = 58.24230769230768%, Loss = 0.010350249994259614
Epoch: 472, Batch Gradient Norm: 1.5398159079288165
Epoch: 472, Batch Gradient Norm after: 1.5398159079288165
Epoch 473/10000, Prediction Accuracy = 58.853846153846156%, Loss = 0.010347926630996741
Epoch: 473, Batch Gradient Norm: 1.473827295404571
Epoch: 473, Batch Gradient Norm after: 1.473827295404571
Epoch 474/10000, Prediction Accuracy = 58.5576923076923%, Loss = 0.010336069748378716
Epoch: 474, Batch Gradient Norm: 1.3784819879804815
Epoch: 474, Batch Gradient Norm after: 1.3784819879804815
Epoch 475/10000, Prediction Accuracy = 58.94615384615384%, Loss = 0.010201129560860304
Epoch: 475, Batch Gradient Norm: 1.3986582022808214
Epoch: 475, Batch Gradient Norm after: 1.3986582022808214
Epoch 476/10000, Prediction Accuracy = 58.77307692307692%, Loss = 0.010210408041110406
Epoch: 476, Batch Gradient Norm: 1.6416548780898756
Epoch: 476, Batch Gradient Norm after: 1.6416548780898756
Epoch 477/10000, Prediction Accuracy = 58.80384615384616%, Loss = 0.010409586919614902
Epoch: 477, Batch Gradient Norm: 1.5570775155227554
Epoch: 477, Batch Gradient Norm after: 1.5570775155227554
Epoch 478/10000, Prediction Accuracy = 58.41923076923077%, Loss = 0.010346506364070453
Epoch: 478, Batch Gradient Norm: 1.4335471875248222
Epoch: 478, Batch Gradient Norm after: 1.4335471875248222
Epoch 479/10000, Prediction Accuracy = 58.53076923076923%, Loss = 0.01026139508646268
Epoch: 479, Batch Gradient Norm: 1.5157577919059513
Epoch: 479, Batch Gradient Norm after: 1.5157577919059513
Epoch 480/10000, Prediction Accuracy = 58.54230769230769%, Loss = 0.010223288160677139
Epoch: 480, Batch Gradient Norm: 1.4895754436590103
Epoch: 480, Batch Gradient Norm after: 1.4895754436590103
Epoch 481/10000, Prediction Accuracy = 58.83846153846154%, Loss = 0.010288394557741972
Epoch: 481, Batch Gradient Norm: 1.4579398298538266
Epoch: 481, Batch Gradient Norm after: 1.4579398298538266
Epoch 482/10000, Prediction Accuracy = 58.77692307692307%, Loss = 0.010274668797277488
Epoch: 482, Batch Gradient Norm: 1.540435780633517
Epoch: 482, Batch Gradient Norm after: 1.540435780633517
Epoch 483/10000, Prediction Accuracy = 58.619230769230775%, Loss = 0.010312132752285553
Epoch: 483, Batch Gradient Norm: 1.6561764750440588
Epoch: 483, Batch Gradient Norm after: 1.6561764750440588
Epoch 484/10000, Prediction Accuracy = 58.957692307692305%, Loss = 0.010316378508622829
Epoch: 484, Batch Gradient Norm: 1.6904645059082277
Epoch: 484, Batch Gradient Norm after: 1.6904645059082277
Epoch 485/10000, Prediction Accuracy = 58.36153846153847%, Loss = 0.010441848578361364
Epoch: 485, Batch Gradient Norm: 1.631061751365305
Epoch: 485, Batch Gradient Norm after: 1.631061751365305
Epoch 486/10000, Prediction Accuracy = 58.23076923076922%, Loss = 0.01042070440374888
Epoch: 486, Batch Gradient Norm: 1.6384222932623227
Epoch: 486, Batch Gradient Norm after: 1.6384222932623227
Epoch 487/10000, Prediction Accuracy = 58.484615384615374%, Loss = 0.010366340239460651
Epoch: 487, Batch Gradient Norm: 1.5720045653673957
Epoch: 487, Batch Gradient Norm after: 1.5720045653673957
Epoch 488/10000, Prediction Accuracy = 58.9076923076923%, Loss = 0.010347270120221835
Epoch: 488, Batch Gradient Norm: 1.5850346893061353
Epoch: 488, Batch Gradient Norm after: 1.5850346893061353
Epoch 489/10000, Prediction Accuracy = 58.407692307692315%, Loss = 0.010436936783102842
Epoch: 489, Batch Gradient Norm: 1.4747549963937965
Epoch: 489, Batch Gradient Norm after: 1.4747549963937965
Epoch 490/10000, Prediction Accuracy = 58.63846153846154%, Loss = 0.010312084896633258
Epoch: 490, Batch Gradient Norm: 1.5224619876703436
Epoch: 490, Batch Gradient Norm after: 1.5224619876703436
Epoch 491/10000, Prediction Accuracy = 58.407692307692294%, Loss = 0.010310012703904739
Epoch: 491, Batch Gradient Norm: 1.4799127738814828
Epoch: 491, Batch Gradient Norm after: 1.4799127738814828
Epoch 492/10000, Prediction Accuracy = 58.85000000000001%, Loss = 0.010198906278954102
Epoch: 492, Batch Gradient Norm: 1.5489098132381993
Epoch: 492, Batch Gradient Norm after: 1.5489098132381993
Epoch 493/10000, Prediction Accuracy = 58.865384615384606%, Loss = 0.010274665430188179
Epoch: 493, Batch Gradient Norm: 1.3981882972162136
Epoch: 493, Batch Gradient Norm after: 1.3981882972162136
Epoch 494/10000, Prediction Accuracy = 59.13461538461537%, Loss = 0.010184765291901736
Epoch: 494, Batch Gradient Norm: 1.484016643158881
Epoch: 494, Batch Gradient Norm after: 1.484016643158881
Epoch 495/10000, Prediction Accuracy = 58.8346153846154%, Loss = 0.010255214758217335
Epoch: 495, Batch Gradient Norm: 1.545860817802262
Epoch: 495, Batch Gradient Norm after: 1.545860817802262
Epoch 496/10000, Prediction Accuracy = 59.05769230769231%, Loss = 0.010214180757219974
Epoch: 496, Batch Gradient Norm: 1.594707210547176
Epoch: 496, Batch Gradient Norm after: 1.594707210547176
Epoch 497/10000, Prediction Accuracy = 59.00384615384616%, Loss = 0.010262799377624806
Epoch: 497, Batch Gradient Norm: 1.6419574164578399
Epoch: 497, Batch Gradient Norm after: 1.6419574164578399
Epoch 498/10000, Prediction Accuracy = 58.846153846153854%, Loss = 0.01034081018028351
Epoch: 498, Batch Gradient Norm: 1.5309032748610276
Epoch: 498, Batch Gradient Norm after: 1.5309032748610276
Epoch 499/10000, Prediction Accuracy = 58.84615384615385%, Loss = 0.010204646593103042
Epoch: 499, Batch Gradient Norm: 1.4945925067639978
Epoch: 499, Batch Gradient Norm after: 1.4945925067639978
Epoch 500/10000, Prediction Accuracy = 59.08076923076923%, Loss = 0.01020535883995203
Epoch: 500, Batch Gradient Norm: 1.3911107847200104
Epoch: 500, Batch Gradient Norm after: 1.3911107847200104
Epoch 501/10000, Prediction Accuracy = 59.36538461538461%, Loss = 0.010040266510958854
Epoch: 501, Batch Gradient Norm: 1.331896725479924
Epoch: 501, Batch Gradient Norm after: 1.331896725479924
Epoch 502/10000, Prediction Accuracy = 58.83461538461539%, Loss = 0.01006649026217369
Epoch: 502, Batch Gradient Norm: 1.4524664628685071
Epoch: 502, Batch Gradient Norm after: 1.4524664628685071
Epoch 503/10000, Prediction Accuracy = 59.4076923076923%, Loss = 0.010080513902581655
Epoch: 503, Batch Gradient Norm: 1.4074158230571618
Epoch: 503, Batch Gradient Norm after: 1.4074158230571618
Epoch 504/10000, Prediction Accuracy = 59.280769230769224%, Loss = 0.010041395130638894
Epoch: 504, Batch Gradient Norm: 1.5611496449680498
Epoch: 504, Batch Gradient Norm after: 1.5611496449680498
Epoch 505/10000, Prediction Accuracy = 58.846153846153854%, Loss = 0.01016874324816924
Epoch: 505, Batch Gradient Norm: 1.5069248552095384
Epoch: 505, Batch Gradient Norm after: 1.5069248552095384
Epoch 506/10000, Prediction Accuracy = 58.85384615384615%, Loss = 0.010211162340755645
Epoch: 506, Batch Gradient Norm: 1.5374230485876808
Epoch: 506, Batch Gradient Norm after: 1.5374230485876808
Epoch 507/10000, Prediction Accuracy = 58.91153846153846%, Loss = 0.010218195115717558
Epoch: 507, Batch Gradient Norm: 1.4653546753214588
Epoch: 507, Batch Gradient Norm after: 1.4653546753214588
Epoch 508/10000, Prediction Accuracy = 59.276923076923076%, Loss = 0.01004962121637968
Epoch: 508, Batch Gradient Norm: 1.4496526390401268
Epoch: 508, Batch Gradient Norm after: 1.4496526390401268
Epoch 509/10000, Prediction Accuracy = 59.315384615384616%, Loss = 0.010153316319561921
Epoch: 509, Batch Gradient Norm: 1.4203276245287635
Epoch: 509, Batch Gradient Norm after: 1.4203276245287635
Epoch 510/10000, Prediction Accuracy = 59.25%, Loss = 0.009969529839089284
Epoch: 510, Batch Gradient Norm: 1.6520641396381783
Epoch: 510, Batch Gradient Norm after: 1.6520641396381783
Epoch 511/10000, Prediction Accuracy = 58.926923076923075%, Loss = 0.01026687162140241
Epoch: 511, Batch Gradient Norm: 1.6124082629903442
Epoch: 511, Batch Gradient Norm after: 1.6124082629903442
Epoch 512/10000, Prediction Accuracy = 58.59615384615385%, Loss = 0.010261203592213301
Epoch: 512, Batch Gradient Norm: 1.5801953383095948
Epoch: 512, Batch Gradient Norm after: 1.5801953383095948
Epoch 513/10000, Prediction Accuracy = 58.98846153846154%, Loss = 0.010260330942960886
Epoch: 513, Batch Gradient Norm: 1.528586338145878
Epoch: 513, Batch Gradient Norm after: 1.528586338145878
Epoch 514/10000, Prediction Accuracy = 59.29615384615384%, Loss = 0.010101119557825418
Epoch: 514, Batch Gradient Norm: 1.460239925621022
Epoch: 514, Batch Gradient Norm after: 1.460239925621022
Epoch 515/10000, Prediction Accuracy = 59.45769230769231%, Loss = 0.010112397014521636
Epoch: 515, Batch Gradient Norm: 1.480660761890695
Epoch: 515, Batch Gradient Norm after: 1.480660761890695
Epoch 516/10000, Prediction Accuracy = 59.43076923076924%, Loss = 0.010045570321381092
Epoch: 516, Batch Gradient Norm: 1.4298608329397178
Epoch: 516, Batch Gradient Norm after: 1.4298608329397178
Epoch 517/10000, Prediction Accuracy = 59.26923076923077%, Loss = 0.010000287698438535
Epoch: 517, Batch Gradient Norm: 1.4606391382658177
Epoch: 517, Batch Gradient Norm after: 1.4606391382658177
Epoch 518/10000, Prediction Accuracy = 59.29615384615385%, Loss = 0.010015424914084949
Epoch: 518, Batch Gradient Norm: 1.7124374426773497
Epoch: 518, Batch Gradient Norm after: 1.7124374426773497
Epoch 519/10000, Prediction Accuracy = 58.73461538461538%, Loss = 0.01022344440794908
Epoch: 519, Batch Gradient Norm: 1.6999539009314462
Epoch: 519, Batch Gradient Norm after: 1.6999539009314462
Epoch 520/10000, Prediction Accuracy = 58.638461538461534%, Loss = 0.010287111195234152
Epoch: 520, Batch Gradient Norm: 1.6401105638595652
Epoch: 520, Batch Gradient Norm after: 1.6401105638595652
Epoch 521/10000, Prediction Accuracy = 58.77307692307692%, Loss = 0.010192680244262401
Epoch: 521, Batch Gradient Norm: 1.5051078949419316
Epoch: 521, Batch Gradient Norm after: 1.5051078949419316
Epoch 522/10000, Prediction Accuracy = 59.15384615384615%, Loss = 0.01008510159758421
Epoch: 522, Batch Gradient Norm: 1.6431456767737598
Epoch: 522, Batch Gradient Norm after: 1.6431456767737598
Epoch 523/10000, Prediction Accuracy = 58.83461538461539%, Loss = 0.010160609291723141
Epoch: 523, Batch Gradient Norm: 1.6719047380367082
Epoch: 523, Batch Gradient Norm after: 1.6719047380367082
Epoch 524/10000, Prediction Accuracy = 58.56923076923078%, Loss = 0.010294347786559509
Epoch: 524, Batch Gradient Norm: 1.430802886541892
Epoch: 524, Batch Gradient Norm after: 1.430802886541892
Epoch 525/10000, Prediction Accuracy = 59.284615384615385%, Loss = 0.00999279384716199
Epoch: 525, Batch Gradient Norm: 1.4746855536733388
Epoch: 525, Batch Gradient Norm after: 1.4746855536733388
Epoch 526/10000, Prediction Accuracy = 59.71538461538463%, Loss = 0.010056934032875758
Epoch: 526, Batch Gradient Norm: 1.5004550089353095
Epoch: 526, Batch Gradient Norm after: 1.5004550089353095
Epoch 527/10000, Prediction Accuracy = 59.31153846153846%, Loss = 0.010073879733681679
Epoch: 527, Batch Gradient Norm: 1.525040048582956
Epoch: 527, Batch Gradient Norm after: 1.525040048582956
Epoch 528/10000, Prediction Accuracy = 59.388461538461534%, Loss = 0.010081919053426156
Epoch: 528, Batch Gradient Norm: 1.6997379360069091
Epoch: 528, Batch Gradient Norm after: 1.6997379360069091
Epoch 529/10000, Prediction Accuracy = 58.95769230769231%, Loss = 0.010210076776834635
Epoch: 529, Batch Gradient Norm: 1.4568741745269203
Epoch: 529, Batch Gradient Norm after: 1.4568741745269203
Epoch 530/10000, Prediction Accuracy = 59.54230769230769%, Loss = 0.01001139715887033
Epoch: 530, Batch Gradient Norm: 1.4653078708494494
Epoch: 530, Batch Gradient Norm after: 1.4653078708494494
Epoch 531/10000, Prediction Accuracy = 59.23461538461538%, Loss = 0.010034324314731818
Epoch: 531, Batch Gradient Norm: 1.563967572232939
Epoch: 531, Batch Gradient Norm after: 1.563967572232939
Epoch 532/10000, Prediction Accuracy = 59.23846153846154%, Loss = 0.010091320468256107
Epoch: 532, Batch Gradient Norm: 1.4885449476558714
Epoch: 532, Batch Gradient Norm after: 1.4885449476558714
Epoch 533/10000, Prediction Accuracy = 59.69615384615384%, Loss = 0.009975255395357426
Epoch: 533, Batch Gradient Norm: 1.5886873751430755
Epoch: 533, Batch Gradient Norm after: 1.5886873751430755
Epoch 534/10000, Prediction Accuracy = 59.223076923076924%, Loss = 0.010070948789899167
Epoch: 534, Batch Gradient Norm: 1.5415420577120844
Epoch: 534, Batch Gradient Norm after: 1.5415420577120844
Epoch 535/10000, Prediction Accuracy = 59.54615384615383%, Loss = 0.010018557453384766
Epoch: 535, Batch Gradient Norm: 1.4238441585642119
Epoch: 535, Batch Gradient Norm after: 1.4238441585642119
Epoch 536/10000, Prediction Accuracy = 59.63846153846154%, Loss = 0.009905793632452305
Epoch: 536, Batch Gradient Norm: 1.6340224506172636
Epoch: 536, Batch Gradient Norm after: 1.6340224506172636
Epoch 537/10000, Prediction Accuracy = 58.934615384615384%, Loss = 0.010094987228512764
Epoch: 537, Batch Gradient Norm: 1.614763899736779
Epoch: 537, Batch Gradient Norm after: 1.614763899736779
Epoch 538/10000, Prediction Accuracy = 58.87307692307692%, Loss = 0.010100940815531291
Epoch: 538, Batch Gradient Norm: 1.554403458862882
Epoch: 538, Batch Gradient Norm after: 1.554403458862882
Epoch 539/10000, Prediction Accuracy = 59.638461538461534%, Loss = 0.010029303769652661
Epoch: 539, Batch Gradient Norm: 1.5939833135061257
Epoch: 539, Batch Gradient Norm after: 1.5939833135061257
Epoch 540/10000, Prediction Accuracy = 59.11538461538461%, Loss = 0.010098904872742983
Epoch: 540, Batch Gradient Norm: 1.6016867941547759
Epoch: 540, Batch Gradient Norm after: 1.6016867941547759
Epoch 541/10000, Prediction Accuracy = 59.40384615384615%, Loss = 0.010071109478863386
Epoch: 541, Batch Gradient Norm: 1.5710849785716599
Epoch: 541, Batch Gradient Norm after: 1.5710849785716599
Epoch 542/10000, Prediction Accuracy = 59.05384615384615%, Loss = 0.01012957339676527
Epoch: 542, Batch Gradient Norm: 1.5728820822577447
Epoch: 542, Batch Gradient Norm after: 1.5728820822577447
Epoch 543/10000, Prediction Accuracy = 58.77307692307693%, Loss = 0.01012452863729917
Epoch: 543, Batch Gradient Norm: 1.5492680477606027
Epoch: 543, Batch Gradient Norm after: 1.5492680477606027
Epoch 544/10000, Prediction Accuracy = 59.12307692307692%, Loss = 0.010090018550936993
Epoch: 544, Batch Gradient Norm: 1.6615428876123952
Epoch: 544, Batch Gradient Norm after: 1.6615428876123952
Epoch 545/10000, Prediction Accuracy = 58.853846153846156%, Loss = 0.010154338625188056
Epoch: 545, Batch Gradient Norm: 1.6631469024822325
Epoch: 545, Batch Gradient Norm after: 1.6631469024822325
Epoch 546/10000, Prediction Accuracy = 59.11153846153846%, Loss = 0.01014089398086071
Epoch: 546, Batch Gradient Norm: 1.4306288815488688
Epoch: 546, Batch Gradient Norm after: 1.4306288815488688
Epoch 547/10000, Prediction Accuracy = 59.55%, Loss = 0.009906956997628395
Epoch: 547, Batch Gradient Norm: 1.4991969943739532
Epoch: 547, Batch Gradient Norm after: 1.4991969943739532
Epoch 548/10000, Prediction Accuracy = 59.29230769230768%, Loss = 0.009993479802058293
Epoch: 548, Batch Gradient Norm: 1.4639631380330946
Epoch: 548, Batch Gradient Norm after: 1.4639631380330946
Epoch 549/10000, Prediction Accuracy = 59.634615384615394%, Loss = 0.009894326615792055
Epoch: 549, Batch Gradient Norm: 1.5864633608895795
Epoch: 549, Batch Gradient Norm after: 1.5864633608895795
Epoch 550/10000, Prediction Accuracy = 59.33076923076923%, Loss = 0.009964689684028808
Epoch: 550, Batch Gradient Norm: 1.6379669532880816
Epoch: 550, Batch Gradient Norm after: 1.6379669532880816
Epoch 551/10000, Prediction Accuracy = 59.39999999999999%, Loss = 0.009996826330629678
Epoch: 551, Batch Gradient Norm: 1.6251332777436576
Epoch: 551, Batch Gradient Norm after: 1.6251332777436576
Epoch 552/10000, Prediction Accuracy = 59.12307692307692%, Loss = 0.010068786402161304
Epoch: 552, Batch Gradient Norm: 1.5950436776651156
Epoch: 552, Batch Gradient Norm after: 1.5950436776651156
Epoch 553/10000, Prediction Accuracy = 59.619230769230775%, Loss = 0.010047084436966823
Epoch: 553, Batch Gradient Norm: 1.62522670669537
Epoch: 553, Batch Gradient Norm after: 1.62522670669537
Epoch 554/10000, Prediction Accuracy = 59.599999999999994%, Loss = 0.009960004844917702
Epoch: 554, Batch Gradient Norm: 1.4407246196218328
Epoch: 554, Batch Gradient Norm after: 1.4407246196218328
Epoch 555/10000, Prediction Accuracy = 59.63461538461539%, Loss = 0.009901524306489872
Epoch: 555, Batch Gradient Norm: 1.6407959003480403
Epoch: 555, Batch Gradient Norm after: 1.6407959003480403
Epoch 556/10000, Prediction Accuracy = 59.13461538461539%, Loss = 0.010100536406613313
Epoch: 556, Batch Gradient Norm: 1.5744282798037252
Epoch: 556, Batch Gradient Norm after: 1.5744282798037252
Epoch 557/10000, Prediction Accuracy = 59.56923076923078%, Loss = 0.009959461382375313
Epoch: 557, Batch Gradient Norm: 1.447678740383557
Epoch: 557, Batch Gradient Norm after: 1.447678740383557
Epoch 558/10000, Prediction Accuracy = 59.7%, Loss = 0.009916650131344795
Epoch: 558, Batch Gradient Norm: 1.6231984990150627
Epoch: 558, Batch Gradient Norm after: 1.6231984990150627
Epoch 559/10000, Prediction Accuracy = 59.56923076923077%, Loss = 0.010010916882982621
Epoch: 559, Batch Gradient Norm: 1.5859744054376517
Epoch: 559, Batch Gradient Norm after: 1.5859744054376517
Epoch 560/10000, Prediction Accuracy = 59.42692307692307%, Loss = 0.009963002915565785
Epoch: 560, Batch Gradient Norm: 1.5619477453401494
Epoch: 560, Batch Gradient Norm after: 1.5619477453401494
Epoch 561/10000, Prediction Accuracy = 59.29230769230768%, Loss = 0.00994084209490281
Epoch: 561, Batch Gradient Norm: 1.5126606412144834
Epoch: 561, Batch Gradient Norm after: 1.5126606412144834
Epoch 562/10000, Prediction Accuracy = 59.45384615384616%, Loss = 0.009921238399468936
Epoch: 562, Batch Gradient Norm: 1.5833306821486004
Epoch: 562, Batch Gradient Norm after: 1.5833306821486004
Epoch 563/10000, Prediction Accuracy = 59.6576923076923%, Loss = 0.010043355779579053
Epoch: 563, Batch Gradient Norm: 1.4764411608046135
Epoch: 563, Batch Gradient Norm after: 1.4764411608046135
Epoch 564/10000, Prediction Accuracy = 59.71153846153847%, Loss = 0.009883212785308178
Epoch: 564, Batch Gradient Norm: 1.5208991003834984
Epoch: 564, Batch Gradient Norm after: 1.5208991003834984
Epoch 565/10000, Prediction Accuracy = 59.857692307692304%, Loss = 0.00985013829687467
Epoch: 565, Batch Gradient Norm: 1.4115474962203638
Epoch: 565, Batch Gradient Norm after: 1.4115474962203638
Epoch 566/10000, Prediction Accuracy = 59.8923076923077%, Loss = 0.009817867396542659
Epoch: 566, Batch Gradient Norm: 1.5254759120610426
Epoch: 566, Batch Gradient Norm after: 1.5254759120610426
Epoch 567/10000, Prediction Accuracy = 59.56923076923078%, Loss = 0.009944176946121912
Epoch: 567, Batch Gradient Norm: 1.4618495791881119
Epoch: 567, Batch Gradient Norm after: 1.4618495791881119
Epoch 568/10000, Prediction Accuracy = 59.61153846153846%, Loss = 0.009805770304340582
Epoch: 568, Batch Gradient Norm: 1.5530062482305451
Epoch: 568, Batch Gradient Norm after: 1.5530062482305451
Epoch 569/10000, Prediction Accuracy = 59.6576923076923%, Loss = 0.009820763021707535
Epoch: 569, Batch Gradient Norm: 1.6589805914850764
Epoch: 569, Batch Gradient Norm after: 1.6589805914850764
Epoch 570/10000, Prediction Accuracy = 59.21923076923077%, Loss = 0.010028051642271189
Epoch: 570, Batch Gradient Norm: 1.6012803591511975
Epoch: 570, Batch Gradient Norm after: 1.6012803591511975
Epoch 571/10000, Prediction Accuracy = 59.23461538461538%, Loss = 0.00997896478153192
Epoch: 571, Batch Gradient Norm: 1.5983646530092452
Epoch: 571, Batch Gradient Norm after: 1.5983646530092452
Epoch 572/10000, Prediction Accuracy = 59.338461538461544%, Loss = 0.010009023504188428
Epoch: 572, Batch Gradient Norm: 1.6232477433785375
Epoch: 572, Batch Gradient Norm after: 1.6232477433785375
Epoch 573/10000, Prediction Accuracy = 59.61923076923077%, Loss = 0.010011714596587878
Epoch: 573, Batch Gradient Norm: 1.4241188746624054
Epoch: 573, Batch Gradient Norm after: 1.4241188746624054
Epoch 574/10000, Prediction Accuracy = 59.72692307692308%, Loss = 0.00978633166792301
Epoch: 574, Batch Gradient Norm: 1.5467479306628928
Epoch: 574, Batch Gradient Norm after: 1.5467479306628928
Epoch 575/10000, Prediction Accuracy = 59.43846153846154%, Loss = 0.009857907533072509
Epoch: 575, Batch Gradient Norm: 1.574111117911214
Epoch: 575, Batch Gradient Norm after: 1.574111117911214
Epoch 576/10000, Prediction Accuracy = 59.699999999999996%, Loss = 0.009977472301286
Epoch: 576, Batch Gradient Norm: 1.5541054401299588
Epoch: 576, Batch Gradient Norm after: 1.5541054401299588
Epoch 577/10000, Prediction Accuracy = 59.73076923076923%, Loss = 0.009903144736129504
Epoch: 577, Batch Gradient Norm: 1.531121124729297
Epoch: 577, Batch Gradient Norm after: 1.531121124729297
Epoch 578/10000, Prediction Accuracy = 59.81153846153847%, Loss = 0.009868909604847431
Epoch: 578, Batch Gradient Norm: 1.4293571758243147
Epoch: 578, Batch Gradient Norm after: 1.4293571758243147
Epoch 579/10000, Prediction Accuracy = 59.842307692307685%, Loss = 0.009831088236891307
Epoch: 579, Batch Gradient Norm: 1.6899478993314363
Epoch: 579, Batch Gradient Norm after: 1.6899478993314363
Epoch 580/10000, Prediction Accuracy = 58.83846153846154%, Loss = 0.010057027380053814
Epoch: 580, Batch Gradient Norm: 1.5967794864807097
Epoch: 580, Batch Gradient Norm after: 1.5967794864807097
Epoch 581/10000, Prediction Accuracy = 59.23846153846155%, Loss = 0.01004948502836319
Epoch: 581, Batch Gradient Norm: 1.5715577430017542
Epoch: 581, Batch Gradient Norm after: 1.5715577430017542
Epoch 582/10000, Prediction Accuracy = 59.71923076923076%, Loss = 0.009926962881134106
Epoch: 582, Batch Gradient Norm: 1.7541210751365233
Epoch: 582, Batch Gradient Norm after: 1.7541210751365233
Epoch 583/10000, Prediction Accuracy = 59.31153846153846%, Loss = 0.01014611841394351
Epoch: 583, Batch Gradient Norm: 1.669697709999605
Epoch: 583, Batch Gradient Norm after: 1.669697709999605
Epoch 584/10000, Prediction Accuracy = 59.42692307692308%, Loss = 0.010062975235856496
Epoch: 584, Batch Gradient Norm: 1.4222858254703217
Epoch: 584, Batch Gradient Norm after: 1.4222858254703217
Epoch 585/10000, Prediction Accuracy = 60.01153846153845%, Loss = 0.009843216707500128
Epoch: 585, Batch Gradient Norm: 1.501335021485992
Epoch: 585, Batch Gradient Norm after: 1.501335021485992
Epoch 586/10000, Prediction Accuracy = 59.63076923076923%, Loss = 0.00989952117491227
Epoch: 586, Batch Gradient Norm: 1.5040002972121846
Epoch: 586, Batch Gradient Norm after: 1.5040002972121846
Epoch 587/10000, Prediction Accuracy = 60.23076923076922%, Loss = 0.009875958857054893
Epoch: 587, Batch Gradient Norm: 1.5095689333550841
Epoch: 587, Batch Gradient Norm after: 1.5095689333550841
Epoch 588/10000, Prediction Accuracy = 59.97692307692307%, Loss = 0.009864612482488155
Epoch: 588, Batch Gradient Norm: 1.5949332999941752
Epoch: 588, Batch Gradient Norm after: 1.5949332999941752
Epoch 589/10000, Prediction Accuracy = 59.60769230769232%, Loss = 0.009973713411734654
Epoch: 589, Batch Gradient Norm: 1.5198311081994587
Epoch: 589, Batch Gradient Norm after: 1.5198311081994587
Epoch 590/10000, Prediction Accuracy = 59.58076923076923%, Loss = 0.009885275664810952
Epoch: 590, Batch Gradient Norm: 1.6408985708659622
Epoch: 590, Batch Gradient Norm after: 1.6408985708659622
Epoch 591/10000, Prediction Accuracy = 59.85769230769232%, Loss = 0.009949339911914788
Epoch: 591, Batch Gradient Norm: 1.7003260843475927
Epoch: 591, Batch Gradient Norm after: 1.7003260843475927
Epoch 592/10000, Prediction Accuracy = 59.38076923076923%, Loss = 0.010001578511526952
Epoch: 592, Batch Gradient Norm: 1.4227360416194874
Epoch: 592, Batch Gradient Norm after: 1.4227360416194874
Epoch 593/10000, Prediction Accuracy = 59.76538461538461%, Loss = 0.009829162261807002
Epoch: 593, Batch Gradient Norm: 1.4361385308897248
Epoch: 593, Batch Gradient Norm after: 1.4361385308897248
Epoch 594/10000, Prediction Accuracy = 59.53076923076923%, Loss = 0.009820499815619908
Epoch: 594, Batch Gradient Norm: 1.6090159366389039
Epoch: 594, Batch Gradient Norm after: 1.6090159366389039
Epoch 595/10000, Prediction Accuracy = 59.76923076923077%, Loss = 0.009911589539394928
Epoch: 595, Batch Gradient Norm: 1.6127061757391883
Epoch: 595, Batch Gradient Norm after: 1.6127061757391883
Epoch 596/10000, Prediction Accuracy = 59.39230769230768%, Loss = 0.009973570202978758
Epoch: 596, Batch Gradient Norm: 1.4548650384394402
Epoch: 596, Batch Gradient Norm after: 1.4548650384394402
Epoch 597/10000, Prediction Accuracy = 59.91538461538461%, Loss = 0.00982410955027892
Epoch: 597, Batch Gradient Norm: 1.4671681668485526
Epoch: 597, Batch Gradient Norm after: 1.4671681668485526
Epoch 598/10000, Prediction Accuracy = 60.29615384615385%, Loss = 0.009743244888690801
Epoch: 598, Batch Gradient Norm: 1.5430030110993764
Epoch: 598, Batch Gradient Norm after: 1.5430030110993764
Epoch 599/10000, Prediction Accuracy = 59.75%, Loss = 0.009797433534493813
Epoch: 599, Batch Gradient Norm: 1.6483640523578682
Epoch: 599, Batch Gradient Norm after: 1.6483640523578682
Epoch 600/10000, Prediction Accuracy = 59.78846153846154%, Loss = 0.009916199657779474
Epoch: 600, Batch Gradient Norm: 1.6510925862131212
Epoch: 600, Batch Gradient Norm after: 1.6510925862131212
Epoch 601/10000, Prediction Accuracy = 59.607692307692304%, Loss = 0.009996178058477549
Epoch: 601, Batch Gradient Norm: 1.5945688100000124
Epoch: 601, Batch Gradient Norm after: 1.5945688100000124
Epoch 602/10000, Prediction Accuracy = 59.63076923076922%, Loss = 0.00994322312852511
Epoch: 602, Batch Gradient Norm: 1.5814738212801303
Epoch: 602, Batch Gradient Norm after: 1.5814738212801303
Epoch 603/10000, Prediction Accuracy = 59.54615384615384%, Loss = 0.00990739414611688
Epoch: 603, Batch Gradient Norm: 1.5960661630620132
Epoch: 603, Batch Gradient Norm after: 1.5960661630620132
Epoch 604/10000, Prediction Accuracy = 59.62307692307694%, Loss = 0.009897021648402397
Epoch: 604, Batch Gradient Norm: 1.5067895541447949
Epoch: 604, Batch Gradient Norm after: 1.5067895541447949
Epoch 605/10000, Prediction Accuracy = 59.77307692307692%, Loss = 0.009950074940346755
Epoch: 605, Batch Gradient Norm: 1.6319319280294953
Epoch: 605, Batch Gradient Norm after: 1.6319319280294953
Epoch 606/10000, Prediction Accuracy = 59.56538461538461%, Loss = 0.009929709136486053
Epoch: 606, Batch Gradient Norm: 1.6360955360615175
Epoch: 606, Batch Gradient Norm after: 1.6360955360615175
Epoch 607/10000, Prediction Accuracy = 59.51538461538461%, Loss = 0.009960560844494747
Epoch: 607, Batch Gradient Norm: 1.5583465600358937
Epoch: 607, Batch Gradient Norm after: 1.5583465600358937
Epoch 608/10000, Prediction Accuracy = 59.45384615384616%, Loss = 0.009907746759171668
Epoch: 608, Batch Gradient Norm: 1.5678853756195335
Epoch: 608, Batch Gradient Norm after: 1.5678853756195335
Epoch 609/10000, Prediction Accuracy = 59.842307692307685%, Loss = 0.009880882472946094
Epoch: 609, Batch Gradient Norm: 1.5515762626022345
Epoch: 609, Batch Gradient Norm after: 1.5515762626022345
Epoch 610/10000, Prediction Accuracy = 59.71923076923076%, Loss = 0.009820517725669421
Epoch: 610, Batch Gradient Norm: 1.487823025575755
Epoch: 610, Batch Gradient Norm after: 1.487823025575755
Epoch 611/10000, Prediction Accuracy = 59.50384615384614%, Loss = 0.009828383389573831
Epoch: 611, Batch Gradient Norm: 1.5845371831453812
Epoch: 611, Batch Gradient Norm after: 1.5845371831453812
Epoch 612/10000, Prediction Accuracy = 59.223076923076924%, Loss = 0.009915083073652707
Epoch: 612, Batch Gradient Norm: 1.4736284789751877
Epoch: 612, Batch Gradient Norm after: 1.4736284789751877
Epoch 613/10000, Prediction Accuracy = 59.6076923076923%, Loss = 0.009831359180120321
Epoch: 613, Batch Gradient Norm: 1.3936221516551226
Epoch: 613, Batch Gradient Norm after: 1.3936221516551226
Epoch 614/10000, Prediction Accuracy = 60.39230769230768%, Loss = 0.009731333344601668
Epoch: 614, Batch Gradient Norm: 1.3683836421531763
Epoch: 614, Batch Gradient Norm after: 1.3683836421531763
Epoch 615/10000, Prediction Accuracy = 60.27692307692307%, Loss = 0.009664439954436742
Epoch: 615, Batch Gradient Norm: 1.5115061791634379
Epoch: 615, Batch Gradient Norm after: 1.5115061791634379
Epoch 616/10000, Prediction Accuracy = 59.85384615384615%, Loss = 0.009748306053762253
Epoch: 616, Batch Gradient Norm: 1.654869224428646
Epoch: 616, Batch Gradient Norm after: 1.654869224428646
Epoch 617/10000, Prediction Accuracy = 60.138461538461534%, Loss = 0.009845563067266574
Epoch: 617, Batch Gradient Norm: 1.6122992486117051
Epoch: 617, Batch Gradient Norm after: 1.6122992486117051
Epoch 618/10000, Prediction Accuracy = 59.76923076923077%, Loss = 0.009917416466543308
Epoch: 618, Batch Gradient Norm: 1.6061938815004169
Epoch: 618, Batch Gradient Norm after: 1.6061938815004169
Epoch 619/10000, Prediction Accuracy = 59.38461538461539%, Loss = 0.009976311801717831
Epoch: 619, Batch Gradient Norm: 1.7128557594871057
Epoch: 619, Batch Gradient Norm after: 1.7128557594871057
Epoch 620/10000, Prediction Accuracy = 59.400000000000006%, Loss = 0.009995394457991306
Epoch: 620, Batch Gradient Norm: 1.790425145933882
Epoch: 620, Batch Gradient Norm after: 1.790425145933882
Epoch 621/10000, Prediction Accuracy = 59.28076923076923%, Loss = 0.010038636481532684
Epoch: 621, Batch Gradient Norm: 1.6391220898706458
Epoch: 621, Batch Gradient Norm after: 1.6391220898706458
Epoch 622/10000, Prediction Accuracy = 59.223076923076924%, Loss = 0.009991730778263165
Epoch: 622, Batch Gradient Norm: 1.6186786294016868
Epoch: 622, Batch Gradient Norm after: 1.6186786294016868
Epoch 623/10000, Prediction Accuracy = 59.29230769230769%, Loss = 0.009962783983120551
Epoch: 623, Batch Gradient Norm: 1.6276342330921603
Epoch: 623, Batch Gradient Norm after: 1.6276342330921603
Epoch 624/10000, Prediction Accuracy = 59.223076923076924%, Loss = 0.009980140182261284
Epoch: 624, Batch Gradient Norm: 1.4861533303115577
Epoch: 624, Batch Gradient Norm after: 1.4861533303115577
Epoch 625/10000, Prediction Accuracy = 59.9423076923077%, Loss = 0.009824734396086289
Epoch: 625, Batch Gradient Norm: 1.4526711497757392
Epoch: 625, Batch Gradient Norm after: 1.4526711497757392
Epoch 626/10000, Prediction Accuracy = 59.861538461538466%, Loss = 0.009788917592511727
Epoch: 626, Batch Gradient Norm: 1.3945248133670565
Epoch: 626, Batch Gradient Norm after: 1.3945248133670565
Epoch 627/10000, Prediction Accuracy = 59.896153846153844%, Loss = 0.009745758385039292
Epoch: 627, Batch Gradient Norm: 1.5729944545812333
Epoch: 627, Batch Gradient Norm after: 1.5729944545812333
Epoch 628/10000, Prediction Accuracy = 59.79615384615385%, Loss = 0.009864786281608619
Epoch: 628, Batch Gradient Norm: 1.598909490897995
Epoch: 628, Batch Gradient Norm after: 1.598909490897995
Epoch 629/10000, Prediction Accuracy = 59.95384615384615%, Loss = 0.009862316414140739
Epoch: 629, Batch Gradient Norm: 1.7777675821770402
Epoch: 629, Batch Gradient Norm after: 1.7777675821770402
Epoch 630/10000, Prediction Accuracy = 59.12307692307692%, Loss = 0.010054307846495738
Epoch: 630, Batch Gradient Norm: 1.7520834551523234
Epoch: 630, Batch Gradient Norm after: 1.7520834551523234
Epoch 631/10000, Prediction Accuracy = 59.407692307692315%, Loss = 0.010101964195760397
Epoch: 631, Batch Gradient Norm: 1.6103858499446826
Epoch: 631, Batch Gradient Norm after: 1.6103858499446826
Epoch 632/10000, Prediction Accuracy = 59.30769230769231%, Loss = 0.009995635240696944
Epoch: 632, Batch Gradient Norm: 1.421188374241348
Epoch: 632, Batch Gradient Norm after: 1.421188374241348
Epoch 633/10000, Prediction Accuracy = 59.903846153846146%, Loss = 0.009831874488064876
Epoch: 633, Batch Gradient Norm: 1.5077041392750903
Epoch: 633, Batch Gradient Norm after: 1.5077041392750903
Epoch 634/10000, Prediction Accuracy = 60.07692307692308%, Loss = 0.00990203252205482
Epoch: 634, Batch Gradient Norm: 1.5606305047069702
Epoch: 634, Batch Gradient Norm after: 1.5606305047069702
Epoch 635/10000, Prediction Accuracy = 59.7423076923077%, Loss = 0.009939085477246689
Epoch: 635, Batch Gradient Norm: 1.5889060150945813
Epoch: 635, Batch Gradient Norm after: 1.5889060150945813
Epoch 636/10000, Prediction Accuracy = 59.41153846153847%, Loss = 0.00993846758053853
Epoch: 636, Batch Gradient Norm: 1.635984297697539
Epoch: 636, Batch Gradient Norm after: 1.635984297697539
Epoch 637/10000, Prediction Accuracy = 59.973076923076924%, Loss = 0.009957368987110944
Epoch: 637, Batch Gradient Norm: 1.4889789888905607
Epoch: 637, Batch Gradient Norm after: 1.4889789888905607
Epoch 638/10000, Prediction Accuracy = 59.99615384615384%, Loss = 0.009874068702069612
Epoch: 638, Batch Gradient Norm: 1.5257502094747217
Epoch: 638, Batch Gradient Norm after: 1.5257502094747217
Epoch 639/10000, Prediction Accuracy = 59.89615384615385%, Loss = 0.009884507180406498
Epoch: 639, Batch Gradient Norm: 1.542083509708814
Epoch: 639, Batch Gradient Norm after: 1.542083509708814
Epoch 640/10000, Prediction Accuracy = 59.72307692307693%, Loss = 0.009854570747568058
Epoch: 640, Batch Gradient Norm: 1.582428157841651
Epoch: 640, Batch Gradient Norm after: 1.582428157841651
Epoch 641/10000, Prediction Accuracy = 59.92307692307691%, Loss = 0.009866995450395804
Epoch: 641, Batch Gradient Norm: 1.500044768985686
Epoch: 641, Batch Gradient Norm after: 1.500044768985686
Epoch 642/10000, Prediction Accuracy = 59.965384615384615%, Loss = 0.009834741457150532
Epoch: 642, Batch Gradient Norm: 1.533590743906756
Epoch: 642, Batch Gradient Norm after: 1.533590743906756
Epoch 643/10000, Prediction Accuracy = 59.75769230769231%, Loss = 0.009910849281228505
Epoch: 643, Batch Gradient Norm: 1.511771246786925
Epoch: 643, Batch Gradient Norm after: 1.511771246786925
Epoch 644/10000, Prediction Accuracy = 59.90000000000001%, Loss = 0.009813277409053765
Epoch: 644, Batch Gradient Norm: 1.5078466309502547
Epoch: 644, Batch Gradient Norm after: 1.5078466309502547
Epoch 645/10000, Prediction Accuracy = 59.51923076923077%, Loss = 0.009879628339639077
Epoch: 645, Batch Gradient Norm: 1.458618869836268
Epoch: 645, Batch Gradient Norm after: 1.458618869836268
Epoch 646/10000, Prediction Accuracy = 59.91153846153846%, Loss = 0.009807913205944575
Epoch: 646, Batch Gradient Norm: 1.6003675454498176
Epoch: 646, Batch Gradient Norm after: 1.6003675454498176
Epoch 647/10000, Prediction Accuracy = 59.48076923076923%, Loss = 0.00992777284521323
Epoch: 647, Batch Gradient Norm: 1.6310097221245017
Epoch: 647, Batch Gradient Norm after: 1.6310097221245017
Epoch 648/10000, Prediction Accuracy = 59.353846153846156%, Loss = 0.009972823282273916
Epoch: 648, Batch Gradient Norm: 1.5679248403972124
Epoch: 648, Batch Gradient Norm after: 1.5679248403972124
Epoch 649/10000, Prediction Accuracy = 59.71923076923076%, Loss = 0.009938008868350433
Epoch: 649, Batch Gradient Norm: 1.6555056794860494
Epoch: 649, Batch Gradient Norm after: 1.6555056794860494
Epoch 650/10000, Prediction Accuracy = 59.42307692307691%, Loss = 0.009949953510211064
Epoch: 650, Batch Gradient Norm: 1.670543130287323
Epoch: 650, Batch Gradient Norm after: 1.670543130287323
Epoch 651/10000, Prediction Accuracy = 59.650000000000006%, Loss = 0.009962482664447565
Epoch: 651, Batch Gradient Norm: 1.6803984976794533
Epoch: 651, Batch Gradient Norm after: 1.6803984976794533
Epoch 652/10000, Prediction Accuracy = 59.346153846153854%, Loss = 0.010081335973854248
Epoch: 652, Batch Gradient Norm: 1.7589346298206798
Epoch: 652, Batch Gradient Norm after: 1.7589346298206798
Epoch 653/10000, Prediction Accuracy = 59.60000000000001%, Loss = 0.010053236610614337
Epoch: 653, Batch Gradient Norm: 1.6169970499593964
Epoch: 653, Batch Gradient Norm after: 1.6169970499593964
Epoch 654/10000, Prediction Accuracy = 59.36923076923078%, Loss = 0.010029912353135072
Epoch: 654, Batch Gradient Norm: 1.6005326005263096
Epoch: 654, Batch Gradient Norm after: 1.6005326005263096
Epoch 655/10000, Prediction Accuracy = 59.642307692307696%, Loss = 0.009856420354201244
Epoch: 655, Batch Gradient Norm: 1.5087121579922151
Epoch: 655, Batch Gradient Norm after: 1.5087121579922151
Epoch 656/10000, Prediction Accuracy = 59.911538461538456%, Loss = 0.009827421261714054
Epoch: 656, Batch Gradient Norm: 1.452970181203286
Epoch: 656, Batch Gradient Norm after: 1.452970181203286
Epoch 657/10000, Prediction Accuracy = 59.73461538461539%, Loss = 0.009877139917359902
Epoch: 657, Batch Gradient Norm: 1.6385835422826949
Epoch: 657, Batch Gradient Norm after: 1.6385835422826949
Epoch 658/10000, Prediction Accuracy = 59.3923076923077%, Loss = 0.010004697224268546
Epoch: 658, Batch Gradient Norm: 1.6664074259751982
Epoch: 658, Batch Gradient Norm after: 1.6664074259751982
Epoch 659/10000, Prediction Accuracy = 59.29615384615385%, Loss = 0.010037815484863061
Epoch: 659, Batch Gradient Norm: 1.4465108388907681
Epoch: 659, Batch Gradient Norm after: 1.4465108388907681
Epoch 660/10000, Prediction Accuracy = 60.02307692307693%, Loss = 0.009806736587331845
Epoch: 660, Batch Gradient Norm: 1.5234265319053717
Epoch: 660, Batch Gradient Norm after: 1.5234265319053717
Epoch 661/10000, Prediction Accuracy = 60.04615384615385%, Loss = 0.009883932984219147
Epoch: 661, Batch Gradient Norm: 1.5586522632880404
Epoch: 661, Batch Gradient Norm after: 1.5586522632880404
Epoch 662/10000, Prediction Accuracy = 59.834615384615375%, Loss = 0.009920850181235718
Epoch: 662, Batch Gradient Norm: 1.5219539232247994
Epoch: 662, Batch Gradient Norm after: 1.5219539232247994
Epoch 663/10000, Prediction Accuracy = 59.46153846153846%, Loss = 0.009867257366959866
Epoch: 663, Batch Gradient Norm: 1.5932370566776388
Epoch: 663, Batch Gradient Norm after: 1.5932370566776388
Epoch 664/10000, Prediction Accuracy = 59.53076923076923%, Loss = 0.009958254316678414
Epoch: 664, Batch Gradient Norm: 1.6856050175313892
Epoch: 664, Batch Gradient Norm after: 1.6856050175313892
Epoch 665/10000, Prediction Accuracy = 59.68076923076923%, Loss = 0.010004305209104832
Epoch: 665, Batch Gradient Norm: 1.524063067011714
Epoch: 665, Batch Gradient Norm after: 1.524063067011714
Epoch 666/10000, Prediction Accuracy = 59.76923076923077%, Loss = 0.009870924270496918
Epoch: 666, Batch Gradient Norm: 1.6193602640406102
Epoch: 666, Batch Gradient Norm after: 1.6193602640406102
Epoch 667/10000, Prediction Accuracy = 59.94230769230769%, Loss = 0.00990441248107415
Epoch: 667, Batch Gradient Norm: 1.8333617842290992
Epoch: 667, Batch Gradient Norm after: 1.8333617842290992
Epoch 668/10000, Prediction Accuracy = 59.0923076923077%, Loss = 0.010181447634330163
Epoch: 668, Batch Gradient Norm: 1.6276292878876706
Epoch: 668, Batch Gradient Norm after: 1.6276292878876706
Epoch 669/10000, Prediction Accuracy = 59.65384615384615%, Loss = 0.009923362531341039
Epoch: 669, Batch Gradient Norm: 1.553549088646945
Epoch: 669, Batch Gradient Norm after: 1.553549088646945
Epoch 670/10000, Prediction Accuracy = 59.76923076923077%, Loss = 0.009958294578469716
Epoch: 670, Batch Gradient Norm: 1.616838891040679
Epoch: 670, Batch Gradient Norm after: 1.616838891040679
Epoch 671/10000, Prediction Accuracy = 59.70384615384615%, Loss = 0.009990277127004586
Epoch: 671, Batch Gradient Norm: 1.5511823272432947
Epoch: 671, Batch Gradient Norm after: 1.5511823272432947
Epoch 672/10000, Prediction Accuracy = 59.48461538461539%, Loss = 0.009951782197906421
Epoch: 672, Batch Gradient Norm: 1.6628626332632284
Epoch: 672, Batch Gradient Norm after: 1.6628626332632284
Epoch 673/10000, Prediction Accuracy = 59.66153846153845%, Loss = 0.010020501768359771
Epoch: 673, Batch Gradient Norm: 1.6208921778230188
Epoch: 673, Batch Gradient Norm after: 1.6208921778230188
Epoch 674/10000, Prediction Accuracy = 59.2%, Loss = 0.009924042253540112
Epoch: 674, Batch Gradient Norm: 1.5670952608689186
Epoch: 674, Batch Gradient Norm after: 1.5670952608689186
Epoch 675/10000, Prediction Accuracy = 59.36538461538461%, Loss = 0.009937340393662453
Epoch: 675, Batch Gradient Norm: 1.519320242369962
Epoch: 675, Batch Gradient Norm after: 1.519320242369962
Epoch 676/10000, Prediction Accuracy = 60.115384615384606%, Loss = 0.00991751726430196
Epoch: 676, Batch Gradient Norm: 1.5686541133777632
Epoch: 676, Batch Gradient Norm after: 1.5686541133777632
Epoch 677/10000, Prediction Accuracy = 60.04230769230769%, Loss = 0.009920882204404244
Epoch: 677, Batch Gradient Norm: 1.608288064338742
Epoch: 677, Batch Gradient Norm after: 1.608288064338742
Epoch 678/10000, Prediction Accuracy = 59.3%, Loss = 0.010042376959553132
Epoch: 678, Batch Gradient Norm: 1.5312173697709694
Epoch: 678, Batch Gradient Norm after: 1.5312173697709694
Epoch 679/10000, Prediction Accuracy = 59.93076923076923%, Loss = 0.009964971946409116
Epoch: 679, Batch Gradient Norm: 1.6405953761344494
Epoch: 679, Batch Gradient Norm after: 1.6405953761344494
Epoch 680/10000, Prediction Accuracy = 59.70384615384615%, Loss = 0.010032930268118015
Epoch: 680, Batch Gradient Norm: 1.5229082274641368
Epoch: 680, Batch Gradient Norm after: 1.5229082274641368
Epoch 681/10000, Prediction Accuracy = 59.42307692307692%, Loss = 0.009975639386818958
Epoch: 681, Batch Gradient Norm: 1.5000577182783346
Epoch: 681, Batch Gradient Norm after: 1.5000577182783346
Epoch 682/10000, Prediction Accuracy = 59.74615384615384%, Loss = 0.00992483008079804
Epoch: 682, Batch Gradient Norm: 1.4612202884882415
Epoch: 682, Batch Gradient Norm after: 1.4612202884882415
Epoch 683/10000, Prediction Accuracy = 59.58076923076923%, Loss = 0.009893757864259757
Epoch: 683, Batch Gradient Norm: 1.4996084570724733
Epoch: 683, Batch Gradient Norm after: 1.4996084570724733
Epoch 684/10000, Prediction Accuracy = 60.05769230769231%, Loss = 0.00997135558953652
Epoch: 684, Batch Gradient Norm: 1.5397715788591606
Epoch: 684, Batch Gradient Norm after: 1.5397715788591606
Epoch 685/10000, Prediction Accuracy = 59.334615384615375%, Loss = 0.010056023056117388
Epoch: 685, Batch Gradient Norm: 1.4492095568348384
Epoch: 685, Batch Gradient Norm after: 1.4492095568348384
Epoch 686/10000, Prediction Accuracy = 59.6576923076923%, Loss = 0.00993828747708064
Epoch: 686, Batch Gradient Norm: 1.6514851394572287
Epoch: 686, Batch Gradient Norm after: 1.6514851394572287
Epoch 687/10000, Prediction Accuracy = 59.88076923076923%, Loss = 0.010051392735196995
Epoch: 687, Batch Gradient Norm: 1.5793492852241233
Epoch: 687, Batch Gradient Norm after: 1.5793492852241233
Epoch 688/10000, Prediction Accuracy = 59.73846153846154%, Loss = 0.010009665615283526
Epoch: 688, Batch Gradient Norm: 1.6274940738601889
Epoch: 688, Batch Gradient Norm after: 1.6274940738601889
Epoch 689/10000, Prediction Accuracy = 59.611538461538466%, Loss = 0.009979808416504126
Epoch: 689, Batch Gradient Norm: 1.6942804592332412
Epoch: 689, Batch Gradient Norm after: 1.6942804592332412
Epoch 690/10000, Prediction Accuracy = 59.63461538461539%, Loss = 0.010005521588027477
Epoch: 690, Batch Gradient Norm: 1.5318870052153868
Epoch: 690, Batch Gradient Norm after: 1.5318870052153868
Epoch 691/10000, Prediction Accuracy = 60.073076923076925%, Loss = 0.009906162651112447
Epoch: 691, Batch Gradient Norm: 1.3821101471123964
Epoch: 691, Batch Gradient Norm after: 1.3821101471123964
Epoch 692/10000, Prediction Accuracy = 60.02692307692309%, Loss = 0.009848500673587505
Epoch: 692, Batch Gradient Norm: 1.4517206634689328
Epoch: 692, Batch Gradient Norm after: 1.4517206634689328
Epoch 693/10000, Prediction Accuracy = 59.96538461538462%, Loss = 0.009924738166423945
Epoch: 693, Batch Gradient Norm: 1.4794857819811427
Epoch: 693, Batch Gradient Norm after: 1.4794857819811427
Epoch 694/10000, Prediction Accuracy = 59.65384615384615%, Loss = 0.009877666759376343
Epoch: 694, Batch Gradient Norm: 1.5703071838089673
Epoch: 694, Batch Gradient Norm after: 1.5703071838089673
Epoch 695/10000, Prediction Accuracy = 59.373076923076916%, Loss = 0.009985679545654701
Epoch: 695, Batch Gradient Norm: 1.4085953094482095
Epoch: 695, Batch Gradient Norm after: 1.4085953094482095
Epoch 696/10000, Prediction Accuracy = 60.223076923076924%, Loss = 0.00985350739210844
Epoch: 696, Batch Gradient Norm: 1.383759790502538
Epoch: 696, Batch Gradient Norm after: 1.383759790502538
Epoch 697/10000, Prediction Accuracy = 59.94615384615385%, Loss = 0.009842919543958627
Epoch: 697, Batch Gradient Norm: 1.6629276453688506
Epoch: 697, Batch Gradient Norm after: 1.6629276453688506
Epoch 698/10000, Prediction Accuracy = 58.96923076923076%, Loss = 0.010098815394135622
Epoch: 698, Batch Gradient Norm: 1.8664868431360808
Epoch: 698, Batch Gradient Norm after: 1.8664868431360808
Epoch 699/10000, Prediction Accuracy = 58.665384615384625%, Loss = 0.010190808572448216
Epoch: 699, Batch Gradient Norm: 1.7927313047495148
Epoch: 699, Batch Gradient Norm after: 1.7927313047495148
Epoch 700/10000, Prediction Accuracy = 58.692307692307686%, Loss = 0.010225997879528083
Epoch: 700, Batch Gradient Norm: 1.5887003138951308
Epoch: 700, Batch Gradient Norm after: 1.5887003138951308
Epoch 701/10000, Prediction Accuracy = 59.56153846153846%, Loss = 0.01002907595382287
Epoch: 701, Batch Gradient Norm: 1.4919604993912994
Epoch: 701, Batch Gradient Norm after: 1.4919604993912994
Epoch 702/10000, Prediction Accuracy = 59.83846153846154%, Loss = 0.010024976558410205
Epoch: 702, Batch Gradient Norm: 1.3907876794945724
Epoch: 702, Batch Gradient Norm after: 1.3907876794945724
Epoch 703/10000, Prediction Accuracy = 60.03076923076923%, Loss = 0.00990393335142961
Epoch: 703, Batch Gradient Norm: 1.4291525613036968
Epoch: 703, Batch Gradient Norm after: 1.4291525613036968
Epoch 704/10000, Prediction Accuracy = 59.8423076923077%, Loss = 0.009894127670962077
Epoch: 704, Batch Gradient Norm: 1.4259859058978384
Epoch: 704, Batch Gradient Norm after: 1.4259859058978384
Epoch 705/10000, Prediction Accuracy = 59.47692307692308%, Loss = 0.00994031081119409
Epoch: 705, Batch Gradient Norm: 1.4238381432364764
Epoch: 705, Batch Gradient Norm after: 1.4238381432364764
Epoch 706/10000, Prediction Accuracy = 59.75%, Loss = 0.00993537874175952
Epoch: 706, Batch Gradient Norm: 1.5385729411514395
Epoch: 706, Batch Gradient Norm after: 1.5385729411514395
Epoch 707/10000, Prediction Accuracy = 60.05769230769231%, Loss = 0.009983163183698287
Epoch: 707, Batch Gradient Norm: 1.5549237114022125
Epoch: 707, Batch Gradient Norm after: 1.5549237114022125
Epoch 708/10000, Prediction Accuracy = 59.55384615384616%, Loss = 0.010092813879824601
Epoch: 708, Batch Gradient Norm: 1.6265904372502422
Epoch: 708, Batch Gradient Norm after: 1.6265904372502422
Epoch 709/10000, Prediction Accuracy = 59.14999999999999%, Loss = 0.01012458000332117
Epoch: 709, Batch Gradient Norm: 1.7021216287040632
Epoch: 709, Batch Gradient Norm after: 1.7021216287040632
Epoch 710/10000, Prediction Accuracy = 59.09615384615385%, Loss = 0.010217108835394565
Epoch: 710, Batch Gradient Norm: 1.5682860401614167
Epoch: 710, Batch Gradient Norm after: 1.5682860401614167
Epoch 711/10000, Prediction Accuracy = 59.5%, Loss = 0.01004425364618118
Epoch: 711, Batch Gradient Norm: 1.5155300092818362
Epoch: 711, Batch Gradient Norm after: 1.5155300092818362
Epoch 712/10000, Prediction Accuracy = 59.449999999999996%, Loss = 0.010068307559077557
Epoch: 712, Batch Gradient Norm: 1.6006196265083807
Epoch: 712, Batch Gradient Norm after: 1.6006196265083807
Epoch 713/10000, Prediction Accuracy = 59.723076923076924%, Loss = 0.010044887805214295
Epoch: 713, Batch Gradient Norm: 1.487266949929042
Epoch: 713, Batch Gradient Norm after: 1.487266949929042
Epoch 714/10000, Prediction Accuracy = 59.646153846153844%, Loss = 0.009995659884925071
Epoch: 714, Batch Gradient Norm: 1.5332668851441547
Epoch: 714, Batch Gradient Norm after: 1.5332668851441547
Epoch 715/10000, Prediction Accuracy = 59.43076923076922%, Loss = 0.010033052199735092
Epoch: 715, Batch Gradient Norm: 1.6373931777310442
Epoch: 715, Batch Gradient Norm after: 1.6373931777310442
Epoch 716/10000, Prediction Accuracy = 59.55769230769231%, Loss = 0.010087956459476398
Epoch: 716, Batch Gradient Norm: 1.5942924021509968
Epoch: 716, Batch Gradient Norm after: 1.5942924021509968
Epoch 717/10000, Prediction Accuracy = 59.38461538461539%, Loss = 0.010149623052431988
Epoch: 717, Batch Gradient Norm: 1.4567478599063723
Epoch: 717, Batch Gradient Norm after: 1.4567478599063723
Epoch 718/10000, Prediction Accuracy = 59.469230769230776%, Loss = 0.010026603364027463
Epoch: 718, Batch Gradient Norm: 1.5291906642586002
Epoch: 718, Batch Gradient Norm after: 1.5291906642586002
Epoch 719/10000, Prediction Accuracy = 59.53846153846155%, Loss = 0.010012344528849308
Epoch: 719, Batch Gradient Norm: 1.4360941868568349
Epoch: 719, Batch Gradient Norm after: 1.4360941868568349
Epoch 720/10000, Prediction Accuracy = 59.98461538461539%, Loss = 0.009947225809670411
Epoch: 720, Batch Gradient Norm: 1.4865851178193288
Epoch: 720, Batch Gradient Norm after: 1.4865851178193288
Epoch 721/10000, Prediction Accuracy = 59.38846153846154%, Loss = 0.009980358899785923
Epoch: 721, Batch Gradient Norm: 1.6076258010014435
Epoch: 721, Batch Gradient Norm after: 1.6076258010014435
Epoch 722/10000, Prediction Accuracy = 59.46538461538463%, Loss = 0.01007306518462988
Epoch: 722, Batch Gradient Norm: 1.4873848223822872
Epoch: 722, Batch Gradient Norm after: 1.4873848223822872
Epoch 723/10000, Prediction Accuracy = 59.784615384615385%, Loss = 0.010027784066131482
Epoch: 723, Batch Gradient Norm: 1.5769766083692447
Epoch: 723, Batch Gradient Norm after: 1.5769766083692447
Epoch 724/10000, Prediction Accuracy = 59.54615384615383%, Loss = 0.010084957529145937
Epoch: 724, Batch Gradient Norm: 1.4614017765880474
Epoch: 724, Batch Gradient Norm after: 1.4614017765880474
Epoch 725/10000, Prediction Accuracy = 59.403846153846146%, Loss = 0.010064856364176823
Epoch: 725, Batch Gradient Norm: 1.5466799998261103
Epoch: 725, Batch Gradient Norm after: 1.5466799998261103
Epoch 726/10000, Prediction Accuracy = 59.16538461538461%, Loss = 0.010062590814553775
Epoch: 726, Batch Gradient Norm: 1.5827257797220065
Epoch: 726, Batch Gradient Norm after: 1.5827257797220065
Epoch 727/10000, Prediction Accuracy = 59.12692307692308%, Loss = 0.01011234729622419
Epoch: 727, Batch Gradient Norm: 1.5300605899340542
Epoch: 727, Batch Gradient Norm after: 1.5300605899340542
Epoch 728/10000, Prediction Accuracy = 59.419230769230765%, Loss = 0.010171876288950443
Epoch: 728, Batch Gradient Norm: 1.5215057022440086
Epoch: 728, Batch Gradient Norm after: 1.5215057022440086
Epoch 729/10000, Prediction Accuracy = 59.55384615384616%, Loss = 0.010094248904631687
Epoch: 729, Batch Gradient Norm: 1.6842812634603894
Epoch: 729, Batch Gradient Norm after: 1.6842812634603894
Epoch 730/10000, Prediction Accuracy = 59.14615384615385%, Loss = 0.010269949714151712
Epoch: 730, Batch Gradient Norm: 1.6395740622669313
Epoch: 730, Batch Gradient Norm after: 1.6395740622669313
Epoch 731/10000, Prediction Accuracy = 58.8%, Loss = 0.010228700147798428
Epoch: 731, Batch Gradient Norm: 1.55350854747759
Epoch: 731, Batch Gradient Norm after: 1.55350854747759
Epoch 732/10000, Prediction Accuracy = 58.973076923076924%, Loss = 0.010250512009056715
Epoch: 732, Batch Gradient Norm: 1.639050251968875
Epoch: 732, Batch Gradient Norm after: 1.639050251968875
Epoch 733/10000, Prediction Accuracy = 58.8576923076923%, Loss = 0.010203576861665798
Epoch: 733, Batch Gradient Norm: 1.3612738642276019
Epoch: 733, Batch Gradient Norm after: 1.3612738642276019
Epoch 734/10000, Prediction Accuracy = 59.6076923076923%, Loss = 0.010080764499994425
Epoch: 734, Batch Gradient Norm: 1.5511314305586232
Epoch: 734, Batch Gradient Norm after: 1.5511314305586232
Epoch 735/10000, Prediction Accuracy = 59.45384615384616%, Loss = 0.010146007729837528
Epoch: 735, Batch Gradient Norm: 1.5254602269215713
Epoch: 735, Batch Gradient Norm after: 1.5254602269215713
Epoch 736/10000, Prediction Accuracy = 59.092307692307685%, Loss = 0.010169440020735446
Epoch: 736, Batch Gradient Norm: 1.5054053380452914
Epoch: 736, Batch Gradient Norm after: 1.5054053380452914
Epoch 737/10000, Prediction Accuracy = 59.565384615384616%, Loss = 0.010109045256215792
Epoch: 737, Batch Gradient Norm: 1.4400855727800577
Epoch: 737, Batch Gradient Norm after: 1.4400855727800577
Epoch 738/10000, Prediction Accuracy = 59.638461538461534%, Loss = 0.010056992706197958
Epoch: 738, Batch Gradient Norm: 1.540377267892358
Epoch: 738, Batch Gradient Norm after: 1.540377267892358
Epoch 739/10000, Prediction Accuracy = 59.103846153846135%, Loss = 0.010146547825290607
Epoch: 739, Batch Gradient Norm: 1.4527674308559977
Epoch: 739, Batch Gradient Norm after: 1.4527674308559977
Epoch 740/10000, Prediction Accuracy = 59.26153846153846%, Loss = 0.0101506718649314
Epoch: 740, Batch Gradient Norm: 1.5299374542279138
Epoch: 740, Batch Gradient Norm after: 1.5299374542279138
Epoch 741/10000, Prediction Accuracy = 59.47692307692308%, Loss = 0.010227741315387763
Epoch: 741, Batch Gradient Norm: 1.5015679843187506
Epoch: 741, Batch Gradient Norm after: 1.5015679843187506
Epoch 742/10000, Prediction Accuracy = 59.18076923076923%, Loss = 0.01021409471734212
Epoch: 742, Batch Gradient Norm: 1.487409272824009
Epoch: 742, Batch Gradient Norm after: 1.487409272824009
Epoch 743/10000, Prediction Accuracy = 59.08076923076923%, Loss = 0.01019527383435231
Epoch: 743, Batch Gradient Norm: 1.5730596029286583
Epoch: 743, Batch Gradient Norm after: 1.5730596029286583
Epoch 744/10000, Prediction Accuracy = 59.68076923076923%, Loss = 0.010187542854020229
Epoch: 744, Batch Gradient Norm: 1.4252827727107722
Epoch: 744, Batch Gradient Norm after: 1.4252827727107722
Epoch 745/10000, Prediction Accuracy = 59.26923076923076%, Loss = 0.010135563806845592
Epoch: 745, Batch Gradient Norm: 1.3731619456040631
Epoch: 745, Batch Gradient Norm after: 1.3731619456040631
Epoch 746/10000, Prediction Accuracy = 59.85384615384615%, Loss = 0.010051801370886656
Epoch: 746, Batch Gradient Norm: 1.434794737656184
Epoch: 746, Batch Gradient Norm after: 1.434794737656184
Epoch 747/10000, Prediction Accuracy = 59.41153846153846%, Loss = 0.010169169220786829
Epoch: 747, Batch Gradient Norm: 1.5128325251650898
Epoch: 747, Batch Gradient Norm after: 1.5128325251650898
Epoch 748/10000, Prediction Accuracy = 59.18846153846153%, Loss = 0.010195094160735607
Epoch: 748, Batch Gradient Norm: 1.4559566524587602
Epoch: 748, Batch Gradient Norm after: 1.4559566524587602
Epoch 749/10000, Prediction Accuracy = 59.44615384615385%, Loss = 0.010124715474935679
Epoch: 749, Batch Gradient Norm: 1.5403031533887777
Epoch: 749, Batch Gradient Norm after: 1.5403031533887777
Epoch 750/10000, Prediction Accuracy = 59.01538461538462%, Loss = 0.010322723036202101
Epoch: 750, Batch Gradient Norm: 1.4871523491146539
Epoch: 750, Batch Gradient Norm after: 1.4871523491146539
Epoch 751/10000, Prediction Accuracy = 59.43846153846154%, Loss = 0.010177608865957994
Epoch: 751, Batch Gradient Norm: 1.4072675921371915
Epoch: 751, Batch Gradient Norm after: 1.4072675921371915
Epoch 752/10000, Prediction Accuracy = 59.51538461538461%, Loss = 0.010139489474777993
Epoch: 752, Batch Gradient Norm: 1.3737743983623218
Epoch: 752, Batch Gradient Norm after: 1.3737743983623218
Epoch 753/10000, Prediction Accuracy = 59.034615384615385%, Loss = 0.010168400736382375
Epoch: 753, Batch Gradient Norm: 1.4946497583925429
Epoch: 753, Batch Gradient Norm after: 1.4946497583925429
Epoch 754/10000, Prediction Accuracy = 59.01923076923076%, Loss = 0.010245570411475806
Epoch: 754, Batch Gradient Norm: 1.5208636672520408
Epoch: 754, Batch Gradient Norm after: 1.5208636672520408
Epoch 755/10000, Prediction Accuracy = 59.1153846153846%, Loss = 0.01025781615708883
Epoch: 755, Batch Gradient Norm: 1.4175812621521215
Epoch: 755, Batch Gradient Norm after: 1.4175812621521215
Epoch 756/10000, Prediction Accuracy = 58.89230769230768%, Loss = 0.010202966845379425
Epoch: 756, Batch Gradient Norm: 1.4952236659184253
Epoch: 756, Batch Gradient Norm after: 1.4952236659184253
Epoch 757/10000, Prediction Accuracy = 59.25384615384615%, Loss = 0.010201165166038733
Epoch: 757, Batch Gradient Norm: 1.5577146301971754
Epoch: 757, Batch Gradient Norm after: 1.5577146301971754
Epoch 758/10000, Prediction Accuracy = 58.853846153846156%, Loss = 0.010302700460530244
Epoch: 758, Batch Gradient Norm: 1.5304002827748426
Epoch: 758, Batch Gradient Norm after: 1.5304002827748426
Epoch 759/10000, Prediction Accuracy = 59.00769230769232%, Loss = 0.0102797020226717
Epoch: 759, Batch Gradient Norm: 1.453308595191383
Epoch: 759, Batch Gradient Norm after: 1.453308595191383
Epoch 760/10000, Prediction Accuracy = 59.22692307692308%, Loss = 0.010190147118499646
Epoch: 760, Batch Gradient Norm: 1.5868512231590455
Epoch: 760, Batch Gradient Norm after: 1.5868512231590455
Epoch 761/10000, Prediction Accuracy = 58.973076923076924%, Loss = 0.010264770772594672
Epoch: 761, Batch Gradient Norm: 1.5400166937881283
Epoch: 761, Batch Gradient Norm after: 1.5400166937881283
Epoch 762/10000, Prediction Accuracy = 59.31153846153847%, Loss = 0.010293010120781569
Epoch: 762, Batch Gradient Norm: 1.4315313970270076
Epoch: 762, Batch Gradient Norm after: 1.4315313970270076
Epoch 763/10000, Prediction Accuracy = 58.91153846153846%, Loss = 0.010214094144220535
Epoch: 763, Batch Gradient Norm: 1.526668170302782
Epoch: 763, Batch Gradient Norm after: 1.526668170302782
Epoch 764/10000, Prediction Accuracy = 59.103846153846156%, Loss = 0.010241547957635842
Epoch: 764, Batch Gradient Norm: 1.5456965705284422
Epoch: 764, Batch Gradient Norm after: 1.5456965705284422
Epoch 765/10000, Prediction Accuracy = 58.57692307692308%, Loss = 0.010351541452109814
Epoch: 765, Batch Gradient Norm: 1.542769396948914
Epoch: 765, Batch Gradient Norm after: 1.542769396948914
Epoch 766/10000, Prediction Accuracy = 59.25384615384616%, Loss = 0.010331779073637266
Epoch: 766, Batch Gradient Norm: 1.4878197975773613
Epoch: 766, Batch Gradient Norm after: 1.4878197975773613
Epoch 767/10000, Prediction Accuracy = 58.91923076923077%, Loss = 0.010307568268707165
Epoch: 767, Batch Gradient Norm: 1.558277993923686
Epoch: 767, Batch Gradient Norm after: 1.558277993923686
Epoch 768/10000, Prediction Accuracy = 58.599999999999994%, Loss = 0.010439450494371928
Epoch: 768, Batch Gradient Norm: 1.5384121130973436
Epoch: 768, Batch Gradient Norm after: 1.5384121130973436
Epoch 769/10000, Prediction Accuracy = 59.196153846153834%, Loss = 0.010331237258819433
Epoch: 769, Batch Gradient Norm: 1.4867290670572102
Epoch: 769, Batch Gradient Norm after: 1.4867290670572102
Epoch 770/10000, Prediction Accuracy = 59.10769230769232%, Loss = 0.010338768291358765
Epoch: 770, Batch Gradient Norm: 1.4947478608216338
Epoch: 770, Batch Gradient Norm after: 1.4947478608216338
Epoch 771/10000, Prediction Accuracy = 58.661538461538456%, Loss = 0.010408016423193308
Epoch: 771, Batch Gradient Norm: 1.5020595569907822
Epoch: 771, Batch Gradient Norm after: 1.5020595569907822
Epoch 772/10000, Prediction Accuracy = 58.88461538461539%, Loss = 0.010380778103493728
Epoch: 772, Batch Gradient Norm: 1.4284848030429647
Epoch: 772, Batch Gradient Norm after: 1.4284848030429647
Epoch 773/10000, Prediction Accuracy = 59.08461538461539%, Loss = 0.010291144538384218
Epoch: 773, Batch Gradient Norm: 1.3966624621772397
Epoch: 773, Batch Gradient Norm after: 1.3966624621772397
Epoch 774/10000, Prediction Accuracy = 59.12692307692308%, Loss = 0.010207289113448216
Epoch: 774, Batch Gradient Norm: 1.66304605637837
Epoch: 774, Batch Gradient Norm after: 1.66304605637837
Epoch 775/10000, Prediction Accuracy = 58.73461538461539%, Loss = 0.010431378148496151
Epoch: 775, Batch Gradient Norm: 1.5747190386408794
Epoch: 775, Batch Gradient Norm after: 1.5747190386408794
Epoch 776/10000, Prediction Accuracy = 58.75%, Loss = 0.010400856415239664
Epoch: 776, Batch Gradient Norm: 1.6437198662281267
Epoch: 776, Batch Gradient Norm after: 1.6437198662281267
Epoch 777/10000, Prediction Accuracy = 58.68846153846153%, Loss = 0.010473676670629244
Epoch: 777, Batch Gradient Norm: 1.5176471497915216
Epoch: 777, Batch Gradient Norm after: 1.5176471497915216
Epoch 778/10000, Prediction Accuracy = 58.82307692307692%, Loss = 0.010419362511199255
Epoch: 778, Batch Gradient Norm: 1.3082911020517773
Epoch: 778, Batch Gradient Norm after: 1.3082911020517773
Epoch 779/10000, Prediction Accuracy = 59.52307692307692%, Loss = 0.010203121874768
Epoch: 779, Batch Gradient Norm: 1.3691742946493521
Epoch: 779, Batch Gradient Norm after: 1.3691742946493521
Epoch 780/10000, Prediction Accuracy = 59.142307692307696%, Loss = 0.010248960139086613
Epoch: 780, Batch Gradient Norm: 1.3962072465247979
Epoch: 780, Batch Gradient Norm after: 1.3962072465247979
Epoch 781/10000, Prediction Accuracy = 59.265384615384626%, Loss = 0.01029132786565102
Epoch: 781, Batch Gradient Norm: 1.5338265828711148
Epoch: 781, Batch Gradient Norm after: 1.5338265828711148
Epoch 782/10000, Prediction Accuracy = 59.01923076923078%, Loss = 0.010356061303844819
Epoch: 782, Batch Gradient Norm: 1.4264565391495767
Epoch: 782, Batch Gradient Norm after: 1.4264565391495767
Epoch 783/10000, Prediction Accuracy = 58.61538461538461%, Loss = 0.010329426696094183
Epoch: 783, Batch Gradient Norm: 1.5843471135707747
Epoch: 783, Batch Gradient Norm after: 1.5843471135707747
Epoch 784/10000, Prediction Accuracy = 58.51153846153846%, Loss = 0.010419458867265629
Epoch: 784, Batch Gradient Norm: 1.569900281812716
Epoch: 784, Batch Gradient Norm after: 1.569900281812716
Epoch 785/10000, Prediction Accuracy = 58.68846153846154%, Loss = 0.01050017150835349
Epoch: 785, Batch Gradient Norm: 1.54232136822675
Epoch: 785, Batch Gradient Norm after: 1.54232136822675
Epoch 786/10000, Prediction Accuracy = 58.8076923076923%, Loss = 0.010470178336478196
Epoch: 786, Batch Gradient Norm: 1.4787849632115173
Epoch: 786, Batch Gradient Norm after: 1.4787849632115173
Epoch 787/10000, Prediction Accuracy = 58.661538461538456%, Loss = 0.010394432223760165
Epoch: 787, Batch Gradient Norm: 1.4743521892335971
Epoch: 787, Batch Gradient Norm after: 1.4743521892335971
Epoch 788/10000, Prediction Accuracy = 58.57307692307692%, Loss = 0.01039339852734254
Epoch: 788, Batch Gradient Norm: 1.5858967466045302
Epoch: 788, Batch Gradient Norm after: 1.5858967466045302
Epoch 789/10000, Prediction Accuracy = 58.06153846153847%, Loss = 0.010509974967974883
Epoch: 789, Batch Gradient Norm: 1.5727144239966993
Epoch: 789, Batch Gradient Norm after: 1.5727144239966993
Epoch 790/10000, Prediction Accuracy = 58.63846153846154%, Loss = 0.010456772377857795
Epoch: 790, Batch Gradient Norm: 1.7623072749360222
Epoch: 790, Batch Gradient Norm after: 1.7623072749360222
Epoch 791/10000, Prediction Accuracy = 58.48846153846154%, Loss = 0.010559966286214499
Epoch: 791, Batch Gradient Norm: 1.601426083255981
Epoch: 791, Batch Gradient Norm after: 1.601426083255981
Epoch 792/10000, Prediction Accuracy = 58.307692307692314%, Loss = 0.01054332870990038
Epoch: 792, Batch Gradient Norm: 1.5838858192891707
Epoch: 792, Batch Gradient Norm after: 1.5838858192891707
Epoch 793/10000, Prediction Accuracy = 58.67692307692308%, Loss = 0.010557155912885299
Epoch: 793, Batch Gradient Norm: 1.517850655978417
Epoch: 793, Batch Gradient Norm after: 1.517850655978417
Epoch 794/10000, Prediction Accuracy = 58.3576923076923%, Loss = 0.01054105807382327
Epoch: 794, Batch Gradient Norm: 1.3632536075966721
Epoch: 794, Batch Gradient Norm after: 1.3632536075966721
Epoch 795/10000, Prediction Accuracy = 58.973076923076924%, Loss = 0.010398739805588355
Epoch: 795, Batch Gradient Norm: 1.3309569256160922
Epoch: 795, Batch Gradient Norm after: 1.3309569256160922
Epoch 796/10000, Prediction Accuracy = 58.82692307692309%, Loss = 0.010392920400660772
Epoch: 796, Batch Gradient Norm: 1.4730326955986286
Epoch: 796, Batch Gradient Norm after: 1.4730326955986286
Epoch 797/10000, Prediction Accuracy = 58.90384615384615%, Loss = 0.010451207868754864
Epoch: 797, Batch Gradient Norm: 1.4691474103131745
Epoch: 797, Batch Gradient Norm after: 1.4691474103131745
Epoch 798/10000, Prediction Accuracy = 58.51153846153847%, Loss = 0.01052862463089136
Epoch: 798, Batch Gradient Norm: 1.3604372179811093
Epoch: 798, Batch Gradient Norm after: 1.3604372179811093
Epoch 799/10000, Prediction Accuracy = 59.04999999999999%, Loss = 0.010427031809320817
Epoch: 799, Batch Gradient Norm: 1.380599186938982
Epoch: 799, Batch Gradient Norm after: 1.380599186938982
Epoch 800/10000, Prediction Accuracy = 58.93461538461539%, Loss = 0.01043067335222776
Epoch: 800, Batch Gradient Norm: 1.4218695434440227
Epoch: 800, Batch Gradient Norm after: 1.4218695434440227
Epoch 801/10000, Prediction Accuracy = 58.75%, Loss = 0.010414650090611897
Epoch: 801, Batch Gradient Norm: 1.4102828648999903
Epoch: 801, Batch Gradient Norm after: 1.4102828648999903
Epoch 802/10000, Prediction Accuracy = 58.557692307692314%, Loss = 0.010475015554290552
Epoch: 802, Batch Gradient Norm: 1.4068154353710176
Epoch: 802, Batch Gradient Norm after: 1.4068154353710176
Epoch 803/10000, Prediction Accuracy = 58.93076923076923%, Loss = 0.010436976615052957
Epoch: 803, Batch Gradient Norm: 1.6046233516211013
Epoch: 803, Batch Gradient Norm after: 1.6046233516211013
Epoch 804/10000, Prediction Accuracy = 58.37692307692308%, Loss = 0.010580804055699935
Epoch: 804, Batch Gradient Norm: 1.6901341716389797
Epoch: 804, Batch Gradient Norm after: 1.6901341716389797
Epoch 805/10000, Prediction Accuracy = 58.223076923076924%, Loss = 0.010707195060184369
Epoch: 805, Batch Gradient Norm: 1.644250756164261
Epoch: 805, Batch Gradient Norm after: 1.644250756164261
Epoch 806/10000, Prediction Accuracy = 58.38076923076922%, Loss = 0.01070319151935669
Epoch: 806, Batch Gradient Norm: 1.5279159686162855
Epoch: 806, Batch Gradient Norm after: 1.5279159686162855
Epoch 807/10000, Prediction Accuracy = 58.23846153846153%, Loss = 0.010662254877388477
Epoch: 807, Batch Gradient Norm: 1.603390809769921
Epoch: 807, Batch Gradient Norm after: 1.603390809769921
Epoch 808/10000, Prediction Accuracy = 57.861538461538466%, Loss = 0.010704964972459353
Epoch: 808, Batch Gradient Norm: 1.5169766369234061
Epoch: 808, Batch Gradient Norm after: 1.5169766369234061
Epoch 809/10000, Prediction Accuracy = 58.5846153846154%, Loss = 0.010652684105130343
Epoch: 809, Batch Gradient Norm: 1.4987026950351554
Epoch: 809, Batch Gradient Norm after: 1.4987026950351554
Epoch 810/10000, Prediction Accuracy = 58.04615384615385%, Loss = 0.010553105591008296
Epoch: 810, Batch Gradient Norm: 1.6401740915591514
Epoch: 810, Batch Gradient Norm after: 1.6401740915591514
Epoch 811/10000, Prediction Accuracy = 58.23846153846155%, Loss = 0.01073444434083425
Epoch: 811, Batch Gradient Norm: 1.4568088854986188
Epoch: 811, Batch Gradient Norm after: 1.4568088854986188
Epoch 812/10000, Prediction Accuracy = 58.5076923076923%, Loss = 0.01052068811483108
Epoch: 812, Batch Gradient Norm: 1.3988970118850148
Epoch: 812, Batch Gradient Norm after: 1.3988970118850148
Epoch 813/10000, Prediction Accuracy = 58.550000000000004%, Loss = 0.010485493004895173
Epoch: 813, Batch Gradient Norm: 1.4456606325439796
Epoch: 813, Batch Gradient Norm after: 1.4456606325439796
Epoch 814/10000, Prediction Accuracy = 59.03846153846153%, Loss = 0.010571440180333761
Epoch: 814, Batch Gradient Norm: 1.4415339185369649
Epoch: 814, Batch Gradient Norm after: 1.4415339185369649
Epoch 815/10000, Prediction Accuracy = 58.44615384615384%, Loss = 0.010591183932354817
Epoch: 815, Batch Gradient Norm: 1.5771706019541734
Epoch: 815, Batch Gradient Norm after: 1.5771706019541734
Epoch 816/10000, Prediction Accuracy = 58.042307692307695%, Loss = 0.01073626049149495
Epoch: 816, Batch Gradient Norm: 1.4348349384217205
Epoch: 816, Batch Gradient Norm after: 1.4348349384217205
Epoch 817/10000, Prediction Accuracy = 58.473076923076924%, Loss = 0.010664872037103543
Epoch: 817, Batch Gradient Norm: 1.4096515477396134
Epoch: 817, Batch Gradient Norm after: 1.4096515477396134
Epoch 818/10000, Prediction Accuracy = 58.603846153846156%, Loss = 0.010579559880380448
Epoch: 818, Batch Gradient Norm: 1.3301917120785776
Epoch: 818, Batch Gradient Norm after: 1.3301917120785776
Epoch 819/10000, Prediction Accuracy = 58.54615384615385%, Loss = 0.010468661068723751
Epoch: 819, Batch Gradient Norm: 1.3800471134641086
Epoch: 819, Batch Gradient Norm after: 1.3800471134641086
Epoch 820/10000, Prediction Accuracy = 58.46923076923077%, Loss = 0.010556610587697763
Epoch: 820, Batch Gradient Norm: 1.4100960640382483
Epoch: 820, Batch Gradient Norm after: 1.4100960640382483
Epoch 821/10000, Prediction Accuracy = 58.61538461538461%, Loss = 0.010620968631253792
Epoch: 821, Batch Gradient Norm: 1.5057411773962368
Epoch: 821, Batch Gradient Norm after: 1.5057411773962368
Epoch 822/10000, Prediction Accuracy = 58.126923076923084%, Loss = 0.010630564764142036
Epoch: 822, Batch Gradient Norm: 1.5985260399723054
Epoch: 822, Batch Gradient Norm after: 1.5985260399723054
Epoch 823/10000, Prediction Accuracy = 58.138461538461534%, Loss = 0.010729003339432754
Epoch: 823, Batch Gradient Norm: 1.52737439714797
Epoch: 823, Batch Gradient Norm after: 1.52737439714797
Epoch 824/10000, Prediction Accuracy = 58.353846153846156%, Loss = 0.010680569120897697
Epoch: 824, Batch Gradient Norm: 1.4157115767996715
Epoch: 824, Batch Gradient Norm after: 1.4157115767996715
Epoch 825/10000, Prediction Accuracy = 58.68076923076922%, Loss = 0.010577715360201322
Epoch: 825, Batch Gradient Norm: 1.4079386052129808
Epoch: 825, Batch Gradient Norm after: 1.4079386052129808
Epoch 826/10000, Prediction Accuracy = 58.68846153846153%, Loss = 0.010621097583610278
Epoch: 826, Batch Gradient Norm: 1.434714441005258
Epoch: 826, Batch Gradient Norm after: 1.434714441005258
Epoch 827/10000, Prediction Accuracy = 58.34615384615385%, Loss = 0.01066268959011023
Epoch: 827, Batch Gradient Norm: 1.339409877024589
Epoch: 827, Batch Gradient Norm after: 1.339409877024589
Epoch 828/10000, Prediction Accuracy = 58.603846153846156%, Loss = 0.010593401196484383
Epoch: 828, Batch Gradient Norm: 1.400168304150666
Epoch: 828, Batch Gradient Norm after: 1.400168304150666
Epoch 829/10000, Prediction Accuracy = 58.31923076923077%, Loss = 0.010629813473385114
Epoch: 829, Batch Gradient Norm: 1.3390059720845946
Epoch: 829, Batch Gradient Norm after: 1.3390059720845946
Epoch 830/10000, Prediction Accuracy = 58.48846153846154%, Loss = 0.010596158412786631
Epoch: 830, Batch Gradient Norm: 1.3413628909066726
Epoch: 830, Batch Gradient Norm after: 1.3413628909066726
Epoch 831/10000, Prediction Accuracy = 58.47692307692308%, Loss = 0.010574001532334548
Epoch: 831, Batch Gradient Norm: 1.418307566251003
Epoch: 831, Batch Gradient Norm after: 1.418307566251003
Epoch 832/10000, Prediction Accuracy = 58.68461538461539%, Loss = 0.010594072680060681
Epoch: 832, Batch Gradient Norm: 1.6191183845940218
Epoch: 832, Batch Gradient Norm after: 1.6191183845940218
Epoch 833/10000, Prediction Accuracy = 57.96538461538462%, Loss = 0.010786088470083017
Epoch: 833, Batch Gradient Norm: 1.3998345291746912
Epoch: 833, Batch Gradient Norm after: 1.3998345291746912
Epoch 834/10000, Prediction Accuracy = 58.16153846153847%, Loss = 0.01069563777687458
Epoch: 834, Batch Gradient Norm: 1.3679182906551755
Epoch: 834, Batch Gradient Norm after: 1.3679182906551755
Epoch 835/10000, Prediction Accuracy = 58.41153846153846%, Loss = 0.010644278417413052
Epoch: 835, Batch Gradient Norm: 1.4847107533482877
Epoch: 835, Batch Gradient Norm after: 1.4847107533482877
Epoch 836/10000, Prediction Accuracy = 58.06153846153847%, Loss = 0.010678116232156754
Epoch: 836, Batch Gradient Norm: 1.557888244936289
Epoch: 836, Batch Gradient Norm after: 1.557888244936289
Epoch 837/10000, Prediction Accuracy = 58.16538461538461%, Loss = 0.010815910708445769
Epoch: 837, Batch Gradient Norm: 1.6353781126431257
Epoch: 837, Batch Gradient Norm after: 1.6353781126431257
Epoch 838/10000, Prediction Accuracy = 57.3076923076923%, Loss = 0.010924225959640283
Epoch: 838, Batch Gradient Norm: 1.4648455693189888
Epoch: 838, Batch Gradient Norm after: 1.4648455693189888
Epoch 839/10000, Prediction Accuracy = 58.176923076923075%, Loss = 0.010768658266617702
Epoch: 839, Batch Gradient Norm: 1.456197208950782
Epoch: 839, Batch Gradient Norm after: 1.456197208950782
Epoch 840/10000, Prediction Accuracy = 58.07307692307692%, Loss = 0.010777150710614828
Epoch: 840, Batch Gradient Norm: 1.4764308738510898
Epoch: 840, Batch Gradient Norm after: 1.4764308738510898
Epoch 841/10000, Prediction Accuracy = 58.16153846153846%, Loss = 0.010752722835884644
Epoch: 841, Batch Gradient Norm: 1.4849808968752598
Epoch: 841, Batch Gradient Norm after: 1.4849808968752598
Epoch 842/10000, Prediction Accuracy = 58.44230769230769%, Loss = 0.010785650891753344
Epoch: 842, Batch Gradient Norm: 1.4357357367695518
Epoch: 842, Batch Gradient Norm after: 1.4357357367695518
Epoch 843/10000, Prediction Accuracy = 58.00384615384615%, Loss = 0.010769773059739517
Epoch: 843, Batch Gradient Norm: 1.5621662308133992
Epoch: 843, Batch Gradient Norm after: 1.5621662308133992
Epoch 844/10000, Prediction Accuracy = 57.92692307692308%, Loss = 0.010853145271539688
Epoch: 844, Batch Gradient Norm: 1.5406219134446204
Epoch: 844, Batch Gradient Norm after: 1.5406219134446204
Epoch 845/10000, Prediction Accuracy = 57.95000000000001%, Loss = 0.010878487633397946
Epoch: 845, Batch Gradient Norm: 1.5228601153305383
Epoch: 845, Batch Gradient Norm after: 1.5228601153305383
Epoch 846/10000, Prediction Accuracy = 57.44615384615385%, Loss = 0.01088797659254991
Epoch: 846, Batch Gradient Norm: 1.41924735267675
Epoch: 846, Batch Gradient Norm after: 1.41924735267675
Epoch 847/10000, Prediction Accuracy = 57.91538461538461%, Loss = 0.010828681648350678
Epoch: 847, Batch Gradient Norm: 1.5360976910745392
Epoch: 847, Batch Gradient Norm after: 1.5360976910745392
Epoch 848/10000, Prediction Accuracy = 57.92307692307692%, Loss = 0.010869969685490314
Epoch: 848, Batch Gradient Norm: 1.3083831259108378
Epoch: 848, Batch Gradient Norm after: 1.3083831259108378
Epoch 849/10000, Prediction Accuracy = 58.31153846153847%, Loss = 0.010786349670245098
Epoch: 849, Batch Gradient Norm: 1.5641256272726578
Epoch: 849, Batch Gradient Norm after: 1.5641256272726578
Epoch 850/10000, Prediction Accuracy = 58.46153846153847%, Loss = 0.01080090244515584
Epoch: 850, Batch Gradient Norm: 1.5731358043970105
Epoch: 850, Batch Gradient Norm after: 1.5731358043970105
Epoch 851/10000, Prediction Accuracy = 58.00769230769232%, Loss = 0.010845444093529995
Epoch: 851, Batch Gradient Norm: 1.4854020136981936
Epoch: 851, Batch Gradient Norm after: 1.4854020136981936
Epoch 852/10000, Prediction Accuracy = 58.00000000000001%, Loss = 0.010848422964605002
Epoch: 852, Batch Gradient Norm: 1.352113671635274
Epoch: 852, Batch Gradient Norm after: 1.352113671635274
Epoch 853/10000, Prediction Accuracy = 58.130769230769225%, Loss = 0.010777698901410285
Epoch: 853, Batch Gradient Norm: 1.4753097301326878
Epoch: 853, Batch Gradient Norm after: 1.4753097301326878
Epoch 854/10000, Prediction Accuracy = 58.0%, Loss = 0.01080756469701345
Epoch: 854, Batch Gradient Norm: 1.5493926411573087
Epoch: 854, Batch Gradient Norm after: 1.5493926411573087
Epoch 855/10000, Prediction Accuracy = 57.96153846153845%, Loss = 0.010900994261296896
Epoch: 855, Batch Gradient Norm: 1.4765825398289507
Epoch: 855, Batch Gradient Norm after: 1.4765825398289507
Epoch 856/10000, Prediction Accuracy = 57.82692307692309%, Loss = 0.010857092144970711
Epoch: 856, Batch Gradient Norm: 1.5621333490998361
Epoch: 856, Batch Gradient Norm after: 1.5621333490998361
Epoch 857/10000, Prediction Accuracy = 57.62307692307692%, Loss = 0.010855490843263956
Epoch: 857, Batch Gradient Norm: 1.392323764095167
Epoch: 857, Batch Gradient Norm after: 1.392323764095167
Epoch 858/10000, Prediction Accuracy = 58.18846153846153%, Loss = 0.010882193580842935
Epoch: 858, Batch Gradient Norm: 1.4284930640281208
Epoch: 858, Batch Gradient Norm after: 1.4284930640281208
Epoch 859/10000, Prediction Accuracy = 57.95384615384616%, Loss = 0.010836133375190772
Epoch: 859, Batch Gradient Norm: 1.4699272147031115
Epoch: 859, Batch Gradient Norm after: 1.4699272147031115
Epoch 860/10000, Prediction Accuracy = 57.74230769230769%, Loss = 0.010897435032977508
Epoch: 860, Batch Gradient Norm: 1.5549501008829643
Epoch: 860, Batch Gradient Norm after: 1.5549501008829643
Epoch 861/10000, Prediction Accuracy = 57.76538461538462%, Loss = 0.010998503090097355
Epoch: 861, Batch Gradient Norm: 1.463584626396657
Epoch: 861, Batch Gradient Norm after: 1.463584626396657
Epoch 862/10000, Prediction Accuracy = 57.79615384615386%, Loss = 0.010961633677092882
Epoch: 862, Batch Gradient Norm: 1.361667089129761
Epoch: 862, Batch Gradient Norm after: 1.361667089129761
Epoch 863/10000, Prediction Accuracy = 57.84615384615385%, Loss = 0.010838101976192914
Epoch: 863, Batch Gradient Norm: 1.3281900665471948
Epoch: 863, Batch Gradient Norm after: 1.3281900665471948
Epoch 864/10000, Prediction Accuracy = 58.36923076923077%, Loss = 0.010772755441184226
Epoch: 864, Batch Gradient Norm: 1.4967727810456708
Epoch: 864, Batch Gradient Norm after: 1.4967727810456708
Epoch 865/10000, Prediction Accuracy = 57.934615384615384%, Loss = 0.010937984244754681
Epoch: 865, Batch Gradient Norm: 1.4774834521590674
Epoch: 865, Batch Gradient Norm after: 1.4774834521590674
Epoch 866/10000, Prediction Accuracy = 57.98846153846154%, Loss = 0.01095896393347245
Epoch: 866, Batch Gradient Norm: 1.4747956481203663
Epoch: 866, Batch Gradient Norm after: 1.4747956481203663
Epoch 867/10000, Prediction Accuracy = 57.39999999999999%, Loss = 0.011079825532550994
Epoch: 867, Batch Gradient Norm: 1.4403379753496794
Epoch: 867, Batch Gradient Norm after: 1.4403379753496794
Epoch 868/10000, Prediction Accuracy = 57.91153846153846%, Loss = 0.010950939085047979
Epoch: 868, Batch Gradient Norm: 1.4282569481874405
Epoch: 868, Batch Gradient Norm after: 1.4282569481874405
Epoch 869/10000, Prediction Accuracy = 57.61153846153846%, Loss = 0.010974889979339562
Epoch: 869, Batch Gradient Norm: 1.4404631323071404
Epoch: 869, Batch Gradient Norm after: 1.4404631323071404
Epoch 870/10000, Prediction Accuracy = 57.91923076923077%, Loss = 0.010953156205897149
Epoch: 870, Batch Gradient Norm: 1.531499178038684
Epoch: 870, Batch Gradient Norm after: 1.531499178038684
Epoch 871/10000, Prediction Accuracy = 57.60769230769232%, Loss = 0.011002151295542717
Epoch: 871, Batch Gradient Norm: 1.6464106049425378
Epoch: 871, Batch Gradient Norm after: 1.6464106049425378
Epoch 872/10000, Prediction Accuracy = 57.207692307692305%, Loss = 0.011128526825744372
Epoch: 872, Batch Gradient Norm: 1.5501830329438409
Epoch: 872, Batch Gradient Norm after: 1.5501830329438409
Epoch 873/10000, Prediction Accuracy = 57.7423076923077%, Loss = 0.01108404342085123
Epoch: 873, Batch Gradient Norm: 1.6387315524400057
Epoch: 873, Batch Gradient Norm after: 1.6387315524400057
Epoch 874/10000, Prediction Accuracy = 57.45384615384616%, Loss = 0.011164588710436454
Epoch: 874, Batch Gradient Norm: 1.462680177635012
Epoch: 874, Batch Gradient Norm after: 1.462680177635012
Epoch 875/10000, Prediction Accuracy = 57.76153846153846%, Loss = 0.011012981502482524
Epoch: 875, Batch Gradient Norm: 1.4657976094369844
Epoch: 875, Batch Gradient Norm after: 1.4657976094369844
Epoch 876/10000, Prediction Accuracy = 56.96153846153846%, Loss = 0.011047617818873662
Epoch: 876, Batch Gradient Norm: 1.4442659995816585
Epoch: 876, Batch Gradient Norm after: 1.4442659995816585
Epoch 877/10000, Prediction Accuracy = 57.742307692307676%, Loss = 0.011035317196868934
Epoch: 877, Batch Gradient Norm: 1.392339629035861
Epoch: 877, Batch Gradient Norm after: 1.392339629035861
Epoch 878/10000, Prediction Accuracy = 57.55384615384615%, Loss = 0.011039005162624212
Epoch: 878, Batch Gradient Norm: 1.4787305351476603
Epoch: 878, Batch Gradient Norm after: 1.4787305351476603
Epoch 879/10000, Prediction Accuracy = 57.53076923076923%, Loss = 0.01103014018959724
Epoch: 879, Batch Gradient Norm: 1.4701842480785994
Epoch: 879, Batch Gradient Norm after: 1.4701842480785994
Epoch 880/10000, Prediction Accuracy = 57.49615384615385%, Loss = 0.011062512460809488
Epoch: 880, Batch Gradient Norm: 1.5152235268942502
Epoch: 880, Batch Gradient Norm after: 1.5152235268942502
Epoch 881/10000, Prediction Accuracy = 57.4423076923077%, Loss = 0.011062991017332444
Epoch: 881, Batch Gradient Norm: 1.5964074833536797
Epoch: 881, Batch Gradient Norm after: 1.5964074833536797
Epoch 882/10000, Prediction Accuracy = 57.50384615384616%, Loss = 0.011143639755363647
Epoch: 882, Batch Gradient Norm: 1.5137232398526677
Epoch: 882, Batch Gradient Norm after: 1.5137232398526677
Epoch 883/10000, Prediction Accuracy = 57.09999999999999%, Loss = 0.011142730354689635
Epoch: 883, Batch Gradient Norm: 1.4908277948702617
Epoch: 883, Batch Gradient Norm after: 1.4908277948702617
Epoch 884/10000, Prediction Accuracy = 57.23076923076924%, Loss = 0.011088014795229984
Epoch: 884, Batch Gradient Norm: 1.320271286821796
Epoch: 884, Batch Gradient Norm after: 1.320271286821796
Epoch 885/10000, Prediction Accuracy = 57.89230769230768%, Loss = 0.01100419139346251
Epoch: 885, Batch Gradient Norm: 1.502253967088629
Epoch: 885, Batch Gradient Norm after: 1.502253967088629
Epoch 886/10000, Prediction Accuracy = 57.66923076923077%, Loss = 0.011095864268449636
Epoch: 886, Batch Gradient Norm: 1.4474190193607253
Epoch: 886, Batch Gradient Norm after: 1.4474190193607253
Epoch 887/10000, Prediction Accuracy = 57.45769230769232%, Loss = 0.011027712804766802
Epoch: 887, Batch Gradient Norm: 1.416335075278258
Epoch: 887, Batch Gradient Norm after: 1.416335075278258
Epoch 888/10000, Prediction Accuracy = 57.78846153846153%, Loss = 0.01102950581564353
Epoch: 888, Batch Gradient Norm: 1.4710825110080075
Epoch: 888, Batch Gradient Norm after: 1.4710825110080075
Epoch 889/10000, Prediction Accuracy = 57.646153846153844%, Loss = 0.011062574143020006
Epoch: 889, Batch Gradient Norm: 1.384304568251762
Epoch: 889, Batch Gradient Norm after: 1.384304568251762
Epoch 890/10000, Prediction Accuracy = 58.01923076923077%, Loss = 0.01100474538711401
Epoch: 890, Batch Gradient Norm: 1.5458043498183855
Epoch: 890, Batch Gradient Norm after: 1.5458043498183855
Epoch 891/10000, Prediction Accuracy = 57.47307692307691%, Loss = 0.011101274536206173
Epoch: 891, Batch Gradient Norm: 1.4657968640718646
Epoch: 891, Batch Gradient Norm after: 1.4657968640718646
Epoch 892/10000, Prediction Accuracy = 57.75384615384614%, Loss = 0.011063253936859278
Epoch: 892, Batch Gradient Norm: 1.4635849722845267
Epoch: 892, Batch Gradient Norm after: 1.4635849722845267
Epoch 893/10000, Prediction Accuracy = 57.57307692307692%, Loss = 0.011047700993143596
Epoch: 893, Batch Gradient Norm: 1.570831348931461
Epoch: 893, Batch Gradient Norm after: 1.570831348931461
Epoch 894/10000, Prediction Accuracy = 57.16538461538461%, Loss = 0.011139829284869708
Epoch: 894, Batch Gradient Norm: 1.4755555248124852
Epoch: 894, Batch Gradient Norm after: 1.4755555248124852
Epoch 895/10000, Prediction Accuracy = 57.600000000000016%, Loss = 0.01112565197623693
Epoch: 895, Batch Gradient Norm: 1.4653501971881366
Epoch: 895, Batch Gradient Norm after: 1.4653501971881366
Epoch 896/10000, Prediction Accuracy = 57.599999999999994%, Loss = 0.01114235667941662
Epoch: 896, Batch Gradient Norm: 1.4877166271214368
Epoch: 896, Batch Gradient Norm after: 1.4877166271214368
Epoch 897/10000, Prediction Accuracy = 57.26538461538462%, Loss = 0.011128343355197173
Epoch: 897, Batch Gradient Norm: 1.611631459132445
Epoch: 897, Batch Gradient Norm after: 1.611631459132445
Epoch 898/10000, Prediction Accuracy = 57.57307692307692%, Loss = 0.011218088679015636
Epoch: 898, Batch Gradient Norm: 1.5002687409968338
Epoch: 898, Batch Gradient Norm after: 1.5002687409968338
Epoch 899/10000, Prediction Accuracy = 57.70384615384616%, Loss = 0.011146380566060543
Epoch: 899, Batch Gradient Norm: 1.4766795202144365
Epoch: 899, Batch Gradient Norm after: 1.4766795202144365
Epoch 900/10000, Prediction Accuracy = 57.07692307692308%, Loss = 0.011206766733756432
Epoch: 900, Batch Gradient Norm: 1.4437219580059701
Epoch: 900, Batch Gradient Norm after: 1.4437219580059701
Epoch 901/10000, Prediction Accuracy = 57.276923076923076%, Loss = 0.011166069083488904
Epoch: 901, Batch Gradient Norm: 1.4128220835305951
Epoch: 901, Batch Gradient Norm after: 1.4128220835305951
Epoch 902/10000, Prediction Accuracy = 57.46923076923077%, Loss = 0.011094823336372009
Epoch: 902, Batch Gradient Norm: 1.4066355490633358
Epoch: 902, Batch Gradient Norm after: 1.4066355490633358
Epoch 903/10000, Prediction Accuracy = 57.396153846153844%, Loss = 0.011097762662057694
Epoch: 903, Batch Gradient Norm: 1.4003712604301035
Epoch: 903, Batch Gradient Norm after: 1.4003712604301035
Epoch 904/10000, Prediction Accuracy = 57.39230769230768%, Loss = 0.011115042134546317
Epoch: 904, Batch Gradient Norm: 1.3845009417356984
Epoch: 904, Batch Gradient Norm after: 1.3845009417356984
Epoch 905/10000, Prediction Accuracy = 57.55769230769231%, Loss = 0.011088468635884615
Epoch: 905, Batch Gradient Norm: 1.506958969592138
Epoch: 905, Batch Gradient Norm after: 1.506958969592138
Epoch 906/10000, Prediction Accuracy = 57.55%, Loss = 0.011066757644025179
Epoch: 906, Batch Gradient Norm: 1.6105356731889569
Epoch: 906, Batch Gradient Norm after: 1.6105356731889569
Epoch 907/10000, Prediction Accuracy = 57.01923076923077%, Loss = 0.011262086363366017
Epoch: 907, Batch Gradient Norm: 1.4436009724598613
Epoch: 907, Batch Gradient Norm after: 1.4436009724598613
Epoch 908/10000, Prediction Accuracy = 57.71153846153847%, Loss = 0.011085397134033533
Epoch: 908, Batch Gradient Norm: 1.432963729227607
Epoch: 908, Batch Gradient Norm after: 1.432963729227607
Epoch 909/10000, Prediction Accuracy = 57.06923076923077%, Loss = 0.011134853944755517
Epoch: 909, Batch Gradient Norm: 1.3351711526982462
Epoch: 909, Batch Gradient Norm after: 1.3351711526982462
Epoch 910/10000, Prediction Accuracy = 57.73846153846154%, Loss = 0.011065015640969459
Epoch: 910, Batch Gradient Norm: 1.4184266200684845
Epoch: 910, Batch Gradient Norm after: 1.4184266200684845
Epoch 911/10000, Prediction Accuracy = 56.98846153846154%, Loss = 0.011220060503826691
Epoch: 911, Batch Gradient Norm: 1.4302090504968046
Epoch: 911, Batch Gradient Norm after: 1.4302090504968046
Epoch 912/10000, Prediction Accuracy = 57.25%, Loss = 0.011202618193167906
Epoch: 912, Batch Gradient Norm: 1.3838956281477335
Epoch: 912, Batch Gradient Norm after: 1.3838956281477335
Epoch 913/10000, Prediction Accuracy = 57.54615384615386%, Loss = 0.011099751107394695
Epoch: 913, Batch Gradient Norm: 1.5452732132528948
Epoch: 913, Batch Gradient Norm after: 1.5452732132528948
Epoch 914/10000, Prediction Accuracy = 57.29999999999998%, Loss = 0.01118503690052491
Epoch: 914, Batch Gradient Norm: 1.5742385509285821
Epoch: 914, Batch Gradient Norm after: 1.5742385509285821
Epoch 915/10000, Prediction Accuracy = 57.276923076923076%, Loss = 0.011249947648208875
Epoch: 915, Batch Gradient Norm: 1.4122258599214725
Epoch: 915, Batch Gradient Norm after: 1.4122258599214725
Epoch 916/10000, Prediction Accuracy = 57.280769230769224%, Loss = 0.011166725092782425
Epoch: 916, Batch Gradient Norm: 1.4749245338204464
Epoch: 916, Batch Gradient Norm after: 1.4749245338204464
Epoch 917/10000, Prediction Accuracy = 56.96538461538462%, Loss = 0.01125176465855195
Epoch: 917, Batch Gradient Norm: 1.4768319268642154
Epoch: 917, Batch Gradient Norm after: 1.4768319268642154
Epoch 918/10000, Prediction Accuracy = 57.70384615384616%, Loss = 0.01117956767288538
Epoch: 918, Batch Gradient Norm: 1.5364229024315958
Epoch: 918, Batch Gradient Norm after: 1.5364229024315958
Epoch 919/10000, Prediction Accuracy = 57.36538461538463%, Loss = 0.011218443512916565
Epoch: 919, Batch Gradient Norm: 1.673074979084049
Epoch: 919, Batch Gradient Norm after: 1.673074979084049
Epoch 920/10000, Prediction Accuracy = 56.68076923076922%, Loss = 0.011368636615001239
Epoch: 920, Batch Gradient Norm: 1.5456528882779073
Epoch: 920, Batch Gradient Norm after: 1.5456528882779073
Epoch 921/10000, Prediction Accuracy = 57.20769230769231%, Loss = 0.011242019514051767
Epoch: 921, Batch Gradient Norm: 1.4852611646853546
Epoch: 921, Batch Gradient Norm after: 1.4852611646853546
Epoch 922/10000, Prediction Accuracy = 57.31923076923077%, Loss = 0.011253791932876293
Epoch: 922, Batch Gradient Norm: 1.4712426663354314
Epoch: 922, Batch Gradient Norm after: 1.4712426663354314
Epoch 923/10000, Prediction Accuracy = 57.23846153846154%, Loss = 0.011263934035713855
Epoch: 923, Batch Gradient Norm: 1.4402861430539555
Epoch: 923, Batch Gradient Norm after: 1.4402861430539555
Epoch 924/10000, Prediction Accuracy = 57.138461538461534%, Loss = 0.011234070246036235
Epoch: 924, Batch Gradient Norm: 1.5968853715766342
Epoch: 924, Batch Gradient Norm after: 1.5968853715766342
Epoch 925/10000, Prediction Accuracy = 56.81153846153847%, Loss = 0.011315630820508186
Epoch: 925, Batch Gradient Norm: 1.6469551083905707
Epoch: 925, Batch Gradient Norm after: 1.6469551083905707
Epoch 926/10000, Prediction Accuracy = 56.93076923076923%, Loss = 0.011395177875573818
Epoch: 926, Batch Gradient Norm: 1.62081422589594
Epoch: 926, Batch Gradient Norm after: 1.62081422589594
Epoch 927/10000, Prediction Accuracy = 56.849999999999994%, Loss = 0.011362673284915777
Epoch: 927, Batch Gradient Norm: 1.7232323461826744
Epoch: 927, Batch Gradient Norm after: 1.7232323461826744
Epoch 928/10000, Prediction Accuracy = 56.888461538461534%, Loss = 0.011481314467696043
Epoch: 928, Batch Gradient Norm: 1.5407667838086554
Epoch: 928, Batch Gradient Norm after: 1.5407667838086554
Epoch 929/10000, Prediction Accuracy = 56.969230769230776%, Loss = 0.01140396074893383
Epoch: 929, Batch Gradient Norm: 1.712436091406976
Epoch: 929, Batch Gradient Norm after: 1.712436091406976
Epoch 930/10000, Prediction Accuracy = 56.51153846153846%, Loss = 0.011480849164609726
Epoch: 930, Batch Gradient Norm: 1.493458826384153
Epoch: 930, Batch Gradient Norm after: 1.493458826384153
Epoch 931/10000, Prediction Accuracy = 57.30384615384615%, Loss = 0.011341281091937652
Epoch: 931, Batch Gradient Norm: 1.6358448550223987
Epoch: 931, Batch Gradient Norm after: 1.6358448550223987
Epoch 932/10000, Prediction Accuracy = 56.64999999999999%, Loss = 0.011475842446088791
Epoch: 932, Batch Gradient Norm: 1.5606270949007988
Epoch: 932, Batch Gradient Norm after: 1.5606270949007988
Epoch 933/10000, Prediction Accuracy = 57.01153846153847%, Loss = 0.011404866137756752
Epoch: 933, Batch Gradient Norm: 1.5247418242191457
Epoch: 933, Batch Gradient Norm after: 1.5247418242191457
Epoch 934/10000, Prediction Accuracy = 56.87307692307694%, Loss = 0.011417494442027349
Epoch: 934, Batch Gradient Norm: 1.4844538989440041
Epoch: 934, Batch Gradient Norm after: 1.4844538989440041
Epoch 935/10000, Prediction Accuracy = 57.026923076923076%, Loss = 0.011352859222545074
Epoch: 935, Batch Gradient Norm: 1.490680898941661
Epoch: 935, Batch Gradient Norm after: 1.490680898941661
Epoch 936/10000, Prediction Accuracy = 56.984615384615374%, Loss = 0.011308530775400309
Epoch: 936, Batch Gradient Norm: 1.4394791471805362
Epoch: 936, Batch Gradient Norm after: 1.4394791471805362
Epoch 937/10000, Prediction Accuracy = 57.15384615384616%, Loss = 0.011289408215536522
Epoch: 937, Batch Gradient Norm: 1.352816666351371
Epoch: 937, Batch Gradient Norm after: 1.352816666351371
Epoch 938/10000, Prediction Accuracy = 57.28461538461538%, Loss = 0.01123946776183752
Epoch: 938, Batch Gradient Norm: 1.4902268216273133
Epoch: 938, Batch Gradient Norm after: 1.4902268216273133
Epoch 939/10000, Prediction Accuracy = 56.94615384615385%, Loss = 0.011287858423132163
Epoch: 939, Batch Gradient Norm: 1.4615763665761454
Epoch: 939, Batch Gradient Norm after: 1.4615763665761454
Epoch 940/10000, Prediction Accuracy = 57.10384615384615%, Loss = 0.011293591286700506
Epoch: 940, Batch Gradient Norm: 1.5928382515685937
Epoch: 940, Batch Gradient Norm after: 1.5928382515685937
Epoch 941/10000, Prediction Accuracy = 56.923076923076934%, Loss = 0.01142392923625616
Epoch: 941, Batch Gradient Norm: 1.4351723626706212
Epoch: 941, Batch Gradient Norm after: 1.4351723626706212
Epoch 942/10000, Prediction Accuracy = 57.32692307692308%, Loss = 0.011274062025432404
Epoch: 942, Batch Gradient Norm: 1.3748779774327884
Epoch: 942, Batch Gradient Norm after: 1.3748779774327884
Epoch 943/10000, Prediction Accuracy = 57.25384615384615%, Loss = 0.011275781175264945
Epoch: 943, Batch Gradient Norm: 1.4198263928432078
Epoch: 943, Batch Gradient Norm after: 1.4198263928432078
Epoch 944/10000, Prediction Accuracy = 57.10384615384615%, Loss = 0.011253443045111803
Epoch: 944, Batch Gradient Norm: 1.5674528797359766
Epoch: 944, Batch Gradient Norm after: 1.5674528797359766
Epoch 945/10000, Prediction Accuracy = 56.92692307692307%, Loss = 0.011411291188918628
Epoch: 945, Batch Gradient Norm: 1.4272111646273795
Epoch: 945, Batch Gradient Norm after: 1.4272111646273795
Epoch 946/10000, Prediction Accuracy = 57.03846153846155%, Loss = 0.011314818205741735
Epoch: 946, Batch Gradient Norm: 1.4563089396699302
Epoch: 946, Batch Gradient Norm after: 1.4563089396699302
Epoch 947/10000, Prediction Accuracy = 57.42307692307692%, Loss = 0.011337424986637555
Epoch: 947, Batch Gradient Norm: 1.5986105452892398
Epoch: 947, Batch Gradient Norm after: 1.5986105452892398
Epoch 948/10000, Prediction Accuracy = 56.888461538461534%, Loss = 0.011381651059939312
Epoch: 948, Batch Gradient Norm: 1.5164538537128955
Epoch: 948, Batch Gradient Norm after: 1.5164538537128955
Epoch 949/10000, Prediction Accuracy = 56.880769230769246%, Loss = 0.011425979507084075
Epoch: 949, Batch Gradient Norm: 1.3731452997441218
Epoch: 949, Batch Gradient Norm after: 1.3731452997441218
Epoch 950/10000, Prediction Accuracy = 57.38461538461537%, Loss = 0.011289941648451181
Epoch: 950, Batch Gradient Norm: 1.577613741535034
Epoch: 950, Batch Gradient Norm after: 1.577613741535034
Epoch 951/10000, Prediction Accuracy = 56.89999999999999%, Loss = 0.01136139314621687
Epoch: 951, Batch Gradient Norm: 1.5323941751721788
Epoch: 951, Batch Gradient Norm after: 1.5323941751721788
Epoch 952/10000, Prediction Accuracy = 56.75%, Loss = 0.01139732371442593
Epoch: 952, Batch Gradient Norm: 1.6054240621528013
Epoch: 952, Batch Gradient Norm after: 1.6054240621528013
Epoch 953/10000, Prediction Accuracy = 56.626923076923084%, Loss = 0.011418838197222123
Epoch: 953, Batch Gradient Norm: 1.632210355690552
Epoch: 953, Batch Gradient Norm after: 1.632210355690552
Epoch 954/10000, Prediction Accuracy = 56.74615384615385%, Loss = 0.011451091832266403
Epoch: 954, Batch Gradient Norm: 1.7742136323931805
Epoch: 954, Batch Gradient Norm after: 1.7742136323931805
Epoch 955/10000, Prediction Accuracy = 56.26153846153846%, Loss = 0.011568230433532825
Epoch: 955, Batch Gradient Norm: 1.6986360016694484
Epoch: 955, Batch Gradient Norm after: 1.6986360016694484
Epoch 956/10000, Prediction Accuracy = 56.89230769230768%, Loss = 0.011602563353685232
Epoch: 956, Batch Gradient Norm: 1.4090024482907382
Epoch: 956, Batch Gradient Norm after: 1.4090024482907382
Epoch 957/10000, Prediction Accuracy = 57.03846153846155%, Loss = 0.01136216872300093
Epoch: 957, Batch Gradient Norm: 1.3692618705333384
Epoch: 957, Batch Gradient Norm after: 1.3692618705333384
Epoch 958/10000, Prediction Accuracy = 57.18846153846153%, Loss = 0.011271664299643956
Epoch: 958, Batch Gradient Norm: 1.5438479937510559
Epoch: 958, Batch Gradient Norm after: 1.5438479937510559
Epoch 959/10000, Prediction Accuracy = 57.157692307692315%, Loss = 0.011395567669891395
Epoch: 959, Batch Gradient Norm: 1.488452468219255
Epoch: 959, Batch Gradient Norm after: 1.488452468219255
Epoch 960/10000, Prediction Accuracy = 56.96923076923076%, Loss = 0.011426757447994672
Epoch: 960, Batch Gradient Norm: 1.5127620300931939
Epoch: 960, Batch Gradient Norm after: 1.5127620300931939
Epoch 961/10000, Prediction Accuracy = 56.55769230769231%, Loss = 0.011495165956708102
Epoch: 961, Batch Gradient Norm: 1.567398168758815
Epoch: 961, Batch Gradient Norm after: 1.567398168758815
Epoch 962/10000, Prediction Accuracy = 56.684615384615384%, Loss = 0.01151656352270108
Epoch: 962, Batch Gradient Norm: 1.523400018528487
Epoch: 962, Batch Gradient Norm after: 1.523400018528487
Epoch 963/10000, Prediction Accuracy = 56.634615384615394%, Loss = 0.011452409223868297
Epoch: 963, Batch Gradient Norm: 1.3418579905230121
Epoch: 963, Batch Gradient Norm after: 1.3418579905230121
Epoch 964/10000, Prediction Accuracy = 57.192307692307686%, Loss = 0.011378496025617305
Epoch: 964, Batch Gradient Norm: 1.4752910316663936
Epoch: 964, Batch Gradient Norm after: 1.4752910316663936
Epoch 965/10000, Prediction Accuracy = 56.82307692307692%, Loss = 0.011399691709532188
Epoch: 965, Batch Gradient Norm: 1.4911549914122368
Epoch: 965, Batch Gradient Norm after: 1.4911549914122368
Epoch 966/10000, Prediction Accuracy = 56.71538461538462%, Loss = 0.011358829645010142
Epoch: 966, Batch Gradient Norm: 1.6366084576389854
Epoch: 966, Batch Gradient Norm after: 1.6366084576389854
Epoch 967/10000, Prediction Accuracy = 57.09999999999999%, Loss = 0.011423587440871276
Epoch: 967, Batch Gradient Norm: 1.5296367170991565
Epoch: 967, Batch Gradient Norm after: 1.5296367170991565
Epoch 968/10000, Prediction Accuracy = 56.82307692307692%, Loss = 0.011474145934558831
Epoch: 968, Batch Gradient Norm: 1.4242448074712422
Epoch: 968, Batch Gradient Norm after: 1.4242448074712422
Epoch 969/10000, Prediction Accuracy = 56.78076923076923%, Loss = 0.011445222995602168
Epoch: 969, Batch Gradient Norm: 1.4290902907191487
Epoch: 969, Batch Gradient Norm after: 1.4290902907191487
Epoch 970/10000, Prediction Accuracy = 57.06923076923077%, Loss = 0.011419452655200776
Epoch: 970, Batch Gradient Norm: 1.530308336716268
Epoch: 970, Batch Gradient Norm after: 1.530308336716268
Epoch 971/10000, Prediction Accuracy = 56.73461538461539%, Loss = 0.011494193226099014
Epoch: 971, Batch Gradient Norm: 1.6272006848619989
Epoch: 971, Batch Gradient Norm after: 1.6272006848619989
Epoch 972/10000, Prediction Accuracy = 56.85769230769232%, Loss = 0.011544411285565449
Epoch: 972, Batch Gradient Norm: 1.4877071778583524
Epoch: 972, Batch Gradient Norm after: 1.4877071778583524
Epoch 973/10000, Prediction Accuracy = 56.665384615384625%, Loss = 0.011516999596586594
Epoch: 973, Batch Gradient Norm: 1.6066191051120884
Epoch: 973, Batch Gradient Norm after: 1.6066191051120884
Epoch 974/10000, Prediction Accuracy = 56.842307692307685%, Loss = 0.011566222716982547
Epoch: 974, Batch Gradient Norm: 1.5162477727666532
Epoch: 974, Batch Gradient Norm after: 1.5162477727666532
Epoch 975/10000, Prediction Accuracy = 56.34615384615384%, Loss = 0.011526106498562373
Epoch: 975, Batch Gradient Norm: 1.4641567893565741
Epoch: 975, Batch Gradient Norm after: 1.4641567893565741
Epoch 976/10000, Prediction Accuracy = 56.611538461538466%, Loss = 0.011459526892464895
Epoch: 976, Batch Gradient Norm: 1.7087808231513317
Epoch: 976, Batch Gradient Norm after: 1.7087808231513317
Epoch 977/10000, Prediction Accuracy = 56.276923076923076%, Loss = 0.011642388641261138
Epoch: 977, Batch Gradient Norm: 1.484466976420493
Epoch: 977, Batch Gradient Norm after: 1.484466976420493
Epoch 978/10000, Prediction Accuracy = 56.96538461538462%, Loss = 0.011480586173442693
Epoch: 978, Batch Gradient Norm: 1.4203116183113083
Epoch: 978, Batch Gradient Norm after: 1.4203116183113083
Epoch 979/10000, Prediction Accuracy = 56.646153846153844%, Loss = 0.011409047847756973
Epoch: 979, Batch Gradient Norm: 1.5078240068091013
Epoch: 979, Batch Gradient Norm after: 1.5078240068091013
Epoch 980/10000, Prediction Accuracy = 56.603846153846156%, Loss = 0.011504206304939894
Epoch: 980, Batch Gradient Norm: 1.552844151076578
Epoch: 980, Batch Gradient Norm after: 1.552844151076578
Epoch 981/10000, Prediction Accuracy = 56.89615384615385%, Loss = 0.011451124141995724
Epoch: 981, Batch Gradient Norm: 1.5811479224618998
Epoch: 981, Batch Gradient Norm after: 1.5811479224618998
Epoch 982/10000, Prediction Accuracy = 57.07692307692309%, Loss = 0.01148030455582417
Epoch: 982, Batch Gradient Norm: 1.536441215579133
Epoch: 982, Batch Gradient Norm after: 1.536441215579133
Epoch 983/10000, Prediction Accuracy = 56.74615384615384%, Loss = 0.01146119639564019
Epoch: 983, Batch Gradient Norm: 1.6271575682405763
Epoch: 983, Batch Gradient Norm after: 1.6271575682405763
Epoch 984/10000, Prediction Accuracy = 56.426923076923075%, Loss = 0.011562343686819077
Epoch: 984, Batch Gradient Norm: 1.5176934784675198
Epoch: 984, Batch Gradient Norm after: 1.5176934784675198
Epoch 985/10000, Prediction Accuracy = 56.726923076923086%, Loss = 0.011495619582442137
Epoch: 985, Batch Gradient Norm: 1.6249434085678331
Epoch: 985, Batch Gradient Norm after: 1.6249434085678331
Epoch 986/10000, Prediction Accuracy = 56.476923076923065%, Loss = 0.011598638258874416
Epoch: 986, Batch Gradient Norm: 1.5529663620960974
Epoch: 986, Batch Gradient Norm after: 1.5529663620960974
Epoch 987/10000, Prediction Accuracy = 56.265384615384626%, Loss = 0.011538129228238877
Epoch: 987, Batch Gradient Norm: 1.5685420238872652
Epoch: 987, Batch Gradient Norm after: 1.5685420238872652
Epoch 988/10000, Prediction Accuracy = 56.361538461538466%, Loss = 0.011558290284413558
Epoch: 988, Batch Gradient Norm: 1.5250252778489182
Epoch: 988, Batch Gradient Norm after: 1.5250252778489182
Epoch 989/10000, Prediction Accuracy = 56.896153846153844%, Loss = 0.011478696305018205
Epoch: 989, Batch Gradient Norm: 1.587300378435062
Epoch: 989, Batch Gradient Norm after: 1.587300378435062
Epoch 990/10000, Prediction Accuracy = 56.35384615384615%, Loss = 0.01157451464006534
Epoch: 990, Batch Gradient Norm: 1.464502906504236
Epoch: 990, Batch Gradient Norm after: 1.464502906504236
Epoch 991/10000, Prediction Accuracy = 56.73076923076923%, Loss = 0.011440533643158583
Epoch: 991, Batch Gradient Norm: 1.4429777148067893
Epoch: 991, Batch Gradient Norm after: 1.4429777148067893
Epoch 992/10000, Prediction Accuracy = 56.93076923076923%, Loss = 0.011439992329822136
Epoch: 992, Batch Gradient Norm: 1.366277435625692
Epoch: 992, Batch Gradient Norm after: 1.366277435625692
Epoch 993/10000, Prediction Accuracy = 57.026923076923076%, Loss = 0.011380399935520612
Epoch: 993, Batch Gradient Norm: 1.456215959524167
Epoch: 993, Batch Gradient Norm after: 1.456215959524167
Epoch 994/10000, Prediction Accuracy = 56.85000000000001%, Loss = 0.011430002820606414
Epoch: 994, Batch Gradient Norm: 1.5368031364357233
Epoch: 994, Batch Gradient Norm after: 1.5368031364357233
Epoch 995/10000, Prediction Accuracy = 56.55%, Loss = 0.011476860524943242
Epoch: 995, Batch Gradient Norm: 1.7508366937097846
Epoch: 995, Batch Gradient Norm after: 1.7508366937097846
Epoch 996/10000, Prediction Accuracy = 56.33461538461539%, Loss = 0.011614491804861106
Epoch: 996, Batch Gradient Norm: 1.5184020365658302
Epoch: 996, Batch Gradient Norm after: 1.5184020365658302
Epoch 997/10000, Prediction Accuracy = 56.642307692307696%, Loss = 0.011551351358111087
Epoch: 997, Batch Gradient Norm: 1.4902942942915522
Epoch: 997, Batch Gradient Norm after: 1.4902942942915522
Epoch 998/10000, Prediction Accuracy = 56.68461538461539%, Loss = 0.011495634985084716
Epoch: 998, Batch Gradient Norm: 1.6594678956826947
Epoch: 998, Batch Gradient Norm after: 1.6594678956826947
Epoch 999/10000, Prediction Accuracy = 56.56923076923077%, Loss = 0.011609909411233205
Epoch: 999, Batch Gradient Norm: 1.6067550140953613
Epoch: 999, Batch Gradient Norm after: 1.6067550140953613
Epoch 1000/10000, Prediction Accuracy = 56.60384615384615%, Loss = 0.011533675357126273
Epoch: 1000, Batch Gradient Norm: 1.5880171190863601
Epoch: 1000, Batch Gradient Norm after: 1.5880171190863601
Epoch 1001/10000, Prediction Accuracy = 56.8423076923077%, Loss = 0.011576495061700161
Epoch: 1001, Batch Gradient Norm: 1.6029456294778082
Epoch: 1001, Batch Gradient Norm after: 1.6029456294778082
Epoch 1002/10000, Prediction Accuracy = 55.965384615384615%, Loss = 0.011587472704167549
Epoch: 1002, Batch Gradient Norm: 1.71434417117374
Epoch: 1002, Batch Gradient Norm after: 1.71434417117374
Epoch 1003/10000, Prediction Accuracy = 56.50384615384615%, Loss = 0.011612446763767647
Epoch: 1003, Batch Gradient Norm: 1.4659235836239257
Epoch: 1003, Batch Gradient Norm after: 1.4659235836239257
Epoch 1004/10000, Prediction Accuracy = 56.67692307692308%, Loss = 0.01142972127462809
Epoch: 1004, Batch Gradient Norm: 1.483260568669797
Epoch: 1004, Batch Gradient Norm after: 1.483260568669797
Epoch 1005/10000, Prediction Accuracy = 57.01538461538461%, Loss = 0.011488516098604752
Epoch: 1005, Batch Gradient Norm: 1.509158205983481
Epoch: 1005, Batch Gradient Norm after: 1.509158205983481
Epoch 1006/10000, Prediction Accuracy = 56.51153846153847%, Loss = 0.011488004587590694
Epoch: 1006, Batch Gradient Norm: 1.5850912932232677
Epoch: 1006, Batch Gradient Norm after: 1.5850912932232677
Epoch 1007/10000, Prediction Accuracy = 56.59615384615385%, Loss = 0.011549909384204792
Epoch: 1007, Batch Gradient Norm: 1.5808842570370238
Epoch: 1007, Batch Gradient Norm after: 1.5808842570370238
Epoch 1008/10000, Prediction Accuracy = 56.43076923076923%, Loss = 0.01158138643950224
Epoch: 1008, Batch Gradient Norm: 1.4988161497315031
Epoch: 1008, Batch Gradient Norm after: 1.4988161497315031
Epoch 1009/10000, Prediction Accuracy = 56.75384615384616%, Loss = 0.011499730655207084
Epoch: 1009, Batch Gradient Norm: 1.6524563367086509
Epoch: 1009, Batch Gradient Norm after: 1.6524563367086509
Epoch 1010/10000, Prediction Accuracy = 56.49230769230769%, Loss = 0.011542868084059311
Epoch: 1010, Batch Gradient Norm: 1.5139716702206933
Epoch: 1010, Batch Gradient Norm after: 1.5139716702206933
Epoch 1011/10000, Prediction Accuracy = 56.83461538461539%, Loss = 0.011473102065233083
Epoch: 1011, Batch Gradient Norm: 1.5877872890410916
Epoch: 1011, Batch Gradient Norm after: 1.5877872890410916
Epoch 1012/10000, Prediction Accuracy = 56.611538461538444%, Loss = 0.011544652139911285
Epoch: 1012, Batch Gradient Norm: 1.6260414924650826
Epoch: 1012, Batch Gradient Norm after: 1.6260414924650826
Epoch 1013/10000, Prediction Accuracy = 56.66538461538461%, Loss = 0.011511857549731549
Epoch: 1013, Batch Gradient Norm: 1.621122817109498
Epoch: 1013, Batch Gradient Norm after: 1.621122817109498
Epoch 1014/10000, Prediction Accuracy = 56.56923076923077%, Loss = 0.011586169425684672
Epoch: 1014, Batch Gradient Norm: 1.6625883863745727
Epoch: 1014, Batch Gradient Norm after: 1.6625883863745727
Epoch 1015/10000, Prediction Accuracy = 56.58846153846154%, Loss = 0.011594007866313824
Epoch: 1015, Batch Gradient Norm: 1.5671385072027832
Epoch: 1015, Batch Gradient Norm after: 1.5671385072027832
Epoch 1016/10000, Prediction Accuracy = 56.50769230769231%, Loss = 0.011550591613810796
Epoch: 1016, Batch Gradient Norm: 1.5097172347694228
Epoch: 1016, Batch Gradient Norm after: 1.5097172347694228
Epoch 1017/10000, Prediction Accuracy = 56.896153846153844%, Loss = 0.011433094811554138
Epoch: 1017, Batch Gradient Norm: 1.6185052829403255
Epoch: 1017, Batch Gradient Norm after: 1.6185052829403255
Epoch 1018/10000, Prediction Accuracy = 56.165384615384625%, Loss = 0.011589488659340601
Epoch: 1018, Batch Gradient Norm: 1.6117194832228667
Epoch: 1018, Batch Gradient Norm after: 1.6117194832228667
Epoch 1019/10000, Prediction Accuracy = 56.665384615384625%, Loss = 0.011581830465449737
Epoch: 1019, Batch Gradient Norm: 1.5198569815845198
Epoch: 1019, Batch Gradient Norm after: 1.5198569815845198
Epoch 1020/10000, Prediction Accuracy = 56.82307692307692%, Loss = 0.011543540570598382
Epoch: 1020, Batch Gradient Norm: 1.607139779710259
Epoch: 1020, Batch Gradient Norm after: 1.607139779710259
Epoch 1021/10000, Prediction Accuracy = 56.94615384615385%, Loss = 0.011604823243732635
Epoch: 1021, Batch Gradient Norm: 1.6589757624142127
Epoch: 1021, Batch Gradient Norm after: 1.6589757624142127
Epoch 1022/10000, Prediction Accuracy = 56.38461538461539%, Loss = 0.011590134710646592
Epoch: 1022, Batch Gradient Norm: 1.6041368201332233
Epoch: 1022, Batch Gradient Norm after: 1.6041368201332233
Epoch 1023/10000, Prediction Accuracy = 56.16153846153846%, Loss = 0.011609772506814737
Epoch: 1023, Batch Gradient Norm: 1.6517429889789967
Epoch: 1023, Batch Gradient Norm after: 1.6517429889789967
Epoch 1024/10000, Prediction Accuracy = 56.330769230769235%, Loss = 0.011632171746056814
Epoch: 1024, Batch Gradient Norm: 1.6573745214250566
Epoch: 1024, Batch Gradient Norm after: 1.6573745214250566
Epoch 1025/10000, Prediction Accuracy = 56.69615384615384%, Loss = 0.011618434308240047
Epoch: 1025, Batch Gradient Norm: 1.558902034273212
Epoch: 1025, Batch Gradient Norm after: 1.558902034273212
Epoch 1026/10000, Prediction Accuracy = 56.43076923076922%, Loss = 0.011586510003186189
Epoch: 1026, Batch Gradient Norm: 1.5115389000155595
Epoch: 1026, Batch Gradient Norm after: 1.5115389000155595
Epoch 1027/10000, Prediction Accuracy = 56.60000000000001%, Loss = 0.01156993554188655
Epoch: 1027, Batch Gradient Norm: 1.7566233245177132
Epoch: 1027, Batch Gradient Norm after: 1.7566233245177132
Epoch 1028/10000, Prediction Accuracy = 56.10000000000001%, Loss = 0.011737121985508846
Epoch: 1028, Batch Gradient Norm: 1.6547848405073198
Epoch: 1028, Batch Gradient Norm after: 1.6547848405073198
Epoch 1029/10000, Prediction Accuracy = 56.442307692307686%, Loss = 0.011680629247656235
Epoch: 1029, Batch Gradient Norm: 1.6571617704473907
Epoch: 1029, Batch Gradient Norm after: 1.6571617704473907
Epoch 1030/10000, Prediction Accuracy = 56.27692307692307%, Loss = 0.011630984882895764
Epoch: 1030, Batch Gradient Norm: 1.573980041274692
Epoch: 1030, Batch Gradient Norm after: 1.573980041274692
Epoch 1031/10000, Prediction Accuracy = 56.53076923076923%, Loss = 0.011643121878688153
Epoch: 1031, Batch Gradient Norm: 1.5057046701054184
Epoch: 1031, Batch Gradient Norm after: 1.5057046701054184
Epoch 1032/10000, Prediction Accuracy = 56.18076923076923%, Loss = 0.011591365560889244
Epoch: 1032, Batch Gradient Norm: 1.5997977050456076
Epoch: 1032, Batch Gradient Norm after: 1.5997977050456076
Epoch 1033/10000, Prediction Accuracy = 56.357692307692304%, Loss = 0.011561759890845189
Epoch: 1033, Batch Gradient Norm: 1.712762919441799
Epoch: 1033, Batch Gradient Norm after: 1.712762919441799
Epoch 1034/10000, Prediction Accuracy = 56.396153846153844%, Loss = 0.011607584901727162
Epoch: 1034, Batch Gradient Norm: 1.5219850157314387
Epoch: 1034, Batch Gradient Norm after: 1.5219850157314387
Epoch 1035/10000, Prediction Accuracy = 56.74230769230768%, Loss = 0.011522560810240416
Epoch: 1035, Batch Gradient Norm: 1.618597174527616
Epoch: 1035, Batch Gradient Norm after: 1.618597174527616
Epoch 1036/10000, Prediction Accuracy = 56.376923076923084%, Loss = 0.011602968837206181
Epoch: 1036, Batch Gradient Norm: 1.5867899461115083
Epoch: 1036, Batch Gradient Norm after: 1.5867899461115083
Epoch 1037/10000, Prediction Accuracy = 56.84615384615386%, Loss = 0.011623825877904892
Epoch: 1037, Batch Gradient Norm: 1.7131860751573191
Epoch: 1037, Batch Gradient Norm after: 1.7131860751573191
Epoch 1038/10000, Prediction Accuracy = 56.276923076923076%, Loss = 0.011609656951175286
Epoch: 1038, Batch Gradient Norm: 1.6714309319126617
Epoch: 1038, Batch Gradient Norm after: 1.6714309319126617
Epoch 1039/10000, Prediction Accuracy = 56.49230769230769%, Loss = 0.01165691318993385
Epoch: 1039, Batch Gradient Norm: 1.629847163848273
Epoch: 1039, Batch Gradient Norm after: 1.629847163848273
Epoch 1040/10000, Prediction Accuracy = 56.065384615384616%, Loss = 0.011645667326564971
Epoch: 1040, Batch Gradient Norm: 1.6581078644169052
Epoch: 1040, Batch Gradient Norm after: 1.6581078644169052
Epoch 1041/10000, Prediction Accuracy = 56.146153846153844%, Loss = 0.011655473795074683
Epoch: 1041, Batch Gradient Norm: 1.7771641428582634
Epoch: 1041, Batch Gradient Norm after: 1.7771641428582634
Epoch 1042/10000, Prediction Accuracy = 56.00384615384615%, Loss = 0.011764920244996365
Epoch: 1042, Batch Gradient Norm: 1.6889721950621193
Epoch: 1042, Batch Gradient Norm after: 1.6889721950621193
Epoch 1043/10000, Prediction Accuracy = 56.43846153846153%, Loss = 0.011810742820111604
Epoch: 1043, Batch Gradient Norm: 1.4948341840942634
Epoch: 1043, Batch Gradient Norm after: 1.4948341840942634
Epoch 1044/10000, Prediction Accuracy = 56.27307692307692%, Loss = 0.011593487328634812
Epoch: 1044, Batch Gradient Norm: 1.6420394757814514
Epoch: 1044, Batch Gradient Norm after: 1.6420394757814514
Epoch 1045/10000, Prediction Accuracy = 56.188461538461524%, Loss = 0.01177670512921535
Epoch: 1045, Batch Gradient Norm: 1.5017675465303135
Epoch: 1045, Batch Gradient Norm after: 1.5017675465303135
Epoch 1046/10000, Prediction Accuracy = 56.392307692307696%, Loss = 0.011556131407045402
Epoch: 1046, Batch Gradient Norm: 1.6553294654832087
Epoch: 1046, Batch Gradient Norm after: 1.6553294654832087
Epoch 1047/10000, Prediction Accuracy = 56.11923076923077%, Loss = 0.011631077155470848
Epoch: 1047, Batch Gradient Norm: 1.658653944208539
Epoch: 1047, Batch Gradient Norm after: 1.658653944208539
Epoch 1048/10000, Prediction Accuracy = 56.26923076923077%, Loss = 0.011695507698907303
Epoch: 1048, Batch Gradient Norm: 1.4990024457231967
Epoch: 1048, Batch Gradient Norm after: 1.4990024457231967
Epoch 1049/10000, Prediction Accuracy = 56.95000000000001%, Loss = 0.011550633021845268
Epoch: 1049, Batch Gradient Norm: 1.6195568015969848
Epoch: 1049, Batch Gradient Norm after: 1.6195568015969848
Epoch 1050/10000, Prediction Accuracy = 56.50769230769231%, Loss = 0.011607741077358905
Epoch: 1050, Batch Gradient Norm: 1.684870466749424
Epoch: 1050, Batch Gradient Norm after: 1.684870466749424
Epoch 1051/10000, Prediction Accuracy = 56.31923076923077%, Loss = 0.011654428349664578
Epoch: 1051, Batch Gradient Norm: 1.6548366500210707
Epoch: 1051, Batch Gradient Norm after: 1.6548366500210707
Epoch 1052/10000, Prediction Accuracy = 56.53461538461538%, Loss = 0.011647446367603082
Epoch: 1052, Batch Gradient Norm: 1.5644429375618971
Epoch: 1052, Batch Gradient Norm after: 1.5644429375618971
Epoch 1053/10000, Prediction Accuracy = 56.45384615384615%, Loss = 0.011605625327389974
Epoch: 1053, Batch Gradient Norm: 1.5018643588887002
Epoch: 1053, Batch Gradient Norm after: 1.5018643588887002
Epoch 1054/10000, Prediction Accuracy = 56.376923076923084%, Loss = 0.011585087157212771
Epoch: 1054, Batch Gradient Norm: 1.6422368141198311
Epoch: 1054, Batch Gradient Norm after: 1.6422368141198311
Epoch 1055/10000, Prediction Accuracy = 56.7%, Loss = 0.011623863990490254
Epoch: 1055, Batch Gradient Norm: 1.6479025651648738
Epoch: 1055, Batch Gradient Norm after: 1.6479025651648738
Epoch 1056/10000, Prediction Accuracy = 56.342307692307685%, Loss = 0.01160616921977355
Epoch: 1056, Batch Gradient Norm: 1.4740786679821696
Epoch: 1056, Batch Gradient Norm after: 1.4740786679821696
Epoch 1057/10000, Prediction Accuracy = 56.38461538461539%, Loss = 0.011557795465565644
Epoch: 1057, Batch Gradient Norm: 1.6742883221175444
Epoch: 1057, Batch Gradient Norm after: 1.6742883221175444
Epoch 1058/10000, Prediction Accuracy = 56.3423076923077%, Loss = 0.011700315114397269
Epoch: 1058, Batch Gradient Norm: 1.8871341685241447
Epoch: 1058, Batch Gradient Norm after: 1.8871341685241447
Epoch 1059/10000, Prediction Accuracy = 55.84615384615385%, Loss = 0.011863141750486998
Epoch: 1059, Batch Gradient Norm: 1.644617622326669
Epoch: 1059, Batch Gradient Norm after: 1.644617622326669
Epoch 1060/10000, Prediction Accuracy = 56.407692307692315%, Loss = 0.011707684598290004
Epoch: 1060, Batch Gradient Norm: 1.6465708087659838
Epoch: 1060, Batch Gradient Norm after: 1.6465708087659838
Epoch 1061/10000, Prediction Accuracy = 56.56153846153846%, Loss = 0.011626986356881948
Epoch: 1061, Batch Gradient Norm: 1.7471425663074835
Epoch: 1061, Batch Gradient Norm after: 1.7471425663074835
Epoch 1062/10000, Prediction Accuracy = 56.13461538461539%, Loss = 0.011760979819183167
Epoch: 1062, Batch Gradient Norm: 1.6357011931244267
Epoch: 1062, Batch Gradient Norm after: 1.6357011931244267
Epoch 1063/10000, Prediction Accuracy = 56.09615384615385%, Loss = 0.01164004779778994
Epoch: 1063, Batch Gradient Norm: 1.6969355425224584
Epoch: 1063, Batch Gradient Norm after: 1.6969355425224584
Epoch 1064/10000, Prediction Accuracy = 56.542307692307695%, Loss = 0.011666647731684722
Epoch: 1064, Batch Gradient Norm: 1.580421994703089
Epoch: 1064, Batch Gradient Norm after: 1.580421994703089
Epoch 1065/10000, Prediction Accuracy = 56.626923076923084%, Loss = 0.011617406128117671
Epoch: 1065, Batch Gradient Norm: 1.5719210500480263
Epoch: 1065, Batch Gradient Norm after: 1.5719210500480263
Epoch 1066/10000, Prediction Accuracy = 56.349999999999994%, Loss = 0.011583085386798931
Epoch: 1066, Batch Gradient Norm: 1.574783596024148
Epoch: 1066, Batch Gradient Norm after: 1.574783596024148
Epoch 1067/10000, Prediction Accuracy = 56.26923076923077%, Loss = 0.011600166272658568
Epoch: 1067, Batch Gradient Norm: 1.5769524154863608
Epoch: 1067, Batch Gradient Norm after: 1.5769524154863608
Epoch 1068/10000, Prediction Accuracy = 56.576923076923066%, Loss = 0.011604100895615725
Epoch: 1068, Batch Gradient Norm: 1.6042939935125886
Epoch: 1068, Batch Gradient Norm after: 1.6042939935125886
Epoch 1069/10000, Prediction Accuracy = 56.60384615384615%, Loss = 0.01163906897776402
Epoch: 1069, Batch Gradient Norm: 1.6752435818371265
Epoch: 1069, Batch Gradient Norm after: 1.6752435818371265
Epoch 1070/10000, Prediction Accuracy = 56.323076923076925%, Loss = 0.011719503511603061
Epoch: 1070, Batch Gradient Norm: 1.8774976281902231
Epoch: 1070, Batch Gradient Norm after: 1.8774976281902231
Epoch 1071/10000, Prediction Accuracy = 56.215384615384615%, Loss = 0.011772117434212795
Epoch: 1071, Batch Gradient Norm: 1.7567029003914
Epoch: 1071, Batch Gradient Norm after: 1.7567029003914
Epoch 1072/10000, Prediction Accuracy = 55.919230769230765%, Loss = 0.011743879232269067
Epoch: 1072, Batch Gradient Norm: 1.5889184138856318
Epoch: 1072, Batch Gradient Norm after: 1.5889184138856318
Epoch 1073/10000, Prediction Accuracy = 56.45384615384614%, Loss = 0.011620997666166378
Epoch: 1073, Batch Gradient Norm: 1.5045708089422045
Epoch: 1073, Batch Gradient Norm after: 1.5045708089422045
Epoch 1074/10000, Prediction Accuracy = 56.44615384615384%, Loss = 0.01152259397965211
Epoch: 1074, Batch Gradient Norm: 1.6790680401530012
Epoch: 1074, Batch Gradient Norm after: 1.6790680401530012
Epoch 1075/10000, Prediction Accuracy = 55.80769230769231%, Loss = 0.011683523225096555
Epoch: 1075, Batch Gradient Norm: 1.768327470711797
Epoch: 1075, Batch Gradient Norm after: 1.768327470711797
Epoch 1076/10000, Prediction Accuracy = 56.065384615384616%, Loss = 0.011734228939391099
Epoch: 1076, Batch Gradient Norm: 1.5646697853886948
Epoch: 1076, Batch Gradient Norm after: 1.5646697853886948
Epoch 1077/10000, Prediction Accuracy = 56.39615384615384%, Loss = 0.011598437308118893
Epoch: 1077, Batch Gradient Norm: 1.5717094957166602
Epoch: 1077, Batch Gradient Norm after: 1.5717094957166602
Epoch 1078/10000, Prediction Accuracy = 56.43076923076923%, Loss = 0.011594693821210127
Epoch: 1078, Batch Gradient Norm: 1.6473435328880022
Epoch: 1078, Batch Gradient Norm after: 1.6473435328880022
Epoch 1079/10000, Prediction Accuracy = 56.25384615384615%, Loss = 0.01163360089636766
Epoch: 1079, Batch Gradient Norm: 1.609848369186768
Epoch: 1079, Batch Gradient Norm after: 1.609848369186768
Epoch 1080/10000, Prediction Accuracy = 56.353846153846156%, Loss = 0.011576221181223026
Epoch: 1080, Batch Gradient Norm: 1.6083367044522834
Epoch: 1080, Batch Gradient Norm after: 1.6083367044522834
Epoch 1081/10000, Prediction Accuracy = 56.51153846153846%, Loss = 0.011589372315658973
Epoch: 1081, Batch Gradient Norm: 1.7283221870551495
Epoch: 1081, Batch Gradient Norm after: 1.7283221870551495
Epoch 1082/10000, Prediction Accuracy = 56.31923076923078%, Loss = 0.011674471772634067
Epoch: 1082, Batch Gradient Norm: 1.6848976434255865
Epoch: 1082, Batch Gradient Norm after: 1.6848976434255865
Epoch 1083/10000, Prediction Accuracy = 56.27307692307692%, Loss = 0.01172354115316501
Epoch: 1083, Batch Gradient Norm: 1.6345622517858795
Epoch: 1083, Batch Gradient Norm after: 1.6345622517858795
Epoch 1084/10000, Prediction Accuracy = 56.3423076923077%, Loss = 0.01159677618684677
Epoch: 1084, Batch Gradient Norm: 1.6500359260204969
Epoch: 1084, Batch Gradient Norm after: 1.6500359260204969
Epoch 1085/10000, Prediction Accuracy = 56.3%, Loss = 0.011622677700450787
Epoch: 1085, Batch Gradient Norm: 1.7464583874547333
Epoch: 1085, Batch Gradient Norm after: 1.7464583874547333
Epoch 1086/10000, Prediction Accuracy = 56.199999999999996%, Loss = 0.01164499197441798
Epoch: 1086, Batch Gradient Norm: 1.521076554495879
Epoch: 1086, Batch Gradient Norm after: 1.521076554495879
Epoch 1087/10000, Prediction Accuracy = 56.73846153846154%, Loss = 0.011534383162282981
Epoch: 1087, Batch Gradient Norm: 1.5545147674299624
Epoch: 1087, Batch Gradient Norm after: 1.5545147674299624
Epoch 1088/10000, Prediction Accuracy = 56.81153846153846%, Loss = 0.011502758456537357
Epoch: 1088, Batch Gradient Norm: 1.603152663061314
Epoch: 1088, Batch Gradient Norm after: 1.603152663061314
Epoch 1089/10000, Prediction Accuracy = 56.19615384615386%, Loss = 0.01155960545516931
Epoch: 1089, Batch Gradient Norm: 1.641205130813397
Epoch: 1089, Batch Gradient Norm after: 1.641205130813397
Epoch 1090/10000, Prediction Accuracy = 56.17307692307692%, Loss = 0.011673619254277302
Epoch: 1090, Batch Gradient Norm: 1.7429554564002991
Epoch: 1090, Batch Gradient Norm after: 1.7429554564002991
Epoch 1091/10000, Prediction Accuracy = 56.43461538461539%, Loss = 0.011641901058073226
Epoch: 1091, Batch Gradient Norm: 1.772543196200752
Epoch: 1091, Batch Gradient Norm after: 1.772543196200752
Epoch 1092/10000, Prediction Accuracy = 56.338461538461544%, Loss = 0.011678540147840977
Epoch: 1092, Batch Gradient Norm: 1.7194420717684342
Epoch: 1092, Batch Gradient Norm after: 1.7194420717684342
Epoch 1093/10000, Prediction Accuracy = 56.388461538461534%, Loss = 0.011611010091236005
Epoch: 1093, Batch Gradient Norm: 1.5812844432060862
Epoch: 1093, Batch Gradient Norm after: 1.5812844432060862
Epoch 1094/10000, Prediction Accuracy = 56.550000000000004%, Loss = 0.011532561495327033
Epoch: 1094, Batch Gradient Norm: 1.8453413242813623
Epoch: 1094, Batch Gradient Norm after: 1.8453413242813623
Epoch 1095/10000, Prediction Accuracy = 56.349999999999994%, Loss = 0.011686971912590357
Epoch: 1095, Batch Gradient Norm: 1.7144576587668678
Epoch: 1095, Batch Gradient Norm after: 1.7144576587668678
Epoch 1096/10000, Prediction Accuracy = 56.11923076923077%, Loss = 0.01174120970356923
Epoch: 1096, Batch Gradient Norm: 1.7615930798726638
Epoch: 1096, Batch Gradient Norm after: 1.7615930798726638
Epoch 1097/10000, Prediction Accuracy = 56.24615384615386%, Loss = 0.011707194794255953
Epoch: 1097, Batch Gradient Norm: 1.6931235091545367
Epoch: 1097, Batch Gradient Norm after: 1.6931235091545367
Epoch 1098/10000, Prediction Accuracy = 56.36538461538461%, Loss = 0.011620134545060305
Epoch: 1098, Batch Gradient Norm: 1.855367512409536
Epoch: 1098, Batch Gradient Norm after: 1.855367512409536
Epoch 1099/10000, Prediction Accuracy = 56.284615384615385%, Loss = 0.011729487074682346
Epoch: 1099, Batch Gradient Norm: 1.8575739543909182
Epoch: 1099, Batch Gradient Norm after: 1.8575739543909182
Epoch 1100/10000, Prediction Accuracy = 55.81923076923077%, Loss = 0.011808740046734992
Epoch: 1100, Batch Gradient Norm: 1.6445749595042616
Epoch: 1100, Batch Gradient Norm after: 1.6445749595042616
Epoch 1101/10000, Prediction Accuracy = 56.19230769230769%, Loss = 0.011713596275792671
Epoch: 1101, Batch Gradient Norm: 1.925667206285931
Epoch: 1101, Batch Gradient Norm after: 1.925667206285931
Epoch 1102/10000, Prediction Accuracy = 55.646153846153844%, Loss = 0.011841526183371361
Epoch: 1102, Batch Gradient Norm: 1.8258778645794274
Epoch: 1102, Batch Gradient Norm after: 1.8258778645794274
Epoch 1103/10000, Prediction Accuracy = 55.926923076923075%, Loss = 0.0117861249555762
Epoch: 1103, Batch Gradient Norm: 1.6386621157593417
Epoch: 1103, Batch Gradient Norm after: 1.6386621157593417
Epoch 1104/10000, Prediction Accuracy = 56.361538461538466%, Loss = 0.011595695781020017
Epoch: 1104, Batch Gradient Norm: 1.6617215304401451
Epoch: 1104, Batch Gradient Norm after: 1.6617215304401451
Epoch 1105/10000, Prediction Accuracy = 56.176923076923075%, Loss = 0.011668254334766131
Epoch: 1105, Batch Gradient Norm: 1.61564709300006
Epoch: 1105, Batch Gradient Norm after: 1.61564709300006
Epoch 1106/10000, Prediction Accuracy = 56.119230769230775%, Loss = 0.011660672939167572
Epoch: 1106, Batch Gradient Norm: 1.6574207948829722
Epoch: 1106, Batch Gradient Norm after: 1.6574207948829722
Epoch 1107/10000, Prediction Accuracy = 56.21153846153846%, Loss = 0.01169013984214801
Epoch: 1107, Batch Gradient Norm: 1.640558159693621
Epoch: 1107, Batch Gradient Norm after: 1.640558159693621
Epoch 1108/10000, Prediction Accuracy = 55.919230769230765%, Loss = 0.011706755926402716
Epoch: 1108, Batch Gradient Norm: 1.84062327712778
Epoch: 1108, Batch Gradient Norm after: 1.84062327712778
Epoch 1109/10000, Prediction Accuracy = 55.74615384615384%, Loss = 0.011763689967875298
Epoch: 1109, Batch Gradient Norm: 1.6730852524627964
Epoch: 1109, Batch Gradient Norm after: 1.6730852524627964
Epoch 1110/10000, Prediction Accuracy = 55.91153846153846%, Loss = 0.011712153943685384
Epoch: 1110, Batch Gradient Norm: 1.8377691217404304
Epoch: 1110, Batch Gradient Norm after: 1.8377691217404304
Epoch 1111/10000, Prediction Accuracy = 56.27307692307692%, Loss = 0.011749230396862213
Epoch: 1111, Batch Gradient Norm: 1.9042681019022782
Epoch: 1111, Batch Gradient Norm after: 1.9042681019022782
Epoch 1112/10000, Prediction Accuracy = 56.41153846153846%, Loss = 0.011826746022472015
Epoch: 1112, Batch Gradient Norm: 1.923045914155683
Epoch: 1112, Batch Gradient Norm after: 1.923045914155683
Epoch 1113/10000, Prediction Accuracy = 55.98461538461538%, Loss = 0.011831412879893413
Epoch: 1113, Batch Gradient Norm: 1.5829810604837176
Epoch: 1113, Batch Gradient Norm after: 1.5829810604837176
Epoch 1114/10000, Prediction Accuracy = 56.23461538461539%, Loss = 0.011629982493244685
Epoch: 1114, Batch Gradient Norm: 1.6491010482307278
Epoch: 1114, Batch Gradient Norm after: 1.6491010482307278
Epoch 1115/10000, Prediction Accuracy = 56.35769230769232%, Loss = 0.011634472829218093
Epoch: 1115, Batch Gradient Norm: 1.725176106889926
Epoch: 1115, Batch Gradient Norm after: 1.725176106889926
Epoch 1116/10000, Prediction Accuracy = 55.849999999999994%, Loss = 0.011687202235827079
Epoch: 1116, Batch Gradient Norm: 1.7385342716512175
Epoch: 1116, Batch Gradient Norm after: 1.7385342716512175
Epoch 1117/10000, Prediction Accuracy = 55.96153846153846%, Loss = 0.011733931202728014
Epoch: 1117, Batch Gradient Norm: 1.582537084568466
Epoch: 1117, Batch Gradient Norm after: 1.582537084568466
Epoch 1118/10000, Prediction Accuracy = 56.45384615384616%, Loss = 0.011586457204360228
Epoch: 1118, Batch Gradient Norm: 1.6618512549564524
Epoch: 1118, Batch Gradient Norm after: 1.6618512549564524
Epoch 1119/10000, Prediction Accuracy = 56.63461538461539%, Loss = 0.011621718724759726
Epoch: 1119, Batch Gradient Norm: 1.5963477010520515
Epoch: 1119, Batch Gradient Norm after: 1.5963477010520515
Epoch 1120/10000, Prediction Accuracy = 56.38846153846154%, Loss = 0.011603633085122475
Epoch: 1120, Batch Gradient Norm: 1.5466974645442921
Epoch: 1120, Batch Gradient Norm after: 1.5466974645442921
Epoch 1121/10000, Prediction Accuracy = 56.43846153846154%, Loss = 0.01157617225096776
Epoch: 1121, Batch Gradient Norm: 1.6288798961051139
Epoch: 1121, Batch Gradient Norm after: 1.6288798961051139
Epoch 1122/10000, Prediction Accuracy = 56.08461538461539%, Loss = 0.011692972423938604
Epoch: 1122, Batch Gradient Norm: 1.7852107045823629
Epoch: 1122, Batch Gradient Norm after: 1.7852107045823629
Epoch 1123/10000, Prediction Accuracy = 55.87692307692306%, Loss = 0.011775854043662548
Epoch: 1123, Batch Gradient Norm: 1.59466893180951
Epoch: 1123, Batch Gradient Norm after: 1.59466893180951
Epoch 1124/10000, Prediction Accuracy = 56.153846153846146%, Loss = 0.011614158964500977
Epoch: 1124, Batch Gradient Norm: 1.5646530457537555
Epoch: 1124, Batch Gradient Norm after: 1.5646530457537555
Epoch 1125/10000, Prediction Accuracy = 56.676923076923075%, Loss = 0.011551692652014585
Epoch: 1125, Batch Gradient Norm: 1.6854641302244098
Epoch: 1125, Batch Gradient Norm after: 1.6854641302244098
Epoch 1126/10000, Prediction Accuracy = 56.36538461538461%, Loss = 0.011623111410209766
Epoch: 1126, Batch Gradient Norm: 1.75031152046053
Epoch: 1126, Batch Gradient Norm after: 1.75031152046053
Epoch 1127/10000, Prediction Accuracy = 56.11153846153846%, Loss = 0.011687749925141152
Epoch: 1127, Batch Gradient Norm: 1.6301712412722174
Epoch: 1127, Batch Gradient Norm after: 1.6301712412722174
Epoch 1128/10000, Prediction Accuracy = 56.31923076923077%, Loss = 0.01155698736413167
Epoch: 1128, Batch Gradient Norm: 1.720909065742118
Epoch: 1128, Batch Gradient Norm after: 1.720909065742118
Epoch 1129/10000, Prediction Accuracy = 56.22307692307693%, Loss = 0.011659002003188316
Epoch: 1129, Batch Gradient Norm: 1.7461285666117852
Epoch: 1129, Batch Gradient Norm after: 1.7461285666117852
Epoch 1130/10000, Prediction Accuracy = 56.634615384615394%, Loss = 0.01165230106562376
Epoch: 1130, Batch Gradient Norm: 1.6523261856085865
Epoch: 1130, Batch Gradient Norm after: 1.6523261856085865
Epoch 1131/10000, Prediction Accuracy = 56.65384615384615%, Loss = 0.011543200351297855
Epoch: 1131, Batch Gradient Norm: 1.5089155877866962
Epoch: 1131, Batch Gradient Norm after: 1.5089155877866962
Epoch 1132/10000, Prediction Accuracy = 56.63461538461539%, Loss = 0.011484960165734474
Epoch: 1132, Batch Gradient Norm: 1.744381628031875
Epoch: 1132, Batch Gradient Norm after: 1.744381628031875
Epoch 1133/10000, Prediction Accuracy = 56.215384615384615%, Loss = 0.011633125921854606
Epoch: 1133, Batch Gradient Norm: 1.719539860865448
Epoch: 1133, Batch Gradient Norm after: 1.719539860865448
Epoch 1134/10000, Prediction Accuracy = 56.32307692307692%, Loss = 0.011594720399723603
Epoch: 1134, Batch Gradient Norm: 1.7353345722823401
Epoch: 1134, Batch Gradient Norm after: 1.7353345722823401
Epoch 1135/10000, Prediction Accuracy = 56.51153846153846%, Loss = 0.011608568306725759
Epoch: 1135, Batch Gradient Norm: 1.5538320136239396
Epoch: 1135, Batch Gradient Norm after: 1.5538320136239396
Epoch 1136/10000, Prediction Accuracy = 56.74230769230769%, Loss = 0.011492781054515105
Epoch: 1136, Batch Gradient Norm: 1.8347078430287376
Epoch: 1136, Batch Gradient Norm after: 1.8347078430287376
Epoch 1137/10000, Prediction Accuracy = 56.49230769230769%, Loss = 0.011616407392116694
Epoch: 1137, Batch Gradient Norm: 1.8831907228398936
Epoch: 1137, Batch Gradient Norm after: 1.8831907228398936
Epoch 1138/10000, Prediction Accuracy = 55.83076923076922%, Loss = 0.011755694062090837
Epoch: 1138, Batch Gradient Norm: 1.9082927271436572
Epoch: 1138, Batch Gradient Norm after: 1.9082927271436572
Epoch 1139/10000, Prediction Accuracy = 56.119230769230775%, Loss = 0.011740112533936134
Epoch: 1139, Batch Gradient Norm: 1.802989458430929
Epoch: 1139, Batch Gradient Norm after: 1.802989458430929
Epoch 1140/10000, Prediction Accuracy = 55.88461538461539%, Loss = 0.01172940332729083
Epoch: 1140, Batch Gradient Norm: 1.6613466663750174
Epoch: 1140, Batch Gradient Norm after: 1.6613466663750174
Epoch 1141/10000, Prediction Accuracy = 56.25384615384615%, Loss = 0.011614581713309655
Epoch: 1141, Batch Gradient Norm: 1.6797238490728017
Epoch: 1141, Batch Gradient Norm after: 1.6797238490728017
Epoch 1142/10000, Prediction Accuracy = 56.54230769230769%, Loss = 0.011554437474562572
Epoch: 1142, Batch Gradient Norm: 1.7929615423001912
Epoch: 1142, Batch Gradient Norm after: 1.7929615423001912
Epoch 1143/10000, Prediction Accuracy = 56.30384615384616%, Loss = 0.011663046593849476
Epoch: 1143, Batch Gradient Norm: 1.8614247904036878
Epoch: 1143, Batch Gradient Norm after: 1.8614247904036878
Epoch 1144/10000, Prediction Accuracy = 56.050000000000004%, Loss = 0.011764881416009022
Epoch: 1144, Batch Gradient Norm: 1.8178676079926153
Epoch: 1144, Batch Gradient Norm after: 1.8178676079926153
Epoch 1145/10000, Prediction Accuracy = 56.396153846153844%, Loss = 0.011608593380795075
Epoch: 1145, Batch Gradient Norm: 1.6941488449236033
Epoch: 1145, Batch Gradient Norm after: 1.6941488449236033
Epoch 1146/10000, Prediction Accuracy = 56.93076923076923%, Loss = 0.011575092274982195
Epoch: 1146, Batch Gradient Norm: 1.6842724836998662
Epoch: 1146, Batch Gradient Norm after: 1.6842724836998662
Epoch 1147/10000, Prediction Accuracy = 56.3%, Loss = 0.011621366469905926
Epoch: 1147, Batch Gradient Norm: 1.85184499341396
Epoch: 1147, Batch Gradient Norm after: 1.85184499341396
Epoch 1148/10000, Prediction Accuracy = 56.26538461538461%, Loss = 0.011683614637989264
Epoch: 1148, Batch Gradient Norm: 1.8333071339443516
Epoch: 1148, Batch Gradient Norm after: 1.8333071339443516
Epoch 1149/10000, Prediction Accuracy = 56.50384615384616%, Loss = 0.01164009801756877
Epoch: 1149, Batch Gradient Norm: 1.9275934197901337
Epoch: 1149, Batch Gradient Norm after: 1.9275934197901337
Epoch 1150/10000, Prediction Accuracy = 56.326923076923066%, Loss = 0.011742043093993114
Epoch: 1150, Batch Gradient Norm: 1.896669779631215
Epoch: 1150, Batch Gradient Norm after: 1.896669779631215
Epoch 1151/10000, Prediction Accuracy = 55.71153846153846%, Loss = 0.01181679261991611
Epoch: 1151, Batch Gradient Norm: 1.9990168410955098
Epoch: 1151, Batch Gradient Norm after: 1.9990168410955098
Epoch 1152/10000, Prediction Accuracy = 55.13461538461539%, Loss = 0.011888911947607994
Epoch: 1152, Batch Gradient Norm: 1.7138264535409695
Epoch: 1152, Batch Gradient Norm after: 1.7138264535409695
Epoch 1153/10000, Prediction Accuracy = 56.08076923076923%, Loss = 0.01166981508812079
Epoch: 1153, Batch Gradient Norm: 1.665491902641969
Epoch: 1153, Batch Gradient Norm after: 1.665491902641969
Epoch 1154/10000, Prediction Accuracy = 56.74999999999999%, Loss = 0.011640334215301733
Epoch: 1154, Batch Gradient Norm: 1.7115647101381717
Epoch: 1154, Batch Gradient Norm after: 1.7115647101381717
Epoch 1155/10000, Prediction Accuracy = 56.36153846153846%, Loss = 0.011654288937839178
Epoch: 1155, Batch Gradient Norm: 1.736266644047853
Epoch: 1155, Batch Gradient Norm after: 1.736266644047853
Epoch 1156/10000, Prediction Accuracy = 56.16153846153846%, Loss = 0.011686852703300806
Epoch: 1156, Batch Gradient Norm: 1.6782236403208448
Epoch: 1156, Batch Gradient Norm after: 1.6782236403208448
Epoch 1157/10000, Prediction Accuracy = 56.70384615384615%, Loss = 0.011600520031956526
Epoch: 1157, Batch Gradient Norm: 1.7001761748161968
Epoch: 1157, Batch Gradient Norm after: 1.7001761748161968
Epoch 1158/10000, Prediction Accuracy = 56.3423076923077%, Loss = 0.01161986582267743
Epoch: 1158, Batch Gradient Norm: 1.7533209019292164
Epoch: 1158, Batch Gradient Norm after: 1.7533209019292164
Epoch 1159/10000, Prediction Accuracy = 56.31923076923077%, Loss = 0.011570875747845722
Epoch: 1159, Batch Gradient Norm: 1.6715591693468548
Epoch: 1159, Batch Gradient Norm after: 1.6715591693468548
Epoch 1160/10000, Prediction Accuracy = 56.4423076923077%, Loss = 0.01157725344483669
Epoch: 1160, Batch Gradient Norm: 1.644862673529705
Epoch: 1160, Batch Gradient Norm after: 1.644862673529705
Epoch 1161/10000, Prediction Accuracy = 56.176923076923075%, Loss = 0.011519740192362895
Epoch: 1161, Batch Gradient Norm: 1.859402802411903
Epoch: 1161, Batch Gradient Norm after: 1.859402802411903
Epoch 1162/10000, Prediction Accuracy = 56.169230769230765%, Loss = 0.011667418723496107
Epoch: 1162, Batch Gradient Norm: 1.8329963013739883
Epoch: 1162, Batch Gradient Norm after: 1.8329963013739883
Epoch 1163/10000, Prediction Accuracy = 56.373076923076916%, Loss = 0.011685125529766083
Epoch: 1163, Batch Gradient Norm: 1.8363213480319203
Epoch: 1163, Batch Gradient Norm after: 1.8363213480319203
Epoch 1164/10000, Prediction Accuracy = 55.9923076923077%, Loss = 0.011719215088165723
Epoch: 1164, Batch Gradient Norm: 2.0868300044266497
Epoch: 1164, Batch Gradient Norm after: 2.0868300044266497
Epoch 1165/10000, Prediction Accuracy = 55.37692307692308%, Loss = 0.011962266209033819
Epoch: 1165, Batch Gradient Norm: 1.9209299766402415
Epoch: 1165, Batch Gradient Norm after: 1.9209299766402415
Epoch 1166/10000, Prediction Accuracy = 56.08461538461539%, Loss = 0.011813284614338325
Epoch: 1166, Batch Gradient Norm: 1.631829235522151
Epoch: 1166, Batch Gradient Norm after: 1.631829235522151
Epoch 1167/10000, Prediction Accuracy = 56.449999999999996%, Loss = 0.011576223473709363
Epoch: 1167, Batch Gradient Norm: 1.6478532699227877
Epoch: 1167, Batch Gradient Norm after: 1.6478532699227877
Epoch 1168/10000, Prediction Accuracy = 56.599999999999994%, Loss = 0.01156538875343708
Epoch: 1168, Batch Gradient Norm: 1.6060901894527533
Epoch: 1168, Batch Gradient Norm after: 1.6060901894527533
Epoch 1169/10000, Prediction Accuracy = 56.61923076923077%, Loss = 0.011482604134541292
Epoch: 1169, Batch Gradient Norm: 1.7928296909494628
Epoch: 1169, Batch Gradient Norm after: 1.7928296909494628
Epoch 1170/10000, Prediction Accuracy = 56.592307692307685%, Loss = 0.011574882082641125
Epoch: 1170, Batch Gradient Norm: 1.6003118272292487
Epoch: 1170, Batch Gradient Norm after: 1.6003118272292487
Epoch 1171/10000, Prediction Accuracy = 56.48076923076922%, Loss = 0.011490048482440986
Epoch: 1171, Batch Gradient Norm: 1.7928120503320797
Epoch: 1171, Batch Gradient Norm after: 1.7928120503320797
Epoch 1172/10000, Prediction Accuracy = 56.45%, Loss = 0.011520611193890754
Epoch: 1172, Batch Gradient Norm: 1.8819589840278586
Epoch: 1172, Batch Gradient Norm after: 1.8819589840278586
Epoch 1173/10000, Prediction Accuracy = 56.07692307692309%, Loss = 0.011624149763240265
Epoch: 1173, Batch Gradient Norm: 1.9295487436218077
Epoch: 1173, Batch Gradient Norm after: 1.9295487436218077
Epoch 1174/10000, Prediction Accuracy = 56.21538461538462%, Loss = 0.011678416425218949
Epoch: 1174, Batch Gradient Norm: 1.850994970233059
Epoch: 1174, Batch Gradient Norm after: 1.850994970233059
Epoch 1175/10000, Prediction Accuracy = 56.2%, Loss = 0.011624464192069493
Epoch: 1175, Batch Gradient Norm: 1.998266300127742
Epoch: 1175, Batch Gradient Norm after: 1.998266300127742
Epoch 1176/10000, Prediction Accuracy = 55.66923076923077%, Loss = 0.011744996890998803
Epoch: 1176, Batch Gradient Norm: 1.8369992829700714
Epoch: 1176, Batch Gradient Norm after: 1.8369992829700714
Epoch 1177/10000, Prediction Accuracy = 56.19615384615385%, Loss = 0.011569264559791638
Epoch: 1177, Batch Gradient Norm: 1.8033875554623913
Epoch: 1177, Batch Gradient Norm after: 1.8033875554623913
Epoch 1178/10000, Prediction Accuracy = 56.380769230769225%, Loss = 0.011578769852908758
Epoch: 1178, Batch Gradient Norm: 1.879388826637932
Epoch: 1178, Batch Gradient Norm after: 1.879388826637932
Epoch 1179/10000, Prediction Accuracy = 56.09615384615385%, Loss = 0.011637775800549068
Epoch: 1179, Batch Gradient Norm: 1.8520972590418299
Epoch: 1179, Batch Gradient Norm after: 1.8520972590418299
Epoch 1180/10000, Prediction Accuracy = 56.28461538461538%, Loss = 0.011602490853804808
Epoch: 1180, Batch Gradient Norm: 1.8108459367801377
Epoch: 1180, Batch Gradient Norm after: 1.8108459367801377
Epoch 1181/10000, Prediction Accuracy = 56.442307692307686%, Loss = 0.011598204262554646
Epoch: 1181, Batch Gradient Norm: 1.9679476168904895
Epoch: 1181, Batch Gradient Norm after: 1.9679476168904895
Epoch 1182/10000, Prediction Accuracy = 56.09615384615384%, Loss = 0.011662923587629428
Epoch: 1182, Batch Gradient Norm: 1.9730339405063557
Epoch: 1182, Batch Gradient Norm after: 1.9730339405063557
Epoch 1183/10000, Prediction Accuracy = 56.40384615384615%, Loss = 0.01161529768544894
Epoch: 1183, Batch Gradient Norm: 1.7303136432541113
Epoch: 1183, Batch Gradient Norm after: 1.7303136432541113
Epoch 1184/10000, Prediction Accuracy = 56.39999999999999%, Loss = 0.011544957971916748
Epoch: 1184, Batch Gradient Norm: 1.7688941985673539
Epoch: 1184, Batch Gradient Norm after: 1.7688941985673539
Epoch 1185/10000, Prediction Accuracy = 56.3%, Loss = 0.011572477407753468
Epoch: 1185, Batch Gradient Norm: 1.9500159901804304
Epoch: 1185, Batch Gradient Norm after: 1.9500159901804304
Epoch 1186/10000, Prediction Accuracy = 56.050000000000004%, Loss = 0.0116557630065542
Epoch: 1186, Batch Gradient Norm: 1.907752492409903
Epoch: 1186, Batch Gradient Norm after: 1.907752492409903
Epoch 1187/10000, Prediction Accuracy = 56.10769230769232%, Loss = 0.011700478454048816
Epoch: 1187, Batch Gradient Norm: 1.7951919276049926
Epoch: 1187, Batch Gradient Norm after: 1.7951919276049926
Epoch 1188/10000, Prediction Accuracy = 55.98846153846153%, Loss = 0.011600149652132621
Epoch: 1188, Batch Gradient Norm: 1.974610734204377
Epoch: 1188, Batch Gradient Norm after: 1.974610734204377
Epoch 1189/10000, Prediction Accuracy = 56.17692307692308%, Loss = 0.01166415515427406
Epoch: 1189, Batch Gradient Norm: 1.8499534060570904
Epoch: 1189, Batch Gradient Norm after: 1.8499534060570904
Epoch 1190/10000, Prediction Accuracy = 56.63461538461539%, Loss = 0.011662980111745687
Epoch: 1190, Batch Gradient Norm: 1.9429209557650466
Epoch: 1190, Batch Gradient Norm after: 1.9429209557650466
Epoch 1191/10000, Prediction Accuracy = 56.13846153846154%, Loss = 0.011681933815662678
Epoch: 1191, Batch Gradient Norm: 1.9221502057434146
Epoch: 1191, Batch Gradient Norm after: 1.9221502057434146
Epoch 1192/10000, Prediction Accuracy = 55.67692307692308%, Loss = 0.011735161479849082
Epoch: 1192, Batch Gradient Norm: 1.7517752951404428
Epoch: 1192, Batch Gradient Norm after: 1.7517752951404428
Epoch 1193/10000, Prediction Accuracy = 56.30384615384615%, Loss = 0.011608576616988732
Epoch: 1193, Batch Gradient Norm: 1.7745244660511288
Epoch: 1193, Batch Gradient Norm after: 1.7745244660511288
Epoch 1194/10000, Prediction Accuracy = 56.576923076923066%, Loss = 0.011564526492013382
Epoch: 1194, Batch Gradient Norm: 1.8165917510036027
Epoch: 1194, Batch Gradient Norm after: 1.8165917510036027
Epoch 1195/10000, Prediction Accuracy = 56.457692307692305%, Loss = 0.011512084720799556
Epoch: 1195, Batch Gradient Norm: 1.7424377831988134
Epoch: 1195, Batch Gradient Norm after: 1.7424377831988134
Epoch 1196/10000, Prediction Accuracy = 56.49230769230769%, Loss = 0.011489964448488675
Epoch: 1196, Batch Gradient Norm: 1.9485184806672229
Epoch: 1196, Batch Gradient Norm after: 1.9485184806672229
Epoch 1197/10000, Prediction Accuracy = 56.346153846153854%, Loss = 0.011630053202120157
Epoch: 1197, Batch Gradient Norm: 1.846364468029593
Epoch: 1197, Batch Gradient Norm after: 1.846364468029593
Epoch 1198/10000, Prediction Accuracy = 56.3%, Loss = 0.011637944011734081
Epoch: 1198, Batch Gradient Norm: 1.8409544562705795
Epoch: 1198, Batch Gradient Norm after: 1.8409544562705795
Epoch 1199/10000, Prediction Accuracy = 56.15384615384616%, Loss = 0.01158930017397954
Epoch: 1199, Batch Gradient Norm: 1.8968654303723707
Epoch: 1199, Batch Gradient Norm after: 1.8968654303723707
Epoch 1200/10000, Prediction Accuracy = 56.01923076923077%, Loss = 0.011683398642792152
Epoch: 1200, Batch Gradient Norm: 1.9340461202065773
Epoch: 1200, Batch Gradient Norm after: 1.9340461202065773
Epoch 1201/10000, Prediction Accuracy = 56.25769230769231%, Loss = 0.011671390742636643
Epoch: 1201, Batch Gradient Norm: 1.9979187408439163
Epoch: 1201, Batch Gradient Norm after: 1.9979187408439163
Epoch 1202/10000, Prediction Accuracy = 56.07692307692308%, Loss = 0.011669690004335
Epoch: 1202, Batch Gradient Norm: 1.9678964407484314
Epoch: 1202, Batch Gradient Norm after: 1.9678964407484314
Epoch 1203/10000, Prediction Accuracy = 55.72307692307691%, Loss = 0.011693072218734484
Epoch: 1203, Batch Gradient Norm: 1.865714094639903
Epoch: 1203, Batch Gradient Norm after: 1.865714094639903
Epoch 1204/10000, Prediction Accuracy = 55.99615384615385%, Loss = 0.011651393169393906
Epoch: 1204, Batch Gradient Norm: 1.9927308349895099
Epoch: 1204, Batch Gradient Norm after: 1.9927308349895099
Epoch 1205/10000, Prediction Accuracy = 56.184615384615384%, Loss = 0.011670993067897283
Epoch: 1205, Batch Gradient Norm: 1.9095045620291875
Epoch: 1205, Batch Gradient Norm after: 1.9095045620291875
Epoch 1206/10000, Prediction Accuracy = 56.603846153846156%, Loss = 0.011600737173396807
Epoch: 1206, Batch Gradient Norm: 1.9750501176866253
Epoch: 1206, Batch Gradient Norm after: 1.9750501176866253
Epoch 1207/10000, Prediction Accuracy = 56.134615384615394%, Loss = 0.011677664059859056
Epoch: 1207, Batch Gradient Norm: 1.740871601235396
Epoch: 1207, Batch Gradient Norm after: 1.740871601235396
Epoch 1208/10000, Prediction Accuracy = 56.78461538461538%, Loss = 0.011510733586664382
Epoch: 1208, Batch Gradient Norm: 1.7510047778178635
Epoch: 1208, Batch Gradient Norm after: 1.7510047778178635
Epoch 1209/10000, Prediction Accuracy = 56.353846153846156%, Loss = 0.011488749215809198
Epoch: 1209, Batch Gradient Norm: 1.9324909002317594
Epoch: 1209, Batch Gradient Norm after: 1.9324909002317594
Epoch 1210/10000, Prediction Accuracy = 56.126923076923084%, Loss = 0.011691083630117087
Epoch: 1210, Batch Gradient Norm: 1.9254049405528282
Epoch: 1210, Batch Gradient Norm after: 1.9254049405528282
Epoch 1211/10000, Prediction Accuracy = 56.51153846153846%, Loss = 0.011594422448139925
Epoch: 1211, Batch Gradient Norm: 1.8073266680666475
Epoch: 1211, Batch Gradient Norm after: 1.8073266680666475
Epoch 1212/10000, Prediction Accuracy = 56.43076923076922%, Loss = 0.011559080404157821
Epoch: 1212, Batch Gradient Norm: 1.610798749154802
Epoch: 1212, Batch Gradient Norm after: 1.610798749154802
Epoch 1213/10000, Prediction Accuracy = 56.74999999999999%, Loss = 0.011444888149316493
Epoch: 1213, Batch Gradient Norm: 1.9402166400693235
Epoch: 1213, Batch Gradient Norm after: 1.9402166400693235
Epoch 1214/10000, Prediction Accuracy = 56.123076923076916%, Loss = 0.01160110948750606
Epoch: 1214, Batch Gradient Norm: 1.8909382818626954
Epoch: 1214, Batch Gradient Norm after: 1.8909382818626954
Epoch 1215/10000, Prediction Accuracy = 56.07692307692308%, Loss = 0.011585995769844605
Epoch: 1215, Batch Gradient Norm: 1.8774503206645121
Epoch: 1215, Batch Gradient Norm after: 1.8774503206645121
Epoch 1216/10000, Prediction Accuracy = 56.68846153846154%, Loss = 0.011547116061242728
Epoch: 1216, Batch Gradient Norm: 1.9307883966762776
Epoch: 1216, Batch Gradient Norm after: 1.9307883966762776
Epoch 1217/10000, Prediction Accuracy = 56.42307692307691%, Loss = 0.011544375107265435
Epoch: 1217, Batch Gradient Norm: 1.9098339704049738
Epoch: 1217, Batch Gradient Norm after: 1.9098339704049738
Epoch 1218/10000, Prediction Accuracy = 56.184615384615384%, Loss = 0.011581252329051495
Epoch: 1218, Batch Gradient Norm: 1.7999801169088805
Epoch: 1218, Batch Gradient Norm after: 1.7999801169088805
Epoch 1219/10000, Prediction Accuracy = 56.48846153846154%, Loss = 0.011494064202102331
Epoch: 1219, Batch Gradient Norm: 1.9723443019942986
Epoch: 1219, Batch Gradient Norm after: 1.9723443019942986
Epoch 1220/10000, Prediction Accuracy = 56.84615384615385%, Loss = 0.011594537287377395
Epoch: 1220, Batch Gradient Norm: 2.07680158686487
Epoch: 1220, Batch Gradient Norm after: 2.07680158686487
Epoch 1221/10000, Prediction Accuracy = 56.092307692307685%, Loss = 0.011623539532033296
Epoch: 1221, Batch Gradient Norm: 2.036126863857777
Epoch: 1221, Batch Gradient Norm after: 2.036126863857777
Epoch 1222/10000, Prediction Accuracy = 56.48846153846154%, Loss = 0.011640342239003915
Epoch: 1222, Batch Gradient Norm: 2.028377421992989
Epoch: 1222, Batch Gradient Norm after: 2.028377421992989
Epoch 1223/10000, Prediction Accuracy = 56.08846153846154%, Loss = 0.011752460868312763
Epoch: 1223, Batch Gradient Norm: 1.7994001310446341
Epoch: 1223, Batch Gradient Norm after: 1.7994001310446341
Epoch 1224/10000, Prediction Accuracy = 56.40384615384615%, Loss = 0.011579122179402756
Epoch: 1224, Batch Gradient Norm: 1.8185190221424838
Epoch: 1224, Batch Gradient Norm after: 1.8185190221424838
Epoch 1225/10000, Prediction Accuracy = 56.69230769230769%, Loss = 0.011559906200720714
Epoch: 1225, Batch Gradient Norm: 1.9348004403339667
Epoch: 1225, Batch Gradient Norm after: 1.9348004403339667
Epoch 1226/10000, Prediction Accuracy = 56.388461538461534%, Loss = 0.011528030037879944
Epoch: 1226, Batch Gradient Norm: 1.873869686520825
Epoch: 1226, Batch Gradient Norm after: 1.873869686520825
Epoch 1227/10000, Prediction Accuracy = 56.31923076923077%, Loss = 0.011561292223632336
Epoch: 1227, Batch Gradient Norm: 1.954844665177292
Epoch: 1227, Batch Gradient Norm after: 1.954844665177292
Epoch 1228/10000, Prediction Accuracy = 56.33846153846153%, Loss = 0.01151146711065219
Epoch: 1228, Batch Gradient Norm: 1.8107456370319965
Epoch: 1228, Batch Gradient Norm after: 1.8107456370319965
Epoch 1229/10000, Prediction Accuracy = 56.71153846153846%, Loss = 0.011443978533721887
Epoch: 1229, Batch Gradient Norm: 1.9103417894990349
Epoch: 1229, Batch Gradient Norm after: 1.9103417894990349
Epoch 1230/10000, Prediction Accuracy = 56.615384615384606%, Loss = 0.011492680256756453
Epoch: 1230, Batch Gradient Norm: 1.7743787915555527
Epoch: 1230, Batch Gradient Norm after: 1.7743787915555527
Epoch 1231/10000, Prediction Accuracy = 56.52692307692309%, Loss = 0.011440994074711433
Epoch: 1231, Batch Gradient Norm: 1.7682265081239852
Epoch: 1231, Batch Gradient Norm after: 1.7682265081239852
Epoch 1232/10000, Prediction Accuracy = 56.42307692307691%, Loss = 0.01141857083600301
Epoch: 1232, Batch Gradient Norm: 1.841668219572304
Epoch: 1232, Batch Gradient Norm after: 1.841668219572304
Epoch 1233/10000, Prediction Accuracy = 56.66153846153846%, Loss = 0.01139580264974099
Epoch: 1233, Batch Gradient Norm: 1.9197608740132353
Epoch: 1233, Batch Gradient Norm after: 1.9197608740132353
Epoch 1234/10000, Prediction Accuracy = 56.949999999999996%, Loss = 0.011420289770914959
Epoch: 1234, Batch Gradient Norm: 1.856586817061818
Epoch: 1234, Batch Gradient Norm after: 1.856586817061818
Epoch 1235/10000, Prediction Accuracy = 56.642307692307675%, Loss = 0.011412763824829688
Epoch: 1235, Batch Gradient Norm: 1.936261987824112
Epoch: 1235, Batch Gradient Norm after: 1.936261987824112
Epoch 1236/10000, Prediction Accuracy = 56.376923076923084%, Loss = 0.011509607904232465
Epoch: 1236, Batch Gradient Norm: 2.123687371078916
Epoch: 1236, Batch Gradient Norm after: 2.123687371078916
Epoch 1237/10000, Prediction Accuracy = 55.5076923076923%, Loss = 0.011699217944764174
Epoch: 1237, Batch Gradient Norm: 1.8526040399752233
Epoch: 1237, Batch Gradient Norm after: 1.8526040399752233
Epoch 1238/10000, Prediction Accuracy = 57.00384615384616%, Loss = 0.011443945937431775
Epoch: 1238, Batch Gradient Norm: 1.729214083998505
Epoch: 1238, Batch Gradient Norm after: 1.729214083998505
Epoch 1239/10000, Prediction Accuracy = 56.77307692307693%, Loss = 0.011354786773713736
Epoch: 1239, Batch Gradient Norm: 1.8934716787577932
Epoch: 1239, Batch Gradient Norm after: 1.8934716787577932
Epoch 1240/10000, Prediction Accuracy = 56.71153846153847%, Loss = 0.011407442605839325
Epoch: 1240, Batch Gradient Norm: 1.7375144530628537
Epoch: 1240, Batch Gradient Norm after: 1.7375144530628537
Epoch 1241/10000, Prediction Accuracy = 56.89615384615385%, Loss = 0.011366568577404205
Epoch: 1241, Batch Gradient Norm: 2.0370927521146425
Epoch: 1241, Batch Gradient Norm after: 2.0370927521146425
Epoch 1242/10000, Prediction Accuracy = 56.44230769230769%, Loss = 0.011563637723716406
Epoch: 1242, Batch Gradient Norm: 1.9429410285610236
Epoch: 1242, Batch Gradient Norm after: 1.9429410285610236
Epoch 1243/10000, Prediction Accuracy = 56.642307692307696%, Loss = 0.011489418908380546
Epoch: 1243, Batch Gradient Norm: 1.9305576435859377
Epoch: 1243, Batch Gradient Norm after: 1.9305576435859377
Epoch 1244/10000, Prediction Accuracy = 56.449999999999996%, Loss = 0.011525862348767428
Epoch: 1244, Batch Gradient Norm: 2.005978493727595
Epoch: 1244, Batch Gradient Norm after: 2.005978493727595
Epoch 1245/10000, Prediction Accuracy = 56.80384615384615%, Loss = 0.01152789843483613
Epoch: 1245, Batch Gradient Norm: 2.0513672856045013
Epoch: 1245, Batch Gradient Norm after: 2.0513672856045013
Epoch 1246/10000, Prediction Accuracy = 55.86538461538463%, Loss = 0.01161129822811255
Epoch: 1246, Batch Gradient Norm: 1.9820891870125732
Epoch: 1246, Batch Gradient Norm after: 1.9820891870125732
Epoch 1247/10000, Prediction Accuracy = 56.3923076923077%, Loss = 0.011546862240021046
Epoch: 1247, Batch Gradient Norm: 1.8210212391491103
Epoch: 1247, Batch Gradient Norm after: 1.8210212391491103
Epoch 1248/10000, Prediction Accuracy = 56.61538461538463%, Loss = 0.011407698074785562
Epoch: 1248, Batch Gradient Norm: 1.892826788437558
Epoch: 1248, Batch Gradient Norm after: 1.892826788437558
Epoch 1249/10000, Prediction Accuracy = 56.44615384615384%, Loss = 0.011425356523921857
Epoch: 1249, Batch Gradient Norm: 1.9247987918176999
Epoch: 1249, Batch Gradient Norm after: 1.9247987918176999
Epoch 1250/10000, Prediction Accuracy = 57.023076923076935%, Loss = 0.011432234269495193
Epoch: 1250, Batch Gradient Norm: 1.9539140723090933
Epoch: 1250, Batch Gradient Norm after: 1.9539140723090933
Epoch 1251/10000, Prediction Accuracy = 56.43076923076923%, Loss = 0.011522999104972068
Epoch: 1251, Batch Gradient Norm: 1.950205191529048
Epoch: 1251, Batch Gradient Norm after: 1.950205191529048
Epoch 1252/10000, Prediction Accuracy = 56.54230769230769%, Loss = 0.011470694381457109
Epoch: 1252, Batch Gradient Norm: 2.0848487587042275
Epoch: 1252, Batch Gradient Norm after: 2.0848487587042275
Epoch 1253/10000, Prediction Accuracy = 56.17692307692309%, Loss = 0.011615538181593785
Epoch: 1253, Batch Gradient Norm: 1.9390758732229985
Epoch: 1253, Batch Gradient Norm after: 1.9390758732229985
Epoch 1254/10000, Prediction Accuracy = 56.6653846153846%, Loss = 0.011457494101845302
Epoch: 1254, Batch Gradient Norm: 2.0564579428450207
Epoch: 1254, Batch Gradient Norm after: 2.0564579428450207
Epoch 1255/10000, Prediction Accuracy = 56.107692307692304%, Loss = 0.011511604444911847
Epoch: 1255, Batch Gradient Norm: 2.099967966942368
Epoch: 1255, Batch Gradient Norm after: 2.099967966942368
Epoch 1256/10000, Prediction Accuracy = 56.30384615384615%, Loss = 0.011594916693866253
Epoch: 1256, Batch Gradient Norm: 1.9367500763294392
Epoch: 1256, Batch Gradient Norm after: 1.9367500763294392
Epoch 1257/10000, Prediction Accuracy = 56.84615384615385%, Loss = 0.011459159951370496
Epoch: 1257, Batch Gradient Norm: 1.9604601045865344
Epoch: 1257, Batch Gradient Norm after: 1.9604601045865344
Epoch 1258/10000, Prediction Accuracy = 56.88846153846154%, Loss = 0.011372126495608917
Epoch: 1258, Batch Gradient Norm: 2.038213366895653
Epoch: 1258, Batch Gradient Norm after: 2.038213366895653
Epoch 1259/10000, Prediction Accuracy = 56.57307692307691%, Loss = 0.011465229237308869
Epoch: 1259, Batch Gradient Norm: 1.9714320843399133
Epoch: 1259, Batch Gradient Norm after: 1.9714320843399133
Epoch 1260/10000, Prediction Accuracy = 56.715384615384615%, Loss = 0.011460321382261239
Epoch: 1260, Batch Gradient Norm: 2.011227052444285
Epoch: 1260, Batch Gradient Norm after: 2.011227052444285
Epoch 1261/10000, Prediction Accuracy = 56.607692307692304%, Loss = 0.011475720586111912
Epoch: 1261, Batch Gradient Norm: 1.8800523615349045
Epoch: 1261, Batch Gradient Norm after: 1.8800523615349045
Epoch 1262/10000, Prediction Accuracy = 56.47692307692308%, Loss = 0.011407818931799669
Epoch: 1262, Batch Gradient Norm: 1.8340886241181713
Epoch: 1262, Batch Gradient Norm after: 1.8340886241181713
Epoch 1263/10000, Prediction Accuracy = 56.684615384615384%, Loss = 0.011305963835464073
Epoch: 1263, Batch Gradient Norm: 1.9366150276744007
Epoch: 1263, Batch Gradient Norm after: 1.9366150276744007
Epoch 1264/10000, Prediction Accuracy = 56.76923076923077%, Loss = 0.011401197443214746
Epoch: 1264, Batch Gradient Norm: 2.096943486345685
Epoch: 1264, Batch Gradient Norm after: 2.096943486345685
Epoch 1265/10000, Prediction Accuracy = 56.68461538461539%, Loss = 0.011478477730773963
Epoch: 1265, Batch Gradient Norm: 2.0566870375350645
Epoch: 1265, Batch Gradient Norm after: 2.0566870375350645
Epoch 1266/10000, Prediction Accuracy = 56.58846153846154%, Loss = 0.011508627508122187
Epoch: 1266, Batch Gradient Norm: 1.830646581094343
Epoch: 1266, Batch Gradient Norm after: 1.830646581094343
Epoch 1267/10000, Prediction Accuracy = 56.888461538461534%, Loss = 0.011302673902649146
Epoch: 1267, Batch Gradient Norm: 1.8501209528415072
Epoch: 1267, Batch Gradient Norm after: 1.8501209528415072
Epoch 1268/10000, Prediction Accuracy = 57.27307692307693%, Loss = 0.011347085309143249
Epoch: 1268, Batch Gradient Norm: 1.9401683433599166
Epoch: 1268, Batch Gradient Norm after: 1.9401683433599166
Epoch 1269/10000, Prediction Accuracy = 56.68076923076922%, Loss = 0.01140093832061841
Epoch: 1269, Batch Gradient Norm: 2.1072390121924753
Epoch: 1269, Batch Gradient Norm after: 2.1072390121924753
Epoch 1270/10000, Prediction Accuracy = 56.50769230769231%, Loss = 0.011429988206006013
Epoch: 1270, Batch Gradient Norm: 2.0148622086553636
Epoch: 1270, Batch Gradient Norm after: 2.0148622086553636
Epoch 1271/10000, Prediction Accuracy = 56.86538461538461%, Loss = 0.011403315772230808
Epoch: 1271, Batch Gradient Norm: 2.161209245085257
Epoch: 1271, Batch Gradient Norm after: 2.161209245085257
Epoch 1272/10000, Prediction Accuracy = 56.33076923076922%, Loss = 0.011544877806535134
Epoch: 1272, Batch Gradient Norm: 2.1460909436688773
Epoch: 1272, Batch Gradient Norm after: 2.1460909436688773
Epoch 1273/10000, Prediction Accuracy = 56.05%, Loss = 0.011574158874841837
Epoch: 1273, Batch Gradient Norm: 2.1311195978093873
Epoch: 1273, Batch Gradient Norm after: 2.1311195978093873
Epoch 1274/10000, Prediction Accuracy = 56.48846153846154%, Loss = 0.011575185908721043
Epoch: 1274, Batch Gradient Norm: 1.918628044681004
Epoch: 1274, Batch Gradient Norm after: 1.918628044681004
Epoch 1275/10000, Prediction Accuracy = 56.792307692307695%, Loss = 0.011367171071469784
Epoch: 1275, Batch Gradient Norm: 2.0507743260507008
Epoch: 1275, Batch Gradient Norm after: 2.0507743260507008
Epoch 1276/10000, Prediction Accuracy = 56.59999999999999%, Loss = 0.011370119280540027
Epoch: 1276, Batch Gradient Norm: 2.21456103371674
Epoch: 1276, Batch Gradient Norm after: 2.21456103371674
Epoch 1277/10000, Prediction Accuracy = 56.23076923076923%, Loss = 0.011569603561208798
Epoch: 1277, Batch Gradient Norm: 2.042733625615509
Epoch: 1277, Batch Gradient Norm after: 2.042733625615509
Epoch 1278/10000, Prediction Accuracy = 56.650000000000006%, Loss = 0.011475564911961555
Epoch: 1278, Batch Gradient Norm: 1.9531620044306721
Epoch: 1278, Batch Gradient Norm after: 1.9531620044306721
Epoch 1279/10000, Prediction Accuracy = 57.06153846153847%, Loss = 0.011393199316584147
Epoch: 1279, Batch Gradient Norm: 1.7754731460847213
Epoch: 1279, Batch Gradient Norm after: 1.7754731460847213
Epoch 1280/10000, Prediction Accuracy = 56.8%, Loss = 0.011315145959647803
Epoch: 1280, Batch Gradient Norm: 1.9940509424914736
Epoch: 1280, Batch Gradient Norm after: 1.9940509424914736
Epoch 1281/10000, Prediction Accuracy = 56.85000000000001%, Loss = 0.011427507520868229
Epoch: 1281, Batch Gradient Norm: 2.0130301095092107
Epoch: 1281, Batch Gradient Norm after: 2.0130301095092107
Epoch 1282/10000, Prediction Accuracy = 56.69615384615384%, Loss = 0.011403067395664178
Epoch: 1282, Batch Gradient Norm: 1.9086655494868343
Epoch: 1282, Batch Gradient Norm after: 1.9086655494868343
Epoch 1283/10000, Prediction Accuracy = 56.65384615384615%, Loss = 0.011360230784003552
Epoch: 1283, Batch Gradient Norm: 2.198061727193491
Epoch: 1283, Batch Gradient Norm after: 2.198061727193491
Epoch 1284/10000, Prediction Accuracy = 56.68461538461539%, Loss = 0.011494319885969162
Epoch: 1284, Batch Gradient Norm: 2.019917958327624
Epoch: 1284, Batch Gradient Norm after: 2.019917958327624
Epoch 1285/10000, Prediction Accuracy = 56.34615384615385%, Loss = 0.011452696501062466
Epoch: 1285, Batch Gradient Norm: 2.10201912723808
Epoch: 1285, Batch Gradient Norm after: 2.10201912723808
Epoch 1286/10000, Prediction Accuracy = 56.96538461538462%, Loss = 0.01147151394532277
Epoch: 1286, Batch Gradient Norm: 2.0633746798656802
Epoch: 1286, Batch Gradient Norm after: 2.0633746798656802
Epoch 1287/10000, Prediction Accuracy = 56.403846153846146%, Loss = 0.011409920138808398
Epoch: 1287, Batch Gradient Norm: 1.874915033447044
Epoch: 1287, Batch Gradient Norm after: 1.874915033447044
Epoch 1288/10000, Prediction Accuracy = 56.63461538461539%, Loss = 0.011348218155594973
Epoch: 1288, Batch Gradient Norm: 1.8396028275347611
Epoch: 1288, Batch Gradient Norm after: 1.8396028275347611
Epoch 1289/10000, Prediction Accuracy = 57.17692307692308%, Loss = 0.011236896308568807
Epoch: 1289, Batch Gradient Norm: 2.296639438869159
Epoch: 1289, Batch Gradient Norm after: 2.296639438869159
Epoch 1290/10000, Prediction Accuracy = 56.83076923076923%, Loss = 0.011497981559771758
Epoch: 1290, Batch Gradient Norm: 2.3327422118123167
Epoch: 1290, Batch Gradient Norm after: 2.3327422118123167
Epoch 1291/10000, Prediction Accuracy = 56.05384615384616%, Loss = 0.01162927196576045
Epoch: 1291, Batch Gradient Norm: 2.031878263018053
Epoch: 1291, Batch Gradient Norm after: 2.031878263018053
Epoch 1292/10000, Prediction Accuracy = 56.23076923076923%, Loss = 0.011476399305348214
Epoch: 1292, Batch Gradient Norm: 1.9639663571561292
Epoch: 1292, Batch Gradient Norm after: 1.9639663571561292
Epoch 1293/10000, Prediction Accuracy = 56.76538461538461%, Loss = 0.011383436548595246
Epoch: 1293, Batch Gradient Norm: 2.0213268832703024
Epoch: 1293, Batch Gradient Norm after: 2.0213268832703024
Epoch 1294/10000, Prediction Accuracy = 56.800000000000004%, Loss = 0.01145925114934261
Epoch: 1294, Batch Gradient Norm: 1.9243782629427437
Epoch: 1294, Batch Gradient Norm after: 1.9243782629427437
Epoch 1295/10000, Prediction Accuracy = 57.02692307692307%, Loss = 0.011347009155612726
Epoch: 1295, Batch Gradient Norm: 2.0859910601540674
Epoch: 1295, Batch Gradient Norm after: 2.0859910601540674
Epoch 1296/10000, Prediction Accuracy = 56.56153846153846%, Loss = 0.011466122375657925
Epoch: 1296, Batch Gradient Norm: 2.10402658989773
Epoch: 1296, Batch Gradient Norm after: 2.10402658989773
Epoch 1297/10000, Prediction Accuracy = 56.93846153846153%, Loss = 0.011432193362942109
Epoch: 1297, Batch Gradient Norm: 2.0744387588200044
Epoch: 1297, Batch Gradient Norm after: 2.0744387588200044
Epoch 1298/10000, Prediction Accuracy = 56.280769230769224%, Loss = 0.01151887714289702
Epoch: 1298, Batch Gradient Norm: 1.9852546078150601
Epoch: 1298, Batch Gradient Norm after: 1.9852546078150601
Epoch 1299/10000, Prediction Accuracy = 56.646153846153844%, Loss = 0.01134687547500317
Epoch: 1299, Batch Gradient Norm: 2.0910224783311833
Epoch: 1299, Batch Gradient Norm after: 2.0910224783311833
Epoch 1300/10000, Prediction Accuracy = 57.04615384615384%, Loss = 0.011373085901141167
Epoch: 1300, Batch Gradient Norm: 2.002971440731668
Epoch: 1300, Batch Gradient Norm after: 2.002971440731668
Epoch 1301/10000, Prediction Accuracy = 56.7%, Loss = 0.01139574906287285
Epoch: 1301, Batch Gradient Norm: 2.2577900297689117
Epoch: 1301, Batch Gradient Norm after: 2.2577900297689117
Epoch 1302/10000, Prediction Accuracy = 56.392307692307696%, Loss = 0.011542760910323033
Epoch: 1302, Batch Gradient Norm: 2.2806289195140876
Epoch: 1302, Batch Gradient Norm after: 2.2806289195140876
Epoch 1303/10000, Prediction Accuracy = 55.79615384615385%, Loss = 0.011528971533362683
Epoch: 1303, Batch Gradient Norm: 1.9405235129563607
Epoch: 1303, Batch Gradient Norm after: 1.9405235129563607
Epoch 1304/10000, Prediction Accuracy = 56.60769230769232%, Loss = 0.011379068789000694
Epoch: 1304, Batch Gradient Norm: 2.0167185404814774
Epoch: 1304, Batch Gradient Norm after: 2.0167185404814774
Epoch 1305/10000, Prediction Accuracy = 56.900000000000006%, Loss = 0.01137044381063718
Epoch: 1305, Batch Gradient Norm: 2.0388549516948165
Epoch: 1305, Batch Gradient Norm after: 2.0388549516948165
Epoch 1306/10000, Prediction Accuracy = 56.93076923076923%, Loss = 0.011322177874927338
Epoch: 1306, Batch Gradient Norm: 1.8260077155871233
Epoch: 1306, Batch Gradient Norm after: 1.8260077155871233
Epoch 1307/10000, Prediction Accuracy = 56.88846153846154%, Loss = 0.01119278442974274
Epoch: 1307, Batch Gradient Norm: 2.055609048614603
Epoch: 1307, Batch Gradient Norm after: 2.055609048614603
Epoch 1308/10000, Prediction Accuracy = 57.18076923076923%, Loss = 0.011289258057681413
Epoch: 1308, Batch Gradient Norm: 2.026458175940289
Epoch: 1308, Batch Gradient Norm after: 2.026458175940289
Epoch 1309/10000, Prediction Accuracy = 56.911538461538456%, Loss = 0.011290156855606116
Epoch: 1309, Batch Gradient Norm: 1.981229403473327
Epoch: 1309, Batch Gradient Norm after: 1.981229403473327
Epoch 1310/10000, Prediction Accuracy = 56.684615384615384%, Loss = 0.011293438334877674
Epoch: 1310, Batch Gradient Norm: 1.9472511579768195
Epoch: 1310, Batch Gradient Norm after: 1.9472511579768195
Epoch 1311/10000, Prediction Accuracy = 57.042307692307695%, Loss = 0.01129533529568177
Epoch: 1311, Batch Gradient Norm: 2.0956960562138938
Epoch: 1311, Batch Gradient Norm after: 2.0956960562138938
Epoch 1312/10000, Prediction Accuracy = 56.6923076923077%, Loss = 0.011401436793116422
Epoch: 1312, Batch Gradient Norm: 1.9087589697989813
Epoch: 1312, Batch Gradient Norm after: 1.9087589697989813
Epoch 1313/10000, Prediction Accuracy = 57.08076923076923%, Loss = 0.01129622241625419
Epoch: 1313, Batch Gradient Norm: 1.8847766035122582
Epoch: 1313, Batch Gradient Norm after: 1.8847766035122582
Epoch 1314/10000, Prediction Accuracy = 56.91153846153846%, Loss = 0.011207481559652548
Epoch: 1314, Batch Gradient Norm: 1.9173172633240587
Epoch: 1314, Batch Gradient Norm after: 1.9173172633240587
Epoch 1315/10000, Prediction Accuracy = 57.27307692307692%, Loss = 0.01128432727777041
Epoch: 1315, Batch Gradient Norm: 2.1116039172125824
Epoch: 1315, Batch Gradient Norm after: 2.1116039172125824
Epoch 1316/10000, Prediction Accuracy = 56.98076923076922%, Loss = 0.011329695510749634
Epoch: 1316, Batch Gradient Norm: 2.199722061607773
Epoch: 1316, Batch Gradient Norm after: 2.199722061607773
Epoch 1317/10000, Prediction Accuracy = 56.51923076923077%, Loss = 0.01138338833474196
Epoch: 1317, Batch Gradient Norm: 1.9965393143590997
Epoch: 1317, Batch Gradient Norm after: 1.9965393143590997
Epoch 1318/10000, Prediction Accuracy = 56.96923076923077%, Loss = 0.011255444815525642
Epoch: 1318, Batch Gradient Norm: 2.065435920341771
Epoch: 1318, Batch Gradient Norm after: 2.065435920341771
Epoch 1319/10000, Prediction Accuracy = 56.699999999999996%, Loss = 0.011236542047789464
Epoch: 1319, Batch Gradient Norm: 2.2908394773069745
Epoch: 1319, Batch Gradient Norm after: 2.2908394773069745
Epoch 1320/10000, Prediction Accuracy = 56.43076923076923%, Loss = 0.011489624014267555
Epoch: 1320, Batch Gradient Norm: 2.370661531478623
Epoch: 1320, Batch Gradient Norm after: 2.370661531478623
Epoch 1321/10000, Prediction Accuracy = 56.23461538461538%, Loss = 0.011568785859988285
Epoch: 1321, Batch Gradient Norm: 2.225913581095471
Epoch: 1321, Batch Gradient Norm after: 2.225913581095471
Epoch 1322/10000, Prediction Accuracy = 56.357692307692304%, Loss = 0.011462717317044735
Epoch: 1322, Batch Gradient Norm: 2.118905229414941
Epoch: 1322, Batch Gradient Norm after: 2.118905229414941
Epoch 1323/10000, Prediction Accuracy = 56.61538461538461%, Loss = 0.011391635482700972
Epoch: 1323, Batch Gradient Norm: 2.022682814389027
Epoch: 1323, Batch Gradient Norm after: 2.022682814389027
Epoch 1324/10000, Prediction Accuracy = 56.815384615384616%, Loss = 0.011305892625107216
Epoch: 1324, Batch Gradient Norm: 1.869555997860726
Epoch: 1324, Batch Gradient Norm after: 1.869555997860726
Epoch 1325/10000, Prediction Accuracy = 56.99615384615385%, Loss = 0.011210000214095298
Epoch: 1325, Batch Gradient Norm: 1.912564456819313
Epoch: 1325, Batch Gradient Norm after: 1.912564456819313
Epoch 1326/10000, Prediction Accuracy = 57.80769230769231%, Loss = 0.011122379881831316
Epoch: 1326, Batch Gradient Norm: 2.0223285241415456
Epoch: 1326, Batch Gradient Norm after: 2.0223285241415456
Epoch 1327/10000, Prediction Accuracy = 56.95769230769231%, Loss = 0.011235618677276831
Epoch: 1327, Batch Gradient Norm: 1.9699373087906005
Epoch: 1327, Batch Gradient Norm after: 1.9699373087906005
Epoch 1328/10000, Prediction Accuracy = 56.784615384615385%, Loss = 0.011235494524813615
Epoch: 1328, Batch Gradient Norm: 2.1465083109465346
Epoch: 1328, Batch Gradient Norm after: 2.1465083109465346
Epoch 1329/10000, Prediction Accuracy = 56.78461538461538%, Loss = 0.011258637747512413
Epoch: 1329, Batch Gradient Norm: 2.1560206765678327
Epoch: 1329, Batch Gradient Norm after: 2.1560206765678327
Epoch 1330/10000, Prediction Accuracy = 56.942307692307686%, Loss = 0.011270964446549233
Epoch: 1330, Batch Gradient Norm: 2.239245481511064
Epoch: 1330, Batch Gradient Norm after: 2.239245481511064
Epoch 1331/10000, Prediction Accuracy = 56.784615384615385%, Loss = 0.011348991439892696
Epoch: 1331, Batch Gradient Norm: 2.229206950044738
Epoch: 1331, Batch Gradient Norm after: 2.229206950044738
Epoch 1332/10000, Prediction Accuracy = 56.98461538461538%, Loss = 0.01127918938604685
Epoch: 1332, Batch Gradient Norm: 2.163932549913492
Epoch: 1332, Batch Gradient Norm after: 2.163932549913492
Epoch 1333/10000, Prediction Accuracy = 56.880769230769225%, Loss = 0.011310816169358216
Epoch: 1333, Batch Gradient Norm: 2.004252342965909
Epoch: 1333, Batch Gradient Norm after: 2.004252342965909
Epoch 1334/10000, Prediction Accuracy = 57.16923076923077%, Loss = 0.01123691271417416
Epoch: 1334, Batch Gradient Norm: 2.2214639568817867
Epoch: 1334, Batch Gradient Norm after: 2.2214639568817867
Epoch 1335/10000, Prediction Accuracy = 56.30384615384616%, Loss = 0.011394964459423836
Epoch: 1335, Batch Gradient Norm: 2.162271182788045
Epoch: 1335, Batch Gradient Norm after: 2.162271182788045
Epoch 1336/10000, Prediction Accuracy = 57.06153846153846%, Loss = 0.01131439359428791
Epoch: 1336, Batch Gradient Norm: 1.9599564922752146
Epoch: 1336, Batch Gradient Norm after: 1.9599564922752146
Epoch 1337/10000, Prediction Accuracy = 57.06538461538461%, Loss = 0.01114792233476272
Epoch: 1337, Batch Gradient Norm: 2.169595948697526
Epoch: 1337, Batch Gradient Norm after: 2.169595948697526
Epoch 1338/10000, Prediction Accuracy = 56.96538461538462%, Loss = 0.011249958680799374
Epoch: 1338, Batch Gradient Norm: 2.3060470689344754
Epoch: 1338, Batch Gradient Norm after: 2.3060470689344754
Epoch 1339/10000, Prediction Accuracy = 56.576923076923066%, Loss = 0.011332848610786291
Epoch: 1339, Batch Gradient Norm: 2.180484890215763
Epoch: 1339, Batch Gradient Norm after: 2.180484890215763
Epoch 1340/10000, Prediction Accuracy = 56.661538461538456%, Loss = 0.011258528639490787
Epoch: 1340, Batch Gradient Norm: 2.037938377945597
Epoch: 1340, Batch Gradient Norm after: 2.037938377945597
Epoch 1341/10000, Prediction Accuracy = 57.376923076923084%, Loss = 0.011146115712248363
Epoch: 1341, Batch Gradient Norm: 2.3341550964715796
Epoch: 1341, Batch Gradient Norm after: 2.3341550964715796
Epoch 1342/10000, Prediction Accuracy = 56.46923076923077%, Loss = 0.011337650008499622
Epoch: 1342, Batch Gradient Norm: 2.1564617317599346
Epoch: 1342, Batch Gradient Norm after: 2.1564617317599346
Epoch 1343/10000, Prediction Accuracy = 56.83846153846154%, Loss = 0.011283071138537847
Epoch: 1343, Batch Gradient Norm: 2.1527909379454027
Epoch: 1343, Batch Gradient Norm after: 2.1527909379454027
Epoch 1344/10000, Prediction Accuracy = 57.21153846153847%, Loss = 0.011213267938448833
Epoch: 1344, Batch Gradient Norm: 2.1669714973416947
Epoch: 1344, Batch Gradient Norm after: 2.1669714973416947
Epoch 1345/10000, Prediction Accuracy = 56.58461538461539%, Loss = 0.01131029033030455
Epoch: 1345, Batch Gradient Norm: 2.1876844182904955
Epoch: 1345, Batch Gradient Norm after: 2.1876844182904955
Epoch 1346/10000, Prediction Accuracy = 56.96153846153847%, Loss = 0.011360313026950909
Epoch: 1346, Batch Gradient Norm: 1.9684208695862895
Epoch: 1346, Batch Gradient Norm after: 1.9684208695862895
Epoch 1347/10000, Prediction Accuracy = 57.076923076923066%, Loss = 0.011176158315860309
Epoch: 1347, Batch Gradient Norm: 2.2219917324386276
Epoch: 1347, Batch Gradient Norm after: 2.2219917324386276
Epoch 1348/10000, Prediction Accuracy = 57.19615384615385%, Loss = 0.011253019150059957
Epoch: 1348, Batch Gradient Norm: 1.963221673721688
Epoch: 1348, Batch Gradient Norm after: 1.963221673721688
Epoch 1349/10000, Prediction Accuracy = 57.47307692307693%, Loss = 0.011093790929477949
Epoch: 1349, Batch Gradient Norm: 1.9015635590163324
Epoch: 1349, Batch Gradient Norm after: 1.9015635590163324
Epoch 1350/10000, Prediction Accuracy = 57.26923076923077%, Loss = 0.0110811608342024
Epoch: 1350, Batch Gradient Norm: 2.1212815636115154
Epoch: 1350, Batch Gradient Norm after: 2.1212815636115154
Epoch 1351/10000, Prediction Accuracy = 57.49615384615385%, Loss = 0.011197061277925968
Epoch: 1351, Batch Gradient Norm: 1.9639900392312577
Epoch: 1351, Batch Gradient Norm after: 1.9639900392312577
Epoch 1352/10000, Prediction Accuracy = 57.28461538461538%, Loss = 0.011106368369207932
Epoch: 1352, Batch Gradient Norm: 2.2873085326519282
Epoch: 1352, Batch Gradient Norm after: 2.2873085326519282
Epoch 1353/10000, Prediction Accuracy = 57.223076923076924%, Loss = 0.011292918513600644
Epoch: 1353, Batch Gradient Norm: 2.231011531571182
Epoch: 1353, Batch Gradient Norm after: 2.231011531571182
Epoch 1354/10000, Prediction Accuracy = 56.82692307692308%, Loss = 0.011315175690329991
Epoch: 1354, Batch Gradient Norm: 2.1094829945275073
Epoch: 1354, Batch Gradient Norm after: 2.1094829945275073
Epoch 1355/10000, Prediction Accuracy = 57.26153846153846%, Loss = 0.011218774562271742
Epoch: 1355, Batch Gradient Norm: 2.249168503634094
Epoch: 1355, Batch Gradient Norm after: 2.249168503634094
Epoch 1356/10000, Prediction Accuracy = 57.00384615384615%, Loss = 0.011307475228722278
Epoch: 1356, Batch Gradient Norm: 2.1941691274731783
Epoch: 1356, Batch Gradient Norm after: 2.1941691274731783
Epoch 1357/10000, Prediction Accuracy = 57.02692307692307%, Loss = 0.011241829166045556
Epoch: 1357, Batch Gradient Norm: 1.9999962811807452
Epoch: 1357, Batch Gradient Norm after: 1.9999962811807452
Epoch 1358/10000, Prediction Accuracy = 57.8423076923077%, Loss = 0.011058647328844437
Epoch: 1358, Batch Gradient Norm: 2.067107158477963
Epoch: 1358, Batch Gradient Norm after: 2.067107158477963
Epoch 1359/10000, Prediction Accuracy = 57.3%, Loss = 0.011133235592681628
Epoch: 1359, Batch Gradient Norm: 2.1125947088182824
Epoch: 1359, Batch Gradient Norm after: 2.1125947088182824
Epoch 1360/10000, Prediction Accuracy = 56.98076923076923%, Loss = 0.011112851735491019
Epoch: 1360, Batch Gradient Norm: 2.062221152573963
Epoch: 1360, Batch Gradient Norm after: 2.062221152573963
Epoch 1361/10000, Prediction Accuracy = 57.08076923076923%, Loss = 0.011068636121658178
Epoch: 1361, Batch Gradient Norm: 2.302152497245011
Epoch: 1361, Batch Gradient Norm after: 2.302152497245011
Epoch 1362/10000, Prediction Accuracy = 56.98461538461539%, Loss = 0.01127882839108889
Epoch: 1362, Batch Gradient Norm: 2.037288231203988
Epoch: 1362, Batch Gradient Norm after: 2.037288231203988
Epoch 1363/10000, Prediction Accuracy = 57.28846153846154%, Loss = 0.011059586388560442
Epoch: 1363, Batch Gradient Norm: 2.1288240893578227
Epoch: 1363, Batch Gradient Norm after: 2.1288240893578227
Epoch 1364/10000, Prediction Accuracy = 57.284615384615385%, Loss = 0.011111736799088808
Epoch: 1364, Batch Gradient Norm: 2.1861651696550934
Epoch: 1364, Batch Gradient Norm after: 2.1861651696550934
Epoch 1365/10000, Prediction Accuracy = 57.576923076923094%, Loss = 0.011134578846395016
Epoch: 1365, Batch Gradient Norm: 2.4222325357470895
Epoch: 1365, Batch Gradient Norm after: 2.4222325357470895
Epoch 1366/10000, Prediction Accuracy = 56.86153846153846%, Loss = 0.01127800581833491
Epoch: 1366, Batch Gradient Norm: 2.5910024437368637
Epoch: 1366, Batch Gradient Norm after: 2.5910024437368637
Epoch 1367/10000, Prediction Accuracy = 56.05384615384615%, Loss = 0.011457712317888554
Epoch: 1367, Batch Gradient Norm: 2.228741254160022
Epoch: 1367, Batch Gradient Norm after: 2.228741254160022
Epoch 1368/10000, Prediction Accuracy = 56.63846153846154%, Loss = 0.011286829096766619
Epoch: 1368, Batch Gradient Norm: 2.1840986044031347
Epoch: 1368, Batch Gradient Norm after: 2.1840986044031347
Epoch 1369/10000, Prediction Accuracy = 56.79615384615384%, Loss = 0.011278714196613202
Epoch: 1369, Batch Gradient Norm: 2.27788191961422
Epoch: 1369, Batch Gradient Norm after: 2.27788191961422
Epoch 1370/10000, Prediction Accuracy = 57.0076923076923%, Loss = 0.011268706419146977
Epoch: 1370, Batch Gradient Norm: 2.409489719027325
Epoch: 1370, Batch Gradient Norm after: 2.409489719027325
Epoch 1371/10000, Prediction Accuracy = 56.16153846153846%, Loss = 0.011420343715984087
Epoch: 1371, Batch Gradient Norm: 2.176145508116628
Epoch: 1371, Batch Gradient Norm after: 2.176145508116628
Epoch 1372/10000, Prediction Accuracy = 56.94615384615385%, Loss = 0.011232358331863698
Epoch: 1372, Batch Gradient Norm: 1.9698915781651993
Epoch: 1372, Batch Gradient Norm after: 1.9698915781651993
Epoch 1373/10000, Prediction Accuracy = 57.29615384615385%, Loss = 0.011062575360903373
Epoch: 1373, Batch Gradient Norm: 2.131333005611948
Epoch: 1373, Batch Gradient Norm after: 2.131333005611948
Epoch 1374/10000, Prediction Accuracy = 56.8%, Loss = 0.011176107809520684
Epoch: 1374, Batch Gradient Norm: 2.098396329850547
Epoch: 1374, Batch Gradient Norm after: 2.098396329850547
Epoch 1375/10000, Prediction Accuracy = 57.18076923076924%, Loss = 0.011151995653143296
Epoch: 1375, Batch Gradient Norm: 2.065451157973754
Epoch: 1375, Batch Gradient Norm after: 2.065451157973754
Epoch 1376/10000, Prediction Accuracy = 57.603846153846156%, Loss = 0.01109820675964539
Epoch: 1376, Batch Gradient Norm: 1.9413644879812895
Epoch: 1376, Batch Gradient Norm after: 1.9413644879812895
Epoch 1377/10000, Prediction Accuracy = 57.81153846153846%, Loss = 0.010980812474512137
Epoch: 1377, Batch Gradient Norm: 2.121447588455109
Epoch: 1377, Batch Gradient Norm after: 2.121447588455109
Epoch 1378/10000, Prediction Accuracy = 57.30384615384616%, Loss = 0.01109503610776021
Epoch: 1378, Batch Gradient Norm: 2.2640996395811572
Epoch: 1378, Batch Gradient Norm after: 2.2640996395811572
Epoch 1379/10000, Prediction Accuracy = 57.36538461538461%, Loss = 0.01111572328954935
Epoch: 1379, Batch Gradient Norm: 2.269390422882681
Epoch: 1379, Batch Gradient Norm after: 2.269390422882681
Epoch 1380/10000, Prediction Accuracy = 57.30384615384615%, Loss = 0.011143124447419094
Epoch: 1380, Batch Gradient Norm: 2.183223480151558
Epoch: 1380, Batch Gradient Norm after: 2.183223480151558
Epoch 1381/10000, Prediction Accuracy = 57.307692307692314%, Loss = 0.011092863833675018
Epoch: 1381, Batch Gradient Norm: 1.946526525482272
Epoch: 1381, Batch Gradient Norm after: 1.946526525482272
Epoch 1382/10000, Prediction Accuracy = 57.38846153846154%, Loss = 0.010927145440991107
Epoch: 1382, Batch Gradient Norm: 2.1809469970194346
Epoch: 1382, Batch Gradient Norm after: 2.1809469970194346
Epoch 1383/10000, Prediction Accuracy = 57.61538461538461%, Loss = 0.011052916327921243
Epoch: 1383, Batch Gradient Norm: 2.258408239475097
Epoch: 1383, Batch Gradient Norm after: 2.258408239475097
Epoch 1384/10000, Prediction Accuracy = 57.43076923076923%, Loss = 0.01104797415721875
Epoch: 1384, Batch Gradient Norm: 2.2706539375839028
Epoch: 1384, Batch Gradient Norm after: 2.2706539375839028
Epoch 1385/10000, Prediction Accuracy = 57.36153846153846%, Loss = 0.011177998824188342
Epoch: 1385, Batch Gradient Norm: 2.0938108751617426
Epoch: 1385, Batch Gradient Norm after: 2.0938108751617426
Epoch 1386/10000, Prediction Accuracy = 57.44230769230769%, Loss = 0.011039139416355353
Epoch: 1386, Batch Gradient Norm: 2.114053720410415
Epoch: 1386, Batch Gradient Norm after: 2.114053720410415
Epoch 1387/10000, Prediction Accuracy = 57.26153846153847%, Loss = 0.011014808040971939
Epoch: 1387, Batch Gradient Norm: 1.9835038316721947
Epoch: 1387, Batch Gradient Norm after: 1.9835038316721947
Epoch 1388/10000, Prediction Accuracy = 57.54999999999999%, Loss = 0.01095664888047255
Epoch: 1388, Batch Gradient Norm: 2.099067479640246
Epoch: 1388, Batch Gradient Norm after: 2.099067479640246
Epoch 1389/10000, Prediction Accuracy = 57.284615384615385%, Loss = 0.010916729099475421
Epoch: 1389, Batch Gradient Norm: 2.2034076457999103
Epoch: 1389, Batch Gradient Norm after: 2.2034076457999103
Epoch 1390/10000, Prediction Accuracy = 57.934615384615384%, Loss = 0.010991615888017874
Epoch: 1390, Batch Gradient Norm: 2.6972151117717478
Epoch: 1390, Batch Gradient Norm after: 2.6972151117717478
Epoch 1391/10000, Prediction Accuracy = 56.92307692307692%, Loss = 0.011316959817822162
Epoch: 1391, Batch Gradient Norm: 2.53677040227645
Epoch: 1391, Batch Gradient Norm after: 2.53677040227645
Epoch 1392/10000, Prediction Accuracy = 56.965384615384615%, Loss = 0.01131460235382502
Epoch: 1392, Batch Gradient Norm: 2.491258573389612
Epoch: 1392, Batch Gradient Norm after: 2.491258573389612
Epoch 1393/10000, Prediction Accuracy = 56.67692307692308%, Loss = 0.011418384499847889
Epoch: 1393, Batch Gradient Norm: 2.263820785360369
Epoch: 1393, Batch Gradient Norm after: 2.263820785360369
Epoch 1394/10000, Prediction Accuracy = 57.146153846153865%, Loss = 0.011148772632273344
Epoch: 1394, Batch Gradient Norm: 2.0520128628950136
Epoch: 1394, Batch Gradient Norm after: 2.0520128628950136
Epoch 1395/10000, Prediction Accuracy = 57.50384615384616%, Loss = 0.011009701026173739
Epoch: 1395, Batch Gradient Norm: 2.2749086296009216
Epoch: 1395, Batch Gradient Norm after: 2.2749086296009216
Epoch 1396/10000, Prediction Accuracy = 57.146153846153844%, Loss = 0.01110403354351337
Epoch: 1396, Batch Gradient Norm: 2.316755122417524
Epoch: 1396, Batch Gradient Norm after: 2.316755122417524
Epoch 1397/10000, Prediction Accuracy = 57.12307692307691%, Loss = 0.011180000451321784
Epoch: 1397, Batch Gradient Norm: 2.504307203056379
Epoch: 1397, Batch Gradient Norm after: 2.504307203056379
Epoch 1398/10000, Prediction Accuracy = 57.13076923076923%, Loss = 0.011380912736058235
Epoch: 1398, Batch Gradient Norm: 2.162776408055847
Epoch: 1398, Batch Gradient Norm after: 2.162776408055847
Epoch 1399/10000, Prediction Accuracy = 57.38846153846154%, Loss = 0.011122341267764568
Epoch: 1399, Batch Gradient Norm: 2.128552843506284
Epoch: 1399, Batch Gradient Norm after: 2.128552843506284
Epoch 1400/10000, Prediction Accuracy = 57.53076923076923%, Loss = 0.011049533191208657
Epoch: 1400, Batch Gradient Norm: 2.3956740723480228
Epoch: 1400, Batch Gradient Norm after: 2.3956740723480228
Epoch 1401/10000, Prediction Accuracy = 57.31153846153845%, Loss = 0.011147105779785376
Epoch: 1401, Batch Gradient Norm: 2.17398449500167
Epoch: 1401, Batch Gradient Norm after: 2.17398449500167
Epoch 1402/10000, Prediction Accuracy = 57.28846153846155%, Loss = 0.011108430818869518
Epoch: 1402, Batch Gradient Norm: 2.282848707898413
Epoch: 1402, Batch Gradient Norm after: 2.282848707898413
Epoch 1403/10000, Prediction Accuracy = 57.03076923076924%, Loss = 0.01106471224473073
Epoch: 1403, Batch Gradient Norm: 2.343233306239077
Epoch: 1403, Batch Gradient Norm after: 2.343233306239077
Epoch 1404/10000, Prediction Accuracy = 56.78461538461538%, Loss = 0.011218716963552512
Epoch: 1404, Batch Gradient Norm: 2.3133184252114196
Epoch: 1404, Batch Gradient Norm after: 2.3133184252114196
Epoch 1405/10000, Prediction Accuracy = 57.17307692307691%, Loss = 0.01115565961943223
Epoch: 1405, Batch Gradient Norm: 2.142226965395361
Epoch: 1405, Batch Gradient Norm after: 2.142226965395361
Epoch 1406/10000, Prediction Accuracy = 57.30769230769231%, Loss = 0.011032786506872911
Epoch: 1406, Batch Gradient Norm: 2.3905285764369837
Epoch: 1406, Batch Gradient Norm after: 2.3905285764369837
Epoch 1407/10000, Prediction Accuracy = 56.99615384615384%, Loss = 0.011205148596603137
Epoch: 1407, Batch Gradient Norm: 2.210845689388224
Epoch: 1407, Batch Gradient Norm after: 2.210845689388224
Epoch 1408/10000, Prediction Accuracy = 57.465384615384615%, Loss = 0.011009734482146226
Epoch: 1408, Batch Gradient Norm: 2.007418994614512
Epoch: 1408, Batch Gradient Norm after: 2.007418994614512
Epoch 1409/10000, Prediction Accuracy = 57.8%, Loss = 0.01089757251051756
Epoch: 1409, Batch Gradient Norm: 2.09195252631647
Epoch: 1409, Batch Gradient Norm after: 2.09195252631647
Epoch 1410/10000, Prediction Accuracy = 57.34615384615384%, Loss = 0.010957356613989059
Epoch: 1410, Batch Gradient Norm: 2.13072418018019
Epoch: 1410, Batch Gradient Norm after: 2.13072418018019
Epoch 1411/10000, Prediction Accuracy = 57.71538461538463%, Loss = 0.010909178795722814
Epoch: 1411, Batch Gradient Norm: 2.2187734378408943
Epoch: 1411, Batch Gradient Norm after: 2.2187734378408943
Epoch 1412/10000, Prediction Accuracy = 57.607692307692304%, Loss = 0.010947167515181579
Epoch: 1412, Batch Gradient Norm: 2.2409343337311873
Epoch: 1412, Batch Gradient Norm after: 2.2409343337311873
Epoch 1413/10000, Prediction Accuracy = 57.58846153846154%, Loss = 0.011007793677540926
Epoch: 1413, Batch Gradient Norm: 2.335224320099087
Epoch: 1413, Batch Gradient Norm after: 2.335224320099087
Epoch 1414/10000, Prediction Accuracy = 57.25%, Loss = 0.011008088405315693
Epoch: 1414, Batch Gradient Norm: 2.1289797278173443
Epoch: 1414, Batch Gradient Norm after: 2.1289797278173443
Epoch 1415/10000, Prediction Accuracy = 57.68846153846153%, Loss = 0.010916875388759833
Epoch: 1415, Batch Gradient Norm: 2.5248809148150726
Epoch: 1415, Batch Gradient Norm after: 2.5248809148150726
Epoch 1416/10000, Prediction Accuracy = 57.01153846153846%, Loss = 0.01122554842955791
Epoch: 1416, Batch Gradient Norm: 2.2194394464103593
Epoch: 1416, Batch Gradient Norm after: 2.2194394464103593
Epoch 1417/10000, Prediction Accuracy = 57.22307692307691%, Loss = 0.010973274421233397
Epoch: 1417, Batch Gradient Norm: 2.1675262131109165
Epoch: 1417, Batch Gradient Norm after: 2.1675262131109165
Epoch 1418/10000, Prediction Accuracy = 57.61153846153847%, Loss = 0.010966399111426793
Epoch: 1418, Batch Gradient Norm: 2.152592505644276
Epoch: 1418, Batch Gradient Norm after: 2.152592505644276
Epoch 1419/10000, Prediction Accuracy = 57.51923076923076%, Loss = 0.010952538882310573
Epoch: 1419, Batch Gradient Norm: 2.4110842610760157
Epoch: 1419, Batch Gradient Norm after: 2.4110842610760157
Epoch 1420/10000, Prediction Accuracy = 57.18076923076922%, Loss = 0.011076094081195502
Epoch: 1420, Batch Gradient Norm: 2.2748687442087308
Epoch: 1420, Batch Gradient Norm after: 2.2748687442087308
Epoch 1421/10000, Prediction Accuracy = 57.41153846153847%, Loss = 0.011015183865450896
Epoch: 1421, Batch Gradient Norm: 2.253976398627357
Epoch: 1421, Batch Gradient Norm after: 2.253976398627357
Epoch 1422/10000, Prediction Accuracy = 57.68076923076924%, Loss = 0.011008336280400936
Epoch: 1422, Batch Gradient Norm: 2.1822897894262336
Epoch: 1422, Batch Gradient Norm after: 2.1822897894262336
Epoch 1423/10000, Prediction Accuracy = 57.834615384615375%, Loss = 0.01089198779887878
Epoch: 1423, Batch Gradient Norm: 2.1876665964151742
Epoch: 1423, Batch Gradient Norm after: 2.1876665964151742
Epoch 1424/10000, Prediction Accuracy = 57.55384615384616%, Loss = 0.010929646615225535
Epoch: 1424, Batch Gradient Norm: 2.2309066804716036
Epoch: 1424, Batch Gradient Norm after: 2.2309066804716036
Epoch 1425/10000, Prediction Accuracy = 57.73076923076924%, Loss = 0.01093371850080215
Epoch: 1425, Batch Gradient Norm: 2.343656903921215
Epoch: 1425, Batch Gradient Norm after: 2.343656903921215
Epoch 1426/10000, Prediction Accuracy = 57.388461538461534%, Loss = 0.011059101885901047
Epoch: 1426, Batch Gradient Norm: 2.309905913278811
Epoch: 1426, Batch Gradient Norm after: 2.309905913278811
Epoch 1427/10000, Prediction Accuracy = 57.41538461538461%, Loss = 0.010973951636025539
Epoch: 1427, Batch Gradient Norm: 2.2482304121430654
Epoch: 1427, Batch Gradient Norm after: 2.2482304121430654
Epoch 1428/10000, Prediction Accuracy = 57.34615384615385%, Loss = 0.010910216432351332
Epoch: 1428, Batch Gradient Norm: 2.252738150506366
Epoch: 1428, Batch Gradient Norm after: 2.252738150506366
Epoch 1429/10000, Prediction Accuracy = 57.349999999999994%, Loss = 0.011032520650097957
Epoch: 1429, Batch Gradient Norm: 2.2204187225781595
Epoch: 1429, Batch Gradient Norm after: 2.2204187225781595
Epoch 1430/10000, Prediction Accuracy = 57.73461538461539%, Loss = 0.010951936388244996
Epoch: 1430, Batch Gradient Norm: 2.2297973437975407
Epoch: 1430, Batch Gradient Norm after: 2.2297973437975407
Epoch 1431/10000, Prediction Accuracy = 57.599999999999994%, Loss = 0.010917476306741055
Epoch: 1431, Batch Gradient Norm: 2.4329460716240865
Epoch: 1431, Batch Gradient Norm after: 2.4329460716240865
Epoch 1432/10000, Prediction Accuracy = 57.90000000000001%, Loss = 0.011005026145050159
Epoch: 1432, Batch Gradient Norm: 2.396902700912207
Epoch: 1432, Batch Gradient Norm after: 2.396902700912207
Epoch 1433/10000, Prediction Accuracy = 57.534615384615385%, Loss = 0.01100395225848143
Epoch: 1433, Batch Gradient Norm: 2.3797541450767477
Epoch: 1433, Batch Gradient Norm after: 2.3797541450767477
Epoch 1434/10000, Prediction Accuracy = 57.365384615384606%, Loss = 0.011017160203594428
Epoch: 1434, Batch Gradient Norm: 2.189441286284304
Epoch: 1434, Batch Gradient Norm after: 2.189441286284304
Epoch 1435/10000, Prediction Accuracy = 57.91923076923077%, Loss = 0.01093820152947536
Epoch: 1435, Batch Gradient Norm: 2.4010617763510136
Epoch: 1435, Batch Gradient Norm after: 2.4010617763510136
Epoch 1436/10000, Prediction Accuracy = 57.14230769230768%, Loss = 0.011019161042685691
Epoch: 1436, Batch Gradient Norm: 2.251610097151506
Epoch: 1436, Batch Gradient Norm after: 2.251610097151506
Epoch 1437/10000, Prediction Accuracy = 57.84615384615385%, Loss = 0.011002407910732122
Epoch: 1437, Batch Gradient Norm: 2.389598436117635
Epoch: 1437, Batch Gradient Norm after: 2.389598436117635
Epoch 1438/10000, Prediction Accuracy = 57.723076923076924%, Loss = 0.010985523892136721
Epoch: 1438, Batch Gradient Norm: 2.104454496678493
Epoch: 1438, Batch Gradient Norm after: 2.104454496678493
Epoch 1439/10000, Prediction Accuracy = 57.72692307692308%, Loss = 0.01086860766204504
Epoch: 1439, Batch Gradient Norm: 2.1954310112997075
Epoch: 1439, Batch Gradient Norm after: 2.1954310112997075
Epoch 1440/10000, Prediction Accuracy = 57.68846153846154%, Loss = 0.010889656483553924
Epoch: 1440, Batch Gradient Norm: 2.2106679089837815
Epoch: 1440, Batch Gradient Norm after: 2.2106679089837815
Epoch 1441/10000, Prediction Accuracy = 57.907692307692315%, Loss = 0.010850132586291203
Epoch: 1441, Batch Gradient Norm: 2.4635711637444144
Epoch: 1441, Batch Gradient Norm after: 2.4635711637444144
Epoch 1442/10000, Prediction Accuracy = 57.723076923076924%, Loss = 0.010950917163147377
Epoch: 1442, Batch Gradient Norm: 2.5561783647304566
Epoch: 1442, Batch Gradient Norm after: 2.5561783647304566
Epoch 1443/10000, Prediction Accuracy = 57.10769230769232%, Loss = 0.011168019129679753
Epoch: 1443, Batch Gradient Norm: 2.5670258028958743
Epoch: 1443, Batch Gradient Norm after: 2.5670258028958743
Epoch 1444/10000, Prediction Accuracy = 57.33076923076923%, Loss = 0.01114195348838201
Epoch: 1444, Batch Gradient Norm: 2.609386630384491
Epoch: 1444, Batch Gradient Norm after: 2.609386630384491
Epoch 1445/10000, Prediction Accuracy = 56.89615384615385%, Loss = 0.011165525764226913
Epoch: 1445, Batch Gradient Norm: 2.5173234694813797
Epoch: 1445, Batch Gradient Norm after: 2.5173234694813797
Epoch 1446/10000, Prediction Accuracy = 57.33846153846154%, Loss = 0.011069349371469937
Epoch: 1446, Batch Gradient Norm: 2.21332872610342
Epoch: 1446, Batch Gradient Norm after: 2.21332872610342
Epoch 1447/10000, Prediction Accuracy = 57.53846153846154%, Loss = 0.01097193997926437
Epoch: 1447, Batch Gradient Norm: 2.1298533453596082
Epoch: 1447, Batch Gradient Norm after: 2.1298533453596082
Epoch 1448/10000, Prediction Accuracy = 57.449999999999996%, Loss = 0.01088757454775847
Epoch: 1448, Batch Gradient Norm: 2.2026566291922203
Epoch: 1448, Batch Gradient Norm after: 2.2026566291922203
Epoch 1449/10000, Prediction Accuracy = 57.99999999999999%, Loss = 0.010826002519864302
Epoch: 1449, Batch Gradient Norm: 2.3588240023717066
Epoch: 1449, Batch Gradient Norm after: 2.3588240023717066
Epoch 1450/10000, Prediction Accuracy = 57.6923076923077%, Loss = 0.010975153973469367
Epoch: 1450, Batch Gradient Norm: 2.1478261990935406
Epoch: 1450, Batch Gradient Norm after: 2.1478261990935406
Epoch 1451/10000, Prediction Accuracy = 57.592307692307685%, Loss = 0.010885663115634369
Epoch: 1451, Batch Gradient Norm: 2.3207580244892037
Epoch: 1451, Batch Gradient Norm after: 2.3207580244892037
Epoch 1452/10000, Prediction Accuracy = 57.86538461538461%, Loss = 0.010952650354458736
Epoch: 1452, Batch Gradient Norm: 2.2633361766037043
Epoch: 1452, Batch Gradient Norm after: 2.2633361766037043
Epoch 1453/10000, Prediction Accuracy = 58.11153846153846%, Loss = 0.010871028527617455
Epoch: 1453, Batch Gradient Norm: 2.338943678118722
Epoch: 1453, Batch Gradient Norm after: 2.338943678118722
Epoch 1454/10000, Prediction Accuracy = 57.61538461538461%, Loss = 0.010951436697863616
Epoch: 1454, Batch Gradient Norm: 2.2130779779516723
Epoch: 1454, Batch Gradient Norm after: 2.2130779779516723
Epoch 1455/10000, Prediction Accuracy = 58.01153846153846%, Loss = 0.01080912767121425
Epoch: 1455, Batch Gradient Norm: 2.310204553140268
Epoch: 1455, Batch Gradient Norm after: 2.310204553140268
Epoch 1456/10000, Prediction Accuracy = 57.584615384615375%, Loss = 0.010841391765727447
Epoch: 1456, Batch Gradient Norm: 2.416763059282439
Epoch: 1456, Batch Gradient Norm after: 2.416763059282439
Epoch 1457/10000, Prediction Accuracy = 57.77692307692309%, Loss = 0.010932168278556604
Epoch: 1457, Batch Gradient Norm: 2.3778296291630068
Epoch: 1457, Batch Gradient Norm after: 2.3778296291630068
Epoch 1458/10000, Prediction Accuracy = 57.419230769230765%, Loss = 0.010899872232515078
Epoch: 1458, Batch Gradient Norm: 2.2310527423538726
Epoch: 1458, Batch Gradient Norm after: 2.2310527423538726
Epoch 1459/10000, Prediction Accuracy = 57.92692307692308%, Loss = 0.010788983378845911
Epoch: 1459, Batch Gradient Norm: 2.3552651739053916
Epoch: 1459, Batch Gradient Norm after: 2.3552651739053916
Epoch 1460/10000, Prediction Accuracy = 57.76153846153846%, Loss = 0.010897511401428627
Epoch: 1460, Batch Gradient Norm: 2.291197974356241
Epoch: 1460, Batch Gradient Norm after: 2.291197974356241
Epoch 1461/10000, Prediction Accuracy = 57.46923076923076%, Loss = 0.010923913751657192
Epoch: 1461, Batch Gradient Norm: 2.2292043535620456
Epoch: 1461, Batch Gradient Norm after: 2.2292043535620456
Epoch 1462/10000, Prediction Accuracy = 58.23076923076922%, Loss = 0.010815274256926317
Epoch: 1462, Batch Gradient Norm: 2.282831058362321
Epoch: 1462, Batch Gradient Norm after: 2.282831058362321
Epoch 1463/10000, Prediction Accuracy = 57.4076923076923%, Loss = 0.010867538002247993
Epoch: 1463, Batch Gradient Norm: 2.444128618073867
Epoch: 1463, Batch Gradient Norm after: 2.444128618073867
Epoch 1464/10000, Prediction Accuracy = 57.27692307692307%, Loss = 0.010966449975967407
Epoch: 1464, Batch Gradient Norm: 2.5269091712796827
Epoch: 1464, Batch Gradient Norm after: 2.5269091712796827
Epoch 1465/10000, Prediction Accuracy = 57.54615384615385%, Loss = 0.01095033515817844
Epoch: 1465, Batch Gradient Norm: 2.2469815649617564
Epoch: 1465, Batch Gradient Norm after: 2.2469815649617564
Epoch 1466/10000, Prediction Accuracy = 58.29615384615385%, Loss = 0.010803779443869224
Epoch: 1466, Batch Gradient Norm: 2.1148758753640653
Epoch: 1466, Batch Gradient Norm after: 2.1148758753640653
Epoch 1467/10000, Prediction Accuracy = 58.27307692307693%, Loss = 0.010707694822205948
Epoch: 1467, Batch Gradient Norm: 2.1923722838138735
Epoch: 1467, Batch Gradient Norm after: 2.1923722838138735
Epoch 1468/10000, Prediction Accuracy = 57.98846153846153%, Loss = 0.01074840479458754
Epoch: 1468, Batch Gradient Norm: 2.4330298291957444
Epoch: 1468, Batch Gradient Norm after: 2.4330298291957444
Epoch 1469/10000, Prediction Accuracy = 57.27307692307692%, Loss = 0.010946057092111845
Epoch: 1469, Batch Gradient Norm: 2.3386542396952184
Epoch: 1469, Batch Gradient Norm after: 2.3386542396952184
Epoch 1470/10000, Prediction Accuracy = 57.41538461538461%, Loss = 0.010866193029169854
Epoch: 1470, Batch Gradient Norm: 2.2713192408403993
Epoch: 1470, Batch Gradient Norm after: 2.2713192408403993
Epoch 1471/10000, Prediction Accuracy = 58.01923076923078%, Loss = 0.01080571673810482
Epoch: 1471, Batch Gradient Norm: 2.16223002177321
Epoch: 1471, Batch Gradient Norm after: 2.16223002177321
Epoch 1472/10000, Prediction Accuracy = 58.05%, Loss = 0.010755171856054893
Epoch: 1472, Batch Gradient Norm: 2.1842951230894454
Epoch: 1472, Batch Gradient Norm after: 2.1842951230894454
Epoch 1473/10000, Prediction Accuracy = 57.82692307692309%, Loss = 0.010736852812652405
Epoch: 1473, Batch Gradient Norm: 2.3523609612374234
Epoch: 1473, Batch Gradient Norm after: 2.3523609612374234
Epoch 1474/10000, Prediction Accuracy = 57.9423076923077%, Loss = 0.01084684064755073
Epoch: 1474, Batch Gradient Norm: 2.648195830952004
Epoch: 1474, Batch Gradient Norm after: 2.648195830952004
Epoch 1475/10000, Prediction Accuracy = 57.53076923076924%, Loss = 0.01105186644081886
Epoch: 1475, Batch Gradient Norm: 2.5641956866358235
Epoch: 1475, Batch Gradient Norm after: 2.5641956866358235
Epoch 1476/10000, Prediction Accuracy = 57.346153846153854%, Loss = 0.011059613468555303
Epoch: 1476, Batch Gradient Norm: 2.239363887082019
Epoch: 1476, Batch Gradient Norm after: 2.239363887082019
Epoch 1477/10000, Prediction Accuracy = 58.03846153846155%, Loss = 0.010799126484646248
Epoch: 1477, Batch Gradient Norm: 2.284687549642087
Epoch: 1477, Batch Gradient Norm after: 2.284687549642087
Epoch 1478/10000, Prediction Accuracy = 58.05384615384616%, Loss = 0.010832713415416388
Epoch: 1478, Batch Gradient Norm: 2.479725435295426
Epoch: 1478, Batch Gradient Norm after: 2.479725435295426
Epoch 1479/10000, Prediction Accuracy = 57.85000000000001%, Loss = 0.010890403762459755
Epoch: 1479, Batch Gradient Norm: 2.5827307249102947
Epoch: 1479, Batch Gradient Norm after: 2.5827307249102947
Epoch 1480/10000, Prediction Accuracy = 57.23846153846153%, Loss = 0.011033813612392316
Epoch: 1480, Batch Gradient Norm: 2.210698593523997
Epoch: 1480, Batch Gradient Norm after: 2.210698593523997
Epoch 1481/10000, Prediction Accuracy = 58.19615384615385%, Loss = 0.010663205686096962
Epoch: 1481, Batch Gradient Norm: 2.2774490036829516
Epoch: 1481, Batch Gradient Norm after: 2.2774490036829516
Epoch 1482/10000, Prediction Accuracy = 58.51923076923076%, Loss = 0.010690376305809388
Epoch: 1482, Batch Gradient Norm: 2.501601802083082
Epoch: 1482, Batch Gradient Norm after: 2.501601802083082
Epoch 1483/10000, Prediction Accuracy = 57.79615384615386%, Loss = 0.010869219254415769
Epoch: 1483, Batch Gradient Norm: 2.491171454181685
Epoch: 1483, Batch Gradient Norm after: 2.491171454181685
Epoch 1484/10000, Prediction Accuracy = 57.70384615384615%, Loss = 0.010836963040324358
Epoch: 1484, Batch Gradient Norm: 2.4775201180174635
Epoch: 1484, Batch Gradient Norm after: 2.4775201180174635
Epoch 1485/10000, Prediction Accuracy = 57.7423076923077%, Loss = 0.010847716878813047
Epoch: 1485, Batch Gradient Norm: 2.5518251794490308
Epoch: 1485, Batch Gradient Norm after: 2.5518251794490308
Epoch 1486/10000, Prediction Accuracy = 57.17692307692308%, Loss = 0.011010123918262811
Epoch: 1486, Batch Gradient Norm: 2.5494394200182384
Epoch: 1486, Batch Gradient Norm after: 2.5494394200182384
Epoch 1487/10000, Prediction Accuracy = 57.61153846153847%, Loss = 0.010899155114132624
Epoch: 1487, Batch Gradient Norm: 2.551002336487006
Epoch: 1487, Batch Gradient Norm after: 2.551002336487006
Epoch 1488/10000, Prediction Accuracy = 57.353846153846156%, Loss = 0.010943179878477868
Epoch: 1488, Batch Gradient Norm: 2.3178339208539795
Epoch: 1488, Batch Gradient Norm after: 2.3178339208539795
Epoch 1489/10000, Prediction Accuracy = 57.82692307692308%, Loss = 0.010800446383655071
Epoch: 1489, Batch Gradient Norm: 2.23718041912924
Epoch: 1489, Batch Gradient Norm after: 2.23718041912924
Epoch 1490/10000, Prediction Accuracy = 58.426923076923075%, Loss = 0.01070538005576684
Epoch: 1490, Batch Gradient Norm: 2.1997801691667513
Epoch: 1490, Batch Gradient Norm after: 2.1997801691667513
Epoch 1491/10000, Prediction Accuracy = 58.26538461538461%, Loss = 0.01074237863604839
Epoch: 1491, Batch Gradient Norm: 2.369796334898838
Epoch: 1491, Batch Gradient Norm after: 2.369796334898838
Epoch 1492/10000, Prediction Accuracy = 58.07692307692309%, Loss = 0.01075955329892727
Epoch: 1492, Batch Gradient Norm: 2.34580371415746
Epoch: 1492, Batch Gradient Norm after: 2.34580371415746
Epoch 1493/10000, Prediction Accuracy = 57.80384615384616%, Loss = 0.010830253291015442
Epoch: 1493, Batch Gradient Norm: 2.257345956002028
Epoch: 1493, Batch Gradient Norm after: 2.257345956002028
Epoch 1494/10000, Prediction Accuracy = 58.18846153846153%, Loss = 0.010747382417321205
Epoch: 1494, Batch Gradient Norm: 2.281335103538242
Epoch: 1494, Batch Gradient Norm after: 2.281335103538242
Epoch 1495/10000, Prediction Accuracy = 58.01153846153847%, Loss = 0.010711738983025918
Epoch: 1495, Batch Gradient Norm: 2.3998611289491025
Epoch: 1495, Batch Gradient Norm after: 2.3998611289491025
Epoch 1496/10000, Prediction Accuracy = 58.22307692307693%, Loss = 0.01065536129933137
Epoch: 1496, Batch Gradient Norm: 2.341960562561176
Epoch: 1496, Batch Gradient Norm after: 2.341960562561176
Epoch 1497/10000, Prediction Accuracy = 58.0576923076923%, Loss = 0.010706037426224122
Epoch: 1497, Batch Gradient Norm: 2.6340044040604655
Epoch: 1497, Batch Gradient Norm after: 2.6340044040604655
Epoch 1498/10000, Prediction Accuracy = 57.91153846153846%, Loss = 0.010855040799539823
Epoch: 1498, Batch Gradient Norm: 2.4374251062137895
Epoch: 1498, Batch Gradient Norm after: 2.4374251062137895
Epoch 1499/10000, Prediction Accuracy = 58.00384615384616%, Loss = 0.01074060883659583
Epoch: 1499, Batch Gradient Norm: 2.319475939217121
Epoch: 1499, Batch Gradient Norm after: 2.319475939217121
Epoch 1500/10000, Prediction Accuracy = 58.23076923076923%, Loss = 0.010736719346963443
Epoch: 1500, Batch Gradient Norm: 2.517104944473832
Epoch: 1500, Batch Gradient Norm after: 2.517104944473832
Epoch 1501/10000, Prediction Accuracy = 57.565384615384616%, Loss = 0.010881766032140989
Epoch: 1501, Batch Gradient Norm: 2.3667762401904078
Epoch: 1501, Batch Gradient Norm after: 2.3667762401904078
Epoch 1502/10000, Prediction Accuracy = 57.67307692307692%, Loss = 0.010800284691728078
Epoch: 1502, Batch Gradient Norm: 2.1864346991167776
Epoch: 1502, Batch Gradient Norm after: 2.1864346991167776
Epoch 1503/10000, Prediction Accuracy = 58.20384615384615%, Loss = 0.010721495589957787
Epoch: 1503, Batch Gradient Norm: 2.547683840225349
Epoch: 1503, Batch Gradient Norm after: 2.547683840225349
Epoch 1504/10000, Prediction Accuracy = 57.79230769230769%, Loss = 0.010845935258727808
Epoch: 1504, Batch Gradient Norm: 2.650395969872207
Epoch: 1504, Batch Gradient Norm after: 2.650395969872207
Epoch 1505/10000, Prediction Accuracy = 57.630769230769246%, Loss = 0.010892324794370394
Epoch: 1505, Batch Gradient Norm: 2.3135475269463175
Epoch: 1505, Batch Gradient Norm after: 2.3135475269463175
Epoch 1506/10000, Prediction Accuracy = 58.3%, Loss = 0.010638792497607378
Epoch: 1506, Batch Gradient Norm: 2.3475534956241724
Epoch: 1506, Batch Gradient Norm after: 2.3475534956241724
Epoch 1507/10000, Prediction Accuracy = 58.130769230769225%, Loss = 0.0106664292084483
Epoch: 1507, Batch Gradient Norm: 2.3393838116826737
Epoch: 1507, Batch Gradient Norm after: 2.3393838116826737
Epoch 1508/10000, Prediction Accuracy = 58.07692307692308%, Loss = 0.010705328044983057
Epoch: 1508, Batch Gradient Norm: 2.2859664624116887
Epoch: 1508, Batch Gradient Norm after: 2.2859664624116887
Epoch 1509/10000, Prediction Accuracy = 58.26923076923077%, Loss = 0.010716089692253333
Epoch: 1509, Batch Gradient Norm: 2.2081669211621837
Epoch: 1509, Batch Gradient Norm after: 2.2081669211621837
Epoch 1510/10000, Prediction Accuracy = 58.357692307692304%, Loss = 0.01057704695715354
Epoch: 1510, Batch Gradient Norm: 2.4835497086518528
Epoch: 1510, Batch Gradient Norm after: 2.4835497086518528
Epoch 1511/10000, Prediction Accuracy = 58.30769230769231%, Loss = 0.010730649631183881
Epoch: 1511, Batch Gradient Norm: 2.2194172354941957
Epoch: 1511, Batch Gradient Norm after: 2.2194172354941957
Epoch 1512/10000, Prediction Accuracy = 58.650000000000006%, Loss = 0.01053802683376349
Epoch: 1512, Batch Gradient Norm: 2.5818101378726235
Epoch: 1512, Batch Gradient Norm after: 2.5818101378726235
Epoch 1513/10000, Prediction Accuracy = 57.58846153846154%, Loss = 0.010791839601901861
Epoch: 1513, Batch Gradient Norm: 2.564596058460146
Epoch: 1513, Batch Gradient Norm after: 2.564596058460146
Epoch 1514/10000, Prediction Accuracy = 57.34615384615384%, Loss = 0.010859344584437517
Epoch: 1514, Batch Gradient Norm: 2.5562461353168717
Epoch: 1514, Batch Gradient Norm after: 2.5562461353168717
Epoch 1515/10000, Prediction Accuracy = 57.96153846153845%, Loss = 0.010805860018500915
Epoch: 1515, Batch Gradient Norm: 2.550995380383134
Epoch: 1515, Batch Gradient Norm after: 2.550995380383134
Epoch 1516/10000, Prediction Accuracy = 57.63076923076923%, Loss = 0.010859477477004895
Epoch: 1516, Batch Gradient Norm: 2.623906044954064
Epoch: 1516, Batch Gradient Norm after: 2.623906044954064
Epoch 1517/10000, Prediction Accuracy = 57.76923076923077%, Loss = 0.010787342889950825
Epoch: 1517, Batch Gradient Norm: 2.3682840933349945
Epoch: 1517, Batch Gradient Norm after: 2.3682840933349945
Epoch 1518/10000, Prediction Accuracy = 58.199999999999996%, Loss = 0.010707905372748008
Epoch: 1518, Batch Gradient Norm: 2.650433967154653
Epoch: 1518, Batch Gradient Norm after: 2.650433967154653
Epoch 1519/10000, Prediction Accuracy = 57.43076923076923%, Loss = 0.010898865616092315
Epoch: 1519, Batch Gradient Norm: 2.4353659682270457
Epoch: 1519, Batch Gradient Norm after: 2.4353659682270457
Epoch 1520/10000, Prediction Accuracy = 58.01923076923078%, Loss = 0.010683271532448439
Epoch: 1520, Batch Gradient Norm: 2.3511607726394974
Epoch: 1520, Batch Gradient Norm after: 2.3511607726394974
Epoch 1521/10000, Prediction Accuracy = 58.07692307692308%, Loss = 0.01065353390115958
Epoch: 1521, Batch Gradient Norm: 2.2703263774517355
Epoch: 1521, Batch Gradient Norm after: 2.2703263774517355
Epoch 1522/10000, Prediction Accuracy = 58.09615384615385%, Loss = 0.01062540437739629
Epoch: 1522, Batch Gradient Norm: 2.4297653279263196
Epoch: 1522, Batch Gradient Norm after: 2.4297653279263196
Epoch 1523/10000, Prediction Accuracy = 57.934615384615384%, Loss = 0.01075410542006676
Epoch: 1523, Batch Gradient Norm: 2.525318138988001
Epoch: 1523, Batch Gradient Norm after: 2.525318138988001
Epoch 1524/10000, Prediction Accuracy = 57.73846153846154%, Loss = 0.010754651963137664
Epoch: 1524, Batch Gradient Norm: 2.5747651218006786
Epoch: 1524, Batch Gradient Norm after: 2.5747651218006786
Epoch 1525/10000, Prediction Accuracy = 58.21538461538463%, Loss = 0.01065360360707228
Epoch: 1525, Batch Gradient Norm: 2.431046706615348
Epoch: 1525, Batch Gradient Norm after: 2.431046706615348
Epoch 1526/10000, Prediction Accuracy = 58.07692307692308%, Loss = 0.010598649557393331
Epoch: 1526, Batch Gradient Norm: 2.2166173284411697
Epoch: 1526, Batch Gradient Norm after: 2.2166173284411697
Epoch 1527/10000, Prediction Accuracy = 58.32307692307691%, Loss = 0.010516749694943428
Epoch: 1527, Batch Gradient Norm: 2.133383166651302
Epoch: 1527, Batch Gradient Norm after: 2.133383166651302
Epoch 1528/10000, Prediction Accuracy = 58.434615384615384%, Loss = 0.01047216054911797
Epoch: 1528, Batch Gradient Norm: 2.346626477987373
Epoch: 1528, Batch Gradient Norm after: 2.346626477987373
Epoch 1529/10000, Prediction Accuracy = 58.330769230769235%, Loss = 0.010571387811348988
Epoch: 1529, Batch Gradient Norm: 2.5440851944231517
Epoch: 1529, Batch Gradient Norm after: 2.5440851944231517
Epoch 1530/10000, Prediction Accuracy = 58.034615384615385%, Loss = 0.010754827195062088
Epoch: 1530, Batch Gradient Norm: 2.6461569980146527
Epoch: 1530, Batch Gradient Norm after: 2.6461569980146527
Epoch 1531/10000, Prediction Accuracy = 58.14230769230768%, Loss = 0.010794051707937168
Epoch: 1531, Batch Gradient Norm: 2.388108758285047
Epoch: 1531, Batch Gradient Norm after: 2.388108758285047
Epoch 1532/10000, Prediction Accuracy = 57.66153846153846%, Loss = 0.010681979429836456
Epoch: 1532, Batch Gradient Norm: 2.4361157027131233
Epoch: 1532, Batch Gradient Norm after: 2.4361157027131233
Epoch 1533/10000, Prediction Accuracy = 57.90384615384616%, Loss = 0.010669517402465526
Epoch: 1533, Batch Gradient Norm: 2.807767336354937
Epoch: 1533, Batch Gradient Norm after: 2.807767336354937
Epoch 1534/10000, Prediction Accuracy = 57.58461538461539%, Loss = 0.010864601757090826
Epoch: 1534, Batch Gradient Norm: 2.416260199121577
Epoch: 1534, Batch Gradient Norm after: 2.416260199121577
Epoch 1535/10000, Prediction Accuracy = 57.91538461538461%, Loss = 0.010651620104908943
Epoch: 1535, Batch Gradient Norm: 2.3951376019109896
Epoch: 1535, Batch Gradient Norm after: 2.3951376019109896
Epoch 1536/10000, Prediction Accuracy = 58.21923076923077%, Loss = 0.010647527013833705
Epoch: 1536, Batch Gradient Norm: 2.477242946635484
Epoch: 1536, Batch Gradient Norm after: 2.477242946635484
Epoch 1537/10000, Prediction Accuracy = 58.04615384615385%, Loss = 0.01077379028384502
Epoch: 1537, Batch Gradient Norm: 2.3233515404748837
Epoch: 1537, Batch Gradient Norm after: 2.3233515404748837
Epoch 1538/10000, Prediction Accuracy = 58.08846153846153%, Loss = 0.010659270346737824
Epoch: 1538, Batch Gradient Norm: 2.327964743991078
Epoch: 1538, Batch Gradient Norm after: 2.327964743991078
Epoch 1539/10000, Prediction Accuracy = 57.96923076923076%, Loss = 0.010571134419968495
Epoch: 1539, Batch Gradient Norm: 2.3161860357644346
Epoch: 1539, Batch Gradient Norm after: 2.3161860357644346
Epoch 1540/10000, Prediction Accuracy = 58.41923076923077%, Loss = 0.010574057769890014
Epoch: 1540, Batch Gradient Norm: 2.561288374725451
Epoch: 1540, Batch Gradient Norm after: 2.561288374725451
Epoch 1541/10000, Prediction Accuracy = 58.32307692307693%, Loss = 0.010702213630653344
Epoch: 1541, Batch Gradient Norm: 2.58520186508114
Epoch: 1541, Batch Gradient Norm after: 2.58520186508114
Epoch 1542/10000, Prediction Accuracy = 58.26923076923077%, Loss = 0.010705920795981701
Epoch: 1542, Batch Gradient Norm: 2.5052406450988314
Epoch: 1542, Batch Gradient Norm after: 2.5052406450988314
Epoch 1543/10000, Prediction Accuracy = 57.44615384615385%, Loss = 0.010740450368477749
Epoch: 1543, Batch Gradient Norm: 2.626593196609191
Epoch: 1543, Batch Gradient Norm after: 2.626593196609191
Epoch 1544/10000, Prediction Accuracy = 57.73076923076922%, Loss = 0.010835843733870067
Epoch: 1544, Batch Gradient Norm: 2.3143277772923176
Epoch: 1544, Batch Gradient Norm after: 2.3143277772923176
Epoch 1545/10000, Prediction Accuracy = 58.54230769230769%, Loss = 0.010568085269859204
Epoch: 1545, Batch Gradient Norm: 2.2319965457146074
Epoch: 1545, Batch Gradient Norm after: 2.2319965457146074
Epoch 1546/10000, Prediction Accuracy = 58.47307692307693%, Loss = 0.010533880657301499
Epoch: 1546, Batch Gradient Norm: 2.458200531855597
Epoch: 1546, Batch Gradient Norm after: 2.458200531855597
Epoch 1547/10000, Prediction Accuracy = 58.51153846153846%, Loss = 0.010519340132864622
Epoch: 1547, Batch Gradient Norm: 2.244348844004242
Epoch: 1547, Batch Gradient Norm after: 2.244348844004242
Epoch 1548/10000, Prediction Accuracy = 58.50000000000001%, Loss = 0.010475310353705516
Epoch: 1548, Batch Gradient Norm: 2.661816778192508
Epoch: 1548, Batch Gradient Norm after: 2.661816778192508
Epoch 1549/10000, Prediction Accuracy = 58.37692307692308%, Loss = 0.010646872150783356
Epoch: 1549, Batch Gradient Norm: 2.651956252373834
Epoch: 1549, Batch Gradient Norm after: 2.651956252373834
Epoch 1550/10000, Prediction Accuracy = 57.86153846153846%, Loss = 0.010804826537003884
Epoch: 1550, Batch Gradient Norm: 2.4724265459880983
Epoch: 1550, Batch Gradient Norm after: 2.4724265459880983
Epoch 1551/10000, Prediction Accuracy = 58.73076923076923%, Loss = 0.010628199491363306
Epoch: 1551, Batch Gradient Norm: 2.410391996819357
Epoch: 1551, Batch Gradient Norm after: 2.410391996819357
Epoch 1552/10000, Prediction Accuracy = 58.357692307692304%, Loss = 0.0105538759380579
Epoch: 1552, Batch Gradient Norm: 2.3207423504771327
Epoch: 1552, Batch Gradient Norm after: 2.3207423504771327
Epoch 1553/10000, Prediction Accuracy = 58.56153846153846%, Loss = 0.010465065232263161
Epoch: 1553, Batch Gradient Norm: 2.3767380045253867
Epoch: 1553, Batch Gradient Norm after: 2.3767380045253867
Epoch 1554/10000, Prediction Accuracy = 58.669230769230765%, Loss = 0.010553636444875827
Epoch: 1554, Batch Gradient Norm: 2.4233159424807744
Epoch: 1554, Batch Gradient Norm after: 2.4233159424807744
Epoch 1555/10000, Prediction Accuracy = 57.93846153846154%, Loss = 0.010632875017248668
Epoch: 1555, Batch Gradient Norm: 2.202806925901749
Epoch: 1555, Batch Gradient Norm after: 2.202806925901749
Epoch 1556/10000, Prediction Accuracy = 58.64615384615385%, Loss = 0.010491960037213106
Epoch: 1556, Batch Gradient Norm: 2.5091057695448438
Epoch: 1556, Batch Gradient Norm after: 2.5091057695448438
Epoch 1557/10000, Prediction Accuracy = 58.5076923076923%, Loss = 0.010571995964990212
Epoch: 1557, Batch Gradient Norm: 2.37180134067987
Epoch: 1557, Batch Gradient Norm after: 2.37180134067987
Epoch 1558/10000, Prediction Accuracy = 58.91153846153846%, Loss = 0.010476786356705885
Epoch: 1558, Batch Gradient Norm: 2.64704183545288
Epoch: 1558, Batch Gradient Norm after: 2.64704183545288
Epoch 1559/10000, Prediction Accuracy = 58.05769230769231%, Loss = 0.01069567553125895
Epoch: 1559, Batch Gradient Norm: 2.4366970633156715
Epoch: 1559, Batch Gradient Norm after: 2.4366970633156715
Epoch 1560/10000, Prediction Accuracy = 58.115384615384606%, Loss = 0.01055684950775825
Epoch: 1560, Batch Gradient Norm: 2.530746117199388
Epoch: 1560, Batch Gradient Norm after: 2.530746117199388
Epoch 1561/10000, Prediction Accuracy = 58.2576923076923%, Loss = 0.010560213373257564
Epoch: 1561, Batch Gradient Norm: 2.5503157477591385
Epoch: 1561, Batch Gradient Norm after: 2.5503157477591385
Epoch 1562/10000, Prediction Accuracy = 58.096153846153854%, Loss = 0.01059122963880117
Epoch: 1562, Batch Gradient Norm: 2.4754470549782304
Epoch: 1562, Batch Gradient Norm after: 2.4754470549782304
Epoch 1563/10000, Prediction Accuracy = 58.03076923076923%, Loss = 0.010597895401028486
Epoch: 1563, Batch Gradient Norm: 2.5504995597749476
Epoch: 1563, Batch Gradient Norm after: 2.5504995597749476
Epoch 1564/10000, Prediction Accuracy = 58.115384615384606%, Loss = 0.0106179451999756
Epoch: 1564, Batch Gradient Norm: 2.4572397676142494
Epoch: 1564, Batch Gradient Norm after: 2.4572397676142494
Epoch 1565/10000, Prediction Accuracy = 58.38461538461539%, Loss = 0.010564154802033534
Epoch: 1565, Batch Gradient Norm: 2.3249807001314955
Epoch: 1565, Batch Gradient Norm after: 2.3249807001314955
Epoch 1566/10000, Prediction Accuracy = 58.54230769230769%, Loss = 0.010461790773731012
Epoch: 1566, Batch Gradient Norm: 2.7054766369679535
Epoch: 1566, Batch Gradient Norm after: 2.7054766369679535
Epoch 1567/10000, Prediction Accuracy = 58.06923076923078%, Loss = 0.010699711023614956
Epoch: 1567, Batch Gradient Norm: 2.6099120402741383
Epoch: 1567, Batch Gradient Norm after: 2.6099120402741383
Epoch 1568/10000, Prediction Accuracy = 57.7153846153846%, Loss = 0.010708113559163533
Epoch: 1568, Batch Gradient Norm: 2.4303741333177067
Epoch: 1568, Batch Gradient Norm after: 2.4303741333177067
Epoch 1569/10000, Prediction Accuracy = 58.55%, Loss = 0.010492263075250845
Epoch: 1569, Batch Gradient Norm: 2.421648057139614
Epoch: 1569, Batch Gradient Norm after: 2.421648057139614
Epoch 1570/10000, Prediction Accuracy = 58.28846153846154%, Loss = 0.01052313305151004
Epoch: 1570, Batch Gradient Norm: 2.4639072766460126
Epoch: 1570, Batch Gradient Norm after: 2.4639072766460126
Epoch 1571/10000, Prediction Accuracy = 58.580769230769235%, Loss = 0.010512226332838718
Epoch: 1571, Batch Gradient Norm: 2.7912374658122037
Epoch: 1571, Batch Gradient Norm after: 2.7912374658122037
Epoch 1572/10000, Prediction Accuracy = 58.31538461538461%, Loss = 0.010730784601317002
Epoch: 1572, Batch Gradient Norm: 2.7783254660431167
Epoch: 1572, Batch Gradient Norm after: 2.7783254660431167
Epoch 1573/10000, Prediction Accuracy = 58.026923076923076%, Loss = 0.010765479447749944
Epoch: 1573, Batch Gradient Norm: 2.4649893838154853
Epoch: 1573, Batch Gradient Norm after: 2.4649893838154853
Epoch 1574/10000, Prediction Accuracy = 58.25769230769232%, Loss = 0.010581651415962439
Epoch: 1574, Batch Gradient Norm: 2.69685484432801
Epoch: 1574, Batch Gradient Norm after: 2.69685484432801
Epoch 1575/10000, Prediction Accuracy = 58.04230769230769%, Loss = 0.01068991687721931
Epoch: 1575, Batch Gradient Norm: 2.3641763918616414
Epoch: 1575, Batch Gradient Norm after: 2.3641763918616414
Epoch 1576/10000, Prediction Accuracy = 58.49615384615385%, Loss = 0.010505017108069016
Epoch: 1576, Batch Gradient Norm: 2.5253645170308294
Epoch: 1576, Batch Gradient Norm after: 2.5253645170308294
Epoch 1577/10000, Prediction Accuracy = 58.13461538461539%, Loss = 0.010643902378013501
Epoch: 1577, Batch Gradient Norm: 2.3556712476860606
Epoch: 1577, Batch Gradient Norm after: 2.3556712476860606
Epoch 1578/10000, Prediction Accuracy = 58.28461538461538%, Loss = 0.010503978826678716
Epoch: 1578, Batch Gradient Norm: 2.4867544643384307
Epoch: 1578, Batch Gradient Norm after: 2.4867544643384307
Epoch 1579/10000, Prediction Accuracy = 58.8423076923077%, Loss = 0.010469570254477171
Epoch: 1579, Batch Gradient Norm: 2.7144627545926494
Epoch: 1579, Batch Gradient Norm after: 2.7144627545926494
Epoch 1580/10000, Prediction Accuracy = 58.1923076923077%, Loss = 0.010578595101833344
Epoch: 1580, Batch Gradient Norm: 2.6014778963183915
Epoch: 1580, Batch Gradient Norm after: 2.6014778963183915
Epoch 1581/10000, Prediction Accuracy = 58.08076923076923%, Loss = 0.010581722339758506
Epoch: 1581, Batch Gradient Norm: 2.6389721221801534
Epoch: 1581, Batch Gradient Norm after: 2.6389721221801534
Epoch 1582/10000, Prediction Accuracy = 58.01153846153845%, Loss = 0.01058404821042831
Epoch: 1582, Batch Gradient Norm: 2.3922330508718264
Epoch: 1582, Batch Gradient Norm after: 2.3922330508718264
Epoch 1583/10000, Prediction Accuracy = 58.94615384615384%, Loss = 0.010485431465965051
Epoch: 1583, Batch Gradient Norm: 2.39173868879462
Epoch: 1583, Batch Gradient Norm after: 2.39173868879462
Epoch 1584/10000, Prediction Accuracy = 58.70769230769232%, Loss = 0.010416989286358539
Epoch: 1584, Batch Gradient Norm: 2.452173029617042
Epoch: 1584, Batch Gradient Norm after: 2.452173029617042
Epoch 1585/10000, Prediction Accuracy = 58.81923076923077%, Loss = 0.01045234315097332
Epoch: 1585, Batch Gradient Norm: 2.733542374869679
Epoch: 1585, Batch Gradient Norm after: 2.733542374869679
Epoch 1586/10000, Prediction Accuracy = 58.51153846153846%, Loss = 0.010583604256121011
Epoch: 1586, Batch Gradient Norm: 2.6773307636154664
Epoch: 1586, Batch Gradient Norm after: 2.6773307636154664
Epoch 1587/10000, Prediction Accuracy = 58.55384615384615%, Loss = 0.010545953248555843
Epoch: 1587, Batch Gradient Norm: 2.837880915374558
Epoch: 1587, Batch Gradient Norm after: 2.837880915374558
Epoch 1588/10000, Prediction Accuracy = 58.169230769230765%, Loss = 0.010634339844378142
Epoch: 1588, Batch Gradient Norm: 2.7937359613156567
Epoch: 1588, Batch Gradient Norm after: 2.7937359613156567
Epoch 1589/10000, Prediction Accuracy = 58.150000000000006%, Loss = 0.010671173508923788
Epoch: 1589, Batch Gradient Norm: 2.617546826529629
Epoch: 1589, Batch Gradient Norm after: 2.617546826529629
Epoch 1590/10000, Prediction Accuracy = 58.25000000000001%, Loss = 0.01062262373474928
Epoch: 1590, Batch Gradient Norm: 2.44868192331608
Epoch: 1590, Batch Gradient Norm after: 2.44868192331608
Epoch 1591/10000, Prediction Accuracy = 58.43076923076923%, Loss = 0.010454165605971446
Epoch: 1591, Batch Gradient Norm: 2.410253136406765
Epoch: 1591, Batch Gradient Norm after: 2.410253136406765
Epoch 1592/10000, Prediction Accuracy = 58.603846153846156%, Loss = 0.010466094916829696
Epoch: 1592, Batch Gradient Norm: 2.697347431616065
Epoch: 1592, Batch Gradient Norm after: 2.697347431616065
Epoch 1593/10000, Prediction Accuracy = 58.31923076923077%, Loss = 0.010644378140568733
Epoch: 1593, Batch Gradient Norm: 2.5419900395158277
Epoch: 1593, Batch Gradient Norm after: 2.5419900395158277
Epoch 1594/10000, Prediction Accuracy = 58.31153846153847%, Loss = 0.010558095760643482
Epoch: 1594, Batch Gradient Norm: 2.438317255464079
Epoch: 1594, Batch Gradient Norm after: 2.438317255464079
Epoch 1595/10000, Prediction Accuracy = 58.73846153846153%, Loss = 0.010469715898999801
Epoch: 1595, Batch Gradient Norm: 2.2686909254856196
Epoch: 1595, Batch Gradient Norm after: 2.2686909254856196
Epoch 1596/10000, Prediction Accuracy = 58.44615384615385%, Loss = 0.010441749714888059
Epoch: 1596, Batch Gradient Norm: 2.642877255682407
Epoch: 1596, Batch Gradient Norm after: 2.642877255682407
Epoch 1597/10000, Prediction Accuracy = 58.396153846153844%, Loss = 0.010570072210752048
Epoch: 1597, Batch Gradient Norm: 2.4913224073291715
Epoch: 1597, Batch Gradient Norm after: 2.4913224073291715
Epoch 1598/10000, Prediction Accuracy = 58.215384615384615%, Loss = 0.010527051483782439
Epoch: 1598, Batch Gradient Norm: 2.546405845369542
Epoch: 1598, Batch Gradient Norm after: 2.546405845369542
Epoch 1599/10000, Prediction Accuracy = 58.66538461538461%, Loss = 0.010463965770143729
Epoch: 1599, Batch Gradient Norm: 2.287762529401569
Epoch: 1599, Batch Gradient Norm after: 2.287762529401569
Epoch 1600/10000, Prediction Accuracy = 58.94615384615385%, Loss = 0.010350151488987299
Epoch: 1600, Batch Gradient Norm: 2.1944436468276765
Epoch: 1600, Batch Gradient Norm after: 2.1944436468276765
Epoch 1601/10000, Prediction Accuracy = 58.64999999999999%, Loss = 0.0102920366737705
Epoch: 1601, Batch Gradient Norm: 2.356198701124492
Epoch: 1601, Batch Gradient Norm after: 2.356198701124492
Epoch 1602/10000, Prediction Accuracy = 58.973076923076924%, Loss = 0.010346774943172932
Epoch: 1602, Batch Gradient Norm: 2.388643351978917
Epoch: 1602, Batch Gradient Norm after: 2.388643351978917
Epoch 1603/10000, Prediction Accuracy = 58.71538461538462%, Loss = 0.010417066156291045
Epoch: 1603, Batch Gradient Norm: 2.381863648314132
Epoch: 1603, Batch Gradient Norm after: 2.381863648314132
Epoch 1604/10000, Prediction Accuracy = 58.96923076923077%, Loss = 0.010361080917601403
Epoch: 1604, Batch Gradient Norm: 2.7393628237981806
Epoch: 1604, Batch Gradient Norm after: 2.7393628237981806
Epoch 1605/10000, Prediction Accuracy = 58.43846153846154%, Loss = 0.010526082550103847
Epoch: 1605, Batch Gradient Norm: 2.698554038769211
Epoch: 1605, Batch Gradient Norm after: 2.698554038769211
Epoch 1606/10000, Prediction Accuracy = 58.57692307692308%, Loss = 0.010507405448991518
Epoch: 1606, Batch Gradient Norm: 2.4509248320284964
Epoch: 1606, Batch Gradient Norm after: 2.4509248320284964
Epoch 1607/10000, Prediction Accuracy = 58.580769230769235%, Loss = 0.010367251001298428
Epoch: 1607, Batch Gradient Norm: 2.5229235382575603
Epoch: 1607, Batch Gradient Norm after: 2.5229235382575603
Epoch 1608/10000, Prediction Accuracy = 58.8346153846154%, Loss = 0.010413257978283443
Epoch: 1608, Batch Gradient Norm: 2.5629178717640992
Epoch: 1608, Batch Gradient Norm after: 2.5629178717640992
Epoch 1609/10000, Prediction Accuracy = 59.03076923076923%, Loss = 0.01042765429100165
Epoch: 1609, Batch Gradient Norm: 2.597997450921727
Epoch: 1609, Batch Gradient Norm after: 2.597997450921727
Epoch 1610/10000, Prediction Accuracy = 58.53846153846155%, Loss = 0.010514290000383671
Epoch: 1610, Batch Gradient Norm: 2.496123409428121
Epoch: 1610, Batch Gradient Norm after: 2.496123409428121
Epoch 1611/10000, Prediction Accuracy = 58.42692307692308%, Loss = 0.010400389607709188
Epoch: 1611, Batch Gradient Norm: 2.3581183550425764
Epoch: 1611, Batch Gradient Norm after: 2.3581183550425764
Epoch 1612/10000, Prediction Accuracy = 58.888461538461534%, Loss = 0.01034059884169927
Epoch: 1612, Batch Gradient Norm: 2.6853862749712754
Epoch: 1612, Batch Gradient Norm after: 2.6853862749712754
Epoch 1613/10000, Prediction Accuracy = 58.65384615384615%, Loss = 0.010424578562378883
Epoch: 1613, Batch Gradient Norm: 2.614246892951413
Epoch: 1613, Batch Gradient Norm after: 2.614246892951413
Epoch 1614/10000, Prediction Accuracy = 58.37307692307692%, Loss = 0.010452903663882842
Epoch: 1614, Batch Gradient Norm: 2.290941321215259
Epoch: 1614, Batch Gradient Norm after: 2.290941321215259
Epoch 1615/10000, Prediction Accuracy = 58.98076923076923%, Loss = 0.010221968046747722
Epoch: 1615, Batch Gradient Norm: 2.265259495099585
Epoch: 1615, Batch Gradient Norm after: 2.265259495099585
Epoch 1616/10000, Prediction Accuracy = 59.23076923076923%, Loss = 0.010201693369218936
Epoch: 1616, Batch Gradient Norm: 2.6826337482000344
Epoch: 1616, Batch Gradient Norm after: 2.6826337482000344
Epoch 1617/10000, Prediction Accuracy = 58.776923076923076%, Loss = 0.010415440138715964
Epoch: 1617, Batch Gradient Norm: 2.686424188552618
Epoch: 1617, Batch Gradient Norm after: 2.686424188552618
Epoch 1618/10000, Prediction Accuracy = 58.6576923076923%, Loss = 0.010468166464796433
Epoch: 1618, Batch Gradient Norm: 2.5516519096711714
Epoch: 1618, Batch Gradient Norm after: 2.5516519096711714
Epoch 1619/10000, Prediction Accuracy = 58.86923076923077%, Loss = 0.010403330939320417
Epoch: 1619, Batch Gradient Norm: 2.508291467511352
Epoch: 1619, Batch Gradient Norm after: 2.508291467511352
Epoch 1620/10000, Prediction Accuracy = 58.79615384615384%, Loss = 0.010358596005691932
Epoch: 1620, Batch Gradient Norm: 2.3815389991175526
Epoch: 1620, Batch Gradient Norm after: 2.3815389991175526
Epoch 1621/10000, Prediction Accuracy = 59.07692307692308%, Loss = 0.010175508088790454
Epoch: 1621, Batch Gradient Norm: 2.5703188151821896
Epoch: 1621, Batch Gradient Norm after: 2.5703188151821896
Epoch 1622/10000, Prediction Accuracy = 58.94230769230769%, Loss = 0.010362404112059336
Epoch: 1622, Batch Gradient Norm: 2.629785577200249
Epoch: 1622, Batch Gradient Norm after: 2.629785577200249
Epoch 1623/10000, Prediction Accuracy = 58.476923076923086%, Loss = 0.010387789028195234
Epoch: 1623, Batch Gradient Norm: 2.6516523131508993
Epoch: 1623, Batch Gradient Norm after: 2.6516523131508993
Epoch 1624/10000, Prediction Accuracy = 58.580769230769235%, Loss = 0.010392499586137442
Epoch: 1624, Batch Gradient Norm: 2.7323551966862243
Epoch: 1624, Batch Gradient Norm after: 2.7323551966862243
Epoch 1625/10000, Prediction Accuracy = 58.72692307692307%, Loss = 0.01042328724780908
Epoch: 1625, Batch Gradient Norm: 2.887730425346712
Epoch: 1625, Batch Gradient Norm after: 2.887730425346712
Epoch 1626/10000, Prediction Accuracy = 58.63076923076923%, Loss = 0.010559783675349675
Epoch: 1626, Batch Gradient Norm: 2.8481858282998647
Epoch: 1626, Batch Gradient Norm after: 2.8481858282998647
Epoch 1627/10000, Prediction Accuracy = 58.43461538461539%, Loss = 0.010562371104382552
Epoch: 1627, Batch Gradient Norm: 3.023458832894367
Epoch: 1627, Batch Gradient Norm after: 3.023458832894367
Epoch 1628/10000, Prediction Accuracy = 58.12307692307694%, Loss = 0.010716085465481648
Epoch: 1628, Batch Gradient Norm: 2.8010540179301158
Epoch: 1628, Batch Gradient Norm after: 2.8010540179301158
Epoch 1629/10000, Prediction Accuracy = 58.526923076923076%, Loss = 0.010509695213001508
Epoch: 1629, Batch Gradient Norm: 2.4038285726986537
Epoch: 1629, Batch Gradient Norm after: 2.4038285726986537
Epoch 1630/10000, Prediction Accuracy = 58.934615384615384%, Loss = 0.0103438924281643
Epoch: 1630, Batch Gradient Norm: 2.4952910035661313
Epoch: 1630, Batch Gradient Norm after: 2.4952910035661313
Epoch 1631/10000, Prediction Accuracy = 58.87692307692308%, Loss = 0.01033163801408731
Epoch: 1631, Batch Gradient Norm: 2.7594621110498823
Epoch: 1631, Batch Gradient Norm after: 2.7594621110498823
Epoch 1632/10000, Prediction Accuracy = 58.38461538461539%, Loss = 0.010463810239273768
Epoch: 1632, Batch Gradient Norm: 2.2723629430409202
Epoch: 1632, Batch Gradient Norm after: 2.2723629430409202
Epoch 1633/10000, Prediction Accuracy = 59.52692307692307%, Loss = 0.01016841227045426
Epoch: 1633, Batch Gradient Norm: 2.68883218896742
Epoch: 1633, Batch Gradient Norm after: 2.68883218896742
Epoch 1634/10000, Prediction Accuracy = 58.576923076923066%, Loss = 0.010429338408777347
Epoch: 1634, Batch Gradient Norm: 2.751355754951057
Epoch: 1634, Batch Gradient Norm after: 2.751355754951057
Epoch 1635/10000, Prediction Accuracy = 58.49230769230769%, Loss = 0.010453766856629115
Epoch: 1635, Batch Gradient Norm: 2.633846032063803
Epoch: 1635, Batch Gradient Norm after: 2.633846032063803
Epoch 1636/10000, Prediction Accuracy = 58.884615384615394%, Loss = 0.01032743645975223
Epoch: 1636, Batch Gradient Norm: 2.475497691903103
Epoch: 1636, Batch Gradient Norm after: 2.475497691903103
Epoch 1637/10000, Prediction Accuracy = 59.01923076923077%, Loss = 0.010267715328014813
Epoch: 1637, Batch Gradient Norm: 2.51518406864181
Epoch: 1637, Batch Gradient Norm after: 2.51518406864181
Epoch 1638/10000, Prediction Accuracy = 59.20000000000001%, Loss = 0.010283282671410304
Epoch: 1638, Batch Gradient Norm: 2.7978979844429235
Epoch: 1638, Batch Gradient Norm after: 2.7978979844429235
Epoch 1639/10000, Prediction Accuracy = 58.51923076923077%, Loss = 0.010544974356889725
Epoch: 1639, Batch Gradient Norm: 2.6928578234920693
Epoch: 1639, Batch Gradient Norm after: 2.6928578234920693
Epoch 1640/10000, Prediction Accuracy = 58.08461538461539%, Loss = 0.010487298767727155
Epoch: 1640, Batch Gradient Norm: 2.596459756104306
Epoch: 1640, Batch Gradient Norm after: 2.596459756104306
Epoch 1641/10000, Prediction Accuracy = 58.69230769230769%, Loss = 0.010404823634486932
Epoch: 1641, Batch Gradient Norm: 2.9403556862462
Epoch: 1641, Batch Gradient Norm after: 2.9403556862462
Epoch 1642/10000, Prediction Accuracy = 58.24615384615385%, Loss = 0.010655139644558612
Epoch: 1642, Batch Gradient Norm: 2.584666083781204
Epoch: 1642, Batch Gradient Norm after: 2.584666083781204
Epoch 1643/10000, Prediction Accuracy = 58.62307692307692%, Loss = 0.010396040761126922
Epoch: 1643, Batch Gradient Norm: 2.624197707838027
Epoch: 1643, Batch Gradient Norm after: 2.624197707838027
Epoch 1644/10000, Prediction Accuracy = 58.82307692307692%, Loss = 0.010431488474401144
Epoch: 1644, Batch Gradient Norm: 2.4634310069556897
Epoch: 1644, Batch Gradient Norm after: 2.4634310069556897
Epoch 1645/10000, Prediction Accuracy = 58.67307692307692%, Loss = 0.010379373740691405
Epoch: 1645, Batch Gradient Norm: 2.6455288504776697
Epoch: 1645, Batch Gradient Norm after: 2.6455288504776697
Epoch 1646/10000, Prediction Accuracy = 58.36153846153846%, Loss = 0.010444159834430767
Epoch: 1646, Batch Gradient Norm: 2.40882569795105
Epoch: 1646, Batch Gradient Norm after: 2.40882569795105
Epoch 1647/10000, Prediction Accuracy = 59.23846153846153%, Loss = 0.010233844415499615
Epoch: 1647, Batch Gradient Norm: 2.7478185830453006
Epoch: 1647, Batch Gradient Norm after: 2.7478185830453006
Epoch 1648/10000, Prediction Accuracy = 58.653846153846146%, Loss = 0.010408438598880401
Epoch: 1648, Batch Gradient Norm: 2.949080977397217
Epoch: 1648, Batch Gradient Norm after: 2.949080977397217
Epoch 1649/10000, Prediction Accuracy = 58.03846153846155%, Loss = 0.010601398033591418
Epoch: 1649, Batch Gradient Norm: 2.790550168949894
Epoch: 1649, Batch Gradient Norm after: 2.790550168949894
Epoch 1650/10000, Prediction Accuracy = 57.91923076923077%, Loss = 0.010513155291286798
Epoch: 1650, Batch Gradient Norm: 2.4531595997868747
Epoch: 1650, Batch Gradient Norm after: 2.4531595997868747
Epoch 1651/10000, Prediction Accuracy = 59.08461538461539%, Loss = 0.01037071358699065
Epoch: 1651, Batch Gradient Norm: 2.2949502300873403
Epoch: 1651, Batch Gradient Norm after: 2.2949502300873403
Epoch 1652/10000, Prediction Accuracy = 59.32307692307692%, Loss = 0.01015010905953554
Epoch: 1652, Batch Gradient Norm: 2.9778625365820868
Epoch: 1652, Batch Gradient Norm after: 2.9778625365820868
Epoch 1653/10000, Prediction Accuracy = 58.29615384615384%, Loss = 0.0105665554650701
Epoch: 1653, Batch Gradient Norm: 2.643324674335294
Epoch: 1653, Batch Gradient Norm after: 2.643324674335294
Epoch 1654/10000, Prediction Accuracy = 58.82692307692308%, Loss = 0.010402025654911995
Epoch: 1654, Batch Gradient Norm: 2.784187017171185
Epoch: 1654, Batch Gradient Norm after: 2.784187017171185
Epoch 1655/10000, Prediction Accuracy = 58.64615384615385%, Loss = 0.01048043492035224
Epoch: 1655, Batch Gradient Norm: 2.6409158034266977
Epoch: 1655, Batch Gradient Norm after: 2.6409158034266977
Epoch 1656/10000, Prediction Accuracy = 58.3423076923077%, Loss = 0.010364576529424924
Epoch: 1656, Batch Gradient Norm: 2.7300146349060315
Epoch: 1656, Batch Gradient Norm after: 2.7300146349060315
Epoch 1657/10000, Prediction Accuracy = 59.29615384615384%, Loss = 0.0103474217825211
Epoch: 1657, Batch Gradient Norm: 2.7303629559833653
Epoch: 1657, Batch Gradient Norm after: 2.7303629559833653
Epoch 1658/10000, Prediction Accuracy = 58.696153846153834%, Loss = 0.010415517080288667
Epoch: 1658, Batch Gradient Norm: 2.4851983982439747
Epoch: 1658, Batch Gradient Norm after: 2.4851983982439747
Epoch 1659/10000, Prediction Accuracy = 59.05384615384615%, Loss = 0.010248990801091377
Epoch: 1659, Batch Gradient Norm: 2.4518012530601743
Epoch: 1659, Batch Gradient Norm after: 2.4518012530601743
Epoch 1660/10000, Prediction Accuracy = 59.18846153846153%, Loss = 0.010166779160499573
Epoch: 1660, Batch Gradient Norm: 2.5475213158757324
Epoch: 1660, Batch Gradient Norm after: 2.5475213158757324
Epoch 1661/10000, Prediction Accuracy = 59.0846153846154%, Loss = 0.010255649470939087
Epoch: 1661, Batch Gradient Norm: 2.349335450232567
Epoch: 1661, Batch Gradient Norm after: 2.349335450232567
Epoch 1662/10000, Prediction Accuracy = 59.38461538461539%, Loss = 0.010167319399233047
Epoch: 1662, Batch Gradient Norm: 2.7291957736214223
Epoch: 1662, Batch Gradient Norm after: 2.7291957736214223
Epoch 1663/10000, Prediction Accuracy = 58.98076923076923%, Loss = 0.010399231543907752
Epoch: 1663, Batch Gradient Norm: 2.8390305290310174
Epoch: 1663, Batch Gradient Norm after: 2.8390305290310174
Epoch 1664/10000, Prediction Accuracy = 58.807692307692314%, Loss = 0.01043969844109737
Epoch: 1664, Batch Gradient Norm: 2.7337021249483873
Epoch: 1664, Batch Gradient Norm after: 2.7337021249483873
Epoch 1665/10000, Prediction Accuracy = 58.919230769230765%, Loss = 0.010325158731295513
Epoch: 1665, Batch Gradient Norm: 2.372526389810331
Epoch: 1665, Batch Gradient Norm after: 2.372526389810331
Epoch 1666/10000, Prediction Accuracy = 59.33461538461539%, Loss = 0.010140548531825725
Epoch: 1666, Batch Gradient Norm: 2.7311501387428225
Epoch: 1666, Batch Gradient Norm after: 2.7311501387428225
Epoch 1667/10000, Prediction Accuracy = 58.49999999999999%, Loss = 0.010387612220186453
Epoch: 1667, Batch Gradient Norm: 2.60953902174527
Epoch: 1667, Batch Gradient Norm after: 2.60953902174527
Epoch 1668/10000, Prediction Accuracy = 58.888461538461534%, Loss = 0.010346359573304653
Epoch: 1668, Batch Gradient Norm: 2.8612569874842726
Epoch: 1668, Batch Gradient Norm after: 2.8612569874842726
Epoch 1669/10000, Prediction Accuracy = 58.292307692307695%, Loss = 0.010561202079630815
Epoch: 1669, Batch Gradient Norm: 2.7398052322262387
Epoch: 1669, Batch Gradient Norm after: 2.7398052322262387
Epoch 1670/10000, Prediction Accuracy = 58.580769230769235%, Loss = 0.0103587695898918
Epoch: 1670, Batch Gradient Norm: 2.3726944887125168
Epoch: 1670, Batch Gradient Norm after: 2.3726944887125168
Epoch 1671/10000, Prediction Accuracy = 59.48461538461539%, Loss = 0.010092871836744823
Epoch: 1671, Batch Gradient Norm: 2.735733874626088
Epoch: 1671, Batch Gradient Norm after: 2.735733874626088
Epoch 1672/10000, Prediction Accuracy = 59.119230769230754%, Loss = 0.010301565393232383
Epoch: 1672, Batch Gradient Norm: 2.786654027604054
Epoch: 1672, Batch Gradient Norm after: 2.786654027604054
Epoch 1673/10000, Prediction Accuracy = 58.26153846153845%, Loss = 0.01042138713483627
Epoch: 1673, Batch Gradient Norm: 2.5090737593264594
Epoch: 1673, Batch Gradient Norm after: 2.5090737593264594
Epoch 1674/10000, Prediction Accuracy = 59.07692307692308%, Loss = 0.010225085613246147
Epoch: 1674, Batch Gradient Norm: 2.643597465601012
Epoch: 1674, Batch Gradient Norm after: 2.643597465601012
Epoch 1675/10000, Prediction Accuracy = 58.51923076923078%, Loss = 0.01031360445687404
Epoch: 1675, Batch Gradient Norm: 2.744780848643913
Epoch: 1675, Batch Gradient Norm after: 2.744780848643913
Epoch 1676/10000, Prediction Accuracy = 58.63076923076923%, Loss = 0.010352142370091034
Epoch: 1676, Batch Gradient Norm: 2.9158426854194053
Epoch: 1676, Batch Gradient Norm after: 2.9158426854194053
Epoch 1677/10000, Prediction Accuracy = 58.65384615384616%, Loss = 0.010485269487477265
Epoch: 1677, Batch Gradient Norm: 2.4122027412813662
Epoch: 1677, Batch Gradient Norm after: 2.4122027412813662
Epoch 1678/10000, Prediction Accuracy = 59.161538461538456%, Loss = 0.010131996196623031
Epoch: 1678, Batch Gradient Norm: 2.5354560180918133
Epoch: 1678, Batch Gradient Norm after: 2.5354560180918133
Epoch 1679/10000, Prediction Accuracy = 59.050000000000004%, Loss = 0.010205708730679292
Epoch: 1679, Batch Gradient Norm: 2.7459074492457045
Epoch: 1679, Batch Gradient Norm after: 2.7459074492457045
Epoch 1680/10000, Prediction Accuracy = 58.70384615384615%, Loss = 0.01033737388654397
Epoch: 1680, Batch Gradient Norm: 2.6504960571318805
Epoch: 1680, Batch Gradient Norm after: 2.6504960571318805
Epoch 1681/10000, Prediction Accuracy = 58.74615384615385%, Loss = 0.010317319717544775
Epoch: 1681, Batch Gradient Norm: 2.7365825423816905
Epoch: 1681, Batch Gradient Norm after: 2.7365825423816905
Epoch 1682/10000, Prediction Accuracy = 58.89615384615385%, Loss = 0.010281734311809907
Epoch: 1682, Batch Gradient Norm: 2.760648868647485
Epoch: 1682, Batch Gradient Norm after: 2.760648868647485
Epoch 1683/10000, Prediction Accuracy = 59.111538461538466%, Loss = 0.010277092815018617
Epoch: 1683, Batch Gradient Norm: 2.493282620291895
Epoch: 1683, Batch Gradient Norm after: 2.493282620291895
Epoch 1684/10000, Prediction Accuracy = 59.21153846153847%, Loss = 0.010166085969943266
Epoch: 1684, Batch Gradient Norm: 2.6367623410039487
Epoch: 1684, Batch Gradient Norm after: 2.6367623410039487
Epoch 1685/10000, Prediction Accuracy = 59.05769230769231%, Loss = 0.010251266451982351
Epoch: 1685, Batch Gradient Norm: 2.5064744562303365
Epoch: 1685, Batch Gradient Norm after: 2.5064744562303365
Epoch 1686/10000, Prediction Accuracy = 59.03846153846154%, Loss = 0.010197080456866668
Epoch: 1686, Batch Gradient Norm: 2.5477591165504214
Epoch: 1686, Batch Gradient Norm after: 2.5477591165504214
Epoch 1687/10000, Prediction Accuracy = 58.72692307692308%, Loss = 0.010239655438524026
Epoch: 1687, Batch Gradient Norm: 2.586498202450977
Epoch: 1687, Batch Gradient Norm after: 2.586498202450977
Epoch 1688/10000, Prediction Accuracy = 59.042307692307695%, Loss = 0.010178536319961915
Epoch: 1688, Batch Gradient Norm: 2.876768958133227
Epoch: 1688, Batch Gradient Norm after: 2.876768958133227
Epoch 1689/10000, Prediction Accuracy = 59.400000000000006%, Loss = 0.010256461082742764
Epoch: 1689, Batch Gradient Norm: 2.357659082107352
Epoch: 1689, Batch Gradient Norm after: 2.357659082107352
Epoch 1690/10000, Prediction Accuracy = 59.426923076923075%, Loss = 0.010059715535205144
Epoch: 1690, Batch Gradient Norm: 2.752851578272633
Epoch: 1690, Batch Gradient Norm after: 2.752851578272633
Epoch 1691/10000, Prediction Accuracy = 59.15384615384615%, Loss = 0.010227568017748686
Epoch: 1691, Batch Gradient Norm: 2.946756260424557
Epoch: 1691, Batch Gradient Norm after: 2.946756260424557
Epoch 1692/10000, Prediction Accuracy = 58.74615384615385%, Loss = 0.010370441640798863
Epoch: 1692, Batch Gradient Norm: 2.8448543845313
Epoch: 1692, Batch Gradient Norm after: 2.8448543845313
Epoch 1693/10000, Prediction Accuracy = 58.61153846153846%, Loss = 0.010371989140716882
Epoch: 1693, Batch Gradient Norm: 2.8234725546900767
Epoch: 1693, Batch Gradient Norm after: 2.8234725546900767
Epoch 1694/10000, Prediction Accuracy = 58.85384615384616%, Loss = 0.010356139463300888
Epoch: 1694, Batch Gradient Norm: 2.6284994597784292
Epoch: 1694, Batch Gradient Norm after: 2.6284994597784292
Epoch 1695/10000, Prediction Accuracy = 58.95769230769231%, Loss = 0.010256519039662985
Epoch: 1695, Batch Gradient Norm: 2.5415807490326983
Epoch: 1695, Batch Gradient Norm after: 2.5415807490326983
Epoch 1696/10000, Prediction Accuracy = 59.44230769230769%, Loss = 0.010155256192844648
Epoch: 1696, Batch Gradient Norm: 2.609099044919204
Epoch: 1696, Batch Gradient Norm after: 2.609099044919204
Epoch 1697/10000, Prediction Accuracy = 59.19615384615385%, Loss = 0.010212398420732755
Epoch: 1697, Batch Gradient Norm: 2.5952939666403396
Epoch: 1697, Batch Gradient Norm after: 2.5952939666403396
Epoch 1698/10000, Prediction Accuracy = 58.81923076923077%, Loss = 0.010169981620632686
Epoch: 1698, Batch Gradient Norm: 2.6585667832983546
Epoch: 1698, Batch Gradient Norm after: 2.6585667832983546
Epoch 1699/10000, Prediction Accuracy = 59.13076923076923%, Loss = 0.010197300750475664
Epoch: 1699, Batch Gradient Norm: 2.7208131313219663
Epoch: 1699, Batch Gradient Norm after: 2.7208131313219663
Epoch 1700/10000, Prediction Accuracy = 59.28846153846155%, Loss = 0.010205921143866502
Epoch: 1700, Batch Gradient Norm: 2.8271408702139045
Epoch: 1700, Batch Gradient Norm after: 2.8271408702139045
Epoch 1701/10000, Prediction Accuracy = 58.861538461538466%, Loss = 0.010321154402425656
Epoch: 1701, Batch Gradient Norm: 2.555270914001824
Epoch: 1701, Batch Gradient Norm after: 2.555270914001824
Epoch 1702/10000, Prediction Accuracy = 59.6423076923077%, Loss = 0.010145392627097093
Epoch: 1702, Batch Gradient Norm: 2.6796567591174214
Epoch: 1702, Batch Gradient Norm after: 2.6796567591174214
Epoch 1703/10000, Prediction Accuracy = 58.69615384615385%, Loss = 0.010231207268169293
Epoch: 1703, Batch Gradient Norm: 2.489497947843954
Epoch: 1703, Batch Gradient Norm after: 2.489497947843954
Epoch 1704/10000, Prediction Accuracy = 59.45384615384614%, Loss = 0.010040709247382788
Epoch: 1704, Batch Gradient Norm: 2.611346529612207
Epoch: 1704, Batch Gradient Norm after: 2.611346529612207
Epoch 1705/10000, Prediction Accuracy = 59.3%, Loss = 0.01013408164278819
Epoch: 1705, Batch Gradient Norm: 2.963294799776324
Epoch: 1705, Batch Gradient Norm after: 2.963294799776324
Epoch 1706/10000, Prediction Accuracy = 58.44615384615384%, Loss = 0.010305073398810167
Epoch: 1706, Batch Gradient Norm: 2.5558639292531327
Epoch: 1706, Batch Gradient Norm after: 2.5558639292531327
Epoch 1707/10000, Prediction Accuracy = 59.1923076923077%, Loss = 0.010131494715236701
Epoch: 1707, Batch Gradient Norm: 2.6457366778722653
Epoch: 1707, Batch Gradient Norm after: 2.6457366778722653
Epoch 1708/10000, Prediction Accuracy = 59.61923076923077%, Loss = 0.010120342557246868
Epoch: 1708, Batch Gradient Norm: 2.7898852896487085
Epoch: 1708, Batch Gradient Norm after: 2.7898852896487085
Epoch 1709/10000, Prediction Accuracy = 58.89615384615385%, Loss = 0.010293793076506028
Epoch: 1709, Batch Gradient Norm: 2.714787328715368
Epoch: 1709, Batch Gradient Norm after: 2.714787328715368
Epoch 1710/10000, Prediction Accuracy = 59.01153846153846%, Loss = 0.010301227036577005
Epoch: 1710, Batch Gradient Norm: 2.8698558619345294
Epoch: 1710, Batch Gradient Norm after: 2.8698558619345294
Epoch 1711/10000, Prediction Accuracy = 58.86538461538463%, Loss = 0.010247627058281349
Epoch: 1711, Batch Gradient Norm: 3.0557819145682537
Epoch: 1711, Batch Gradient Norm after: 3.0557819145682537
Epoch 1712/10000, Prediction Accuracy = 58.43846153846155%, Loss = 0.010475553715458283
Epoch: 1712, Batch Gradient Norm: 2.7902355395953546
Epoch: 1712, Batch Gradient Norm after: 2.7902355395953546
Epoch 1713/10000, Prediction Accuracy = 58.873076923076916%, Loss = 0.010313794375039063
Epoch: 1713, Batch Gradient Norm: 3.0418406895097427
Epoch: 1713, Batch Gradient Norm after: 3.0418406895097427
Epoch 1714/10000, Prediction Accuracy = 58.56153846153846%, Loss = 0.010430534728444539
Epoch: 1714, Batch Gradient Norm: 2.7529452234320173
Epoch: 1714, Batch Gradient Norm after: 2.7529452234320173
Epoch 1715/10000, Prediction Accuracy = 58.78846153846153%, Loss = 0.010313889799782863
Epoch: 1715, Batch Gradient Norm: 2.499977688073206
Epoch: 1715, Batch Gradient Norm after: 2.499977688073206
Epoch 1716/10000, Prediction Accuracy = 59.31538461538461%, Loss = 0.010070882665996369
Epoch: 1716, Batch Gradient Norm: 2.9380088270258207
Epoch: 1716, Batch Gradient Norm after: 2.9380088270258207
Epoch 1717/10000, Prediction Accuracy = 58.830769230769235%, Loss = 0.010250321732690701
Epoch: 1717, Batch Gradient Norm: 3.090015347886263
Epoch: 1717, Batch Gradient Norm after: 3.090015347886263
Epoch 1718/10000, Prediction Accuracy = 58.5923076923077%, Loss = 0.010509907196347531
Epoch: 1718, Batch Gradient Norm: 2.506890052637165
Epoch: 1718, Batch Gradient Norm after: 2.506890052637165
Epoch 1719/10000, Prediction Accuracy = 59.54999999999999%, Loss = 0.010107941853885468
Epoch: 1719, Batch Gradient Norm: 2.4009318138199536
Epoch: 1719, Batch Gradient Norm after: 2.4009318138199536
Epoch 1720/10000, Prediction Accuracy = 59.43846153846154%, Loss = 0.010019270989757318
Epoch: 1720, Batch Gradient Norm: 2.548935659672908
Epoch: 1720, Batch Gradient Norm after: 2.548935659672908
Epoch 1721/10000, Prediction Accuracy = 59.31153846153846%, Loss = 0.010098120484214563
Epoch: 1721, Batch Gradient Norm: 2.3532684204652443
Epoch: 1721, Batch Gradient Norm after: 2.3532684204652443
Epoch 1722/10000, Prediction Accuracy = 59.46923076923076%, Loss = 0.009976612332348641
Epoch: 1722, Batch Gradient Norm: 2.7697039367661356
Epoch: 1722, Batch Gradient Norm after: 2.7697039367661356
Epoch 1723/10000, Prediction Accuracy = 58.88076923076923%, Loss = 0.010181403289047571
Epoch: 1723, Batch Gradient Norm: 2.8446569761528453
Epoch: 1723, Batch Gradient Norm after: 2.8446569761528453
Epoch 1724/10000, Prediction Accuracy = 59.05384615384616%, Loss = 0.010301899093274888
Epoch: 1724, Batch Gradient Norm: 2.982974551225592
Epoch: 1724, Batch Gradient Norm after: 2.982974551225592
Epoch 1725/10000, Prediction Accuracy = 59.22692307692308%, Loss = 0.01036575952401528
Epoch: 1725, Batch Gradient Norm: 2.985213202207298
Epoch: 1725, Batch Gradient Norm after: 2.985213202207298
Epoch 1726/10000, Prediction Accuracy = 58.673076923076934%, Loss = 0.01035891709705958
Epoch: 1726, Batch Gradient Norm: 2.5755101014655315
Epoch: 1726, Batch Gradient Norm after: 2.5755101014655315
Epoch 1727/10000, Prediction Accuracy = 59.24230769230769%, Loss = 0.010152792414793601
Epoch: 1727, Batch Gradient Norm: 2.5495793015845947
Epoch: 1727, Batch Gradient Norm after: 2.5495793015845947
Epoch 1728/10000, Prediction Accuracy = 59.45769230769231%, Loss = 0.010091661332318416
Epoch: 1728, Batch Gradient Norm: 2.478276295131367
Epoch: 1728, Batch Gradient Norm after: 2.478276295131367
Epoch 1729/10000, Prediction Accuracy = 59.56538461538462%, Loss = 0.010018538397092085
Epoch: 1729, Batch Gradient Norm: 2.618470039319533
Epoch: 1729, Batch Gradient Norm after: 2.618470039319533
Epoch 1730/10000, Prediction Accuracy = 59.46923076923077%, Loss = 0.010098044545604633
Epoch: 1730, Batch Gradient Norm: 2.5668963694439246
Epoch: 1730, Batch Gradient Norm after: 2.5668963694439246
Epoch 1731/10000, Prediction Accuracy = 59.52307692307693%, Loss = 0.010050284246412607
Epoch: 1731, Batch Gradient Norm: 2.515872567259946
Epoch: 1731, Batch Gradient Norm after: 2.515872567259946
Epoch 1732/10000, Prediction Accuracy = 59.54230769230768%, Loss = 0.009988501453055786
Epoch: 1732, Batch Gradient Norm: 2.80237252829028
Epoch: 1732, Batch Gradient Norm after: 2.80237252829028
Epoch 1733/10000, Prediction Accuracy = 59.44230769230769%, Loss = 0.010170605320196886
Epoch: 1733, Batch Gradient Norm: 2.60737990926411
Epoch: 1733, Batch Gradient Norm after: 2.60737990926411
Epoch 1734/10000, Prediction Accuracy = 59.27307692307693%, Loss = 0.0100858614135247
Epoch: 1734, Batch Gradient Norm: 2.9781021920775506
Epoch: 1734, Batch Gradient Norm after: 2.9781021920775506
Epoch 1735/10000, Prediction Accuracy = 58.99230769230769%, Loss = 0.010252480466778461
Epoch: 1735, Batch Gradient Norm: 2.832416179763894
Epoch: 1735, Batch Gradient Norm after: 2.832416179763894
Epoch 1736/10000, Prediction Accuracy = 58.76153846153848%, Loss = 0.010216535498889593
Epoch: 1736, Batch Gradient Norm: 2.8484951190725707
Epoch: 1736, Batch Gradient Norm after: 2.8484951190725707
Epoch 1737/10000, Prediction Accuracy = 58.826923076923066%, Loss = 0.010314896702766418
Epoch: 1737, Batch Gradient Norm: 2.4545283770290585
Epoch: 1737, Batch Gradient Norm after: 2.4545283770290585
Epoch 1738/10000, Prediction Accuracy = 59.78846153846154%, Loss = 0.009975864551961422
Epoch: 1738, Batch Gradient Norm: 2.7059628654327654
Epoch: 1738, Batch Gradient Norm after: 2.7059628654327654
Epoch 1739/10000, Prediction Accuracy = 59.3576923076923%, Loss = 0.010107771135293521
Epoch: 1739, Batch Gradient Norm: 2.663832527100044
Epoch: 1739, Batch Gradient Norm after: 2.663832527100044
Epoch 1740/10000, Prediction Accuracy = 59.49615384615384%, Loss = 0.010022850492252754
Epoch: 1740, Batch Gradient Norm: 2.900137173714208
Epoch: 1740, Batch Gradient Norm after: 2.900137173714208
Epoch 1741/10000, Prediction Accuracy = 59.06923076923078%, Loss = 0.010226555813390475
Epoch: 1741, Batch Gradient Norm: 2.803945718548949
Epoch: 1741, Batch Gradient Norm after: 2.803945718548949
Epoch 1742/10000, Prediction Accuracy = 59.18076923076923%, Loss = 0.010167466261639046
Epoch: 1742, Batch Gradient Norm: 2.8112061037441083
Epoch: 1742, Batch Gradient Norm after: 2.8112061037441083
Epoch 1743/10000, Prediction Accuracy = 59.026923076923076%, Loss = 0.010215474865757503
Epoch: 1743, Batch Gradient Norm: 2.7606334718763597
Epoch: 1743, Batch Gradient Norm after: 2.7606334718763597
Epoch 1744/10000, Prediction Accuracy = 59.23461538461538%, Loss = 0.010194330691145016
Epoch: 1744, Batch Gradient Norm: 2.5299417687632633
Epoch: 1744, Batch Gradient Norm after: 2.5299417687632633
Epoch 1745/10000, Prediction Accuracy = 59.47692307692308%, Loss = 0.010041358952338878
Epoch: 1745, Batch Gradient Norm: 2.5245224212061705
Epoch: 1745, Batch Gradient Norm after: 2.5245224212061705
Epoch 1746/10000, Prediction Accuracy = 59.56538461538461%, Loss = 0.010034122146092929
Epoch: 1746, Batch Gradient Norm: 2.629240540220265
Epoch: 1746, Batch Gradient Norm after: 2.629240540220265
Epoch 1747/10000, Prediction Accuracy = 59.592307692307685%, Loss = 0.010040701366961002
Epoch: 1747, Batch Gradient Norm: 2.8511443222342674
Epoch: 1747, Batch Gradient Norm after: 2.8511443222342674
Epoch 1748/10000, Prediction Accuracy = 59.04230769230769%, Loss = 0.010169562238913316
Epoch: 1748, Batch Gradient Norm: 2.682061570268454
Epoch: 1748, Batch Gradient Norm after: 2.682061570268454
Epoch 1749/10000, Prediction Accuracy = 59.58846153846154%, Loss = 0.010061767525397815
Epoch: 1749, Batch Gradient Norm: 2.566950163824096
Epoch: 1749, Batch Gradient Norm after: 2.566950163824096
Epoch 1750/10000, Prediction Accuracy = 59.415384615384625%, Loss = 0.010043313368581809
Epoch: 1750, Batch Gradient Norm: 2.8263336259460585
Epoch: 1750, Batch Gradient Norm after: 2.8263336259460585
Epoch 1751/10000, Prediction Accuracy = 59.349999999999994%, Loss = 0.01008879801688286
Epoch: 1751, Batch Gradient Norm: 2.7732458789301533
Epoch: 1751, Batch Gradient Norm after: 2.7732458789301533
Epoch 1752/10000, Prediction Accuracy = 59.55384615384615%, Loss = 0.010110038619201917
Epoch: 1752, Batch Gradient Norm: 2.8864698951268273
Epoch: 1752, Batch Gradient Norm after: 2.8864698951268273
Epoch 1753/10000, Prediction Accuracy = 59.13846153846154%, Loss = 0.010126034872463116
Epoch: 1753, Batch Gradient Norm: 2.484643404472764
Epoch: 1753, Batch Gradient Norm after: 2.484643404472764
Epoch 1754/10000, Prediction Accuracy = 59.62307692307691%, Loss = 0.009902705151874285
Epoch: 1754, Batch Gradient Norm: 2.5801194611622438
Epoch: 1754, Batch Gradient Norm after: 2.5801194611622438
Epoch 1755/10000, Prediction Accuracy = 59.53846153846155%, Loss = 0.00993935434290996
Epoch: 1755, Batch Gradient Norm: 2.600284368810147
Epoch: 1755, Batch Gradient Norm after: 2.600284368810147
Epoch 1756/10000, Prediction Accuracy = 59.5%, Loss = 0.00998174399137497
Epoch: 1756, Batch Gradient Norm: 2.540665787663475
Epoch: 1756, Batch Gradient Norm after: 2.540665787663475
Epoch 1757/10000, Prediction Accuracy = 59.97307692307693%, Loss = 0.009954768519562025
Epoch: 1757, Batch Gradient Norm: 2.6760404910153364
Epoch: 1757, Batch Gradient Norm after: 2.6760404910153364
Epoch 1758/10000, Prediction Accuracy = 59.56153846153845%, Loss = 0.00999138905451848
Epoch: 1758, Batch Gradient Norm: 2.916577985783904
Epoch: 1758, Batch Gradient Norm after: 2.916577985783904
Epoch 1759/10000, Prediction Accuracy = 59.09615384615385%, Loss = 0.01023892442194315
Epoch: 1759, Batch Gradient Norm: 2.8700048434878394
Epoch: 1759, Batch Gradient Norm after: 2.8700048434878394
Epoch 1760/10000, Prediction Accuracy = 59.3423076923077%, Loss = 0.01009989522684079
Epoch: 1760, Batch Gradient Norm: 2.709620497143804
Epoch: 1760, Batch Gradient Norm after: 2.709620497143804
Epoch 1761/10000, Prediction Accuracy = 59.2%, Loss = 0.010079251459011665
Epoch: 1761, Batch Gradient Norm: 2.9771689998327546
Epoch: 1761, Batch Gradient Norm after: 2.9771689998327546
Epoch 1762/10000, Prediction Accuracy = 59.165384615384625%, Loss = 0.010203785191361722
Epoch: 1762, Batch Gradient Norm: 2.736257693595594
Epoch: 1762, Batch Gradient Norm after: 2.736257693595594
Epoch 1763/10000, Prediction Accuracy = 59.330769230769235%, Loss = 0.010116865715155235
Epoch: 1763, Batch Gradient Norm: 2.7012401698321824
Epoch: 1763, Batch Gradient Norm after: 2.7012401698321824
Epoch 1764/10000, Prediction Accuracy = 59.19230769230769%, Loss = 0.010101917414711071
Epoch: 1764, Batch Gradient Norm: 2.8527630950984775
Epoch: 1764, Batch Gradient Norm after: 2.8527630950984775
Epoch 1765/10000, Prediction Accuracy = 59.5%, Loss = 0.010106233378442435
Epoch: 1765, Batch Gradient Norm: 2.8693597977223293
Epoch: 1765, Batch Gradient Norm after: 2.8693597977223293
Epoch 1766/10000, Prediction Accuracy = 59.64230769230768%, Loss = 0.010104973513919573
Epoch: 1766, Batch Gradient Norm: 2.7979498759178445
Epoch: 1766, Batch Gradient Norm after: 2.7979498759178445
Epoch 1767/10000, Prediction Accuracy = 59.603846153846156%, Loss = 0.01014050511786571
Epoch: 1767, Batch Gradient Norm: 2.6512281886143114
Epoch: 1767, Batch Gradient Norm after: 2.6512281886143114
Epoch 1768/10000, Prediction Accuracy = 59.59615384615385%, Loss = 0.009985034425671283
Epoch: 1768, Batch Gradient Norm: 2.9759817855429254
Epoch: 1768, Batch Gradient Norm after: 2.9759817855429254
Epoch 1769/10000, Prediction Accuracy = 59.28846153846154%, Loss = 0.010165815384915242
Epoch: 1769, Batch Gradient Norm: 2.6882972064479773
Epoch: 1769, Batch Gradient Norm after: 2.6882972064479773
Epoch 1770/10000, Prediction Accuracy = 59.18846153846153%, Loss = 0.010090668112612687
Epoch: 1770, Batch Gradient Norm: 2.601063485324343
Epoch: 1770, Batch Gradient Norm after: 2.601063485324343
Epoch 1771/10000, Prediction Accuracy = 59.657692307692294%, Loss = 0.00997571969548097
Epoch: 1771, Batch Gradient Norm: 2.8231052375015215
Epoch: 1771, Batch Gradient Norm after: 2.8231052375015215
Epoch 1772/10000, Prediction Accuracy = 59.31153846153847%, Loss = 0.010180523690695945
Epoch: 1772, Batch Gradient Norm: 2.745968294933416
Epoch: 1772, Batch Gradient Norm after: 2.745968294933416
Epoch 1773/10000, Prediction Accuracy = 59.31923076923078%, Loss = 0.010106909088790417
Epoch: 1773, Batch Gradient Norm: 2.6427966644477823
Epoch: 1773, Batch Gradient Norm after: 2.6427966644477823
Epoch 1774/10000, Prediction Accuracy = 59.46153846153845%, Loss = 0.009954350355726022
Epoch: 1774, Batch Gradient Norm: 2.707190709827168
Epoch: 1774, Batch Gradient Norm after: 2.707190709827168
Epoch 1775/10000, Prediction Accuracy = 59.376923076923084%, Loss = 0.01001709563514361
Epoch: 1775, Batch Gradient Norm: 2.632516312736373
Epoch: 1775, Batch Gradient Norm after: 2.632516312736373
Epoch 1776/10000, Prediction Accuracy = 59.58076923076923%, Loss = 0.009934232212029971
Epoch: 1776, Batch Gradient Norm: 2.88507754895338
Epoch: 1776, Batch Gradient Norm after: 2.88507754895338
Epoch 1777/10000, Prediction Accuracy = 59.32692307692309%, Loss = 0.01010449044406414
Epoch: 1777, Batch Gradient Norm: 2.6316504036557546
Epoch: 1777, Batch Gradient Norm after: 2.6316504036557546
Epoch 1778/10000, Prediction Accuracy = 59.70384615384616%, Loss = 0.009907781433027524
Epoch: 1778, Batch Gradient Norm: 2.6455825039545613
Epoch: 1778, Batch Gradient Norm after: 2.6455825039545613
Epoch 1779/10000, Prediction Accuracy = 59.64615384615385%, Loss = 0.009901663575034875
Epoch: 1779, Batch Gradient Norm: 2.593293646466334
Epoch: 1779, Batch Gradient Norm after: 2.593293646466334
Epoch 1780/10000, Prediction Accuracy = 59.76923076923078%, Loss = 0.009915345276777562
Epoch: 1780, Batch Gradient Norm: 2.476588089227011
Epoch: 1780, Batch Gradient Norm after: 2.476588089227011
Epoch 1781/10000, Prediction Accuracy = 59.98846153846154%, Loss = 0.009872209352369491
Epoch: 1781, Batch Gradient Norm: 2.912808541228387
Epoch: 1781, Batch Gradient Norm after: 2.912808541228387
Epoch 1782/10000, Prediction Accuracy = 58.98846153846154%, Loss = 0.01005803750684628
Epoch: 1782, Batch Gradient Norm: 3.216251224678071
Epoch: 1782, Batch Gradient Norm after: 3.216251224678071
Epoch 1783/10000, Prediction Accuracy = 58.92307692307692%, Loss = 0.010218726112865485
Epoch: 1783, Batch Gradient Norm: 3.099210172642951
Epoch: 1783, Batch Gradient Norm after: 3.099210172642951
Epoch 1784/10000, Prediction Accuracy = 58.91923076923077%, Loss = 0.010237363238747303
Epoch: 1784, Batch Gradient Norm: 2.8254301850292545
Epoch: 1784, Batch Gradient Norm after: 2.8254301850292545
Epoch 1785/10000, Prediction Accuracy = 59.42692307692308%, Loss = 0.010062706800034413
Epoch: 1785, Batch Gradient Norm: 2.819562647806343
Epoch: 1785, Batch Gradient Norm after: 2.819562647806343
Epoch 1786/10000, Prediction Accuracy = 59.20384615384616%, Loss = 0.010094361164822029
Epoch: 1786, Batch Gradient Norm: 2.721082147583766
Epoch: 1786, Batch Gradient Norm after: 2.721082147583766
Epoch 1787/10000, Prediction Accuracy = 59.75769230769232%, Loss = 0.009941204451024532
Epoch: 1787, Batch Gradient Norm: 2.6898359556363927
Epoch: 1787, Batch Gradient Norm after: 2.6898359556363927
Epoch 1788/10000, Prediction Accuracy = 59.98846153846153%, Loss = 0.009845044965354295
Epoch: 1788, Batch Gradient Norm: 2.62010900890292
Epoch: 1788, Batch Gradient Norm after: 2.62010900890292
Epoch 1789/10000, Prediction Accuracy = 59.819230769230785%, Loss = 0.009947724855290009
Epoch: 1789, Batch Gradient Norm: 2.668332050323003
Epoch: 1789, Batch Gradient Norm after: 2.668332050323003
Epoch 1790/10000, Prediction Accuracy = 59.380769230769225%, Loss = 0.010000760165544657
Epoch: 1790, Batch Gradient Norm: 2.8197652636646815
Epoch: 1790, Batch Gradient Norm after: 2.8197652636646815
Epoch 1791/10000, Prediction Accuracy = 59.473076923076924%, Loss = 0.010045208681661349
Epoch: 1791, Batch Gradient Norm: 3.066040053453698
Epoch: 1791, Batch Gradient Norm after: 3.066040053453698
Epoch 1792/10000, Prediction Accuracy = 59.23461538461539%, Loss = 0.010144812054932117
Epoch: 1792, Batch Gradient Norm: 2.89755749577809
Epoch: 1792, Batch Gradient Norm after: 2.89755749577809
Epoch 1793/10000, Prediction Accuracy = 59.43076923076924%, Loss = 0.0100672089566405
Epoch: 1793, Batch Gradient Norm: 2.8894021303695534
Epoch: 1793, Batch Gradient Norm after: 2.8894021303695534
Epoch 1794/10000, Prediction Accuracy = 59.32692307692308%, Loss = 0.010056949793719329
Epoch: 1794, Batch Gradient Norm: 3.0545445157397024
Epoch: 1794, Batch Gradient Norm after: 3.0545445157397024
Epoch 1795/10000, Prediction Accuracy = 59.07692307692308%, Loss = 0.01023124036594079
Epoch: 1795, Batch Gradient Norm: 2.843203783633372
Epoch: 1795, Batch Gradient Norm after: 2.843203783633372
Epoch 1796/10000, Prediction Accuracy = 59.13461538461537%, Loss = 0.010096772215687312
Epoch: 1796, Batch Gradient Norm: 2.729448199774724
Epoch: 1796, Batch Gradient Norm after: 2.729448199774724
Epoch 1797/10000, Prediction Accuracy = 59.603846153846156%, Loss = 0.009995535302620668
Epoch: 1797, Batch Gradient Norm: 2.607152292833114
Epoch: 1797, Batch Gradient Norm after: 2.607152292833114
Epoch 1798/10000, Prediction Accuracy = 59.66538461538461%, Loss = 0.009944238628332432
Epoch: 1798, Batch Gradient Norm: 2.699027036182578
Epoch: 1798, Batch Gradient Norm after: 2.699027036182578
Epoch 1799/10000, Prediction Accuracy = 59.98461538461538%, Loss = 0.009929206938697742
Epoch: 1799, Batch Gradient Norm: 2.8703314681571306
Epoch: 1799, Batch Gradient Norm after: 2.8703314681571306
Epoch 1800/10000, Prediction Accuracy = 59.25769230769231%, Loss = 0.010090205102012707
Epoch: 1800, Batch Gradient Norm: 2.816902823173078
Epoch: 1800, Batch Gradient Norm after: 2.816902823173078
Epoch 1801/10000, Prediction Accuracy = 59.31153846153846%, Loss = 0.010148888597121606
Epoch: 1801, Batch Gradient Norm: 2.668309171209004
Epoch: 1801, Batch Gradient Norm after: 2.668309171209004
Epoch 1802/10000, Prediction Accuracy = 59.39230769230768%, Loss = 0.010028396016703202
Epoch: 1802, Batch Gradient Norm: 2.604313846089303
Epoch: 1802, Batch Gradient Norm after: 2.604313846089303
Epoch 1803/10000, Prediction Accuracy = 59.83076923076923%, Loss = 0.009897695209544439
Epoch: 1803, Batch Gradient Norm: 2.5240304193001726
Epoch: 1803, Batch Gradient Norm after: 2.5240304193001726
Epoch 1804/10000, Prediction Accuracy = 59.80384615384615%, Loss = 0.009810052167337675
Epoch: 1804, Batch Gradient Norm: 2.6063479642947573
Epoch: 1804, Batch Gradient Norm after: 2.6063479642947573
Epoch 1805/10000, Prediction Accuracy = 59.78461538461538%, Loss = 0.009856497582334738
Epoch: 1805, Batch Gradient Norm: 2.6561188353251577
Epoch: 1805, Batch Gradient Norm after: 2.6561188353251577
Epoch 1806/10000, Prediction Accuracy = 59.776923076923076%, Loss = 0.00988101507895268
Epoch: 1806, Batch Gradient Norm: 2.767319743530928
Epoch: 1806, Batch Gradient Norm after: 2.767319743530928
Epoch 1807/10000, Prediction Accuracy = 59.53846153846154%, Loss = 0.009875979417791734
Epoch: 1807, Batch Gradient Norm: 2.784425027321057
Epoch: 1807, Batch Gradient Norm after: 2.784425027321057
Epoch 1808/10000, Prediction Accuracy = 59.55384615384616%, Loss = 0.010010566992255358
Epoch: 1808, Batch Gradient Norm: 2.7103259698597815
Epoch: 1808, Batch Gradient Norm after: 2.7103259698597815
Epoch 1809/10000, Prediction Accuracy = 59.684615384615384%, Loss = 0.009943574308775939
Epoch: 1809, Batch Gradient Norm: 2.59162885737862
Epoch: 1809, Batch Gradient Norm after: 2.59162885737862
Epoch 1810/10000, Prediction Accuracy = 59.876923076923084%, Loss = 0.00984832515510229
Epoch: 1810, Batch Gradient Norm: 2.5232776107030213
Epoch: 1810, Batch Gradient Norm after: 2.5232776107030213
Epoch 1811/10000, Prediction Accuracy = 60.43846153846153%, Loss = 0.00978645897255494
Epoch: 1811, Batch Gradient Norm: 2.6258178194932285
Epoch: 1811, Batch Gradient Norm after: 2.6258178194932285
Epoch 1812/10000, Prediction Accuracy = 59.49615384615384%, Loss = 0.00989077935138574
Epoch: 1812, Batch Gradient Norm: 2.539519121491823
Epoch: 1812, Batch Gradient Norm after: 2.539519121491823
Epoch 1813/10000, Prediction Accuracy = 60.21923076923076%, Loss = 0.009757666060557732
Epoch: 1813, Batch Gradient Norm: 2.7596654603528843
Epoch: 1813, Batch Gradient Norm after: 2.7596654603528843
Epoch 1814/10000, Prediction Accuracy = 59.76538461538462%, Loss = 0.009890349295276862
Epoch: 1814, Batch Gradient Norm: 2.896337951242477
Epoch: 1814, Batch Gradient Norm after: 2.896337951242477
Epoch 1815/10000, Prediction Accuracy = 59.699999999999996%, Loss = 0.00994647595171745
Epoch: 1815, Batch Gradient Norm: 3.0628686938761223
Epoch: 1815, Batch Gradient Norm after: 3.0628686938761223
Epoch 1816/10000, Prediction Accuracy = 59.484615384615374%, Loss = 0.010038201697170734
Epoch: 1816, Batch Gradient Norm: 2.9256470253284146
Epoch: 1816, Batch Gradient Norm after: 2.9256470253284146
Epoch 1817/10000, Prediction Accuracy = 59.56538461538462%, Loss = 0.01010705423183166
Epoch: 1817, Batch Gradient Norm: 3.0016596963847864
Epoch: 1817, Batch Gradient Norm after: 3.0016596963847864
Epoch 1818/10000, Prediction Accuracy = 59.52692307692307%, Loss = 0.010110882469094716
Epoch: 1818, Batch Gradient Norm: 3.0087061635667016
Epoch: 1818, Batch Gradient Norm after: 3.0087061635667016
Epoch 1819/10000, Prediction Accuracy = 59.36538461538463%, Loss = 0.010102878611248273
Epoch: 1819, Batch Gradient Norm: 2.8757500613020084
Epoch: 1819, Batch Gradient Norm after: 2.8757500613020084
Epoch 1820/10000, Prediction Accuracy = 59.72692307692308%, Loss = 0.009962771661006488
Epoch: 1820, Batch Gradient Norm: 2.6550189632224614
Epoch: 1820, Batch Gradient Norm after: 2.6550189632224614
Epoch 1821/10000, Prediction Accuracy = 60.01923076923077%, Loss = 0.009857518383516716
Epoch: 1821, Batch Gradient Norm: 2.853768028951701
Epoch: 1821, Batch Gradient Norm after: 2.853768028951701
Epoch 1822/10000, Prediction Accuracy = 59.69615384615386%, Loss = 0.010000569745898247
Epoch: 1822, Batch Gradient Norm: 2.8551656876368923
Epoch: 1822, Batch Gradient Norm after: 2.8551656876368923
Epoch 1823/10000, Prediction Accuracy = 59.31923076923077%, Loss = 0.010046682678736173
Epoch: 1823, Batch Gradient Norm: 2.950138045813637
Epoch: 1823, Batch Gradient Norm after: 2.950138045813637
Epoch 1824/10000, Prediction Accuracy = 59.99999999999999%, Loss = 0.010004837710696917
Epoch: 1824, Batch Gradient Norm: 2.849422808310091
Epoch: 1824, Batch Gradient Norm after: 2.849422808310091
Epoch 1825/10000, Prediction Accuracy = 59.3923076923077%, Loss = 0.009958327604601016
Epoch: 1825, Batch Gradient Norm: 2.973045551530636
Epoch: 1825, Batch Gradient Norm after: 2.973045551530636
Epoch 1826/10000, Prediction Accuracy = 59.41923076923076%, Loss = 0.010026462304477509
Epoch: 1826, Batch Gradient Norm: 2.9772450139679196
Epoch: 1826, Batch Gradient Norm after: 2.9772450139679196
Epoch 1827/10000, Prediction Accuracy = 59.26153846153847%, Loss = 0.01006196797467195
Epoch: 1827, Batch Gradient Norm: 2.8173305796956853
Epoch: 1827, Batch Gradient Norm after: 2.8173305796956853
Epoch 1828/10000, Prediction Accuracy = 59.800000000000004%, Loss = 0.010055880778684067
Epoch: 1828, Batch Gradient Norm: 2.883680333412383
Epoch: 1828, Batch Gradient Norm after: 2.883680333412383
Epoch 1829/10000, Prediction Accuracy = 59.49230769230768%, Loss = 0.009976467619148584
Epoch: 1829, Batch Gradient Norm: 3.019991202224634
Epoch: 1829, Batch Gradient Norm after: 3.019991202224634
Epoch 1830/10000, Prediction Accuracy = 59.24230769230769%, Loss = 0.010061055135268431
Epoch: 1830, Batch Gradient Norm: 2.8008654619585105
Epoch: 1830, Batch Gradient Norm after: 2.8008654619585105
Epoch 1831/10000, Prediction Accuracy = 59.800000000000004%, Loss = 0.009996890376966733
Epoch: 1831, Batch Gradient Norm: 3.1118947644956347
Epoch: 1831, Batch Gradient Norm after: 3.1118947644956347
Epoch 1832/10000, Prediction Accuracy = 59.58076923076923%, Loss = 0.01010063741929256
Epoch: 1832, Batch Gradient Norm: 2.628350217558571
Epoch: 1832, Batch Gradient Norm after: 2.628350217558571
Epoch 1833/10000, Prediction Accuracy = 60.45%, Loss = 0.009723928327170702
Epoch: 1833, Batch Gradient Norm: 2.74211108943811
Epoch: 1833, Batch Gradient Norm after: 2.74211108943811
Epoch 1834/10000, Prediction Accuracy = 59.8%, Loss = 0.009789910883857654
Epoch: 1834, Batch Gradient Norm: 2.5888257347920844
Epoch: 1834, Batch Gradient Norm after: 2.5888257347920844
Epoch 1835/10000, Prediction Accuracy = 60.14230769230768%, Loss = 0.009772518506416908
Epoch: 1835, Batch Gradient Norm: 2.6808162560335247
Epoch: 1835, Batch Gradient Norm after: 2.6808162560335247
Epoch 1836/10000, Prediction Accuracy = 59.96923076923077%, Loss = 0.009779504930170683
Epoch: 1836, Batch Gradient Norm: 2.812166990527276
Epoch: 1836, Batch Gradient Norm after: 2.812166990527276
Epoch 1837/10000, Prediction Accuracy = 59.55384615384615%, Loss = 0.009910146992367048
Epoch: 1837, Batch Gradient Norm: 2.9955788656263933
Epoch: 1837, Batch Gradient Norm after: 2.9955788656263933
Epoch 1838/10000, Prediction Accuracy = 59.48461538461539%, Loss = 0.009972074140722934
Epoch: 1838, Batch Gradient Norm: 2.8671807828087674
Epoch: 1838, Batch Gradient Norm after: 2.8671807828087674
Epoch 1839/10000, Prediction Accuracy = 59.01153846153846%, Loss = 0.010039191478146957
Epoch: 1839, Batch Gradient Norm: 2.546122243159237
Epoch: 1839, Batch Gradient Norm after: 2.546122243159237
Epoch 1840/10000, Prediction Accuracy = 60.5076923076923%, Loss = 0.009766731984340228
Epoch: 1840, Batch Gradient Norm: 2.9589920909005354
Epoch: 1840, Batch Gradient Norm after: 2.9589920909005354
Epoch 1841/10000, Prediction Accuracy = 59.673076923076934%, Loss = 0.009902526266299762
Epoch: 1841, Batch Gradient Norm: 3.1952947033239445
Epoch: 1841, Batch Gradient Norm after: 3.1952947033239445
Epoch 1842/10000, Prediction Accuracy = 59.21153846153845%, Loss = 0.010026911488519264
Epoch: 1842, Batch Gradient Norm: 2.864461063124064
Epoch: 1842, Batch Gradient Norm after: 2.864461063124064
Epoch 1843/10000, Prediction Accuracy = 59.142307692307696%, Loss = 0.00997157172801403
Epoch: 1843, Batch Gradient Norm: 2.747150310021002
Epoch: 1843, Batch Gradient Norm after: 2.747150310021002
Epoch 1844/10000, Prediction Accuracy = 59.72307692307693%, Loss = 0.009872292383359028
Epoch: 1844, Batch Gradient Norm: 2.6908671121597867
Epoch: 1844, Batch Gradient Norm after: 2.6908671121597867
Epoch 1845/10000, Prediction Accuracy = 59.74615384615385%, Loss = 0.009804804952671895
Epoch: 1845, Batch Gradient Norm: 2.8371430301058687
Epoch: 1845, Batch Gradient Norm after: 2.8371430301058687
Epoch 1846/10000, Prediction Accuracy = 59.98846153846154%, Loss = 0.009828301648107858
Epoch: 1846, Batch Gradient Norm: 2.74451147940015
Epoch: 1846, Batch Gradient Norm after: 2.74451147940015
Epoch 1847/10000, Prediction Accuracy = 60.0846153846154%, Loss = 0.009818864914660271
Epoch: 1847, Batch Gradient Norm: 2.8127992093653496
Epoch: 1847, Batch Gradient Norm after: 2.8127992093653496
Epoch 1848/10000, Prediction Accuracy = 59.630769230769225%, Loss = 0.00979907144434177
Epoch: 1848, Batch Gradient Norm: 2.9612974889561134
Epoch: 1848, Batch Gradient Norm after: 2.9612974889561134
Epoch 1849/10000, Prediction Accuracy = 59.78846153846155%, Loss = 0.009877090628903646
Epoch: 1849, Batch Gradient Norm: 2.781817949865578
Epoch: 1849, Batch Gradient Norm after: 2.781817949865578
Epoch 1850/10000, Prediction Accuracy = 59.91538461538461%, Loss = 0.009809864756579582
Epoch: 1850, Batch Gradient Norm: 2.658313806117075
Epoch: 1850, Batch Gradient Norm after: 2.658313806117075
Epoch 1851/10000, Prediction Accuracy = 60.20769230769232%, Loss = 0.009710397428044906
Epoch: 1851, Batch Gradient Norm: 2.9980857269891796
Epoch: 1851, Batch Gradient Norm after: 2.9980857269891796
Epoch 1852/10000, Prediction Accuracy = 59.56153846153847%, Loss = 0.009918047616688104
Epoch: 1852, Batch Gradient Norm: 2.817163528568935
Epoch: 1852, Batch Gradient Norm after: 2.817163528568935
Epoch 1853/10000, Prediction Accuracy = 59.51538461538462%, Loss = 0.009878397990877811
Epoch: 1853, Batch Gradient Norm: 2.763999477608681
Epoch: 1853, Batch Gradient Norm after: 2.763999477608681
Epoch 1854/10000, Prediction Accuracy = 60.05%, Loss = 0.00980452154404842
Epoch: 1854, Batch Gradient Norm: 2.5548799094319787
Epoch: 1854, Batch Gradient Norm after: 2.5548799094319787
Epoch 1855/10000, Prediction Accuracy = 60.223076923076924%, Loss = 0.009627393948344084
Epoch: 1855, Batch Gradient Norm: 2.913540043983033
Epoch: 1855, Batch Gradient Norm after: 2.913540043983033
Epoch 1856/10000, Prediction Accuracy = 60.04230769230769%, Loss = 0.009830950974271847
Epoch: 1856, Batch Gradient Norm: 2.553919694879406
Epoch: 1856, Batch Gradient Norm after: 2.553919694879406
Epoch 1857/10000, Prediction Accuracy = 60.596153846153854%, Loss = 0.009634986519813538
Epoch: 1857, Batch Gradient Norm: 2.920296453283494
Epoch: 1857, Batch Gradient Norm after: 2.920296453283494
Epoch 1858/10000, Prediction Accuracy = 59.59615384615385%, Loss = 0.009920686626663575
Epoch: 1858, Batch Gradient Norm: 3.032479685228101
Epoch: 1858, Batch Gradient Norm after: 3.032479685228101
Epoch 1859/10000, Prediction Accuracy = 59.76538461538461%, Loss = 0.0099532064766838
Epoch: 1859, Batch Gradient Norm: 3.1531643326620755
Epoch: 1859, Batch Gradient Norm after: 3.1531643326620755
Epoch 1860/10000, Prediction Accuracy = 59.37307692307692%, Loss = 0.010027945399857484
Epoch: 1860, Batch Gradient Norm: 2.9486304469663405
Epoch: 1860, Batch Gradient Norm after: 2.9486304469663405
Epoch 1861/10000, Prediction Accuracy = 60.01538461538462%, Loss = 0.009912801118424306
Epoch: 1861, Batch Gradient Norm: 3.151079749966329
Epoch: 1861, Batch Gradient Norm after: 3.151079749966329
Epoch 1862/10000, Prediction Accuracy = 59.161538461538456%, Loss = 0.010086051474970121
Epoch: 1862, Batch Gradient Norm: 3.316119985399905
Epoch: 1862, Batch Gradient Norm after: 3.316119985399905
Epoch 1863/10000, Prediction Accuracy = 59.24615384615384%, Loss = 0.01014343799593357
Epoch: 1863, Batch Gradient Norm: 2.724455980079725
Epoch: 1863, Batch Gradient Norm after: 2.724455980079725
Epoch 1864/10000, Prediction Accuracy = 59.95769230769231%, Loss = 0.009866477635044318
Epoch: 1864, Batch Gradient Norm: 2.607919249125291
Epoch: 1864, Batch Gradient Norm after: 2.607919249125291
Epoch 1865/10000, Prediction Accuracy = 60.042307692307695%, Loss = 0.009740379065848313
Epoch: 1865, Batch Gradient Norm: 2.9224767196323995
Epoch: 1865, Batch Gradient Norm after: 2.9224767196323995
Epoch 1866/10000, Prediction Accuracy = 59.82692307692309%, Loss = 0.009905960554113755
Epoch: 1866, Batch Gradient Norm: 2.7510279669912983
Epoch: 1866, Batch Gradient Norm after: 2.7510279669912983
Epoch 1867/10000, Prediction Accuracy = 59.842307692307685%, Loss = 0.009755047539678903
Epoch: 1867, Batch Gradient Norm: 3.481596207809751
Epoch: 1867, Batch Gradient Norm after: 3.481596207809751
Epoch 1868/10000, Prediction Accuracy = 59.37692307692308%, Loss = 0.010142578958318783
Epoch: 1868, Batch Gradient Norm: 3.195027016695671
Epoch: 1868, Batch Gradient Norm after: 3.195027016695671
Epoch 1869/10000, Prediction Accuracy = 59.25384615384616%, Loss = 0.010115111748186441
Epoch: 1869, Batch Gradient Norm: 2.897150228608137
Epoch: 1869, Batch Gradient Norm after: 2.897150228608137
Epoch 1870/10000, Prediction Accuracy = 59.83461538461539%, Loss = 0.009928658318061095
Epoch: 1870, Batch Gradient Norm: 2.594340282082609
Epoch: 1870, Batch Gradient Norm after: 2.594340282082609
Epoch 1871/10000, Prediction Accuracy = 60.33846153846153%, Loss = 0.009732201623802002
Epoch: 1871, Batch Gradient Norm: 2.7254648077713566
Epoch: 1871, Batch Gradient Norm after: 2.7254648077713566
Epoch 1872/10000, Prediction Accuracy = 60.20384615384615%, Loss = 0.009861017004228555
Epoch: 1872, Batch Gradient Norm: 2.764200548812012
Epoch: 1872, Batch Gradient Norm after: 2.764200548812012
Epoch 1873/10000, Prediction Accuracy = 60.01538461538461%, Loss = 0.009787715899829682
Epoch: 1873, Batch Gradient Norm: 2.9105464915106007
Epoch: 1873, Batch Gradient Norm after: 2.9105464915106007
Epoch 1874/10000, Prediction Accuracy = 59.80769230769231%, Loss = 0.009842094392157517
Epoch: 1874, Batch Gradient Norm: 2.7346321391075366
Epoch: 1874, Batch Gradient Norm after: 2.7346321391075366
Epoch 1875/10000, Prediction Accuracy = 60.06923076923077%, Loss = 0.009752578173692409
Epoch: 1875, Batch Gradient Norm: 2.8392453754246194
Epoch: 1875, Batch Gradient Norm after: 2.8392453754246194
Epoch 1876/10000, Prediction Accuracy = 59.73076923076923%, Loss = 0.009820664301514626
Epoch: 1876, Batch Gradient Norm: 3.0372385395896924
Epoch: 1876, Batch Gradient Norm after: 3.0372385395896924
Epoch 1877/10000, Prediction Accuracy = 59.411538461538456%, Loss = 0.009947949948792275
Epoch: 1877, Batch Gradient Norm: 2.624122278839279
Epoch: 1877, Batch Gradient Norm after: 2.624122278839279
Epoch 1878/10000, Prediction Accuracy = 60.22692307692307%, Loss = 0.009693636415669551
Epoch: 1878, Batch Gradient Norm: 2.7971782662656888
Epoch: 1878, Batch Gradient Norm after: 2.7971782662656888
Epoch 1879/10000, Prediction Accuracy = 59.76153846153846%, Loss = 0.009725656360387802
Epoch: 1879, Batch Gradient Norm: 2.7502222763759487
Epoch: 1879, Batch Gradient Norm after: 2.7502222763759487
Epoch 1880/10000, Prediction Accuracy = 59.99615384615386%, Loss = 0.009747996424826292
Epoch: 1880, Batch Gradient Norm: 2.644459180925431
Epoch: 1880, Batch Gradient Norm after: 2.644459180925431
Epoch 1881/10000, Prediction Accuracy = 59.91153846153846%, Loss = 0.009802754323642988
Epoch: 1881, Batch Gradient Norm: 2.7126243041742213
Epoch: 1881, Batch Gradient Norm after: 2.7126243041742213
Epoch 1882/10000, Prediction Accuracy = 60.111538461538466%, Loss = 0.009747964759858755
Epoch: 1882, Batch Gradient Norm: 2.8698804935518436
Epoch: 1882, Batch Gradient Norm after: 2.8698804935518436
Epoch 1883/10000, Prediction Accuracy = 60.20384615384616%, Loss = 0.009810058400034904
Epoch: 1883, Batch Gradient Norm: 2.7642440865141844
Epoch: 1883, Batch Gradient Norm after: 2.7642440865141844
Epoch 1884/10000, Prediction Accuracy = 59.92307692307691%, Loss = 0.009807634382293774
Epoch: 1884, Batch Gradient Norm: 3.285238725487945
Epoch: 1884, Batch Gradient Norm after: 3.285238725487945
Epoch 1885/10000, Prediction Accuracy = 59.74230769230769%, Loss = 0.01005875555655131
Epoch: 1885, Batch Gradient Norm: 3.1513934811787445
Epoch: 1885, Batch Gradient Norm after: 3.1513934811787445
Epoch 1886/10000, Prediction Accuracy = 59.25769230769231%, Loss = 0.010064119258179115
Epoch: 1886, Batch Gradient Norm: 2.718088946870001
Epoch: 1886, Batch Gradient Norm after: 2.718088946870001
Epoch 1887/10000, Prediction Accuracy = 59.8423076923077%, Loss = 0.00976146779094751
Epoch: 1887, Batch Gradient Norm: 2.5127947913964075
Epoch: 1887, Batch Gradient Norm after: 2.5127947913964075
Epoch 1888/10000, Prediction Accuracy = 60.38076923076922%, Loss = 0.009599472037874736
Epoch: 1888, Batch Gradient Norm: 2.5763525314880638
Epoch: 1888, Batch Gradient Norm after: 2.5763525314880638
Epoch 1889/10000, Prediction Accuracy = 60.396153846153844%, Loss = 0.009684596640559344
Epoch: 1889, Batch Gradient Norm: 2.8320071503705297
Epoch: 1889, Batch Gradient Norm after: 2.8320071503705297
Epoch 1890/10000, Prediction Accuracy = 59.66538461538461%, Loss = 0.009818059463913623
Epoch: 1890, Batch Gradient Norm: 2.8847717750289013
Epoch: 1890, Batch Gradient Norm after: 2.8847717750289013
Epoch 1891/10000, Prediction Accuracy = 60.28846153846153%, Loss = 0.009798900367548833
Epoch: 1891, Batch Gradient Norm: 2.8882212818792343
Epoch: 1891, Batch Gradient Norm after: 2.8882212818792343
Epoch 1892/10000, Prediction Accuracy = 59.8423076923077%, Loss = 0.009924316348937841
Epoch: 1892, Batch Gradient Norm: 2.8011449748404837
Epoch: 1892, Batch Gradient Norm after: 2.8011449748404837
Epoch 1893/10000, Prediction Accuracy = 60.165384615384625%, Loss = 0.009720346173987938
Epoch: 1893, Batch Gradient Norm: 2.9593990863091624
Epoch: 1893, Batch Gradient Norm after: 2.9593990863091624
Epoch 1894/10000, Prediction Accuracy = 59.8%, Loss = 0.00990053115842434
Epoch: 1894, Batch Gradient Norm: 2.861518186847467
Epoch: 1894, Batch Gradient Norm after: 2.861518186847467
Epoch 1895/10000, Prediction Accuracy = 59.907692307692294%, Loss = 0.009846567247922603
Epoch: 1895, Batch Gradient Norm: 2.957698216739301
Epoch: 1895, Batch Gradient Norm after: 2.957698216739301
Epoch 1896/10000, Prediction Accuracy = 59.74230769230769%, Loss = 0.009883688118022222
Epoch: 1896, Batch Gradient Norm: 3.071971439539534
Epoch: 1896, Batch Gradient Norm after: 3.071971439539534
Epoch 1897/10000, Prediction Accuracy = 59.51923076923078%, Loss = 0.009905435574742464
Epoch: 1897, Batch Gradient Norm: 2.774410288810256
Epoch: 1897, Batch Gradient Norm after: 2.774410288810256
Epoch 1898/10000, Prediction Accuracy = 60.21538461538462%, Loss = 0.009680998654892812
Epoch: 1898, Batch Gradient Norm: 3.131173915590633
Epoch: 1898, Batch Gradient Norm after: 3.131173915590633
Epoch 1899/10000, Prediction Accuracy = 59.65384615384615%, Loss = 0.009865793256232372
Epoch: 1899, Batch Gradient Norm: 3.0085547666127392
Epoch: 1899, Batch Gradient Norm after: 3.0085547666127392
Epoch 1900/10000, Prediction Accuracy = 60.034615384615385%, Loss = 0.009834265837875696
Epoch: 1900, Batch Gradient Norm: 3.1598251577984056
Epoch: 1900, Batch Gradient Norm after: 3.1598251577984056
Epoch 1901/10000, Prediction Accuracy = 59.83846153846154%, Loss = 0.009915252932562279
Epoch: 1901, Batch Gradient Norm: 2.961874987605161
Epoch: 1901, Batch Gradient Norm after: 2.961874987605161
Epoch 1902/10000, Prediction Accuracy = 60.042307692307695%, Loss = 0.009822140376155194
Epoch: 1902, Batch Gradient Norm: 2.8879183298398368
Epoch: 1902, Batch Gradient Norm after: 2.8879183298398368
Epoch 1903/10000, Prediction Accuracy = 59.62307692307692%, Loss = 0.009842314470845919
Epoch: 1903, Batch Gradient Norm: 2.92397984945244
Epoch: 1903, Batch Gradient Norm after: 2.92397984945244
Epoch 1904/10000, Prediction Accuracy = 59.78846153846155%, Loss = 0.009790777801894225
Epoch: 1904, Batch Gradient Norm: 3.1597811807191176
Epoch: 1904, Batch Gradient Norm after: 3.1597811807191176
Epoch 1905/10000, Prediction Accuracy = 59.68076923076923%, Loss = 0.009860912481179604
Epoch: 1905, Batch Gradient Norm: 3.1449629868364846
Epoch: 1905, Batch Gradient Norm after: 3.1449629868364846
Epoch 1906/10000, Prediction Accuracy = 59.873076923076916%, Loss = 0.009930499112949921
Epoch: 1906, Batch Gradient Norm: 2.8778036027026648
Epoch: 1906, Batch Gradient Norm after: 2.8778036027026648
Epoch 1907/10000, Prediction Accuracy = 59.74230769230769%, Loss = 0.009830511604937224
Epoch: 1907, Batch Gradient Norm: 3.0108383514830717
Epoch: 1907, Batch Gradient Norm after: 3.0108383514830717
Epoch 1908/10000, Prediction Accuracy = 59.357692307692304%, Loss = 0.009862679128463451
Epoch: 1908, Batch Gradient Norm: 2.706676343818841
Epoch: 1908, Batch Gradient Norm after: 2.706676343818841
Epoch 1909/10000, Prediction Accuracy = 60.157692307692315%, Loss = 0.009649194562091278
Epoch: 1909, Batch Gradient Norm: 2.904154653798643
Epoch: 1909, Batch Gradient Norm after: 2.904154653798643
Epoch 1910/10000, Prediction Accuracy = 59.830769230769235%, Loss = 0.009753365427828752
Epoch: 1910, Batch Gradient Norm: 3.1968313229367897
Epoch: 1910, Batch Gradient Norm after: 3.1968313229367897
Epoch 1911/10000, Prediction Accuracy = 59.588461538461544%, Loss = 0.00998878564972144
Epoch: 1911, Batch Gradient Norm: 3.155484011129595
Epoch: 1911, Batch Gradient Norm after: 3.155484011129595
Epoch 1912/10000, Prediction Accuracy = 59.33076923076924%, Loss = 0.010032088710711552
Epoch: 1912, Batch Gradient Norm: 2.7627148242763298
Epoch: 1912, Batch Gradient Norm after: 2.7627148242763298
Epoch 1913/10000, Prediction Accuracy = 59.60384615384615%, Loss = 0.009781993710650848
Epoch: 1913, Batch Gradient Norm: 3.362340527008875
Epoch: 1913, Batch Gradient Norm after: 3.362340527008875
Epoch 1914/10000, Prediction Accuracy = 59.01538461538461%, Loss = 0.010066096241084429
Epoch: 1914, Batch Gradient Norm: 3.2004555633051317
Epoch: 1914, Batch Gradient Norm after: 3.2004555633051317
Epoch 1915/10000, Prediction Accuracy = 59.08461538461539%, Loss = 0.010159040729586895
Epoch: 1915, Batch Gradient Norm: 3.0317580923037335
Epoch: 1915, Batch Gradient Norm after: 3.0317580923037335
Epoch 1916/10000, Prediction Accuracy = 59.42307692307691%, Loss = 0.009993695582334813
Epoch: 1916, Batch Gradient Norm: 2.801291121382793
Epoch: 1916, Batch Gradient Norm after: 2.801291121382793
Epoch 1917/10000, Prediction Accuracy = 60.0846153846154%, Loss = 0.009772375154380616
Epoch: 1917, Batch Gradient Norm: 2.6748181625590908
Epoch: 1917, Batch Gradient Norm after: 2.6748181625590908
Epoch 1918/10000, Prediction Accuracy = 60.48461538461539%, Loss = 0.009649958174962264
Epoch: 1918, Batch Gradient Norm: 2.74978631401823
Epoch: 1918, Batch Gradient Norm after: 2.74978631401823
Epoch 1919/10000, Prediction Accuracy = 59.84615384615385%, Loss = 0.009746112430898042
Epoch: 1919, Batch Gradient Norm: 2.7607026535323294
Epoch: 1919, Batch Gradient Norm after: 2.7607026535323294
Epoch 1920/10000, Prediction Accuracy = 60.1923076923077%, Loss = 0.009733066750833621
Epoch: 1920, Batch Gradient Norm: 3.146566277692186
Epoch: 1920, Batch Gradient Norm after: 3.146566277692186
Epoch 1921/10000, Prediction Accuracy = 59.38461538461539%, Loss = 0.009953936633582298
Epoch: 1921, Batch Gradient Norm: 3.1446629732662297
Epoch: 1921, Batch Gradient Norm after: 3.1446629732662297
Epoch 1922/10000, Prediction Accuracy = 59.473076923076924%, Loss = 0.009893622249364853
Epoch: 1922, Batch Gradient Norm: 2.7946191966064498
Epoch: 1922, Batch Gradient Norm after: 2.7946191966064498
Epoch 1923/10000, Prediction Accuracy = 59.734615384615395%, Loss = 0.009726771726631202
Epoch: 1923, Batch Gradient Norm: 2.7880649369804713
Epoch: 1923, Batch Gradient Norm after: 2.7880649369804713
Epoch 1924/10000, Prediction Accuracy = 60.32692307692308%, Loss = 0.009654393921104761
Epoch: 1924, Batch Gradient Norm: 2.6565955913710764
Epoch: 1924, Batch Gradient Norm after: 2.6565955913710764
Epoch 1925/10000, Prediction Accuracy = 60.06923076923076%, Loss = 0.009615710291724939
Epoch: 1925, Batch Gradient Norm: 2.738313996549812
Epoch: 1925, Batch Gradient Norm after: 2.738313996549812
Epoch 1926/10000, Prediction Accuracy = 60.43846153846153%, Loss = 0.009622582234442234
Epoch: 1926, Batch Gradient Norm: 2.8712066132937917
Epoch: 1926, Batch Gradient Norm after: 2.8712066132937917
Epoch 1927/10000, Prediction Accuracy = 60.46153846153847%, Loss = 0.009654299857524725
Epoch: 1927, Batch Gradient Norm: 2.7670431020816935
Epoch: 1927, Batch Gradient Norm after: 2.7670431020816935
Epoch 1928/10000, Prediction Accuracy = 60.199999999999996%, Loss = 0.009682092672357192
Epoch: 1928, Batch Gradient Norm: 2.867017811208653
Epoch: 1928, Batch Gradient Norm after: 2.867017811208653
Epoch 1929/10000, Prediction Accuracy = 60.55%, Loss = 0.009669033523935538
Epoch: 1929, Batch Gradient Norm: 3.0203635260069546
Epoch: 1929, Batch Gradient Norm after: 3.0203635260069546
Epoch 1930/10000, Prediction Accuracy = 60.0576923076923%, Loss = 0.009776078451138277
Epoch: 1930, Batch Gradient Norm: 3.011177563332322
Epoch: 1930, Batch Gradient Norm after: 3.011177563332322
Epoch 1931/10000, Prediction Accuracy = 60.25769230769231%, Loss = 0.009856771677732468
Epoch: 1931, Batch Gradient Norm: 3.0688771764850755
Epoch: 1931, Batch Gradient Norm after: 3.0688771764850755
Epoch 1932/10000, Prediction Accuracy = 59.888461538461534%, Loss = 0.009795218276289793
Epoch: 1932, Batch Gradient Norm: 3.021676514198404
Epoch: 1932, Batch Gradient Norm after: 3.021676514198404
Epoch 1933/10000, Prediction Accuracy = 59.86538461538463%, Loss = 0.009829857601569248
Epoch: 1933, Batch Gradient Norm: 2.7916441492572197
Epoch: 1933, Batch Gradient Norm after: 2.7916441492572197
Epoch 1934/10000, Prediction Accuracy = 60.55%, Loss = 0.009619369386480404
Epoch: 1934, Batch Gradient Norm: 2.950236659563497
Epoch: 1934, Batch Gradient Norm after: 2.950236659563497
Epoch 1935/10000, Prediction Accuracy = 60.36923076923077%, Loss = 0.009738173980552416
Epoch: 1935, Batch Gradient Norm: 3.1524224550647864
Epoch: 1935, Batch Gradient Norm after: 3.1524224550647864
Epoch 1936/10000, Prediction Accuracy = 59.80769230769231%, Loss = 0.009961008953933533
Epoch: 1936, Batch Gradient Norm: 3.0672594308619625
Epoch: 1936, Batch Gradient Norm after: 3.0672594308619625
Epoch 1937/10000, Prediction Accuracy = 59.48076923076923%, Loss = 0.00998536260941854
Epoch: 1937, Batch Gradient Norm: 2.8719084792784693
Epoch: 1937, Batch Gradient Norm after: 2.8719084792784693
Epoch 1938/10000, Prediction Accuracy = 60.392307692307696%, Loss = 0.009730954439594196
Epoch: 1938, Batch Gradient Norm: 3.0260672220886917
Epoch: 1938, Batch Gradient Norm after: 3.0260672220886917
Epoch 1939/10000, Prediction Accuracy = 59.75384615384616%, Loss = 0.009830292744132189
Epoch: 1939, Batch Gradient Norm: 2.880996861961295
Epoch: 1939, Batch Gradient Norm after: 2.880996861961295
Epoch 1940/10000, Prediction Accuracy = 60.176923076923075%, Loss = 0.009757444835626163
Epoch: 1940, Batch Gradient Norm: 2.775130857274074
Epoch: 1940, Batch Gradient Norm after: 2.775130857274074
Epoch 1941/10000, Prediction Accuracy = 60.43076923076922%, Loss = 0.009634751611604141
Epoch: 1941, Batch Gradient Norm: 2.7970151728338677
Epoch: 1941, Batch Gradient Norm after: 2.7970151728338677
Epoch 1942/10000, Prediction Accuracy = 60.23846153846154%, Loss = 0.009688189754692407
Epoch: 1942, Batch Gradient Norm: 2.6569025103310095
Epoch: 1942, Batch Gradient Norm after: 2.6569025103310095
Epoch 1943/10000, Prediction Accuracy = 60.51923076923078%, Loss = 0.009612051411890067
Epoch: 1943, Batch Gradient Norm: 2.926923659982973
Epoch: 1943, Batch Gradient Norm after: 2.926923659982973
Epoch 1944/10000, Prediction Accuracy = 60.41538461538461%, Loss = 0.009771349983146558
Epoch: 1944, Batch Gradient Norm: 2.9679758492715225
Epoch: 1944, Batch Gradient Norm after: 2.9679758492715225
Epoch 1945/10000, Prediction Accuracy = 60.084615384615375%, Loss = 0.009777420558608495
Epoch: 1945, Batch Gradient Norm: 2.8070362127533675
Epoch: 1945, Batch Gradient Norm after: 2.8070362127533675
Epoch 1946/10000, Prediction Accuracy = 60.49230769230769%, Loss = 0.009591462233891854
Epoch: 1946, Batch Gradient Norm: 2.9562326027750023
Epoch: 1946, Batch Gradient Norm after: 2.9562326027750023
Epoch 1947/10000, Prediction Accuracy = 60.18076923076923%, Loss = 0.009715146528413663
Epoch: 1947, Batch Gradient Norm: 2.8678623889750945
Epoch: 1947, Batch Gradient Norm after: 2.8678623889750945
Epoch 1948/10000, Prediction Accuracy = 60.01923076923077%, Loss = 0.009700160401944932
Epoch: 1948, Batch Gradient Norm: 2.8106524305019946
Epoch: 1948, Batch Gradient Norm after: 2.8106524305019946
Epoch 1949/10000, Prediction Accuracy = 60.5576923076923%, Loss = 0.009607530055710902
Epoch: 1949, Batch Gradient Norm: 2.7533944157705648
Epoch: 1949, Batch Gradient Norm after: 2.7533944157705648
Epoch 1950/10000, Prediction Accuracy = 60.284615384615385%, Loss = 0.009570352446574431
Epoch: 1950, Batch Gradient Norm: 3.1299891067233143
Epoch: 1950, Batch Gradient Norm after: 3.1299891067233143
Epoch 1951/10000, Prediction Accuracy = 59.861538461538466%, Loss = 0.009798488006568871
Epoch: 1951, Batch Gradient Norm: 2.9824194319059347
Epoch: 1951, Batch Gradient Norm after: 2.9824194319059347
Epoch 1952/10000, Prediction Accuracy = 59.91153846153846%, Loss = 0.009742815620624103
Epoch: 1952, Batch Gradient Norm: 3.112221157740385
Epoch: 1952, Batch Gradient Norm after: 3.112221157740385
Epoch 1953/10000, Prediction Accuracy = 59.942307692307686%, Loss = 0.009869618986088496
Epoch: 1953, Batch Gradient Norm: 2.9636015052739144
Epoch: 1953, Batch Gradient Norm after: 2.9636015052739144
Epoch 1954/10000, Prediction Accuracy = 60.2153846153846%, Loss = 0.009736621394180335
Epoch: 1954, Batch Gradient Norm: 2.96889990563307
Epoch: 1954, Batch Gradient Norm after: 2.96889990563307
Epoch 1955/10000, Prediction Accuracy = 60.12307692307692%, Loss = 0.009739721981951823
Epoch: 1955, Batch Gradient Norm: 2.7680587814376993
Epoch: 1955, Batch Gradient Norm after: 2.7680587814376993
Epoch 1956/10000, Prediction Accuracy = 60.68076923076922%, Loss = 0.009573829002105273
Epoch: 1956, Batch Gradient Norm: 3.1834856184978255
Epoch: 1956, Batch Gradient Norm after: 3.1834856184978255
Epoch 1957/10000, Prediction Accuracy = 59.55384615384615%, Loss = 0.009924200220176807
Epoch: 1957, Batch Gradient Norm: 3.1800984344690972
Epoch: 1957, Batch Gradient Norm after: 3.1800984344690972
Epoch 1958/10000, Prediction Accuracy = 59.81153846153845%, Loss = 0.009881950914859772
Epoch: 1958, Batch Gradient Norm: 2.828954355668011
Epoch: 1958, Batch Gradient Norm after: 2.828954355668011
Epoch 1959/10000, Prediction Accuracy = 60.25%, Loss = 0.009672552777024416
Epoch: 1959, Batch Gradient Norm: 2.695524117009508
Epoch: 1959, Batch Gradient Norm after: 2.695524117009508
Epoch 1960/10000, Prediction Accuracy = 60.59999999999999%, Loss = 0.009488641212765988
Epoch: 1960, Batch Gradient Norm: 3.074434645778552
Epoch: 1960, Batch Gradient Norm after: 3.074434645778552
Epoch 1961/10000, Prediction Accuracy = 59.619230769230775%, Loss = 0.00976256445909922
Epoch: 1961, Batch Gradient Norm: 3.0761496342345085
Epoch: 1961, Batch Gradient Norm after: 3.0761496342345085
Epoch 1962/10000, Prediction Accuracy = 59.96538461538462%, Loss = 0.009782648000579614
Epoch: 1962, Batch Gradient Norm: 2.9691659094329443
Epoch: 1962, Batch Gradient Norm after: 2.9691659094329443
Epoch 1963/10000, Prediction Accuracy = 59.54615384615385%, Loss = 0.009819829979768166
Epoch: 1963, Batch Gradient Norm: 3.2185242731440895
Epoch: 1963, Batch Gradient Norm after: 3.2185242731440895
Epoch 1964/10000, Prediction Accuracy = 59.85000000000001%, Loss = 0.00981769603318893
Epoch: 1964, Batch Gradient Norm: 2.951509413085883
Epoch: 1964, Batch Gradient Norm after: 2.951509413085883
Epoch 1965/10000, Prediction Accuracy = 60.192307692307686%, Loss = 0.009766380660809003
Epoch: 1965, Batch Gradient Norm: 2.913994664627628
Epoch: 1965, Batch Gradient Norm after: 2.913994664627628
Epoch 1966/10000, Prediction Accuracy = 60.35769230769232%, Loss = 0.009717218721142182
Epoch: 1966, Batch Gradient Norm: 3.0398379084528866
Epoch: 1966, Batch Gradient Norm after: 3.0398379084528866
Epoch 1967/10000, Prediction Accuracy = 59.81923076923078%, Loss = 0.00982829606017241
Epoch: 1967, Batch Gradient Norm: 3.494890547732586
Epoch: 1967, Batch Gradient Norm after: 3.494890547732586
Epoch 1968/10000, Prediction Accuracy = 59.38076923076922%, Loss = 0.010151566507724615
Epoch: 1968, Batch Gradient Norm: 3.1498680260984315
Epoch: 1968, Batch Gradient Norm after: 3.1498680260984315
Epoch 1969/10000, Prediction Accuracy = 59.66153846153846%, Loss = 0.009928683248850016
Epoch: 1969, Batch Gradient Norm: 3.1029673618505593
Epoch: 1969, Batch Gradient Norm after: 3.1029673618505593
Epoch 1970/10000, Prediction Accuracy = 59.66153846153846%, Loss = 0.009852827311708378
Epoch: 1970, Batch Gradient Norm: 3.1669903933038017
Epoch: 1970, Batch Gradient Norm after: 3.1669903933038017
Epoch 1971/10000, Prediction Accuracy = 59.80384615384616%, Loss = 0.009898130925228963
Epoch: 1971, Batch Gradient Norm: 2.8102727779939967
Epoch: 1971, Batch Gradient Norm after: 2.8102727779939967
Epoch 1972/10000, Prediction Accuracy = 60.484615384615374%, Loss = 0.00965612532141117
Epoch: 1972, Batch Gradient Norm: 2.9808913441243856
Epoch: 1972, Batch Gradient Norm after: 2.9808913441243856
Epoch 1973/10000, Prediction Accuracy = 59.896153846153844%, Loss = 0.009789933307239642
Epoch: 1973, Batch Gradient Norm: 2.3894845594983884
Epoch: 1973, Batch Gradient Norm after: 2.3894845594983884
Epoch 1974/10000, Prediction Accuracy = 61.21153846153846%, Loss = 0.009355724216080628
Epoch: 1974, Batch Gradient Norm: 2.757932564068693
Epoch: 1974, Batch Gradient Norm after: 2.757932564068693
Epoch 1975/10000, Prediction Accuracy = 60.48076923076923%, Loss = 0.00952867604792118
Epoch: 1975, Batch Gradient Norm: 3.040300404274914
Epoch: 1975, Batch Gradient Norm after: 3.040300404274914
Epoch 1976/10000, Prediction Accuracy = 60.03846153846154%, Loss = 0.009787537873937534
Epoch: 1976, Batch Gradient Norm: 2.8504806280011508
Epoch: 1976, Batch Gradient Norm after: 2.8504806280011508
Epoch 1977/10000, Prediction Accuracy = 59.93076923076924%, Loss = 0.009672524908987375
Epoch: 1977, Batch Gradient Norm: 3.1633534265764496
Epoch: 1977, Batch Gradient Norm after: 3.1633534265764496
Epoch 1978/10000, Prediction Accuracy = 59.646153846153844%, Loss = 0.009779768351178903
Epoch: 1978, Batch Gradient Norm: 2.9744340252442605
Epoch: 1978, Batch Gradient Norm after: 2.9744340252442605
Epoch 1979/10000, Prediction Accuracy = 60.08846153846154%, Loss = 0.009715698014658231
Epoch: 1979, Batch Gradient Norm: 3.0913308691234986
Epoch: 1979, Batch Gradient Norm after: 3.0913308691234986
Epoch 1980/10000, Prediction Accuracy = 59.619230769230775%, Loss = 0.00982493506028102
Epoch: 1980, Batch Gradient Norm: 3.2045250114047095
Epoch: 1980, Batch Gradient Norm after: 3.2045250114047095
Epoch 1981/10000, Prediction Accuracy = 59.61923076923077%, Loss = 0.009864857491965476
Epoch: 1981, Batch Gradient Norm: 2.6822070556792488
Epoch: 1981, Batch Gradient Norm after: 2.6822070556792488
Epoch 1982/10000, Prediction Accuracy = 60.72307692307693%, Loss = 0.009510447271168232
Epoch: 1982, Batch Gradient Norm: 3.018576896679245
Epoch: 1982, Batch Gradient Norm after: 3.018576896679245
Epoch 1983/10000, Prediction Accuracy = 60.36153846153846%, Loss = 0.009719137532206682
Epoch: 1983, Batch Gradient Norm: 2.8036398518649337
Epoch: 1983, Batch Gradient Norm after: 2.8036398518649337
Epoch 1984/10000, Prediction Accuracy = 60.5923076923077%, Loss = 0.009631890087173535
Epoch: 1984, Batch Gradient Norm: 3.1208085012387667
Epoch: 1984, Batch Gradient Norm after: 3.1208085012387667
Epoch 1985/10000, Prediction Accuracy = 60.449999999999996%, Loss = 0.009726802173715372
Epoch: 1985, Batch Gradient Norm: 3.0400032632653207
Epoch: 1985, Batch Gradient Norm after: 3.0400032632653207
Epoch 1986/10000, Prediction Accuracy = 60.119230769230775%, Loss = 0.009723706170916557
Epoch: 1986, Batch Gradient Norm: 3.217548257110911
Epoch: 1986, Batch Gradient Norm after: 3.217548257110911
Epoch 1987/10000, Prediction Accuracy = 60.18461538461539%, Loss = 0.009704463112239655
Epoch: 1987, Batch Gradient Norm: 3.1999872082462337
Epoch: 1987, Batch Gradient Norm after: 3.1999872082462337
Epoch 1988/10000, Prediction Accuracy = 59.68846153846153%, Loss = 0.009798958467749449
Epoch: 1988, Batch Gradient Norm: 3.101016112677782
Epoch: 1988, Batch Gradient Norm after: 3.101016112677782
Epoch 1989/10000, Prediction Accuracy = 59.826923076923066%, Loss = 0.009774808270426897
Epoch: 1989, Batch Gradient Norm: 3.072685847066113
Epoch: 1989, Batch Gradient Norm after: 3.072685847066113
Epoch 1990/10000, Prediction Accuracy = 59.926923076923075%, Loss = 0.009659356294343105
Epoch: 1990, Batch Gradient Norm: 2.7527280074720344
Epoch: 1990, Batch Gradient Norm after: 2.7527280074720344
Epoch 1991/10000, Prediction Accuracy = 60.28846153846155%, Loss = 0.009589895820961548
Epoch: 1991, Batch Gradient Norm: 2.9871982021843895
Epoch: 1991, Batch Gradient Norm after: 2.9871982021843895
Epoch 1992/10000, Prediction Accuracy = 60.2576923076923%, Loss = 0.00968414294318511
Epoch: 1992, Batch Gradient Norm: 2.8332253100715694
Epoch: 1992, Batch Gradient Norm after: 2.8332253100715694
Epoch 1993/10000, Prediction Accuracy = 60.3576923076923%, Loss = 0.009576913255911607
Epoch: 1993, Batch Gradient Norm: 2.9056997272594587
Epoch: 1993, Batch Gradient Norm after: 2.9056997272594587
Epoch 1994/10000, Prediction Accuracy = 60.13846153846154%, Loss = 0.009605002302963
Epoch: 1994, Batch Gradient Norm: 2.8089568337927537
Epoch: 1994, Batch Gradient Norm after: 2.8089568337927537
Epoch 1995/10000, Prediction Accuracy = 61.05769230769231%, Loss = 0.009578224486456467
Epoch: 1995, Batch Gradient Norm: 3.1539187208825807
Epoch: 1995, Batch Gradient Norm after: 3.1539187208825807
Epoch 1996/10000, Prediction Accuracy = 60.28846153846154%, Loss = 0.00976736879406067
Epoch: 1996, Batch Gradient Norm: 2.8230451024590875
Epoch: 1996, Batch Gradient Norm after: 2.8230451024590875
Epoch 1997/10000, Prediction Accuracy = 60.45000000000001%, Loss = 0.00951727730436967
Epoch: 1997, Batch Gradient Norm: 3.1185108442648786
Epoch: 1997, Batch Gradient Norm after: 3.1185108442648786
Epoch 1998/10000, Prediction Accuracy = 59.934615384615384%, Loss = 0.009702921271897279
Epoch: 1998, Batch Gradient Norm: 3.2194366022511844
Epoch: 1998, Batch Gradient Norm after: 3.2194366022511844
Epoch 1999/10000, Prediction Accuracy = 59.95384615384615%, Loss = 0.009723387085474454
Epoch: 1999, Batch Gradient Norm: 2.8547642371016186
Epoch: 1999, Batch Gradient Norm after: 2.8547642371016186
Epoch 2000/10000, Prediction Accuracy = 60.4076923076923%, Loss = 0.009684924824306598
Epoch: 2000, Batch Gradient Norm: 2.995835691218384
Epoch: 2000, Batch Gradient Norm after: 2.995835691218384
Epoch 2001/10000, Prediction Accuracy = 59.96153846153846%, Loss = 0.00968211882102948
Epoch: 2001, Batch Gradient Norm: 2.9123962361311913
Epoch: 2001, Batch Gradient Norm after: 2.9123962361311913
Epoch 2002/10000, Prediction Accuracy = 60.646153846153844%, Loss = 0.009606117812486796
Epoch: 2002, Batch Gradient Norm: 2.888159900806433
Epoch: 2002, Batch Gradient Norm after: 2.888159900806433
Epoch 2003/10000, Prediction Accuracy = 60.19230769230769%, Loss = 0.00962025335488411
Epoch: 2003, Batch Gradient Norm: 3.052350250266818
Epoch: 2003, Batch Gradient Norm after: 3.052350250266818
Epoch 2004/10000, Prediction Accuracy = 60.330769230769235%, Loss = 0.00964050181210041
Epoch: 2004, Batch Gradient Norm: 2.6432781551086464
Epoch: 2004, Batch Gradient Norm after: 2.6432781551086464
Epoch 2005/10000, Prediction Accuracy = 61.119230769230775%, Loss = 0.00940736411855771
Epoch: 2005, Batch Gradient Norm: 2.866230225853355
Epoch: 2005, Batch Gradient Norm after: 2.866230225853355
Epoch 2006/10000, Prediction Accuracy = 60.77307692307692%, Loss = 0.009549113348699532
Epoch: 2006, Batch Gradient Norm: 2.5333793924835115
Epoch: 2006, Batch Gradient Norm after: 2.5333793924835115
Epoch 2007/10000, Prediction Accuracy = 60.78846153846154%, Loss = 0.009271776232008751
Epoch: 2007, Batch Gradient Norm: 3.2183770147299833
Epoch: 2007, Batch Gradient Norm after: 3.2183770147299833
Epoch 2008/10000, Prediction Accuracy = 60.092307692307685%, Loss = 0.009633194798460374
Epoch: 2008, Batch Gradient Norm: 3.1401462514729417
Epoch: 2008, Batch Gradient Norm after: 3.1401462514729417
Epoch 2009/10000, Prediction Accuracy = 60.35384615384615%, Loss = 0.009588565892324997
Epoch: 2009, Batch Gradient Norm: 3.1123642121066704
Epoch: 2009, Batch Gradient Norm after: 3.1123642121066704
Epoch 2010/10000, Prediction Accuracy = 59.98846153846154%, Loss = 0.009731224952982022
Epoch: 2010, Batch Gradient Norm: 3.2370702058510568
Epoch: 2010, Batch Gradient Norm after: 3.2370702058510568
Epoch 2011/10000, Prediction Accuracy = 59.83461538461539%, Loss = 0.0097806526777836
Epoch: 2011, Batch Gradient Norm: 3.284470032064178
Epoch: 2011, Batch Gradient Norm after: 3.284470032064178
Epoch 2012/10000, Prediction Accuracy = 60.161538461538456%, Loss = 0.009783026905587086
Epoch: 2012, Batch Gradient Norm: 3.0898479320989676
Epoch: 2012, Batch Gradient Norm after: 3.0898479320989676
Epoch 2013/10000, Prediction Accuracy = 60.00384615384616%, Loss = 0.009692186418061074
Epoch: 2013, Batch Gradient Norm: 2.9460586938066853
Epoch: 2013, Batch Gradient Norm after: 2.9460586938066853
Epoch 2014/10000, Prediction Accuracy = 60.75%, Loss = 0.009609136658792313
Epoch: 2014, Batch Gradient Norm: 2.915367381320072
Epoch: 2014, Batch Gradient Norm after: 2.915367381320072
Epoch 2015/10000, Prediction Accuracy = 60.66153846153846%, Loss = 0.009582862114677062
Epoch: 2015, Batch Gradient Norm: 3.2250586039594626
Epoch: 2015, Batch Gradient Norm after: 3.2250586039594626
Epoch 2016/10000, Prediction Accuracy = 60.073076923076925%, Loss = 0.009749711276246952
Epoch: 2016, Batch Gradient Norm: 2.752373625889628
Epoch: 2016, Batch Gradient Norm after: 2.752373625889628
Epoch 2017/10000, Prediction Accuracy = 60.78076923076923%, Loss = 0.009437121021059843
Epoch: 2017, Batch Gradient Norm: 2.9726515634752233
Epoch: 2017, Batch Gradient Norm after: 2.9726515634752233
Epoch 2018/10000, Prediction Accuracy = 60.80384615384616%, Loss = 0.009597232851844568
Epoch: 2018, Batch Gradient Norm: 2.701781373733974
Epoch: 2018, Batch Gradient Norm after: 2.701781373733974
Epoch 2019/10000, Prediction Accuracy = 61.092307692307685%, Loss = 0.009396621169379124
Epoch: 2019, Batch Gradient Norm: 2.918670389471586
Epoch: 2019, Batch Gradient Norm after: 2.918670389471586
Epoch 2020/10000, Prediction Accuracy = 60.47307692307691%, Loss = 0.009491180857786765
Epoch: 2020, Batch Gradient Norm: 3.2876731474039333
Epoch: 2020, Batch Gradient Norm after: 3.2876731474039333
Epoch 2021/10000, Prediction Accuracy = 60.20384615384615%, Loss = 0.009649681643797802
Epoch: 2021, Batch Gradient Norm: 3.362089049684636
Epoch: 2021, Batch Gradient Norm after: 3.362089049684636
Epoch 2022/10000, Prediction Accuracy = 59.75%, Loss = 0.009812838254639735
Epoch: 2022, Batch Gradient Norm: 3.0010145086080198
Epoch: 2022, Batch Gradient Norm after: 3.0010145086080198
Epoch 2023/10000, Prediction Accuracy = 60.36538461538463%, Loss = 0.009574749936851172
Epoch: 2023, Batch Gradient Norm: 2.6959101088782926
Epoch: 2023, Batch Gradient Norm after: 2.6959101088782926
Epoch 2024/10000, Prediction Accuracy = 60.807692307692314%, Loss = 0.009417665477555532
Epoch: 2024, Batch Gradient Norm: 2.947027349694574
Epoch: 2024, Batch Gradient Norm after: 2.947027349694574
Epoch 2025/10000, Prediction Accuracy = 60.853846153846156%, Loss = 0.00949889263854577
Epoch: 2025, Batch Gradient Norm: 3.0384385241220513
Epoch: 2025, Batch Gradient Norm after: 3.0384385241220513
Epoch 2026/10000, Prediction Accuracy = 60.099999999999994%, Loss = 0.009638464221587548
Epoch: 2026, Batch Gradient Norm: 3.092122476429859
Epoch: 2026, Batch Gradient Norm after: 3.092122476429859
Epoch 2027/10000, Prediction Accuracy = 60.04230769230769%, Loss = 0.009670885279774666
Epoch: 2027, Batch Gradient Norm: 3.338773380269292
Epoch: 2027, Batch Gradient Norm after: 3.338773380269292
Epoch 2028/10000, Prediction Accuracy = 59.93846153846154%, Loss = 0.009820243200430503
Epoch: 2028, Batch Gradient Norm: 3.24679891783697
Epoch: 2028, Batch Gradient Norm after: 3.24679891783697
Epoch 2029/10000, Prediction Accuracy = 59.776923076923076%, Loss = 0.009821894793556286
Epoch: 2029, Batch Gradient Norm: 2.971623557624019
Epoch: 2029, Batch Gradient Norm after: 2.971623557624019
Epoch 2030/10000, Prediction Accuracy = 60.20384615384615%, Loss = 0.009574818281600108
Epoch: 2030, Batch Gradient Norm: 3.1054238949297006
Epoch: 2030, Batch Gradient Norm after: 3.1054238949297006
Epoch 2031/10000, Prediction Accuracy = 60.096153846153854%, Loss = 0.009628908708691597
Epoch: 2031, Batch Gradient Norm: 2.8281865476963564
Epoch: 2031, Batch Gradient Norm after: 2.8281865476963564
Epoch 2032/10000, Prediction Accuracy = 60.553846153846166%, Loss = 0.009491516563754816
Epoch: 2032, Batch Gradient Norm: 2.7802880898316547
Epoch: 2032, Batch Gradient Norm after: 2.7802880898316547
Epoch 2033/10000, Prediction Accuracy = 60.573076923076925%, Loss = 0.00949455052614212
Epoch: 2033, Batch Gradient Norm: 3.107162571621413
Epoch: 2033, Batch Gradient Norm after: 3.107162571621413
Epoch 2034/10000, Prediction Accuracy = 60.373076923076916%, Loss = 0.00956558550779636
Epoch: 2034, Batch Gradient Norm: 2.9109559480716825
Epoch: 2034, Batch Gradient Norm after: 2.9109559480716825
Epoch 2035/10000, Prediction Accuracy = 60.534615384615385%, Loss = 0.009521387015970854
Epoch: 2035, Batch Gradient Norm: 2.7885261828089662
Epoch: 2035, Batch Gradient Norm after: 2.7885261828089662
Epoch 2036/10000, Prediction Accuracy = 60.46923076923077%, Loss = 0.00941139617218421
Epoch: 2036, Batch Gradient Norm: 3.457694211000059
Epoch: 2036, Batch Gradient Norm after: 3.457694211000059
Epoch 2037/10000, Prediction Accuracy = 59.4923076923077%, Loss = 0.00987397564145235
Epoch: 2037, Batch Gradient Norm: 3.4049911678885088
Epoch: 2037, Batch Gradient Norm after: 3.4049911678885088
Epoch 2038/10000, Prediction Accuracy = 59.70384615384615%, Loss = 0.0099420018064288
Epoch: 2038, Batch Gradient Norm: 2.9901183186753495
Epoch: 2038, Batch Gradient Norm after: 2.9901183186753495
Epoch 2039/10000, Prediction Accuracy = 59.92307692307691%, Loss = 0.009718577162577556
Epoch: 2039, Batch Gradient Norm: 3.2053622949862404
Epoch: 2039, Batch Gradient Norm after: 3.2053622949862404
Epoch 2040/10000, Prediction Accuracy = 59.96923076923076%, Loss = 0.00971738535624284
Epoch: 2040, Batch Gradient Norm: 3.0856999143059887
Epoch: 2040, Batch Gradient Norm after: 3.0856999143059887
Epoch 2041/10000, Prediction Accuracy = 60.16538461538461%, Loss = 0.009653271104280766
Epoch: 2041, Batch Gradient Norm: 3.1676810963092636
Epoch: 2041, Batch Gradient Norm after: 3.1676810963092636
Epoch 2042/10000, Prediction Accuracy = 59.86538461538461%, Loss = 0.009699382675954929
Epoch: 2042, Batch Gradient Norm: 3.2039098152116714
Epoch: 2042, Batch Gradient Norm after: 3.2039098152116714
Epoch 2043/10000, Prediction Accuracy = 60.07692307692308%, Loss = 0.009818329547460262
Epoch: 2043, Batch Gradient Norm: 2.961994480236827
Epoch: 2043, Batch Gradient Norm after: 2.961994480236827
Epoch 2044/10000, Prediction Accuracy = 60.465384615384615%, Loss = 0.00953720287921337
Epoch: 2044, Batch Gradient Norm: 3.011257994064354
Epoch: 2044, Batch Gradient Norm after: 3.011257994064354
Epoch 2045/10000, Prediction Accuracy = 60.34615384615384%, Loss = 0.009598214680758806
Epoch: 2045, Batch Gradient Norm: 3.22116533269055
Epoch: 2045, Batch Gradient Norm after: 3.22116533269055
Epoch 2046/10000, Prediction Accuracy = 60.01923076923077%, Loss = 0.0098048083914014
Epoch: 2046, Batch Gradient Norm: 3.3124034047433137
Epoch: 2046, Batch Gradient Norm after: 3.3124034047433137
Epoch 2047/10000, Prediction Accuracy = 59.95769230769231%, Loss = 0.009744346643296571
Epoch: 2047, Batch Gradient Norm: 3.1689147294399898
Epoch: 2047, Batch Gradient Norm after: 3.1689147294399898
Epoch 2048/10000, Prediction Accuracy = 60.473076923076924%, Loss = 0.009671836948165527
Epoch: 2048, Batch Gradient Norm: 3.1486984944574483
Epoch: 2048, Batch Gradient Norm after: 3.1486984944574483
Epoch 2049/10000, Prediction Accuracy = 60.51538461538461%, Loss = 0.009658566389519434
Epoch: 2049, Batch Gradient Norm: 3.006452960942077
Epoch: 2049, Batch Gradient Norm after: 3.006452960942077
Epoch 2050/10000, Prediction Accuracy = 60.530769230769224%, Loss = 0.009590491437568115
Epoch: 2050, Batch Gradient Norm: 3.126174970684407
Epoch: 2050, Batch Gradient Norm after: 3.126174970684407
Epoch 2051/10000, Prediction Accuracy = 60.573076923076925%, Loss = 0.009585435430590924
Epoch: 2051, Batch Gradient Norm: 3.1753174601282903
Epoch: 2051, Batch Gradient Norm after: 3.1753174601282903
Epoch 2052/10000, Prediction Accuracy = 60.07692307692308%, Loss = 0.00970724275192389
Epoch: 2052, Batch Gradient Norm: 2.6402914683162444
Epoch: 2052, Batch Gradient Norm after: 2.6402914683162444
Epoch 2053/10000, Prediction Accuracy = 60.66538461538461%, Loss = 0.009411853881409535
Epoch: 2053, Batch Gradient Norm: 2.9549926030315485
Epoch: 2053, Batch Gradient Norm after: 2.9549926030315485
Epoch 2054/10000, Prediction Accuracy = 60.68076923076923%, Loss = 0.009526530352349464
Epoch: 2054, Batch Gradient Norm: 2.9894899237912784
Epoch: 2054, Batch Gradient Norm after: 2.9894899237912784
Epoch 2055/10000, Prediction Accuracy = 60.80769230769231%, Loss = 0.009545835308157481
Epoch: 2055, Batch Gradient Norm: 2.9286912534171385
Epoch: 2055, Batch Gradient Norm after: 2.9286912534171385
Epoch 2056/10000, Prediction Accuracy = 60.73076923076923%, Loss = 0.009530027540257344
Epoch: 2056, Batch Gradient Norm: 2.853092763059639
Epoch: 2056, Batch Gradient Norm after: 2.853092763059639
Epoch 2057/10000, Prediction Accuracy = 60.69230769230771%, Loss = 0.009442474907980515
Epoch: 2057, Batch Gradient Norm: 2.9358646344652697
Epoch: 2057, Batch Gradient Norm after: 2.9358646344652697
Epoch 2058/10000, Prediction Accuracy = 60.369230769230775%, Loss = 0.009490480145009665
Epoch: 2058, Batch Gradient Norm: 3.0592664634415194
Epoch: 2058, Batch Gradient Norm after: 3.0592664634415194
Epoch 2059/10000, Prediction Accuracy = 60.5846153846154%, Loss = 0.009506082018980613
Epoch: 2059, Batch Gradient Norm: 3.2843853485785
Epoch: 2059, Batch Gradient Norm after: 3.2843853485785
Epoch 2060/10000, Prediction Accuracy = 60.48846153846154%, Loss = 0.009607494020691285
Epoch: 2060, Batch Gradient Norm: 3.0432043081084004
Epoch: 2060, Batch Gradient Norm after: 3.0432043081084004
Epoch 2061/10000, Prediction Accuracy = 60.43076923076923%, Loss = 0.009600769513501571
Epoch: 2061, Batch Gradient Norm: 2.9906521324915736
Epoch: 2061, Batch Gradient Norm after: 2.9906521324915736
Epoch 2062/10000, Prediction Accuracy = 60.43461538461538%, Loss = 0.00951398629695177
Epoch: 2062, Batch Gradient Norm: 3.0765092341785287
Epoch: 2062, Batch Gradient Norm after: 3.0765092341785287
Epoch 2063/10000, Prediction Accuracy = 60.48076923076923%, Loss = 0.009567279655199785
Epoch: 2063, Batch Gradient Norm: 3.0818094056401786
Epoch: 2063, Batch Gradient Norm after: 3.0818094056401786
Epoch 2064/10000, Prediction Accuracy = 60.52307692307693%, Loss = 0.00963351338242109
Epoch: 2064, Batch Gradient Norm: 3.075966970595932
Epoch: 2064, Batch Gradient Norm after: 3.075966970595932
Epoch 2065/10000, Prediction Accuracy = 60.54230769230769%, Loss = 0.009592209656078082
Epoch: 2065, Batch Gradient Norm: 2.9488770519218006
Epoch: 2065, Batch Gradient Norm after: 2.9488770519218006
Epoch 2066/10000, Prediction Accuracy = 60.911538461538456%, Loss = 0.009480340191378044
Epoch: 2066, Batch Gradient Norm: 3.129810286698934
Epoch: 2066, Batch Gradient Norm after: 3.129810286698934
Epoch 2067/10000, Prediction Accuracy = 60.63461538461539%, Loss = 0.009503701343559302
Epoch: 2067, Batch Gradient Norm: 2.8439543125068334
Epoch: 2067, Batch Gradient Norm after: 2.8439543125068334
Epoch 2068/10000, Prediction Accuracy = 60.776923076923076%, Loss = 0.009363192921647659
Epoch: 2068, Batch Gradient Norm: 3.0574141079152537
Epoch: 2068, Batch Gradient Norm after: 3.0574141079152537
Epoch 2069/10000, Prediction Accuracy = 60.75769230769231%, Loss = 0.009512162337509485
Epoch: 2069, Batch Gradient Norm: 3.1117617576814967
Epoch: 2069, Batch Gradient Norm after: 3.1117617576814967
Epoch 2070/10000, Prediction Accuracy = 60.11923076923077%, Loss = 0.009570412767621187
Epoch: 2070, Batch Gradient Norm: 3.1564555929901914
Epoch: 2070, Batch Gradient Norm after: 3.1564555929901914
Epoch 2071/10000, Prediction Accuracy = 60.14999999999999%, Loss = 0.009671686432109429
Epoch: 2071, Batch Gradient Norm: 3.134439191176977
Epoch: 2071, Batch Gradient Norm after: 3.134439191176977
Epoch 2072/10000, Prediction Accuracy = 60.7423076923077%, Loss = 0.009589258939600907
Epoch: 2072, Batch Gradient Norm: 3.234745802687106
Epoch: 2072, Batch Gradient Norm after: 3.234745802687106
Epoch 2073/10000, Prediction Accuracy = 60.47692307692307%, Loss = 0.009633166930423332
Epoch: 2073, Batch Gradient Norm: 2.8704473877420256
Epoch: 2073, Batch Gradient Norm after: 2.8704473877420256
Epoch 2074/10000, Prediction Accuracy = 61.01923076923077%, Loss = 0.009472358971834183
Epoch: 2074, Batch Gradient Norm: 2.8338275148684393
Epoch: 2074, Batch Gradient Norm after: 2.8338275148684393
Epoch 2075/10000, Prediction Accuracy = 60.87307692307692%, Loss = 0.00943674397869752
Epoch: 2075, Batch Gradient Norm: 3.0478100362922693
Epoch: 2075, Batch Gradient Norm after: 3.0478100362922693
Epoch 2076/10000, Prediction Accuracy = 60.26153846153846%, Loss = 0.00949945909759173
Epoch: 2076, Batch Gradient Norm: 2.827467243747851
Epoch: 2076, Batch Gradient Norm after: 2.827467243747851
Epoch 2077/10000, Prediction Accuracy = 60.79615384615385%, Loss = 0.009348832142467681
Epoch: 2077, Batch Gradient Norm: 3.0466981180611943
Epoch: 2077, Batch Gradient Norm after: 3.0466981180611943
Epoch 2078/10000, Prediction Accuracy = 60.49230769230769%, Loss = 0.00948399556084321
Epoch: 2078, Batch Gradient Norm: 3.3363023187055725
Epoch: 2078, Batch Gradient Norm after: 3.3363023187055725
Epoch 2079/10000, Prediction Accuracy = 59.95384615384616%, Loss = 0.009665176845513858
Epoch: 2079, Batch Gradient Norm: 3.4314558763451664
Epoch: 2079, Batch Gradient Norm after: 3.4314558763451664
Epoch 2080/10000, Prediction Accuracy = 60.207692307692305%, Loss = 0.009675476485146927
Epoch: 2080, Batch Gradient Norm: 3.152465157280492
Epoch: 2080, Batch Gradient Norm after: 3.152465157280492
Epoch 2081/10000, Prediction Accuracy = 60.63461538461539%, Loss = 0.009589807918438545
Epoch: 2081, Batch Gradient Norm: 3.000558523530401
Epoch: 2081, Batch Gradient Norm after: 3.000558523530401
Epoch 2082/10000, Prediction Accuracy = 60.52692307692309%, Loss = 0.009509893420797128
Epoch: 2082, Batch Gradient Norm: 2.896024561490671
Epoch: 2082, Batch Gradient Norm after: 2.896024561490671
Epoch 2083/10000, Prediction Accuracy = 61.030769230769224%, Loss = 0.009388642385601997
Epoch: 2083, Batch Gradient Norm: 2.8014566903395224
Epoch: 2083, Batch Gradient Norm after: 2.8014566903395224
Epoch 2084/10000, Prediction Accuracy = 61.38461538461537%, Loss = 0.00926844861644965
Epoch: 2084, Batch Gradient Norm: 2.9151312475252382
Epoch: 2084, Batch Gradient Norm after: 2.9151312475252382
Epoch 2085/10000, Prediction Accuracy = 61.01923076923077%, Loss = 0.009374734945595264
Epoch: 2085, Batch Gradient Norm: 2.937284994011439
Epoch: 2085, Batch Gradient Norm after: 2.937284994011439
Epoch 2086/10000, Prediction Accuracy = 60.684615384615384%, Loss = 0.00942533420255551
Epoch: 2086, Batch Gradient Norm: 3.2826182732197515
Epoch: 2086, Batch Gradient Norm after: 3.2826182732197515
Epoch 2087/10000, Prediction Accuracy = 60.16538461538463%, Loss = 0.009543191713209335
Epoch: 2087, Batch Gradient Norm: 3.0503473664327894
Epoch: 2087, Batch Gradient Norm after: 3.0503473664327894
Epoch 2088/10000, Prediction Accuracy = 60.51153846153847%, Loss = 0.009466771609508075
Epoch: 2088, Batch Gradient Norm: 3.2323677026784527
Epoch: 2088, Batch Gradient Norm after: 3.2323677026784527
Epoch 2089/10000, Prediction Accuracy = 60.68461538461538%, Loss = 0.009519475082365366
Epoch: 2089, Batch Gradient Norm: 3.1743838475514328
Epoch: 2089, Batch Gradient Norm after: 3.1743838475514328
Epoch 2090/10000, Prediction Accuracy = 60.90384615384615%, Loss = 0.009482539187257107
Epoch: 2090, Batch Gradient Norm: 2.8510352815831057
Epoch: 2090, Batch Gradient Norm after: 2.8510352815831057
Epoch 2091/10000, Prediction Accuracy = 61.3923076923077%, Loss = 0.009327055241626043
Epoch: 2091, Batch Gradient Norm: 3.2919592046267367
Epoch: 2091, Batch Gradient Norm after: 3.2919592046267367
Epoch 2092/10000, Prediction Accuracy = 60.48461538461538%, Loss = 0.009599283051032286
Epoch: 2092, Batch Gradient Norm: 2.89142553803385
Epoch: 2092, Batch Gradient Norm after: 2.89142553803385
Epoch 2093/10000, Prediction Accuracy = 60.638461538461534%, Loss = 0.009443399926217703
Epoch: 2093, Batch Gradient Norm: 2.950104462333944
Epoch: 2093, Batch Gradient Norm after: 2.950104462333944
Epoch 2094/10000, Prediction Accuracy = 60.83461538461539%, Loss = 0.009452592868071336
Epoch: 2094, Batch Gradient Norm: 3.092195274979634
Epoch: 2094, Batch Gradient Norm after: 3.092195274979634
Epoch 2095/10000, Prediction Accuracy = 60.75769230769231%, Loss = 0.009477150053358994
Epoch: 2095, Batch Gradient Norm: 3.151932314470847
Epoch: 2095, Batch Gradient Norm after: 3.151932314470847
Epoch 2096/10000, Prediction Accuracy = 60.30769230769231%, Loss = 0.009537351031142931
Epoch: 2096, Batch Gradient Norm: 3.2006641065215526
Epoch: 2096, Batch Gradient Norm after: 3.2006641065215526
Epoch 2097/10000, Prediction Accuracy = 60.49615384615384%, Loss = 0.009524199037024608
Epoch: 2097, Batch Gradient Norm: 3.1058413535204434
Epoch: 2097, Batch Gradient Norm after: 3.1058413535204434
Epoch 2098/10000, Prediction Accuracy = 60.61153846153847%, Loss = 0.009511535270855976
Epoch: 2098, Batch Gradient Norm: 3.052839147093014
Epoch: 2098, Batch Gradient Norm after: 3.052839147093014
Epoch 2099/10000, Prediction Accuracy = 60.49999999999999%, Loss = 0.00943906970608693
Epoch: 2099, Batch Gradient Norm: 3.068117170633035
Epoch: 2099, Batch Gradient Norm after: 3.068117170633035
Epoch 2100/10000, Prediction Accuracy = 60.44230769230769%, Loss = 0.009514535060868813
Epoch: 2100, Batch Gradient Norm: 3.1802743831714326
Epoch: 2100, Batch Gradient Norm after: 3.1802743831714326
Epoch 2101/10000, Prediction Accuracy = 60.73846153846154%, Loss = 0.009573817539673585
Epoch: 2101, Batch Gradient Norm: 3.165459826255566
Epoch: 2101, Batch Gradient Norm after: 3.165459826255566
Epoch 2102/10000, Prediction Accuracy = 60.446153846153834%, Loss = 0.009594661900057243
Epoch: 2102, Batch Gradient Norm: 2.9670301148361986
Epoch: 2102, Batch Gradient Norm after: 2.9670301148361986
Epoch 2103/10000, Prediction Accuracy = 60.784615384615385%, Loss = 0.009431862773803564
Epoch: 2103, Batch Gradient Norm: 3.0732296047555065
Epoch: 2103, Batch Gradient Norm after: 3.0732296047555065
Epoch 2104/10000, Prediction Accuracy = 60.60384615384616%, Loss = 0.009549044359188814
Epoch: 2104, Batch Gradient Norm: 3.028705977248096
Epoch: 2104, Batch Gradient Norm after: 3.028705977248096
Epoch 2105/10000, Prediction Accuracy = 60.68846153846153%, Loss = 0.009500722902325483
Epoch: 2105, Batch Gradient Norm: 2.917863165836146
Epoch: 2105, Batch Gradient Norm after: 2.917863165836146
Epoch 2106/10000, Prediction Accuracy = 60.46153846153846%, Loss = 0.009413586929440498
Epoch: 2106, Batch Gradient Norm: 2.829166715357316
Epoch: 2106, Batch Gradient Norm after: 2.829166715357316
Epoch 2107/10000, Prediction Accuracy = 60.638461538461534%, Loss = 0.009368190685143838
Epoch: 2107, Batch Gradient Norm: 2.941410276607872
Epoch: 2107, Batch Gradient Norm after: 2.941410276607872
Epoch 2108/10000, Prediction Accuracy = 61.18076923076922%, Loss = 0.009348147763655735
Epoch: 2108, Batch Gradient Norm: 3.215450488236825
Epoch: 2108, Batch Gradient Norm after: 3.215450488236825
Epoch 2109/10000, Prediction Accuracy = 60.52307692307693%, Loss = 0.009444231525636636
Epoch: 2109, Batch Gradient Norm: 3.3182745329917465
Epoch: 2109, Batch Gradient Norm after: 3.3182745329917465
Epoch 2110/10000, Prediction Accuracy = 60.638461538461534%, Loss = 0.009593168560128946
Epoch: 2110, Batch Gradient Norm: 3.6152392626506415
Epoch: 2110, Batch Gradient Norm after: 3.6152392626506415
Epoch 2111/10000, Prediction Accuracy = 60.28846153846153%, Loss = 0.009675977966533257
Epoch: 2111, Batch Gradient Norm: 2.876746686121412
Epoch: 2111, Batch Gradient Norm after: 2.876746686121412
Epoch 2112/10000, Prediction Accuracy = 60.56923076923077%, Loss = 0.009466588497161865
Epoch: 2112, Batch Gradient Norm: 3.030723168985382
Epoch: 2112, Batch Gradient Norm after: 3.030723168985382
Epoch 2113/10000, Prediction Accuracy = 60.61538461538463%, Loss = 0.009421258591688596
Epoch: 2113, Batch Gradient Norm: 3.055015289172092
Epoch: 2113, Batch Gradient Norm after: 3.055015289172092
Epoch 2114/10000, Prediction Accuracy = 60.63076923076923%, Loss = 0.009471101256517263
Epoch: 2114, Batch Gradient Norm: 3.1969162314844715
Epoch: 2114, Batch Gradient Norm after: 3.1969162314844715
Epoch 2115/10000, Prediction Accuracy = 60.70769230769231%, Loss = 0.00949503223483379
Epoch: 2115, Batch Gradient Norm: 3.1709893127755824
Epoch: 2115, Batch Gradient Norm after: 3.1709893127755824
Epoch 2116/10000, Prediction Accuracy = 60.22307692307693%, Loss = 0.009504703231728993
Epoch: 2116, Batch Gradient Norm: 3.417516629333527
Epoch: 2116, Batch Gradient Norm after: 3.417516629333527
Epoch 2117/10000, Prediction Accuracy = 60.42692307692307%, Loss = 0.00968058049105681
Epoch: 2117, Batch Gradient Norm: 3.4093518066625714
Epoch: 2117, Batch Gradient Norm after: 3.4093518066625714
Epoch 2118/10000, Prediction Accuracy = 60.43846153846155%, Loss = 0.009684573500775374
Epoch: 2118, Batch Gradient Norm: 2.970173164150389
Epoch: 2118, Batch Gradient Norm after: 2.970173164150389
Epoch 2119/10000, Prediction Accuracy = 61.08076923076924%, Loss = 0.009380699063722905
Epoch: 2119, Batch Gradient Norm: 2.7217212758829086
Epoch: 2119, Batch Gradient Norm after: 2.7217212758829086
Epoch 2120/10000, Prediction Accuracy = 61.21923076923077%, Loss = 0.0093126198133597
Epoch: 2120, Batch Gradient Norm: 2.8345039808981296
Epoch: 2120, Batch Gradient Norm after: 2.8345039808981296
Epoch 2121/10000, Prediction Accuracy = 61.096153846153854%, Loss = 0.009377233182581572
Epoch: 2121, Batch Gradient Norm: 3.009096805383678
Epoch: 2121, Batch Gradient Norm after: 3.009096805383678
Epoch 2122/10000, Prediction Accuracy = 60.892307692307696%, Loss = 0.00945603080953543
Epoch: 2122, Batch Gradient Norm: 3.620470306512964
Epoch: 2122, Batch Gradient Norm after: 3.620470306512964
Epoch 2123/10000, Prediction Accuracy = 59.54615384615386%, Loss = 0.009824754670262337
Epoch: 2123, Batch Gradient Norm: 3.2167615990151863
Epoch: 2123, Batch Gradient Norm after: 3.2167615990151863
Epoch 2124/10000, Prediction Accuracy = 60.09999999999999%, Loss = 0.009628682827147154
Epoch: 2124, Batch Gradient Norm: 2.897674084081408
Epoch: 2124, Batch Gradient Norm after: 2.897674084081408
Epoch 2125/10000, Prediction Accuracy = 60.73846153846154%, Loss = 0.009426017435124287
Epoch: 2125, Batch Gradient Norm: 2.8707418126199786
Epoch: 2125, Batch Gradient Norm after: 2.8707418126199786
Epoch 2126/10000, Prediction Accuracy = 60.85000000000001%, Loss = 0.00939175937897884
Epoch: 2126, Batch Gradient Norm: 3.0019627418215036
Epoch: 2126, Batch Gradient Norm after: 3.0019627418215036
Epoch 2127/10000, Prediction Accuracy = 60.63461538461539%, Loss = 0.00943037337408616
Epoch: 2127, Batch Gradient Norm: 3.2606669604347123
Epoch: 2127, Batch Gradient Norm after: 3.2606669604347123
Epoch 2128/10000, Prediction Accuracy = 60.48461538461539%, Loss = 0.009457795379253535
Epoch: 2128, Batch Gradient Norm: 3.216788714879859
Epoch: 2128, Batch Gradient Norm after: 3.216788714879859
Epoch 2129/10000, Prediction Accuracy = 60.37692307692308%, Loss = 0.009584051413604846
Epoch: 2129, Batch Gradient Norm: 2.980423029502353
Epoch: 2129, Batch Gradient Norm after: 2.980423029502353
Epoch 2130/10000, Prediction Accuracy = 60.35000000000001%, Loss = 0.009470006522650901
Epoch: 2130, Batch Gradient Norm: 3.2877069462311552
Epoch: 2130, Batch Gradient Norm after: 3.2877069462311552
Epoch 2131/10000, Prediction Accuracy = 60.526923076923076%, Loss = 0.009468477649184374
Epoch: 2131, Batch Gradient Norm: 3.1085772741188484
Epoch: 2131, Batch Gradient Norm after: 3.1085772741188484
Epoch 2132/10000, Prediction Accuracy = 60.96153846153847%, Loss = 0.009442925883027224
Epoch: 2132, Batch Gradient Norm: 3.1037207554954116
Epoch: 2132, Batch Gradient Norm after: 3.1037207554954116
Epoch 2133/10000, Prediction Accuracy = 61.12692307692306%, Loss = 0.009406543193528285
Epoch: 2133, Batch Gradient Norm: 3.110160408117319
Epoch: 2133, Batch Gradient Norm after: 3.110160408117319
Epoch 2134/10000, Prediction Accuracy = 60.42692307692307%, Loss = 0.009486780072060915
Epoch: 2134, Batch Gradient Norm: 2.851622293509835
Epoch: 2134, Batch Gradient Norm after: 2.851622293509835
Epoch 2135/10000, Prediction Accuracy = 60.91923076923077%, Loss = 0.009340306672339257
Epoch: 2135, Batch Gradient Norm: 3.374376259614295
Epoch: 2135, Batch Gradient Norm after: 3.374376259614295
Epoch 2136/10000, Prediction Accuracy = 60.33076923076923%, Loss = 0.009644000576092647
Epoch: 2136, Batch Gradient Norm: 3.3438490398954945
Epoch: 2136, Batch Gradient Norm after: 3.3438490398954945
Epoch 2137/10000, Prediction Accuracy = 59.98076923076923%, Loss = 0.00974853766652254
Epoch: 2137, Batch Gradient Norm: 3.2927708196747685
Epoch: 2137, Batch Gradient Norm after: 3.2927708196747685
Epoch 2138/10000, Prediction Accuracy = 60.26923076923078%, Loss = 0.009525080139820393
Epoch: 2138, Batch Gradient Norm: 2.8804699631171418
Epoch: 2138, Batch Gradient Norm after: 2.8804699631171418
Epoch 2139/10000, Prediction Accuracy = 61.00769230769231%, Loss = 0.009252337667231377
Epoch: 2139, Batch Gradient Norm: 3.276513040701435
Epoch: 2139, Batch Gradient Norm after: 3.276513040701435
Epoch 2140/10000, Prediction Accuracy = 60.380769230769225%, Loss = 0.009535700011138733
Epoch: 2140, Batch Gradient Norm: 3.078051038043372
Epoch: 2140, Batch Gradient Norm after: 3.078051038043372
Epoch 2141/10000, Prediction Accuracy = 60.565384615384616%, Loss = 0.009454195960783042
Epoch: 2141, Batch Gradient Norm: 2.7832949494551142
Epoch: 2141, Batch Gradient Norm after: 2.7832949494551142
Epoch 2142/10000, Prediction Accuracy = 61.065384615384616%, Loss = 0.009330119794377914
Epoch: 2142, Batch Gradient Norm: 2.9613078984012704
Epoch: 2142, Batch Gradient Norm after: 2.9613078984012704
Epoch 2143/10000, Prediction Accuracy = 60.47692307692308%, Loss = 0.009368786659951393
Epoch: 2143, Batch Gradient Norm: 3.2405661217408004
Epoch: 2143, Batch Gradient Norm after: 3.2405661217408004
Epoch 2144/10000, Prediction Accuracy = 60.78076923076923%, Loss = 0.009470918788932838
Epoch: 2144, Batch Gradient Norm: 3.454931898108173
Epoch: 2144, Batch Gradient Norm after: 3.454931898108173
Epoch 2145/10000, Prediction Accuracy = 60.24230769230769%, Loss = 0.00959445908665657
Epoch: 2145, Batch Gradient Norm: 3.4628500877800663
Epoch: 2145, Batch Gradient Norm after: 3.4628500877800663
Epoch 2146/10000, Prediction Accuracy = 60.273076923076914%, Loss = 0.0097155047294039
Epoch: 2146, Batch Gradient Norm: 3.368045242455738
Epoch: 2146, Batch Gradient Norm after: 3.368045242455738
Epoch 2147/10000, Prediction Accuracy = 60.63076923076923%, Loss = 0.009583904766119443
Epoch: 2147, Batch Gradient Norm: 3.1689044137514157
Epoch: 2147, Batch Gradient Norm after: 3.1689044137514157
Epoch 2148/10000, Prediction Accuracy = 60.70384615384615%, Loss = 0.009491159938848935
Epoch: 2148, Batch Gradient Norm: 3.0987991357003586
Epoch: 2148, Batch Gradient Norm after: 3.0987991357003586
Epoch 2149/10000, Prediction Accuracy = 61.10000000000001%, Loss = 0.009434801884568654
Epoch: 2149, Batch Gradient Norm: 3.183273095988867
Epoch: 2149, Batch Gradient Norm after: 3.183273095988867
Epoch 2150/10000, Prediction Accuracy = 60.70769230769231%, Loss = 0.009528468219706645
Epoch: 2150, Batch Gradient Norm: 3.2891936327098623
Epoch: 2150, Batch Gradient Norm after: 3.2891936327098623
Epoch 2151/10000, Prediction Accuracy = 60.223076923076924%, Loss = 0.009551878445423566
Epoch: 2151, Batch Gradient Norm: 3.029710344103028
Epoch: 2151, Batch Gradient Norm after: 3.029710344103028
Epoch 2152/10000, Prediction Accuracy = 60.91538461538461%, Loss = 0.009423053178649683
Epoch: 2152, Batch Gradient Norm: 2.9968901176347904
Epoch: 2152, Batch Gradient Norm after: 2.9968901176347904
Epoch 2153/10000, Prediction Accuracy = 60.76153846153846%, Loss = 0.009317890454370242
Epoch: 2153, Batch Gradient Norm: 3.2421941961103236
Epoch: 2153, Batch Gradient Norm after: 3.2421941961103236
Epoch 2154/10000, Prediction Accuracy = 61.119230769230775%, Loss = 0.009361767639907507
Epoch: 2154, Batch Gradient Norm: 3.0707616228858123
Epoch: 2154, Batch Gradient Norm after: 3.0707616228858123
Epoch 2155/10000, Prediction Accuracy = 60.94615384615385%, Loss = 0.00943082284468871
Epoch: 2155, Batch Gradient Norm: 3.1787398351482725
Epoch: 2155, Batch Gradient Norm after: 3.1787398351482725
Epoch 2156/10000, Prediction Accuracy = 60.41923076923077%, Loss = 0.00947245668906432
Epoch: 2156, Batch Gradient Norm: 3.431546834289427
Epoch: 2156, Batch Gradient Norm after: 3.431546834289427
Epoch 2157/10000, Prediction Accuracy = 60.465384615384615%, Loss = 0.009584854285304364
Epoch: 2157, Batch Gradient Norm: 3.4859856380538177
Epoch: 2157, Batch Gradient Norm after: 3.4859856380538177
Epoch 2158/10000, Prediction Accuracy = 60.11538461538461%, Loss = 0.009700792698332896
Epoch: 2158, Batch Gradient Norm: 3.082882854036092
Epoch: 2158, Batch Gradient Norm after: 3.082882854036092
Epoch 2159/10000, Prediction Accuracy = 60.21153846153846%, Loss = 0.009486922349494237
Epoch: 2159, Batch Gradient Norm: 2.996869820631742
Epoch: 2159, Batch Gradient Norm after: 2.996869820631742
Epoch 2160/10000, Prediction Accuracy = 61.01923076923076%, Loss = 0.009351564499621209
Epoch: 2160, Batch Gradient Norm: 2.8509607096316705
Epoch: 2160, Batch Gradient Norm after: 2.8509607096316705
Epoch 2161/10000, Prediction Accuracy = 61.284615384615385%, Loss = 0.009240750724879595
Epoch: 2161, Batch Gradient Norm: 2.9612265133033064
Epoch: 2161, Batch Gradient Norm after: 2.9612265133033064
Epoch 2162/10000, Prediction Accuracy = 61.39615384615385%, Loss = 0.009251198659722622
Epoch: 2162, Batch Gradient Norm: 2.9056954749719073
Epoch: 2162, Batch Gradient Norm after: 2.9056954749719073
Epoch 2163/10000, Prediction Accuracy = 61.31153846153847%, Loss = 0.009194122842298104
Epoch: 2163, Batch Gradient Norm: 3.068062064620128
Epoch: 2163, Batch Gradient Norm after: 3.068062064620128
Epoch 2164/10000, Prediction Accuracy = 60.8346153846154%, Loss = 0.009312688229748836
Epoch: 2164, Batch Gradient Norm: 3.094696746264191
Epoch: 2164, Batch Gradient Norm after: 3.094696746264191
Epoch 2165/10000, Prediction Accuracy = 60.665384615384625%, Loss = 0.009378297182802971
Epoch: 2165, Batch Gradient Norm: 3.311388569826909
Epoch: 2165, Batch Gradient Norm after: 3.311388569826909
Epoch 2166/10000, Prediction Accuracy = 60.63076923076923%, Loss = 0.00948206063073415
Epoch: 2166, Batch Gradient Norm: 3.1387865889693143
Epoch: 2166, Batch Gradient Norm after: 3.1387865889693143
Epoch 2167/10000, Prediction Accuracy = 60.74615384615386%, Loss = 0.00945008395669552
Epoch: 2167, Batch Gradient Norm: 3.4103134253565393
Epoch: 2167, Batch Gradient Norm after: 3.4103134253565393
Epoch 2168/10000, Prediction Accuracy = 60.53076923076924%, Loss = 0.009575616353406357
Epoch: 2168, Batch Gradient Norm: 3.268000954794783
Epoch: 2168, Batch Gradient Norm after: 3.268000954794783
Epoch 2169/10000, Prediction Accuracy = 60.65384615384615%, Loss = 0.009539451665030075
Epoch: 2169, Batch Gradient Norm: 3.3689837753594376
Epoch: 2169, Batch Gradient Norm after: 3.3689837753594376
Epoch 2170/10000, Prediction Accuracy = 60.28461538461538%, Loss = 0.00959091791166709
Epoch: 2170, Batch Gradient Norm: 3.0812051791262167
Epoch: 2170, Batch Gradient Norm after: 3.0812051791262167
Epoch 2171/10000, Prediction Accuracy = 60.896153846153844%, Loss = 0.009423767359784016
Epoch: 2171, Batch Gradient Norm: 3.3147074475485265
Epoch: 2171, Batch Gradient Norm after: 3.3147074475485265
Epoch 2172/10000, Prediction Accuracy = 60.98846153846153%, Loss = 0.009479408295681844
Epoch: 2172, Batch Gradient Norm: 3.2336483502260416
Epoch: 2172, Batch Gradient Norm after: 3.2336483502260416
Epoch 2173/10000, Prediction Accuracy = 61.04615384615386%, Loss = 0.009339200046200018
Epoch: 2173, Batch Gradient Norm: 2.9458935271741806
Epoch: 2173, Batch Gradient Norm after: 2.9458935271741806
Epoch 2174/10000, Prediction Accuracy = 61.48846153846154%, Loss = 0.009291898100995101
Epoch: 2174, Batch Gradient Norm: 3.1846734538206958
Epoch: 2174, Batch Gradient Norm after: 3.1846734538206958
Epoch 2175/10000, Prediction Accuracy = 61.030769230769224%, Loss = 0.009374174647606336
Epoch: 2175, Batch Gradient Norm: 3.0857746919006916
Epoch: 2175, Batch Gradient Norm after: 3.0857746919006916
Epoch 2176/10000, Prediction Accuracy = 60.723076923076924%, Loss = 0.00938402646436141
Epoch: 2176, Batch Gradient Norm: 3.0146950836778106
Epoch: 2176, Batch Gradient Norm after: 3.0146950836778106
Epoch 2177/10000, Prediction Accuracy = 61.01923076923076%, Loss = 0.009348198914757142
Epoch: 2177, Batch Gradient Norm: 2.8339368369345417
Epoch: 2177, Batch Gradient Norm after: 2.8339368369345417
Epoch 2178/10000, Prediction Accuracy = 61.0923076923077%, Loss = 0.009243051951321272
Epoch: 2178, Batch Gradient Norm: 3.3498011010003803
Epoch: 2178, Batch Gradient Norm after: 3.3498011010003803
Epoch 2179/10000, Prediction Accuracy = 60.25769230769231%, Loss = 0.009501801158946294
Epoch: 2179, Batch Gradient Norm: 3.198200338918997
Epoch: 2179, Batch Gradient Norm after: 3.198200338918997
Epoch 2180/10000, Prediction Accuracy = 60.723076923076924%, Loss = 0.009402161464095116
Epoch: 2180, Batch Gradient Norm: 3.2766154084353554
Epoch: 2180, Batch Gradient Norm after: 3.2766154084353554
Epoch 2181/10000, Prediction Accuracy = 60.661538461538456%, Loss = 0.009448939074690525
Epoch: 2181, Batch Gradient Norm: 2.9403942905664153
Epoch: 2181, Batch Gradient Norm after: 2.9403942905664153
Epoch 2182/10000, Prediction Accuracy = 60.93846153846155%, Loss = 0.00929999122252831
Epoch: 2182, Batch Gradient Norm: 2.8672693594141623
Epoch: 2182, Batch Gradient Norm after: 2.8672693594141623
Epoch 2183/10000, Prediction Accuracy = 61.357692307692304%, Loss = 0.009176362449159989
Epoch: 2183, Batch Gradient Norm: 3.1019915987147653
Epoch: 2183, Batch Gradient Norm after: 3.1019915987147653
Epoch 2184/10000, Prediction Accuracy = 61.119230769230775%, Loss = 0.009265850513027264
Epoch: 2184, Batch Gradient Norm: 3.009800972726818
Epoch: 2184, Batch Gradient Norm after: 3.009800972726818
Epoch 2185/10000, Prediction Accuracy = 60.96923076923076%, Loss = 0.009257521193761092
Epoch: 2185, Batch Gradient Norm: 3.0857570881054017
Epoch: 2185, Batch Gradient Norm after: 3.0857570881054017
Epoch 2186/10000, Prediction Accuracy = 61.14230769230768%, Loss = 0.009311752393841743
Epoch: 2186, Batch Gradient Norm: 3.0962465919173643
Epoch: 2186, Batch Gradient Norm after: 3.0962465919173643
Epoch 2187/10000, Prediction Accuracy = 61.1576923076923%, Loss = 0.009320071181998802
Epoch: 2187, Batch Gradient Norm: 3.4578077945308427
Epoch: 2187, Batch Gradient Norm after: 3.4578077945308427
Epoch 2188/10000, Prediction Accuracy = 60.30384615384616%, Loss = 0.009474994328159552
Epoch: 2188, Batch Gradient Norm: 3.3727608338899824
Epoch: 2188, Batch Gradient Norm after: 3.3727608338899824
Epoch 2189/10000, Prediction Accuracy = 60.86923076923077%, Loss = 0.009429020019104848
Epoch: 2189, Batch Gradient Norm: 3.20586800554728
Epoch: 2189, Batch Gradient Norm after: 3.20586800554728
Epoch 2190/10000, Prediction Accuracy = 60.5923076923077%, Loss = 0.009361015990949594
Epoch: 2190, Batch Gradient Norm: 3.126325380387117
Epoch: 2190, Batch Gradient Norm after: 3.126325380387117
Epoch 2191/10000, Prediction Accuracy = 60.692307692307686%, Loss = 0.009432414761529518
Epoch: 2191, Batch Gradient Norm: 2.7328257688032696
Epoch: 2191, Batch Gradient Norm after: 2.7328257688032696
Epoch 2192/10000, Prediction Accuracy = 61.53846153846153%, Loss = 0.00915425385420139
Epoch: 2192, Batch Gradient Norm: 3.2842949501203367
Epoch: 2192, Batch Gradient Norm after: 3.2842949501203367
Epoch 2193/10000, Prediction Accuracy = 60.52307692307693%, Loss = 0.00936004569610724
Epoch: 2193, Batch Gradient Norm: 3.283781375258956
Epoch: 2193, Batch Gradient Norm after: 3.283781375258956
Epoch 2194/10000, Prediction Accuracy = 60.72307692307693%, Loss = 0.009379011220656909
Epoch: 2194, Batch Gradient Norm: 3.2183207524065556
Epoch: 2194, Batch Gradient Norm after: 3.2183207524065556
Epoch 2195/10000, Prediction Accuracy = 61.00384615384615%, Loss = 0.009331212737239324
Epoch: 2195, Batch Gradient Norm: 3.3391126800818407
Epoch: 2195, Batch Gradient Norm after: 3.3391126800818407
Epoch 2196/10000, Prediction Accuracy = 60.78461538461538%, Loss = 0.00937202673118848
Epoch: 2196, Batch Gradient Norm: 3.2909495226032988
Epoch: 2196, Batch Gradient Norm after: 3.2909495226032988
Epoch 2197/10000, Prediction Accuracy = 60.80769230769231%, Loss = 0.009493542190354604
Epoch: 2197, Batch Gradient Norm: 3.147797186742383
Epoch: 2197, Batch Gradient Norm after: 3.147797186742383
Epoch 2198/10000, Prediction Accuracy = 60.94230769230769%, Loss = 0.009367489685805945
Epoch: 2198, Batch Gradient Norm: 3.2135547538691465
Epoch: 2198, Batch Gradient Norm after: 3.2135547538691465
Epoch 2199/10000, Prediction Accuracy = 61.16153846153846%, Loss = 0.0093411782469887
Epoch: 2199, Batch Gradient Norm: 3.3122992722668942
Epoch: 2199, Batch Gradient Norm after: 3.3122992722668942
Epoch 2200/10000, Prediction Accuracy = 60.84615384615385%, Loss = 0.009426463968478717
Epoch: 2200, Batch Gradient Norm: 3.3233512030008123
Epoch: 2200, Batch Gradient Norm after: 3.3233512030008123
Epoch 2201/10000, Prediction Accuracy = 60.48076923076923%, Loss = 0.009513867374223012
Epoch: 2201, Batch Gradient Norm: 3.366418063346944
Epoch: 2201, Batch Gradient Norm after: 3.366418063346944
Epoch 2202/10000, Prediction Accuracy = 60.361538461538466%, Loss = 0.009562214693197837
Epoch: 2202, Batch Gradient Norm: 2.953187199479785
Epoch: 2202, Batch Gradient Norm after: 2.953187199479785
Epoch 2203/10000, Prediction Accuracy = 61.3423076923077%, Loss = 0.009233905432315974
Epoch: 2203, Batch Gradient Norm: 2.9294939851206365
Epoch: 2203, Batch Gradient Norm after: 2.9294939851206365
Epoch 2204/10000, Prediction Accuracy = 61.43076923076923%, Loss = 0.009156900744598646
Epoch: 2204, Batch Gradient Norm: 3.1786104895496203
Epoch: 2204, Batch Gradient Norm after: 3.1786104895496203
Epoch 2205/10000, Prediction Accuracy = 61.326923076923094%, Loss = 0.009282659667615708
Epoch: 2205, Batch Gradient Norm: 3.429384040072486
Epoch: 2205, Batch Gradient Norm after: 3.429384040072486
Epoch 2206/10000, Prediction Accuracy = 60.4423076923077%, Loss = 0.009513009339571
Epoch: 2206, Batch Gradient Norm: 3.19448483450032
Epoch: 2206, Batch Gradient Norm after: 3.19448483450032
Epoch 2207/10000, Prediction Accuracy = 61.01153846153847%, Loss = 0.009308100463106083
Epoch: 2207, Batch Gradient Norm: 3.193987741188003
Epoch: 2207, Batch Gradient Norm after: 3.193987741188003
Epoch 2208/10000, Prediction Accuracy = 60.93846153846153%, Loss = 0.00934860110282898
Epoch: 2208, Batch Gradient Norm: 3.2808240300875804
Epoch: 2208, Batch Gradient Norm after: 3.2808240300875804
Epoch 2209/10000, Prediction Accuracy = 60.94230769230769%, Loss = 0.009366416587279392
Epoch: 2209, Batch Gradient Norm: 3.2805032989132275
Epoch: 2209, Batch Gradient Norm after: 3.2805032989132275
Epoch 2210/10000, Prediction Accuracy = 60.842307692307685%, Loss = 0.00936300465120719
Epoch: 2210, Batch Gradient Norm: 3.0964364359964396
Epoch: 2210, Batch Gradient Norm after: 3.0964364359964396
Epoch 2211/10000, Prediction Accuracy = 60.869230769230754%, Loss = 0.00938358000264718
Epoch: 2211, Batch Gradient Norm: 3.1035504964606324
Epoch: 2211, Batch Gradient Norm after: 3.1035504964606324
Epoch 2212/10000, Prediction Accuracy = 60.76923076923076%, Loss = 0.009330743565582313
Epoch: 2212, Batch Gradient Norm: 2.7906826678928036
Epoch: 2212, Batch Gradient Norm after: 2.7906826678928036
Epoch 2213/10000, Prediction Accuracy = 61.46923076923077%, Loss = 0.009163554829473678
Epoch: 2213, Batch Gradient Norm: 3.1846169262463873
Epoch: 2213, Batch Gradient Norm after: 3.1846169262463873
Epoch 2214/10000, Prediction Accuracy = 60.619230769230775%, Loss = 0.00937191740824626
Epoch: 2214, Batch Gradient Norm: 3.3426868235047595
Epoch: 2214, Batch Gradient Norm after: 3.3426868235047595
Epoch 2215/10000, Prediction Accuracy = 60.5076923076923%, Loss = 0.009443187871231483
Epoch: 2215, Batch Gradient Norm: 3.202794459865641
Epoch: 2215, Batch Gradient Norm after: 3.202794459865641
Epoch 2216/10000, Prediction Accuracy = 61.10000000000001%, Loss = 0.009367970964656426
Epoch: 2216, Batch Gradient Norm: 3.047578326608726
Epoch: 2216, Batch Gradient Norm after: 3.047578326608726
Epoch 2217/10000, Prediction Accuracy = 61.23846153846154%, Loss = 0.009255455305370001
Epoch: 2217, Batch Gradient Norm: 3.126002222745977
Epoch: 2217, Batch Gradient Norm after: 3.126002222745977
Epoch 2218/10000, Prediction Accuracy = 61.27307692307693%, Loss = 0.009293524620051567
Epoch: 2218, Batch Gradient Norm: 3.137517590643472
Epoch: 2218, Batch Gradient Norm after: 3.137517590643472
Epoch 2219/10000, Prediction Accuracy = 60.93461538461539%, Loss = 0.00932264944108633
Epoch: 2219, Batch Gradient Norm: 3.187407284714834
Epoch: 2219, Batch Gradient Norm after: 3.187407284714834
Epoch 2220/10000, Prediction Accuracy = 61.03846153846153%, Loss = 0.009351056713897448
Epoch: 2220, Batch Gradient Norm: 3.2319216820418006
Epoch: 2220, Batch Gradient Norm after: 3.2319216820418006
Epoch 2221/10000, Prediction Accuracy = 60.77307692307692%, Loss = 0.009442685816723567
Epoch: 2221, Batch Gradient Norm: 3.35421414368533
Epoch: 2221, Batch Gradient Norm after: 3.35421414368533
Epoch 2222/10000, Prediction Accuracy = 60.52692307692309%, Loss = 0.009509814544939078
Epoch: 2222, Batch Gradient Norm: 3.359510636653567
Epoch: 2222, Batch Gradient Norm after: 3.359510636653567
Epoch 2223/10000, Prediction Accuracy = 60.588461538461544%, Loss = 0.009443717220654855
Epoch: 2223, Batch Gradient Norm: 3.349210449216911
Epoch: 2223, Batch Gradient Norm after: 3.349210449216911
Epoch 2224/10000, Prediction Accuracy = 60.66538461538461%, Loss = 0.009406788131365409
Epoch: 2224, Batch Gradient Norm: 3.166096328613772
Epoch: 2224, Batch Gradient Norm after: 3.166096328613772
Epoch 2225/10000, Prediction Accuracy = 61.080769230769235%, Loss = 0.009332334622740746
Epoch: 2225, Batch Gradient Norm: 3.223044461297139
Epoch: 2225, Batch Gradient Norm after: 3.223044461297139
Epoch 2226/10000, Prediction Accuracy = 61.23846153846152%, Loss = 0.009333951542010674
Epoch: 2226, Batch Gradient Norm: 3.33851785750646
Epoch: 2226, Batch Gradient Norm after: 3.33851785750646
Epoch 2227/10000, Prediction Accuracy = 60.7%, Loss = 0.009468659830208007
Epoch: 2227, Batch Gradient Norm: 3.3450874169232825
Epoch: 2227, Batch Gradient Norm after: 3.3450874169232825
Epoch 2228/10000, Prediction Accuracy = 60.9153846153846%, Loss = 0.00939151279341716
Epoch: 2228, Batch Gradient Norm: 3.152994669381285
Epoch: 2228, Batch Gradient Norm after: 3.152994669381285
Epoch 2229/10000, Prediction Accuracy = 60.869230769230775%, Loss = 0.009278734716085287
Epoch: 2229, Batch Gradient Norm: 3.1062978085539408
Epoch: 2229, Batch Gradient Norm after: 3.1062978085539408
Epoch 2230/10000, Prediction Accuracy = 61.01923076923077%, Loss = 0.009311868379322382
Epoch: 2230, Batch Gradient Norm: 2.9215469667440006
Epoch: 2230, Batch Gradient Norm after: 2.9215469667440006
Epoch 2231/10000, Prediction Accuracy = 61.284615384615385%, Loss = 0.009226518898056103
Epoch: 2231, Batch Gradient Norm: 3.4887750298422424
Epoch: 2231, Batch Gradient Norm after: 3.4887750298422424
Epoch 2232/10000, Prediction Accuracy = 60.699999999999996%, Loss = 0.009496068581938744
Epoch: 2232, Batch Gradient Norm: 3.3081947425009957
Epoch: 2232, Batch Gradient Norm after: 3.3081947425009957
Epoch 2233/10000, Prediction Accuracy = 60.88076923076923%, Loss = 0.009332489867049914
Epoch: 2233, Batch Gradient Norm: 3.2854094642800655
Epoch: 2233, Batch Gradient Norm after: 3.2854094642800655
Epoch 2234/10000, Prediction Accuracy = 61.07307692307692%, Loss = 0.00938075465651659
Epoch: 2234, Batch Gradient Norm: 3.0940700994379977
Epoch: 2234, Batch Gradient Norm after: 3.0940700994379977
Epoch 2235/10000, Prediction Accuracy = 60.77307692307693%, Loss = 0.00941277352663187
Epoch: 2235, Batch Gradient Norm: 2.9679729757533937
Epoch: 2235, Batch Gradient Norm after: 2.9679729757533937
Epoch 2236/10000, Prediction Accuracy = 61.165384615384625%, Loss = 0.009190291811067324
Epoch: 2236, Batch Gradient Norm: 3.093174192145794
Epoch: 2236, Batch Gradient Norm after: 3.093174192145794
Epoch 2237/10000, Prediction Accuracy = 61.292307692307695%, Loss = 0.009311006691020269
Epoch: 2237, Batch Gradient Norm: 3.191686185251556
Epoch: 2237, Batch Gradient Norm after: 3.191686185251556
Epoch 2238/10000, Prediction Accuracy = 61.103846153846156%, Loss = 0.009284013524078406
Epoch: 2238, Batch Gradient Norm: 3.2454236059976878
Epoch: 2238, Batch Gradient Norm after: 3.2454236059976878
Epoch 2239/10000, Prediction Accuracy = 61.01538461538461%, Loss = 0.009323088810420953
Epoch: 2239, Batch Gradient Norm: 3.2025957386429957
Epoch: 2239, Batch Gradient Norm after: 3.2025957386429957
Epoch 2240/10000, Prediction Accuracy = 61.26538461538462%, Loss = 0.009329203587885086
Epoch: 2240, Batch Gradient Norm: 3.006292335587576
Epoch: 2240, Batch Gradient Norm after: 3.006292335587576
Epoch 2241/10000, Prediction Accuracy = 61.223076923076924%, Loss = 0.009195212847911395
Epoch: 2241, Batch Gradient Norm: 2.976788468510922
Epoch: 2241, Batch Gradient Norm after: 2.976788468510922
Epoch 2242/10000, Prediction Accuracy = 61.17307692307691%, Loss = 0.009223929319817286
Epoch: 2242, Batch Gradient Norm: 3.0287281307452347
Epoch: 2242, Batch Gradient Norm after: 3.0287281307452347
Epoch 2243/10000, Prediction Accuracy = 61.15384615384615%, Loss = 0.009231195140343446
Epoch: 2243, Batch Gradient Norm: 3.348260470950071
Epoch: 2243, Batch Gradient Norm after: 3.348260470950071
Epoch 2244/10000, Prediction Accuracy = 61.015384615384626%, Loss = 0.009288017852948261
Epoch: 2244, Batch Gradient Norm: 3.3424711716781164
Epoch: 2244, Batch Gradient Norm after: 3.3424711716781164
Epoch 2245/10000, Prediction Accuracy = 60.83461538461537%, Loss = 0.009353120166521806
Epoch: 2245, Batch Gradient Norm: 3.0112660707742664
Epoch: 2245, Batch Gradient Norm after: 3.0112660707742664
Epoch 2246/10000, Prediction Accuracy = 61.342307692307685%, Loss = 0.009169690310955048
Epoch: 2246, Batch Gradient Norm: 3.3853224744990067
Epoch: 2246, Batch Gradient Norm after: 3.3853224744990067
Epoch 2247/10000, Prediction Accuracy = 60.67307692307692%, Loss = 0.009365805138189059
Epoch: 2247, Batch Gradient Norm: 3.179989125880339
Epoch: 2247, Batch Gradient Norm after: 3.179989125880339
Epoch 2248/10000, Prediction Accuracy = 60.78076923076923%, Loss = 0.009279009957726184
Epoch: 2248, Batch Gradient Norm: 2.9824082788884048
Epoch: 2248, Batch Gradient Norm after: 2.9824082788884048
Epoch 2249/10000, Prediction Accuracy = 61.388461538461534%, Loss = 0.00915704581599969
Epoch: 2249, Batch Gradient Norm: 3.409997462397258
Epoch: 2249, Batch Gradient Norm after: 3.409997462397258
Epoch 2250/10000, Prediction Accuracy = 60.64999999999999%, Loss = 0.009390645732100193
Epoch: 2250, Batch Gradient Norm: 3.25402117681738
Epoch: 2250, Batch Gradient Norm after: 3.25402117681738
Epoch 2251/10000, Prediction Accuracy = 61.034615384615385%, Loss = 0.009286580965496026
Epoch: 2251, Batch Gradient Norm: 3.031318270443523
Epoch: 2251, Batch Gradient Norm after: 3.031318270443523
Epoch 2252/10000, Prediction Accuracy = 61.526923076923076%, Loss = 0.009143821751842132
Epoch: 2252, Batch Gradient Norm: 3.198372588766892
Epoch: 2252, Batch Gradient Norm after: 3.198372588766892
Epoch 2253/10000, Prediction Accuracy = 60.865384615384606%, Loss = 0.009262550049103223
Epoch: 2253, Batch Gradient Norm: 3.465928676317773
Epoch: 2253, Batch Gradient Norm after: 3.465928676317773
Epoch 2254/10000, Prediction Accuracy = 60.923076923076934%, Loss = 0.009375303625487365
Epoch: 2254, Batch Gradient Norm: 3.5222033708648723
Epoch: 2254, Batch Gradient Norm after: 3.5222033708648723
Epoch 2255/10000, Prediction Accuracy = 60.884615384615394%, Loss = 0.009510977766834773
Epoch: 2255, Batch Gradient Norm: 3.3869665744702995
Epoch: 2255, Batch Gradient Norm after: 3.3869665744702995
Epoch 2256/10000, Prediction Accuracy = 60.73076923076923%, Loss = 0.009412977916116897
Epoch: 2256, Batch Gradient Norm: 2.8752489271994763
Epoch: 2256, Batch Gradient Norm after: 2.8752489271994763
Epoch 2257/10000, Prediction Accuracy = 61.284615384615385%, Loss = 0.009179031977859827
Epoch: 2257, Batch Gradient Norm: 2.889442611182943
Epoch: 2257, Batch Gradient Norm after: 2.889442611182943
Epoch 2258/10000, Prediction Accuracy = 61.51153846153846%, Loss = 0.009133017263733424
Epoch: 2258, Batch Gradient Norm: 3.0921654028347776
Epoch: 2258, Batch Gradient Norm after: 3.0921654028347776
Epoch 2259/10000, Prediction Accuracy = 61.57692307692309%, Loss = 0.00916729408961076
Epoch: 2259, Batch Gradient Norm: 3.375889540476293
Epoch: 2259, Batch Gradient Norm after: 3.375889540476293
Epoch 2260/10000, Prediction Accuracy = 61.2423076923077%, Loss = 0.009313796718533222
Epoch: 2260, Batch Gradient Norm: 3.4352525208867872
Epoch: 2260, Batch Gradient Norm after: 3.4352525208867872
Epoch 2261/10000, Prediction Accuracy = 60.74615384615384%, Loss = 0.009410715661942959
Epoch: 2261, Batch Gradient Norm: 2.8996443201454314
Epoch: 2261, Batch Gradient Norm after: 2.8996443201454314
Epoch 2262/10000, Prediction Accuracy = 61.419230769230765%, Loss = 0.009134048166183325
Epoch: 2262, Batch Gradient Norm: 3.2735381851253704
Epoch: 2262, Batch Gradient Norm after: 3.2735381851253704
Epoch 2263/10000, Prediction Accuracy = 60.70384615384614%, Loss = 0.009326029783831192
Epoch: 2263, Batch Gradient Norm: 3.2077496530307323
Epoch: 2263, Batch Gradient Norm after: 3.2077496530307323
Epoch 2264/10000, Prediction Accuracy = 61.42307692307692%, Loss = 0.00917055751555241
Epoch: 2264, Batch Gradient Norm: 3.2743638279145655
Epoch: 2264, Batch Gradient Norm after: 3.2743638279145655
Epoch 2265/10000, Prediction Accuracy = 61.21923076923077%, Loss = 0.009191315692777816
Epoch: 2265, Batch Gradient Norm: 3.103449641139638
Epoch: 2265, Batch Gradient Norm after: 3.103449641139638
Epoch 2266/10000, Prediction Accuracy = 61.157692307692294%, Loss = 0.009212343595348872
Epoch: 2266, Batch Gradient Norm: 3.4402822550852106
Epoch: 2266, Batch Gradient Norm after: 3.4402822550852106
Epoch 2267/10000, Prediction Accuracy = 60.56923076923078%, Loss = 0.009424509623875985
Epoch: 2267, Batch Gradient Norm: 3.180823714409265
Epoch: 2267, Batch Gradient Norm after: 3.180823714409265
Epoch 2268/10000, Prediction Accuracy = 60.650000000000006%, Loss = 0.009360287266855057
Epoch: 2268, Batch Gradient Norm: 3.192000692297158
Epoch: 2268, Batch Gradient Norm after: 3.192000692297158
Epoch 2269/10000, Prediction Accuracy = 61.14230769230768%, Loss = 0.009220970436357535
Epoch: 2269, Batch Gradient Norm: 3.238391014261025
Epoch: 2269, Batch Gradient Norm after: 3.238391014261025
Epoch 2270/10000, Prediction Accuracy = 60.83076923076923%, Loss = 0.00931032202564753
Epoch: 2270, Batch Gradient Norm: 3.368939588885124
Epoch: 2270, Batch Gradient Norm after: 3.368939588885124
Epoch 2271/10000, Prediction Accuracy = 60.92307692307692%, Loss = 0.009318993641779972
Epoch: 2271, Batch Gradient Norm: 3.307702483095924
Epoch: 2271, Batch Gradient Norm after: 3.307702483095924
Epoch 2272/10000, Prediction Accuracy = 60.76538461538462%, Loss = 0.009401843883097172
Epoch: 2272, Batch Gradient Norm: 3.0513487612237684
Epoch: 2272, Batch Gradient Norm after: 3.0513487612237684
Epoch 2273/10000, Prediction Accuracy = 60.76538461538462%, Loss = 0.009346588729665829
Epoch: 2273, Batch Gradient Norm: 3.3552817102923314
Epoch: 2273, Batch Gradient Norm after: 3.3552817102923314
Epoch 2274/10000, Prediction Accuracy = 60.91538461538461%, Loss = 0.009349656148025623
Epoch: 2274, Batch Gradient Norm: 3.391944923095109
Epoch: 2274, Batch Gradient Norm after: 3.391944923095109
Epoch 2275/10000, Prediction Accuracy = 60.82692307692308%, Loss = 0.009319203905761242
Epoch: 2275, Batch Gradient Norm: 3.08714029988178
Epoch: 2275, Batch Gradient Norm after: 3.08714029988178
Epoch 2276/10000, Prediction Accuracy = 61.292307692307695%, Loss = 0.00920464277554017
Epoch: 2276, Batch Gradient Norm: 3.4755868480646894
Epoch: 2276, Batch Gradient Norm after: 3.4755868480646894
Epoch 2277/10000, Prediction Accuracy = 61.096153846153854%, Loss = 0.00935833564457985
Epoch: 2277, Batch Gradient Norm: 3.611524240032388
Epoch: 2277, Batch Gradient Norm after: 3.611524240032388
Epoch 2278/10000, Prediction Accuracy = 60.21538461538462%, Loss = 0.009669091910696946
Epoch: 2278, Batch Gradient Norm: 3.5560601480189296
Epoch: 2278, Batch Gradient Norm after: 3.5560601480189296
Epoch 2279/10000, Prediction Accuracy = 60.57307692307692%, Loss = 0.009521556230118642
Epoch: 2279, Batch Gradient Norm: 3.2602697605308975
Epoch: 2279, Batch Gradient Norm after: 3.2602697605308975
Epoch 2280/10000, Prediction Accuracy = 60.93846153846155%, Loss = 0.009352882894185873
Epoch: 2280, Batch Gradient Norm: 3.2088427254134593
Epoch: 2280, Batch Gradient Norm after: 3.2088427254134593
Epoch 2281/10000, Prediction Accuracy = 60.29615384615386%, Loss = 0.009392623789608479
Epoch: 2281, Batch Gradient Norm: 3.1413173152797333
Epoch: 2281, Batch Gradient Norm after: 3.1413173152797333
Epoch 2282/10000, Prediction Accuracy = 60.98461538461539%, Loss = 0.009317667868274909
Epoch: 2282, Batch Gradient Norm: 3.009179460873733
Epoch: 2282, Batch Gradient Norm after: 3.009179460873733
Epoch 2283/10000, Prediction Accuracy = 61.48846153846154%, Loss = 0.009168105199933052
Epoch: 2283, Batch Gradient Norm: 3.180337420932591
Epoch: 2283, Batch Gradient Norm after: 3.180337420932591
Epoch 2284/10000, Prediction Accuracy = 61.46923076923077%, Loss = 0.009239279306851901
Epoch: 2284, Batch Gradient Norm: 3.303625308856902
Epoch: 2284, Batch Gradient Norm after: 3.303625308856902
Epoch 2285/10000, Prediction Accuracy = 60.792307692307695%, Loss = 0.009408293936688166
Epoch: 2285, Batch Gradient Norm: 3.333757907796474
Epoch: 2285, Batch Gradient Norm after: 3.333757907796474
Epoch 2286/10000, Prediction Accuracy = 60.776923076923076%, Loss = 0.00935134721490053
Epoch: 2286, Batch Gradient Norm: 3.2164201480755383
Epoch: 2286, Batch Gradient Norm after: 3.2164201480755383
Epoch 2287/10000, Prediction Accuracy = 61.08461538461539%, Loss = 0.009254415591175739
Epoch: 2287, Batch Gradient Norm: 3.1438680194350512
Epoch: 2287, Batch Gradient Norm after: 3.1438680194350512
Epoch 2288/10000, Prediction Accuracy = 61.065384615384616%, Loss = 0.009241422781577477
Epoch: 2288, Batch Gradient Norm: 3.101338544890966
Epoch: 2288, Batch Gradient Norm after: 3.101338544890966
Epoch 2289/10000, Prediction Accuracy = 61.41538461538461%, Loss = 0.009179525865385165
Epoch: 2289, Batch Gradient Norm: 3.1689325668018937
Epoch: 2289, Batch Gradient Norm after: 3.1689325668018937
Epoch 2290/10000, Prediction Accuracy = 61.349999999999994%, Loss = 0.009185335598886013
Epoch: 2290, Batch Gradient Norm: 3.1778965645952506
Epoch: 2290, Batch Gradient Norm after: 3.1778965645952506
Epoch 2291/10000, Prediction Accuracy = 61.126923076923084%, Loss = 0.009268743845705803
Epoch: 2291, Batch Gradient Norm: 3.2713509911189935
Epoch: 2291, Batch Gradient Norm after: 3.2713509911189935
Epoch 2292/10000, Prediction Accuracy = 60.73076923076923%, Loss = 0.009387680186102023
Epoch: 2292, Batch Gradient Norm: 3.3755365018092167
Epoch: 2292, Batch Gradient Norm after: 3.3755365018092167
Epoch 2293/10000, Prediction Accuracy = 61.07692307692306%, Loss = 0.00934355018230585
Epoch: 2293, Batch Gradient Norm: 2.974008591440944
Epoch: 2293, Batch Gradient Norm after: 2.974008591440944
Epoch 2294/10000, Prediction Accuracy = 61.330769230769235%, Loss = 0.009172178589953827
Epoch: 2294, Batch Gradient Norm: 3.2571060975067136
Epoch: 2294, Batch Gradient Norm after: 3.2571060975067136
Epoch 2295/10000, Prediction Accuracy = 61.111538461538466%, Loss = 0.009295889176428318
Epoch: 2295, Batch Gradient Norm: 3.02209152587041
Epoch: 2295, Batch Gradient Norm after: 3.02209152587041
Epoch 2296/10000, Prediction Accuracy = 61.54615384615385%, Loss = 0.009161471532514462
Epoch: 2296, Batch Gradient Norm: 3.0048025171020014
Epoch: 2296, Batch Gradient Norm after: 3.0048025171020014
Epoch 2297/10000, Prediction Accuracy = 61.426923076923075%, Loss = 0.00917182332621171
Epoch: 2297, Batch Gradient Norm: 3.2194871428322136
Epoch: 2297, Batch Gradient Norm after: 3.2194871428322136
Epoch 2298/10000, Prediction Accuracy = 61.44615384615385%, Loss = 0.009206933757433524
Epoch: 2298, Batch Gradient Norm: 3.2454266665908955
Epoch: 2298, Batch Gradient Norm after: 3.2454266665908955
Epoch 2299/10000, Prediction Accuracy = 61.23076923076922%, Loss = 0.009169895560122453
Epoch: 2299, Batch Gradient Norm: 3.334993499821768
Epoch: 2299, Batch Gradient Norm after: 3.334993499821768
Epoch 2300/10000, Prediction Accuracy = 60.88076923076923%, Loss = 0.009225634786372002
Epoch: 2300, Batch Gradient Norm: 3.5375932093788633
Epoch: 2300, Batch Gradient Norm after: 3.5375932093788633
Epoch 2301/10000, Prediction Accuracy = 61.06153846153845%, Loss = 0.009405627416876646
Epoch: 2301, Batch Gradient Norm: 3.40863708830962
Epoch: 2301, Batch Gradient Norm after: 3.40863708830962
Epoch 2302/10000, Prediction Accuracy = 60.98846153846153%, Loss = 0.009353082125576643
Epoch: 2302, Batch Gradient Norm: 3.6049592636418466
Epoch: 2302, Batch Gradient Norm after: 3.6049592636418466
Epoch 2303/10000, Prediction Accuracy = 60.22692307692308%, Loss = 0.0095545738362349
Epoch: 2303, Batch Gradient Norm: 3.346346544328184
Epoch: 2303, Batch Gradient Norm after: 3.346346544328184
Epoch 2304/10000, Prediction Accuracy = 60.723076923076924%, Loss = 0.009469501459254669
Epoch: 2304, Batch Gradient Norm: 3.213717174254882
Epoch: 2304, Batch Gradient Norm after: 3.213717174254882
Epoch 2305/10000, Prediction Accuracy = 61.007692307692295%, Loss = 0.009348391053768305
Epoch: 2305, Batch Gradient Norm: 3.319361565926239
Epoch: 2305, Batch Gradient Norm after: 3.319361565926239
Epoch 2306/10000, Prediction Accuracy = 60.973076923076924%, Loss = 0.00935822968872694
Epoch: 2306, Batch Gradient Norm: 3.4513836759489185
Epoch: 2306, Batch Gradient Norm after: 3.4513836759489185
Epoch 2307/10000, Prediction Accuracy = 60.73846153846154%, Loss = 0.009373885149566026
Epoch: 2307, Batch Gradient Norm: 3.6026531370524713
Epoch: 2307, Batch Gradient Norm after: 3.6026531370524713
Epoch 2308/10000, Prediction Accuracy = 60.74615384615384%, Loss = 0.009524544844260583
Epoch: 2308, Batch Gradient Norm: 3.122173035794505
Epoch: 2308, Batch Gradient Norm after: 3.122173035794505
Epoch 2309/10000, Prediction Accuracy = 61.31923076923078%, Loss = 0.009159262005526286
Epoch: 2309, Batch Gradient Norm: 3.0239528308436014
Epoch: 2309, Batch Gradient Norm after: 3.0239528308436014
Epoch 2310/10000, Prediction Accuracy = 61.58846153846154%, Loss = 0.009111413373970069
Epoch: 2310, Batch Gradient Norm: 3.5701443181674977
Epoch: 2310, Batch Gradient Norm after: 3.5701443181674977
Epoch 2311/10000, Prediction Accuracy = 60.63461538461539%, Loss = 0.009401483246340202
Epoch: 2311, Batch Gradient Norm: 3.0834311060671076
Epoch: 2311, Batch Gradient Norm after: 3.0834311060671076
Epoch 2312/10000, Prediction Accuracy = 61.40384615384615%, Loss = 0.009145592554257466
Epoch: 2312, Batch Gradient Norm: 2.9817724443848945
Epoch: 2312, Batch Gradient Norm after: 2.9817724443848945
Epoch 2313/10000, Prediction Accuracy = 61.60384615384615%, Loss = 0.009077993006660389
Epoch: 2313, Batch Gradient Norm: 3.0083074656635396
Epoch: 2313, Batch Gradient Norm after: 3.0083074656635396
Epoch 2314/10000, Prediction Accuracy = 61.51538461538461%, Loss = 0.009077645408419462
Epoch: 2314, Batch Gradient Norm: 3.160859271373908
Epoch: 2314, Batch Gradient Norm after: 3.160859271373908
Epoch 2315/10000, Prediction Accuracy = 61.68846153846153%, Loss = 0.00912157790018962
Epoch: 2315, Batch Gradient Norm: 3.2885920102626054
Epoch: 2315, Batch Gradient Norm after: 3.2885920102626054
Epoch 2316/10000, Prediction Accuracy = 61.43076923076922%, Loss = 0.009213784924493386
Epoch: 2316, Batch Gradient Norm: 3.6531379656265948
Epoch: 2316, Batch Gradient Norm after: 3.6531379656265948
Epoch 2317/10000, Prediction Accuracy = 60.56923076923076%, Loss = 0.009417311288416386
Epoch: 2317, Batch Gradient Norm: 3.249607540347695
Epoch: 2317, Batch Gradient Norm after: 3.249607540347695
Epoch 2318/10000, Prediction Accuracy = 61.23846153846154%, Loss = 0.009270541728115998
Epoch: 2318, Batch Gradient Norm: 2.974001147081942
Epoch: 2318, Batch Gradient Norm after: 2.974001147081942
Epoch 2319/10000, Prediction Accuracy = 61.58076923076923%, Loss = 0.009058281994209839
Epoch: 2319, Batch Gradient Norm: 2.98874400176898
Epoch: 2319, Batch Gradient Norm after: 2.98874400176898
Epoch 2320/10000, Prediction Accuracy = 61.83846153846153%, Loss = 0.00899824915597072
Epoch: 2320, Batch Gradient Norm: 3.210781360761839
Epoch: 2320, Batch Gradient Norm after: 3.210781360761839
Epoch 2321/10000, Prediction Accuracy = 61.56153846153845%, Loss = 0.009161335917619558
Epoch: 2321, Batch Gradient Norm: 3.1753610592052888
Epoch: 2321, Batch Gradient Norm after: 3.1753610592052888
Epoch 2322/10000, Prediction Accuracy = 61.657692307692315%, Loss = 0.009133184758516459
Epoch: 2322, Batch Gradient Norm: 3.194760497011879
Epoch: 2322, Batch Gradient Norm after: 3.194760497011879
Epoch 2323/10000, Prediction Accuracy = 60.98846153846154%, Loss = 0.00919609022541688
Epoch: 2323, Batch Gradient Norm: 3.109686707628501
Epoch: 2323, Batch Gradient Norm after: 3.109686707628501
Epoch 2324/10000, Prediction Accuracy = 61.48846153846154%, Loss = 0.009127858524712233
Epoch: 2324, Batch Gradient Norm: 2.8611643884866984
Epoch: 2324, Batch Gradient Norm after: 2.8611643884866984
Epoch 2325/10000, Prediction Accuracy = 61.98846153846154%, Loss = 0.008885734213086275
Epoch: 2325, Batch Gradient Norm: 3.327469569835017
Epoch: 2325, Batch Gradient Norm after: 3.327469569835017
Epoch 2326/10000, Prediction Accuracy = 61.619230769230775%, Loss = 0.009109372846209086
Epoch: 2326, Batch Gradient Norm: 3.1808377160951196
Epoch: 2326, Batch Gradient Norm after: 3.1808377160951196
Epoch 2327/10000, Prediction Accuracy = 61.31153846153845%, Loss = 0.009088566311849998
Epoch: 2327, Batch Gradient Norm: 3.1409459319560913
Epoch: 2327, Batch Gradient Norm after: 3.1409459319560913
Epoch 2328/10000, Prediction Accuracy = 61.784615384615385%, Loss = 0.009045871476141306
Epoch: 2328, Batch Gradient Norm: 3.4587162467826547
Epoch: 2328, Batch Gradient Norm after: 3.4587162467826547
Epoch 2329/10000, Prediction Accuracy = 61.02307692307693%, Loss = 0.009339900185855536
Epoch: 2329, Batch Gradient Norm: 3.345466643874291
Epoch: 2329, Batch Gradient Norm after: 3.345466643874291
Epoch 2330/10000, Prediction Accuracy = 61.38076923076923%, Loss = 0.009219006133767275
Epoch: 2330, Batch Gradient Norm: 3.1306030620965273
Epoch: 2330, Batch Gradient Norm after: 3.1306030620965273
Epoch 2331/10000, Prediction Accuracy = 61.619230769230775%, Loss = 0.009081522719218181
Epoch: 2331, Batch Gradient Norm: 3.1405582696163226
Epoch: 2331, Batch Gradient Norm after: 3.1405582696163226
Epoch 2332/10000, Prediction Accuracy = 61.419230769230765%, Loss = 0.009069451345847203
Epoch: 2332, Batch Gradient Norm: 3.332869437608644
Epoch: 2332, Batch Gradient Norm after: 3.332869437608644
Epoch 2333/10000, Prediction Accuracy = 61.276923076923076%, Loss = 0.00921520683914423
Epoch: 2333, Batch Gradient Norm: 3.4179658689600254
Epoch: 2333, Batch Gradient Norm after: 3.4179658689600254
Epoch 2334/10000, Prediction Accuracy = 61.14999999999999%, Loss = 0.009307956537948204
Epoch: 2334, Batch Gradient Norm: 3.374614405741069
Epoch: 2334, Batch Gradient Norm after: 3.374614405741069
Epoch 2335/10000, Prediction Accuracy = 61.23461538461538%, Loss = 0.00926966005219863
Epoch: 2335, Batch Gradient Norm: 3.5907817701596483
Epoch: 2335, Batch Gradient Norm after: 3.5907817701596483
Epoch 2336/10000, Prediction Accuracy = 60.54615384615384%, Loss = 0.009374709513324957
Epoch: 2336, Batch Gradient Norm: 3.2716504882966677
Epoch: 2336, Batch Gradient Norm after: 3.2716504882966677
Epoch 2337/10000, Prediction Accuracy = 60.973076923076924%, Loss = 0.009222528324104272
Epoch: 2337, Batch Gradient Norm: 3.2550627630690796
Epoch: 2337, Batch Gradient Norm after: 3.2550627630690796
Epoch 2338/10000, Prediction Accuracy = 61.25769230769231%, Loss = 0.009200268568327794
Epoch: 2338, Batch Gradient Norm: 3.362222780149823
Epoch: 2338, Batch Gradient Norm after: 3.362222780149823
Epoch 2339/10000, Prediction Accuracy = 60.86538461538461%, Loss = 0.009306781495419832
Epoch: 2339, Batch Gradient Norm: 3.335738955590031
Epoch: 2339, Batch Gradient Norm after: 3.335738955590031
Epoch 2340/10000, Prediction Accuracy = 61.66153846153847%, Loss = 0.009156113991943689
Epoch: 2340, Batch Gradient Norm: 3.6415707122605236
Epoch: 2340, Batch Gradient Norm after: 3.6415707122605236
Epoch 2341/10000, Prediction Accuracy = 60.784615384615385%, Loss = 0.009491763077676296
Epoch: 2341, Batch Gradient Norm: 3.7360704967262346
Epoch: 2341, Batch Gradient Norm after: 3.7360704967262346
Epoch 2342/10000, Prediction Accuracy = 60.88846153846154%, Loss = 0.009533778835947696
Epoch: 2342, Batch Gradient Norm: 3.2748792766488295
Epoch: 2342, Batch Gradient Norm after: 3.2748792766488295
Epoch 2343/10000, Prediction Accuracy = 60.90384615384615%, Loss = 0.009288218087301804
Epoch: 2343, Batch Gradient Norm: 3.2239117272706515
Epoch: 2343, Batch Gradient Norm after: 3.2239117272706515
Epoch 2344/10000, Prediction Accuracy = 61.76538461538462%, Loss = 0.009173143941622514
Epoch: 2344, Batch Gradient Norm: 3.094992167457575
Epoch: 2344, Batch Gradient Norm after: 3.094992167457575
Epoch 2345/10000, Prediction Accuracy = 62.09999999999999%, Loss = 0.009037968917534901
Epoch: 2345, Batch Gradient Norm: 2.9990025558156757
Epoch: 2345, Batch Gradient Norm after: 2.9990025558156757
Epoch 2346/10000, Prediction Accuracy = 61.66923076923077%, Loss = 0.009013803031008977
Epoch: 2346, Batch Gradient Norm: 3.66897623067945
Epoch: 2346, Batch Gradient Norm after: 3.66897623067945
Epoch 2347/10000, Prediction Accuracy = 60.78076923076923%, Loss = 0.009354963468817564
Epoch: 2347, Batch Gradient Norm: 3.7227632669962563
Epoch: 2347, Batch Gradient Norm after: 3.7227632669962563
Epoch 2348/10000, Prediction Accuracy = 59.83076923076923%, Loss = 0.009499186434997963
Epoch: 2348, Batch Gradient Norm: 3.1813424299357456
Epoch: 2348, Batch Gradient Norm after: 3.1813424299357456
Epoch 2349/10000, Prediction Accuracy = 61.33076923076923%, Loss = 0.009208389844458837
Epoch: 2349, Batch Gradient Norm: 3.266286701145095
Epoch: 2349, Batch Gradient Norm after: 3.266286701145095
Epoch 2350/10000, Prediction Accuracy = 61.32692307692309%, Loss = 0.009221259791117448
Epoch: 2350, Batch Gradient Norm: 3.0354615569557724
Epoch: 2350, Batch Gradient Norm after: 3.0354615569557724
Epoch 2351/10000, Prediction Accuracy = 61.39615384615385%, Loss = 0.008995250512201052
Epoch: 2351, Batch Gradient Norm: 3.07953717284611
Epoch: 2351, Batch Gradient Norm after: 3.07953717284611
Epoch 2352/10000, Prediction Accuracy = 61.79615384615385%, Loss = 0.009041606162029963
Epoch: 2352, Batch Gradient Norm: 3.1150776739015855
Epoch: 2352, Batch Gradient Norm after: 3.1150776739015855
Epoch 2353/10000, Prediction Accuracy = 62.111538461538466%, Loss = 0.009055717561680537
Epoch: 2353, Batch Gradient Norm: 3.059865572984426
Epoch: 2353, Batch Gradient Norm after: 3.059865572984426
Epoch 2354/10000, Prediction Accuracy = 61.63846153846153%, Loss = 0.009107357607438015
Epoch: 2354, Batch Gradient Norm: 3.262344803249064
Epoch: 2354, Batch Gradient Norm after: 3.262344803249064
Epoch 2355/10000, Prediction Accuracy = 61.26538461538462%, Loss = 0.00921789907778685
Epoch: 2355, Batch Gradient Norm: 3.25431697759699
Epoch: 2355, Batch Gradient Norm after: 3.25431697759699
Epoch 2356/10000, Prediction Accuracy = 61.0%, Loss = 0.009252006689516397
Epoch: 2356, Batch Gradient Norm: 3.084026075566087
Epoch: 2356, Batch Gradient Norm after: 3.084026075566087
Epoch 2357/10000, Prediction Accuracy = 61.388461538461534%, Loss = 0.009060669905291153
Epoch: 2357, Batch Gradient Norm: 3.5010475947892794
Epoch: 2357, Batch Gradient Norm after: 3.5010475947892794
Epoch 2358/10000, Prediction Accuracy = 61.4076923076923%, Loss = 0.009216993545683531
Epoch: 2358, Batch Gradient Norm: 3.337636412396528
Epoch: 2358, Batch Gradient Norm after: 3.337636412396528
Epoch 2359/10000, Prediction Accuracy = 61.25%, Loss = 0.009172642460236182
Epoch: 2359, Batch Gradient Norm: 3.0651019082858704
Epoch: 2359, Batch Gradient Norm after: 3.0651019082858704
Epoch 2360/10000, Prediction Accuracy = 62.01923076923077%, Loss = 0.009055572633559886
Epoch: 2360, Batch Gradient Norm: 3.237375455545594
Epoch: 2360, Batch Gradient Norm after: 3.237375455545594
Epoch 2361/10000, Prediction Accuracy = 61.27307692307692%, Loss = 0.009160145973929992
Epoch: 2361, Batch Gradient Norm: 3.4444032959739386
Epoch: 2361, Batch Gradient Norm after: 3.4444032959739386
Epoch 2362/10000, Prediction Accuracy = 61.30769230769231%, Loss = 0.009220734381904969
Epoch: 2362, Batch Gradient Norm: 3.418667284392481
Epoch: 2362, Batch Gradient Norm after: 3.418667284392481
Epoch 2363/10000, Prediction Accuracy = 61.103846153846135%, Loss = 0.009245169492295155
Epoch: 2363, Batch Gradient Norm: 3.125307730572681
Epoch: 2363, Batch Gradient Norm after: 3.125307730572681
Epoch 2364/10000, Prediction Accuracy = 61.88846153846154%, Loss = 0.009044043003366543
Epoch: 2364, Batch Gradient Norm: 3.2149006686536548
Epoch: 2364, Batch Gradient Norm after: 3.2149006686536548
Epoch 2365/10000, Prediction Accuracy = 61.18076923076922%, Loss = 0.0091754632213941
Epoch: 2365, Batch Gradient Norm: 3.295924172415159
Epoch: 2365, Batch Gradient Norm after: 3.295924172415159
Epoch 2366/10000, Prediction Accuracy = 61.315384615384616%, Loss = 0.009150048216375021
Epoch: 2366, Batch Gradient Norm: 3.439632877361787
Epoch: 2366, Batch Gradient Norm after: 3.439632877361787
Epoch 2367/10000, Prediction Accuracy = 61.04615384615385%, Loss = 0.009281454607844353
Epoch: 2367, Batch Gradient Norm: 3.5511241373628235
Epoch: 2367, Batch Gradient Norm after: 3.5511241373628235
Epoch 2368/10000, Prediction Accuracy = 61.42307692307692%, Loss = 0.009257597992053399
Epoch: 2368, Batch Gradient Norm: 3.6509042016856466
Epoch: 2368, Batch Gradient Norm after: 3.6509042016856466
Epoch 2369/10000, Prediction Accuracy = 60.75000000000001%, Loss = 0.009367342751759749
Epoch: 2369, Batch Gradient Norm: 3.3778487204259884
Epoch: 2369, Batch Gradient Norm after: 3.3778487204259884
Epoch 2370/10000, Prediction Accuracy = 61.28076923076923%, Loss = 0.009229140929304637
Epoch: 2370, Batch Gradient Norm: 3.5048950440214437
Epoch: 2370, Batch Gradient Norm after: 3.5048950440214437
Epoch 2371/10000, Prediction Accuracy = 60.592307692307685%, Loss = 0.009359027903813582
Epoch: 2371, Batch Gradient Norm: 3.333308896899178
Epoch: 2371, Batch Gradient Norm after: 3.333308896899178
Epoch 2372/10000, Prediction Accuracy = 61.44230769230769%, Loss = 0.00922957413758223
Epoch: 2372, Batch Gradient Norm: 3.2395836293281843
Epoch: 2372, Batch Gradient Norm after: 3.2395836293281843
Epoch 2373/10000, Prediction Accuracy = 61.43076923076922%, Loss = 0.009117926112734355
Epoch: 2373, Batch Gradient Norm: 3.240707312205301
Epoch: 2373, Batch Gradient Norm after: 3.240707312205301
Epoch 2374/10000, Prediction Accuracy = 61.28076923076923%, Loss = 0.009084200414900597
Epoch: 2374, Batch Gradient Norm: 3.2193890983451072
Epoch: 2374, Batch Gradient Norm after: 3.2193890983451072
Epoch 2375/10000, Prediction Accuracy = 61.46153846153846%, Loss = 0.009139388871307556
Epoch: 2375, Batch Gradient Norm: 3.2467044309195803
Epoch: 2375, Batch Gradient Norm after: 3.2467044309195803
Epoch 2376/10000, Prediction Accuracy = 61.36923076923077%, Loss = 0.009083313939089958
Epoch: 2376, Batch Gradient Norm: 3.754588082980834
Epoch: 2376, Batch Gradient Norm after: 3.754588082980834
Epoch 2377/10000, Prediction Accuracy = 60.81153846153846%, Loss = 0.009395386092364788
Epoch: 2377, Batch Gradient Norm: 3.6493085030650865
Epoch: 2377, Batch Gradient Norm after: 3.6493085030650865
Epoch 2378/10000, Prediction Accuracy = 60.74615384615385%, Loss = 0.009475196640078839
Epoch: 2378, Batch Gradient Norm: 3.4287331531707856
Epoch: 2378, Batch Gradient Norm after: 3.4287331531707856
Epoch 2379/10000, Prediction Accuracy = 60.99230769230769%, Loss = 0.009325166447804524
Epoch: 2379, Batch Gradient Norm: 3.5165803258213257
Epoch: 2379, Batch Gradient Norm after: 3.5165803258213257
Epoch 2380/10000, Prediction Accuracy = 61.03846153846155%, Loss = 0.00931757760162537
Epoch: 2380, Batch Gradient Norm: 3.2202389773528646
Epoch: 2380, Batch Gradient Norm after: 3.2202389773528646
Epoch 2381/10000, Prediction Accuracy = 61.40384615384616%, Loss = 0.009106397485503783
Epoch: 2381, Batch Gradient Norm: 2.9503319773393897
Epoch: 2381, Batch Gradient Norm after: 2.9503319773393897
Epoch 2382/10000, Prediction Accuracy = 61.99230769230768%, Loss = 0.008974490615610894
Epoch: 2382, Batch Gradient Norm: 3.05464397551611
Epoch: 2382, Batch Gradient Norm after: 3.05464397551611
Epoch 2383/10000, Prediction Accuracy = 61.82307692307692%, Loss = 0.008963264524936676
Epoch: 2383, Batch Gradient Norm: 3.155725206950497
Epoch: 2383, Batch Gradient Norm after: 3.155725206950497
Epoch 2384/10000, Prediction Accuracy = 61.51923076923077%, Loss = 0.009016984858765053
Epoch: 2384, Batch Gradient Norm: 3.0067802235306567
Epoch: 2384, Batch Gradient Norm after: 3.0067802235306567
Epoch 2385/10000, Prediction Accuracy = 61.88461538461539%, Loss = 0.00893151036535318
Epoch: 2385, Batch Gradient Norm: 3.1331433958638786
Epoch: 2385, Batch Gradient Norm after: 3.1331433958638786
Epoch 2386/10000, Prediction Accuracy = 62.11538461538461%, Loss = 0.008947057649493217
Epoch: 2386, Batch Gradient Norm: 3.0798673503936334
Epoch: 2386, Batch Gradient Norm after: 3.0798673503936334
Epoch 2387/10000, Prediction Accuracy = 61.58846153846153%, Loss = 0.009001602203800129
Epoch: 2387, Batch Gradient Norm: 3.5799858170425884
Epoch: 2387, Batch Gradient Norm after: 3.5799858170425884
Epoch 2388/10000, Prediction Accuracy = 61.61538461538461%, Loss = 0.009152566011135396
Epoch: 2388, Batch Gradient Norm: 3.5899932164198467
Epoch: 2388, Batch Gradient Norm after: 3.5899932164198467
Epoch 2389/10000, Prediction Accuracy = 61.43846153846153%, Loss = 0.009161638597456308
Epoch: 2389, Batch Gradient Norm: 3.2542308041951657
Epoch: 2389, Batch Gradient Norm after: 3.2542308041951657
Epoch 2390/10000, Prediction Accuracy = 61.534615384615385%, Loss = 0.009065823844419075
Epoch: 2390, Batch Gradient Norm: 3.107107529472554
Epoch: 2390, Batch Gradient Norm after: 3.107107529472554
Epoch 2391/10000, Prediction Accuracy = 61.85000000000001%, Loss = 0.009027729097467203
Epoch: 2391, Batch Gradient Norm: 3.391912019745523
Epoch: 2391, Batch Gradient Norm after: 3.391912019745523
Epoch 2392/10000, Prediction Accuracy = 61.47307692307691%, Loss = 0.009154390472059067
Epoch: 2392, Batch Gradient Norm: 3.6687508858691573
Epoch: 2392, Batch Gradient Norm after: 3.6687508858691573
Epoch 2393/10000, Prediction Accuracy = 60.75384615384615%, Loss = 0.009385610429140238
Epoch: 2393, Batch Gradient Norm: 3.3198073650462363
Epoch: 2393, Batch Gradient Norm after: 3.3198073650462363
Epoch 2394/10000, Prediction Accuracy = 61.353846153846156%, Loss = 0.009233689508759059
Epoch: 2394, Batch Gradient Norm: 3.2455132620550553
Epoch: 2394, Batch Gradient Norm after: 3.2455132620550553
Epoch 2395/10000, Prediction Accuracy = 61.400000000000006%, Loss = 0.009172681217583327
Epoch: 2395, Batch Gradient Norm: 2.9234452552286383
Epoch: 2395, Batch Gradient Norm after: 2.9234452552286383
Epoch 2396/10000, Prediction Accuracy = 62.00384615384616%, Loss = 0.008928236193381824
Epoch: 2396, Batch Gradient Norm: 3.3682370204458683
Epoch: 2396, Batch Gradient Norm after: 3.3682370204458683
Epoch 2397/10000, Prediction Accuracy = 61.50769230769231%, Loss = 0.00918014870526699
Epoch: 2397, Batch Gradient Norm: 3.0147734951670495
Epoch: 2397, Batch Gradient Norm after: 3.0147734951670495
Epoch 2398/10000, Prediction Accuracy = 62.07307692307695%, Loss = 0.008943377850720515
Epoch: 2398, Batch Gradient Norm: 3.165523586513063
Epoch: 2398, Batch Gradient Norm after: 3.165523586513063
Epoch 2399/10000, Prediction Accuracy = 61.57692307692308%, Loss = 0.00904304813593626
Epoch: 2399, Batch Gradient Norm: 3.177635683441332
Epoch: 2399, Batch Gradient Norm after: 3.177635683441332
Epoch 2400/10000, Prediction Accuracy = 61.98461538461538%, Loss = 0.00900936914751163
Epoch: 2400, Batch Gradient Norm: 3.1457782451928407
Epoch: 2400, Batch Gradient Norm after: 3.1457782451928407
Epoch 2401/10000, Prediction Accuracy = 61.71153846153846%, Loss = 0.009000024973199917
Epoch: 2401, Batch Gradient Norm: 3.1127302438866846
Epoch: 2401, Batch Gradient Norm after: 3.1127302438866846
Epoch 2402/10000, Prediction Accuracy = 61.70000000000001%, Loss = 0.0090112413208072
Epoch: 2402, Batch Gradient Norm: 3.4123024597937155
Epoch: 2402, Batch Gradient Norm after: 3.4123024597937155
Epoch 2403/10000, Prediction Accuracy = 61.67692307692307%, Loss = 0.00911890622228384
Epoch: 2403, Batch Gradient Norm: 3.4204820510830967
Epoch: 2403, Batch Gradient Norm after: 3.4204820510830967
Epoch 2404/10000, Prediction Accuracy = 61.02307692307692%, Loss = 0.009222023403988434
Epoch: 2404, Batch Gradient Norm: 3.592844395561102
Epoch: 2404, Batch Gradient Norm after: 3.592844395561102
Epoch 2405/10000, Prediction Accuracy = 61.153846153846146%, Loss = 0.009354737515632924
Epoch: 2405, Batch Gradient Norm: 3.375109542540913
Epoch: 2405, Batch Gradient Norm after: 3.375109542540913
Epoch 2406/10000, Prediction Accuracy = 61.857692307692304%, Loss = 0.009150571834582549
Epoch: 2406, Batch Gradient Norm: 3.3900900002514867
Epoch: 2406, Batch Gradient Norm after: 3.3900900002514867
Epoch 2407/10000, Prediction Accuracy = 61.14615384615384%, Loss = 0.009204729531820003
Epoch: 2407, Batch Gradient Norm: 3.597552883484551
Epoch: 2407, Batch Gradient Norm after: 3.597552883484551
Epoch 2408/10000, Prediction Accuracy = 61.21153846153846%, Loss = 0.009313285494079957
Epoch: 2408, Batch Gradient Norm: 3.2277285885960394
Epoch: 2408, Batch Gradient Norm after: 3.2277285885960394
Epoch 2409/10000, Prediction Accuracy = 61.86538461538461%, Loss = 0.009088428117907964
Epoch: 2409, Batch Gradient Norm: 3.195278848373602
Epoch: 2409, Batch Gradient Norm after: 3.195278848373602
Epoch 2410/10000, Prediction Accuracy = 61.70384615384614%, Loss = 0.00908667493898135
Epoch: 2410, Batch Gradient Norm: 3.379527833518227
Epoch: 2410, Batch Gradient Norm after: 3.379527833518227
Epoch 2411/10000, Prediction Accuracy = 61.51923076923077%, Loss = 0.009071713098539757
Epoch: 2411, Batch Gradient Norm: 3.218366850932136
Epoch: 2411, Batch Gradient Norm after: 3.218366850932136
Epoch 2412/10000, Prediction Accuracy = 61.157692307692315%, Loss = 0.009092854479184518
Epoch: 2412, Batch Gradient Norm: 3.7083374434134795
Epoch: 2412, Batch Gradient Norm after: 3.7083374434134795
Epoch 2413/10000, Prediction Accuracy = 61.01538461538462%, Loss = 0.009299334425192613
Epoch: 2413, Batch Gradient Norm: 3.8492023727553755
Epoch: 2413, Batch Gradient Norm after: 3.8492023727553755
Epoch 2414/10000, Prediction Accuracy = 60.51153846153847%, Loss = 0.009445691982714029
Epoch: 2414, Batch Gradient Norm: 3.1460722425943106
Epoch: 2414, Batch Gradient Norm after: 3.1460722425943106
Epoch 2415/10000, Prediction Accuracy = 61.215384615384615%, Loss = 0.009035981045319484
Epoch: 2415, Batch Gradient Norm: 3.0512538907850604
Epoch: 2415, Batch Gradient Norm after: 3.0512538907850604
Epoch 2416/10000, Prediction Accuracy = 61.71923076923077%, Loss = 0.008942008018493652
Epoch: 2416, Batch Gradient Norm: 3.189582170332286
Epoch: 2416, Batch Gradient Norm after: 3.189582170332286
Epoch 2417/10000, Prediction Accuracy = 61.53461538461538%, Loss = 0.009023119408923846
Epoch: 2417, Batch Gradient Norm: 3.092857081384025
Epoch: 2417, Batch Gradient Norm after: 3.092857081384025
Epoch 2418/10000, Prediction Accuracy = 61.80384615384615%, Loss = 0.008994656829879833
Epoch: 2418, Batch Gradient Norm: 3.447917917409542
Epoch: 2418, Batch Gradient Norm after: 3.447917917409542
Epoch 2419/10000, Prediction Accuracy = 62.138461538461534%, Loss = 0.009096826498325054
Epoch: 2419, Batch Gradient Norm: 3.4978199471014033
Epoch: 2419, Batch Gradient Norm after: 3.4978199471014033
Epoch 2420/10000, Prediction Accuracy = 61.43076923076922%, Loss = 0.009137637125184903
Epoch: 2420, Batch Gradient Norm: 3.239286221978975
Epoch: 2420, Batch Gradient Norm after: 3.239286221978975
Epoch 2421/10000, Prediction Accuracy = 61.73461538461538%, Loss = 0.009033159209558597
Epoch: 2421, Batch Gradient Norm: 3.2947798557637085
Epoch: 2421, Batch Gradient Norm after: 3.2947798557637085
Epoch 2422/10000, Prediction Accuracy = 61.41153846153847%, Loss = 0.009093854361428665
Epoch: 2422, Batch Gradient Norm: 3.5057221341998672
Epoch: 2422, Batch Gradient Norm after: 3.5057221341998672
Epoch 2423/10000, Prediction Accuracy = 61.18846153846153%, Loss = 0.009164475764219578
Epoch: 2423, Batch Gradient Norm: 3.023123215685264
Epoch: 2423, Batch Gradient Norm after: 3.023123215685264
Epoch 2424/10000, Prediction Accuracy = 61.661538461538456%, Loss = 0.008967451536311554
Epoch: 2424, Batch Gradient Norm: 3.083033533370203
Epoch: 2424, Batch Gradient Norm after: 3.083033533370203
Epoch 2425/10000, Prediction Accuracy = 62.16153846153847%, Loss = 0.00895181276763861
Epoch: 2425, Batch Gradient Norm: 3.037720398189161
Epoch: 2425, Batch Gradient Norm after: 3.037720398189161
Epoch 2426/10000, Prediction Accuracy = 61.79615384615386%, Loss = 0.008910061433338202
Epoch: 2426, Batch Gradient Norm: 3.174051035325642
Epoch: 2426, Batch Gradient Norm after: 3.174051035325642
Epoch 2427/10000, Prediction Accuracy = 61.76538461538461%, Loss = 0.008969360819229713
Epoch: 2427, Batch Gradient Norm: 3.3550489776255983
Epoch: 2427, Batch Gradient Norm after: 3.3550489776255983
Epoch 2428/10000, Prediction Accuracy = 61.66923076923078%, Loss = 0.009069407287125405
Epoch: 2428, Batch Gradient Norm: 3.106392505211144
Epoch: 2428, Batch Gradient Norm after: 3.106392505211144
Epoch 2429/10000, Prediction Accuracy = 61.94615384615384%, Loss = 0.008847032816937337
Epoch: 2429, Batch Gradient Norm: 3.336007683275905
Epoch: 2429, Batch Gradient Norm after: 3.336007683275905
Epoch 2430/10000, Prediction Accuracy = 62.14230769230768%, Loss = 0.0089512958119695
Epoch: 2430, Batch Gradient Norm: 3.1559616915659663
Epoch: 2430, Batch Gradient Norm after: 3.1559616915659663
Epoch 2431/10000, Prediction Accuracy = 62.06538461538461%, Loss = 0.008931466306631382
Epoch: 2431, Batch Gradient Norm: 3.361709954628402
Epoch: 2431, Batch Gradient Norm after: 3.361709954628402
Epoch 2432/10000, Prediction Accuracy = 61.91923076923077%, Loss = 0.009026163186018284
Epoch: 2432, Batch Gradient Norm: 3.4987440351258687
Epoch: 2432, Batch Gradient Norm after: 3.4987440351258687
Epoch 2433/10000, Prediction Accuracy = 61.6076923076923%, Loss = 0.00912835062123262
Epoch: 2433, Batch Gradient Norm: 3.1607859579044124
Epoch: 2433, Batch Gradient Norm after: 3.1607859579044124
Epoch 2434/10000, Prediction Accuracy = 61.638461538461534%, Loss = 0.008970936903586755
Epoch: 2434, Batch Gradient Norm: 3.7163734458042126
Epoch: 2434, Batch Gradient Norm after: 3.7163734458042126
Epoch 2435/10000, Prediction Accuracy = 61.0846153846154%, Loss = 0.009231436567810865
Epoch: 2435, Batch Gradient Norm: 3.2304854766089197
Epoch: 2435, Batch Gradient Norm after: 3.2304854766089197
Epoch 2436/10000, Prediction Accuracy = 61.323076923076925%, Loss = 0.00900865919314898
Epoch: 2436, Batch Gradient Norm: 3.0355622045413364
Epoch: 2436, Batch Gradient Norm after: 3.0355622045413364
Epoch 2437/10000, Prediction Accuracy = 62.138461538461534%, Loss = 0.008877360763458105
Epoch: 2437, Batch Gradient Norm: 3.4853239225344304
Epoch: 2437, Batch Gradient Norm after: 3.4853239225344304
Epoch 2438/10000, Prediction Accuracy = 61.334615384615375%, Loss = 0.009103492260552369
Epoch: 2438, Batch Gradient Norm: 3.621510091843205
Epoch: 2438, Batch Gradient Norm after: 3.621510091843205
Epoch 2439/10000, Prediction Accuracy = 60.99615384615384%, Loss = 0.009322891298394937
Epoch: 2439, Batch Gradient Norm: 3.3965541281379705
Epoch: 2439, Batch Gradient Norm after: 3.3965541281379705
Epoch 2440/10000, Prediction Accuracy = 61.81153846153846%, Loss = 0.009026026209959617
Epoch: 2440, Batch Gradient Norm: 3.0887012978918498
Epoch: 2440, Batch Gradient Norm after: 3.0887012978918498
Epoch 2441/10000, Prediction Accuracy = 62.04615384615385%, Loss = 0.00887323858646246
Epoch: 2441, Batch Gradient Norm: 3.426430748372643
Epoch: 2441, Batch Gradient Norm after: 3.426430748372643
Epoch 2442/10000, Prediction Accuracy = 61.70384615384616%, Loss = 0.009016905338145219
Epoch: 2442, Batch Gradient Norm: 3.4018877926169764
Epoch: 2442, Batch Gradient Norm after: 3.4018877926169764
Epoch 2443/10000, Prediction Accuracy = 61.72307692307693%, Loss = 0.00906509354424018
Epoch: 2443, Batch Gradient Norm: 3.1223527232897776
Epoch: 2443, Batch Gradient Norm after: 3.1223527232897776
Epoch 2444/10000, Prediction Accuracy = 61.49230769230769%, Loss = 0.009005116442075143
Epoch: 2444, Batch Gradient Norm: 3.6658333881327927
Epoch: 2444, Batch Gradient Norm after: 3.6658333881327927
Epoch 2445/10000, Prediction Accuracy = 61.28846153846155%, Loss = 0.009165743724084817
Epoch: 2445, Batch Gradient Norm: 3.499806644184741
Epoch: 2445, Batch Gradient Norm after: 3.499806644184741
Epoch 2446/10000, Prediction Accuracy = 61.14230769230768%, Loss = 0.009217336057470394
Epoch: 2446, Batch Gradient Norm: 3.7129484039787353
Epoch: 2446, Batch Gradient Norm after: 3.7129484039787353
Epoch 2447/10000, Prediction Accuracy = 61.30384615384615%, Loss = 0.009190373122692108
Epoch: 2447, Batch Gradient Norm: 3.5675218559273585
Epoch: 2447, Batch Gradient Norm after: 3.5675218559273585
Epoch 2448/10000, Prediction Accuracy = 61.10384615384615%, Loss = 0.009271825950306196
Epoch: 2448, Batch Gradient Norm: 3.0300746196022996
Epoch: 2448, Batch Gradient Norm after: 3.0300746196022996
Epoch 2449/10000, Prediction Accuracy = 62.42307692307692%, Loss = 0.008913868250182042
Epoch: 2449, Batch Gradient Norm: 3.409600571730912
Epoch: 2449, Batch Gradient Norm after: 3.409600571730912
Epoch 2450/10000, Prediction Accuracy = 61.419230769230765%, Loss = 0.009071292355656624
Epoch: 2450, Batch Gradient Norm: 3.3373692381542375
Epoch: 2450, Batch Gradient Norm after: 3.3373692381542375
Epoch 2451/10000, Prediction Accuracy = 61.626923076923084%, Loss = 0.009016425348818302
Epoch: 2451, Batch Gradient Norm: 3.4585414395670493
Epoch: 2451, Batch Gradient Norm after: 3.4585414395670493
Epoch 2452/10000, Prediction Accuracy = 61.542307692307695%, Loss = 0.009079080504866747
Epoch: 2452, Batch Gradient Norm: 3.4745295224562804
Epoch: 2452, Batch Gradient Norm after: 3.4745295224562804
Epoch 2453/10000, Prediction Accuracy = 61.42692307692308%, Loss = 0.009095926267596392
Epoch: 2453, Batch Gradient Norm: 3.562757982608682
Epoch: 2453, Batch Gradient Norm after: 3.562757982608682
Epoch 2454/10000, Prediction Accuracy = 61.22692307692307%, Loss = 0.009173329489735456
Epoch: 2454, Batch Gradient Norm: 3.3346504622180726
Epoch: 2454, Batch Gradient Norm after: 3.3346504622180726
Epoch 2455/10000, Prediction Accuracy = 61.392307692307696%, Loss = 0.009068067615421919
Epoch: 2455, Batch Gradient Norm: 3.6204131894374285
Epoch: 2455, Batch Gradient Norm after: 3.6204131894374285
Epoch 2456/10000, Prediction Accuracy = 61.119230769230754%, Loss = 0.009287208390350524
Epoch: 2456, Batch Gradient Norm: 3.6935555423362807
Epoch: 2456, Batch Gradient Norm after: 3.6935555423362807
Epoch 2457/10000, Prediction Accuracy = 60.95769230769231%, Loss = 0.009323273642131915
Epoch: 2457, Batch Gradient Norm: 3.4788774637715427
Epoch: 2457, Batch Gradient Norm after: 3.4788774637715427
Epoch 2458/10000, Prediction Accuracy = 61.58846153846154%, Loss = 0.00913028777218782
Epoch: 2458, Batch Gradient Norm: 3.105888079599775
Epoch: 2458, Batch Gradient Norm after: 3.105888079599775
Epoch 2459/10000, Prediction Accuracy = 61.80384615384616%, Loss = 0.009009763168600889
Epoch: 2459, Batch Gradient Norm: 3.0380941260199337
Epoch: 2459, Batch Gradient Norm after: 3.0380941260199337
Epoch 2460/10000, Prediction Accuracy = 62.01538461538461%, Loss = 0.008871872622806292
Epoch: 2460, Batch Gradient Norm: 3.46473864560674
Epoch: 2460, Batch Gradient Norm after: 3.46473864560674
Epoch 2461/10000, Prediction Accuracy = 61.869230769230775%, Loss = 0.009084627891962346
Epoch: 2461, Batch Gradient Norm: 3.3517493958220728
Epoch: 2461, Batch Gradient Norm after: 3.3517493958220728
Epoch 2462/10000, Prediction Accuracy = 61.54230769230768%, Loss = 0.00903958404579988
Epoch: 2462, Batch Gradient Norm: 3.2641154964134893
Epoch: 2462, Batch Gradient Norm after: 3.2641154964134893
Epoch 2463/10000, Prediction Accuracy = 62.00000000000001%, Loss = 0.009013508876355795
Epoch: 2463, Batch Gradient Norm: 3.007886909128959
Epoch: 2463, Batch Gradient Norm after: 3.007886909128959
Epoch 2464/10000, Prediction Accuracy = 61.93846153846154%, Loss = 0.008855568030132698
Epoch: 2464, Batch Gradient Norm: 3.473587274360414
Epoch: 2464, Batch Gradient Norm after: 3.473587274360414
Epoch 2465/10000, Prediction Accuracy = 61.900000000000006%, Loss = 0.009050730902415056
Epoch: 2465, Batch Gradient Norm: 3.3385464676941163
Epoch: 2465, Batch Gradient Norm after: 3.3385464676941163
Epoch 2466/10000, Prediction Accuracy = 61.89230769230768%, Loss = 0.008984473390647998
Epoch: 2466, Batch Gradient Norm: 3.5921520035479784
Epoch: 2466, Batch Gradient Norm after: 3.5921520035479784
Epoch 2467/10000, Prediction Accuracy = 61.79999999999999%, Loss = 0.009036446205125405
Epoch: 2467, Batch Gradient Norm: 3.7323321051923273
Epoch: 2467, Batch Gradient Norm after: 3.7323321051923273
Epoch 2468/10000, Prediction Accuracy = 60.815384615384616%, Loss = 0.009265662744068183
Epoch: 2468, Batch Gradient Norm: 3.4052090436525364
Epoch: 2468, Batch Gradient Norm after: 3.4052090436525364
Epoch 2469/10000, Prediction Accuracy = 61.51153846153847%, Loss = 0.009110632065970164
Epoch: 2469, Batch Gradient Norm: 3.5989551188281514
Epoch: 2469, Batch Gradient Norm after: 3.5989551188281514
Epoch 2470/10000, Prediction Accuracy = 61.46923076923077%, Loss = 0.009195041126356674
Epoch: 2470, Batch Gradient Norm: 3.3886123069528957
Epoch: 2470, Batch Gradient Norm after: 3.3886123069528957
Epoch 2471/10000, Prediction Accuracy = 61.699999999999996%, Loss = 0.009059959306166722
Epoch: 2471, Batch Gradient Norm: 3.296947744946104
Epoch: 2471, Batch Gradient Norm after: 3.296947744946104
Epoch 2472/10000, Prediction Accuracy = 61.526923076923076%, Loss = 0.008953736665157171
Epoch: 2472, Batch Gradient Norm: 3.3568994358746216
Epoch: 2472, Batch Gradient Norm after: 3.3568994358746216
Epoch 2473/10000, Prediction Accuracy = 61.68461538461539%, Loss = 0.009000619157002522
Epoch: 2473, Batch Gradient Norm: 3.446191439554255
Epoch: 2473, Batch Gradient Norm after: 3.446191439554255
Epoch 2474/10000, Prediction Accuracy = 61.35384615384615%, Loss = 0.009031661427938022
Epoch: 2474, Batch Gradient Norm: 3.55658141218501
Epoch: 2474, Batch Gradient Norm after: 3.55658141218501
Epoch 2475/10000, Prediction Accuracy = 61.426923076923075%, Loss = 0.0091827348447763
Epoch: 2475, Batch Gradient Norm: 3.1650588027878515
Epoch: 2475, Batch Gradient Norm after: 3.1650588027878515
Epoch 2476/10000, Prediction Accuracy = 62.01923076923077%, Loss = 0.008915875321970535
Epoch: 2476, Batch Gradient Norm: 3.2288560551731056
Epoch: 2476, Batch Gradient Norm after: 3.2288560551731056
Epoch 2477/10000, Prediction Accuracy = 61.90384615384615%, Loss = 0.008942444450580157
Epoch: 2477, Batch Gradient Norm: 2.9701175365803487
Epoch: 2477, Batch Gradient Norm after: 2.9701175365803487
Epoch 2478/10000, Prediction Accuracy = 62.36153846153846%, Loss = 0.008766830468980165
Epoch: 2478, Batch Gradient Norm: 3.3383137806510033
Epoch: 2478, Batch Gradient Norm after: 3.3383137806510033
Epoch 2479/10000, Prediction Accuracy = 61.73461538461538%, Loss = 0.008963373632958302
Epoch: 2479, Batch Gradient Norm: 3.353768516604766
Epoch: 2479, Batch Gradient Norm after: 3.353768516604766
Epoch 2480/10000, Prediction Accuracy = 61.734615384615395%, Loss = 0.009021977105965981
Epoch: 2480, Batch Gradient Norm: 3.589218056308892
Epoch: 2480, Batch Gradient Norm after: 3.589218056308892
Epoch 2481/10000, Prediction Accuracy = 61.584615384615375%, Loss = 0.009106150040259728
Epoch: 2481, Batch Gradient Norm: 3.4623364346951204
Epoch: 2481, Batch Gradient Norm after: 3.4623364346951204
Epoch 2482/10000, Prediction Accuracy = 61.62307692307692%, Loss = 0.009073758569474403
Epoch: 2482, Batch Gradient Norm: 3.240030836622022
Epoch: 2482, Batch Gradient Norm after: 3.240030836622022
Epoch 2483/10000, Prediction Accuracy = 61.71153846153846%, Loss = 0.008926394825371413
Epoch: 2483, Batch Gradient Norm: 3.69128858067036
Epoch: 2483, Batch Gradient Norm after: 3.69128858067036
Epoch 2484/10000, Prediction Accuracy = 61.43076923076923%, Loss = 0.009118247204102002
Epoch: 2484, Batch Gradient Norm: 3.195629369766518
Epoch: 2484, Batch Gradient Norm after: 3.195629369766518
Epoch 2485/10000, Prediction Accuracy = 62.13846153846154%, Loss = 0.009007762974271407
Epoch: 2485, Batch Gradient Norm: 3.3359926902780255
Epoch: 2485, Batch Gradient Norm after: 3.3359926902780255
Epoch 2486/10000, Prediction Accuracy = 61.96923076923077%, Loss = 0.009012504050937982
Epoch: 2486, Batch Gradient Norm: 3.4616482578420555
Epoch: 2486, Batch Gradient Norm after: 3.4616482578420555
Epoch 2487/10000, Prediction Accuracy = 61.48076923076922%, Loss = 0.009114372329070019
Epoch: 2487, Batch Gradient Norm: 3.273348350292021
Epoch: 2487, Batch Gradient Norm after: 3.273348350292021
Epoch 2488/10000, Prediction Accuracy = 62.161538461538456%, Loss = 0.008960419047910433
Epoch: 2488, Batch Gradient Norm: 3.2577247464427597
Epoch: 2488, Batch Gradient Norm after: 3.2577247464427597
Epoch 2489/10000, Prediction Accuracy = 62.01153846153845%, Loss = 0.008984028863219114
Epoch: 2489, Batch Gradient Norm: 3.4949002092567154
Epoch: 2489, Batch Gradient Norm after: 3.4949002092567154
Epoch 2490/10000, Prediction Accuracy = 61.64230769230768%, Loss = 0.009096050778260598
Epoch: 2490, Batch Gradient Norm: 3.3533257910628924
Epoch: 2490, Batch Gradient Norm after: 3.3533257910628924
Epoch 2491/10000, Prediction Accuracy = 62.18461538461539%, Loss = 0.00890884598573813
Epoch: 2491, Batch Gradient Norm: 3.0344982051922615
Epoch: 2491, Batch Gradient Norm after: 3.0344982051922615
Epoch 2492/10000, Prediction Accuracy = 62.53846153846153%, Loss = 0.008773227437184406
Epoch: 2492, Batch Gradient Norm: 3.5134479087974384
Epoch: 2492, Batch Gradient Norm after: 3.5134479087974384
Epoch 2493/10000, Prediction Accuracy = 61.407692307692315%, Loss = 0.009003152569326071
Epoch: 2493, Batch Gradient Norm: 3.008710119607469
Epoch: 2493, Batch Gradient Norm after: 3.008710119607469
Epoch 2494/10000, Prediction Accuracy = 62.07307692307692%, Loss = 0.00879436287169273
Epoch: 2494, Batch Gradient Norm: 3.4879647967410174
Epoch: 2494, Batch Gradient Norm after: 3.4879647967410174
Epoch 2495/10000, Prediction Accuracy = 60.89615384615385%, Loss = 0.009067520570869628
Epoch: 2495, Batch Gradient Norm: 3.3341242614695243
Epoch: 2495, Batch Gradient Norm after: 3.3341242614695243
Epoch 2496/10000, Prediction Accuracy = 62.08461538461539%, Loss = 0.008951053453179507
Epoch: 2496, Batch Gradient Norm: 3.5182063555167535
Epoch: 2496, Batch Gradient Norm after: 3.5182063555167535
Epoch 2497/10000, Prediction Accuracy = 61.08846153846154%, Loss = 0.009005131987998119
Epoch: 2497, Batch Gradient Norm: 3.363537769313306
Epoch: 2497, Batch Gradient Norm after: 3.363537769313306
Epoch 2498/10000, Prediction Accuracy = 61.67307692307692%, Loss = 0.009001129163572421
Epoch: 2498, Batch Gradient Norm: 3.5633011685214444
Epoch: 2498, Batch Gradient Norm after: 3.5633011685214444
Epoch 2499/10000, Prediction Accuracy = 61.650000000000006%, Loss = 0.009098489052401139
Epoch: 2499, Batch Gradient Norm: 3.4552234048248716
Epoch: 2499, Batch Gradient Norm after: 3.4552234048248716
Epoch 2500/10000, Prediction Accuracy = 61.926923076923075%, Loss = 0.009007003015050521
Epoch: 2500, Batch Gradient Norm: 3.4510098501987843
Epoch: 2500, Batch Gradient Norm after: 3.4510098501987843
Epoch 2501/10000, Prediction Accuracy = 61.580769230769235%, Loss = 0.009070409318575492
Epoch: 2501, Batch Gradient Norm: 3.327594455260318
Epoch: 2501, Batch Gradient Norm after: 3.327594455260318
Epoch 2502/10000, Prediction Accuracy = 61.86153846153846%, Loss = 0.008994381874799728
Epoch: 2502, Batch Gradient Norm: 3.296194753044591
Epoch: 2502, Batch Gradient Norm after: 3.296194753044591
Epoch 2503/10000, Prediction Accuracy = 61.615384615384606%, Loss = 0.009071830946665544
Epoch: 2503, Batch Gradient Norm: 3.495293995472954
Epoch: 2503, Batch Gradient Norm after: 3.495293995472954
Epoch 2504/10000, Prediction Accuracy = 61.35384615384616%, Loss = 0.009089225043471042
Epoch: 2504, Batch Gradient Norm: 3.590024398741534
Epoch: 2504, Batch Gradient Norm after: 3.590024398741534
Epoch 2505/10000, Prediction Accuracy = 61.092307692307685%, Loss = 0.009175829589366913
Epoch: 2505, Batch Gradient Norm: 3.621170020588389
Epoch: 2505, Batch Gradient Norm after: 3.621170020588389
Epoch 2506/10000, Prediction Accuracy = 61.696153846153834%, Loss = 0.009073454743394485
Epoch: 2506, Batch Gradient Norm: 3.621624431500937
Epoch: 2506, Batch Gradient Norm after: 3.621624431500937
Epoch 2507/10000, Prediction Accuracy = 61.51153846153846%, Loss = 0.009100310146235503
Epoch: 2507, Batch Gradient Norm: 3.400598347413017
Epoch: 2507, Batch Gradient Norm after: 3.400598347413017
Epoch 2508/10000, Prediction Accuracy = 61.650000000000006%, Loss = 0.009035279186299214
Epoch: 2508, Batch Gradient Norm: 3.2522419040440123
Epoch: 2508, Batch Gradient Norm after: 3.2522419040440123
Epoch 2509/10000, Prediction Accuracy = 61.45769230769231%, Loss = 0.008931998593302874
Epoch: 2509, Batch Gradient Norm: 3.204157882476872
Epoch: 2509, Batch Gradient Norm after: 3.204157882476872
Epoch 2510/10000, Prediction Accuracy = 62.05384615384615%, Loss = 0.00891255415402926
Epoch: 2510, Batch Gradient Norm: 3.219791982503018
Epoch: 2510, Batch Gradient Norm after: 3.219791982503018
Epoch 2511/10000, Prediction Accuracy = 62.053846153846166%, Loss = 0.008940606951140441
Epoch: 2511, Batch Gradient Norm: 3.3039539190120695
Epoch: 2511, Batch Gradient Norm after: 3.3039539190120695
Epoch 2512/10000, Prediction Accuracy = 61.888461538461534%, Loss = 0.008890056982636452
Epoch: 2512, Batch Gradient Norm: 3.7352903003283195
Epoch: 2512, Batch Gradient Norm after: 3.7352903003283195
Epoch 2513/10000, Prediction Accuracy = 61.53076923076923%, Loss = 0.009161505848169327
Epoch: 2513, Batch Gradient Norm: 3.76646566229595
Epoch: 2513, Batch Gradient Norm after: 3.76646566229595
Epoch 2514/10000, Prediction Accuracy = 61.30384615384616%, Loss = 0.009261827342785321
Epoch: 2514, Batch Gradient Norm: 3.478575608971343
Epoch: 2514, Batch Gradient Norm after: 3.478575608971343
Epoch 2515/10000, Prediction Accuracy = 61.44615384615385%, Loss = 0.009073476808575483
Epoch: 2515, Batch Gradient Norm: 3.6246884089725895
Epoch: 2515, Batch Gradient Norm after: 3.6246884089725895
Epoch 2516/10000, Prediction Accuracy = 61.08846153846154%, Loss = 0.0092357095474234
Epoch: 2516, Batch Gradient Norm: 3.5113468880623886
Epoch: 2516, Batch Gradient Norm after: 3.5113468880623886
Epoch 2517/10000, Prediction Accuracy = 61.10000000000001%, Loss = 0.0091748577900804
Epoch: 2517, Batch Gradient Norm: 3.106578662675886
Epoch: 2517, Batch Gradient Norm after: 3.106578662675886
Epoch 2518/10000, Prediction Accuracy = 62.36923076923077%, Loss = 0.0088811692280265
Epoch: 2518, Batch Gradient Norm: 3.339044539437749
Epoch: 2518, Batch Gradient Norm after: 3.339044539437749
Epoch 2519/10000, Prediction Accuracy = 61.826923076923066%, Loss = 0.008922092186716886
Epoch: 2519, Batch Gradient Norm: 3.2822280540849094
Epoch: 2519, Batch Gradient Norm after: 3.2822280540849094
Epoch 2520/10000, Prediction Accuracy = 62.24230769230769%, Loss = 0.008901339597426929
Epoch: 2520, Batch Gradient Norm: 3.4188951176791753
Epoch: 2520, Batch Gradient Norm after: 3.4188951176791753
Epoch 2521/10000, Prediction Accuracy = 62.115384615384606%, Loss = 0.008973353470747288
Epoch: 2521, Batch Gradient Norm: 3.425037121227576
Epoch: 2521, Batch Gradient Norm after: 3.425037121227576
Epoch 2522/10000, Prediction Accuracy = 61.869230769230775%, Loss = 0.008951933911213508
Epoch: 2522, Batch Gradient Norm: 3.528531201416714
Epoch: 2522, Batch Gradient Norm after: 3.528531201416714
Epoch 2523/10000, Prediction Accuracy = 61.357692307692304%, Loss = 0.009137093662642516
Epoch: 2523, Batch Gradient Norm: 3.431757076756154
Epoch: 2523, Batch Gradient Norm after: 3.431757076756154
Epoch 2524/10000, Prediction Accuracy = 61.973076923076924%, Loss = 0.00896260615151662
Epoch: 2524, Batch Gradient Norm: 3.6345039335057217
Epoch: 2524, Batch Gradient Norm after: 3.6345039335057217
Epoch 2525/10000, Prediction Accuracy = 61.873076923076916%, Loss = 0.009053905351230731
Epoch: 2525, Batch Gradient Norm: 3.659679796042347
Epoch: 2525, Batch Gradient Norm after: 3.659679796042347
Epoch 2526/10000, Prediction Accuracy = 61.29230769230768%, Loss = 0.009198853459495764
Epoch: 2526, Batch Gradient Norm: 3.3607353636768926
Epoch: 2526, Batch Gradient Norm after: 3.3607353636768926
Epoch 2527/10000, Prediction Accuracy = 61.40384615384615%, Loss = 0.00908528476093824
Epoch: 2527, Batch Gradient Norm: 3.778318794707864
Epoch: 2527, Batch Gradient Norm after: 3.778318794707864
Epoch 2528/10000, Prediction Accuracy = 61.150000000000006%, Loss = 0.009184797652638875
Epoch: 2528, Batch Gradient Norm: 3.6329998583286636
Epoch: 2528, Batch Gradient Norm after: 3.6329998583286636
Epoch 2529/10000, Prediction Accuracy = 61.30384615384615%, Loss = 0.009125758463946672
Epoch: 2529, Batch Gradient Norm: 3.3144621570838404
Epoch: 2529, Batch Gradient Norm after: 3.3144621570838404
Epoch 2530/10000, Prediction Accuracy = 61.51923076923078%, Loss = 0.008929349553699676
Epoch: 2530, Batch Gradient Norm: 3.4746951762774763
Epoch: 2530, Batch Gradient Norm after: 3.4746951762774763
Epoch 2531/10000, Prediction Accuracy = 61.23076923076923%, Loss = 0.009079557127104355
Epoch: 2531, Batch Gradient Norm: 3.476402185753684
Epoch: 2531, Batch Gradient Norm after: 3.476402185753684
Epoch 2532/10000, Prediction Accuracy = 61.30384615384615%, Loss = 0.009074601559684826
Epoch: 2532, Batch Gradient Norm: 3.2301932852972715
Epoch: 2532, Batch Gradient Norm after: 3.2301932852972715
Epoch 2533/10000, Prediction Accuracy = 61.99230769230769%, Loss = 0.009001067338081507
Epoch: 2533, Batch Gradient Norm: 3.2347343888173685
Epoch: 2533, Batch Gradient Norm after: 3.2347343888173685
Epoch 2534/10000, Prediction Accuracy = 62.20769230769229%, Loss = 0.008907053547982987
Epoch: 2534, Batch Gradient Norm: 3.4279555546881935
Epoch: 2534, Batch Gradient Norm after: 3.4279555546881935
Epoch 2535/10000, Prediction Accuracy = 61.80769230769231%, Loss = 0.00902906977213346
Epoch: 2535, Batch Gradient Norm: 3.221577344854586
Epoch: 2535, Batch Gradient Norm after: 3.221577344854586
Epoch 2536/10000, Prediction Accuracy = 62.26538461538462%, Loss = 0.008895801093715888
Epoch: 2536, Batch Gradient Norm: 3.5110587191409337
Epoch: 2536, Batch Gradient Norm after: 3.5110587191409337
Epoch 2537/10000, Prediction Accuracy = 61.357692307692304%, Loss = 0.00911320516696343
Epoch: 2537, Batch Gradient Norm: 3.3782874426727694
Epoch: 2537, Batch Gradient Norm after: 3.3782874426727694
Epoch 2538/10000, Prediction Accuracy = 61.83076923076923%, Loss = 0.009037675550923897
Epoch: 2538, Batch Gradient Norm: 3.9139603402939027
Epoch: 2538, Batch Gradient Norm after: 3.9139603402939027
Epoch 2539/10000, Prediction Accuracy = 61.580769230769235%, Loss = 0.009253117757347913
Epoch: 2539, Batch Gradient Norm: 3.430089465411041
Epoch: 2539, Batch Gradient Norm after: 3.430089465411041
Epoch 2540/10000, Prediction Accuracy = 61.56153846153846%, Loss = 0.009035243151279597
Epoch: 2540, Batch Gradient Norm: 3.370864093592981
Epoch: 2540, Batch Gradient Norm after: 3.370864093592981
Epoch 2541/10000, Prediction Accuracy = 62.05384615384615%, Loss = 0.00894327239634899
Epoch: 2541, Batch Gradient Norm: 3.5071461414062504
Epoch: 2541, Batch Gradient Norm after: 3.5071461414062504
Epoch 2542/10000, Prediction Accuracy = 61.59230769230768%, Loss = 0.009120718432733646
Epoch: 2542, Batch Gradient Norm: 3.563331009552127
Epoch: 2542, Batch Gradient Norm after: 3.563331009552127
Epoch 2543/10000, Prediction Accuracy = 61.776923076923076%, Loss = 0.009110684506595135
Epoch: 2543, Batch Gradient Norm: 3.427783200861709
Epoch: 2543, Batch Gradient Norm after: 3.427783200861709
Epoch 2544/10000, Prediction Accuracy = 61.69230769230769%, Loss = 0.009047690492409926
Epoch: 2544, Batch Gradient Norm: 3.5771553505935776
Epoch: 2544, Batch Gradient Norm after: 3.5771553505935776
Epoch 2545/10000, Prediction Accuracy = 61.4153846153846%, Loss = 0.009099302097008778
Epoch: 2545, Batch Gradient Norm: 3.2785337735302345
Epoch: 2545, Batch Gradient Norm after: 3.2785337735302345
Epoch 2546/10000, Prediction Accuracy = 62.13461538461537%, Loss = 0.008868489844294695
Epoch: 2546, Batch Gradient Norm: 3.3698784194508025
Epoch: 2546, Batch Gradient Norm after: 3.3698784194508025
Epoch 2547/10000, Prediction Accuracy = 61.900000000000006%, Loss = 0.008938802334551629
Epoch: 2547, Batch Gradient Norm: 3.6440427641410946
Epoch: 2547, Batch Gradient Norm after: 3.6440427641410946
Epoch 2548/10000, Prediction Accuracy = 61.330769230769235%, Loss = 0.00912805560689706
Epoch: 2548, Batch Gradient Norm: 3.577197320229619
Epoch: 2548, Batch Gradient Norm after: 3.577197320229619
Epoch 2549/10000, Prediction Accuracy = 61.77307692307693%, Loss = 0.009097079818065349
Epoch: 2549, Batch Gradient Norm: 3.222459752696757
Epoch: 2549, Batch Gradient Norm after: 3.222459752696757
Epoch 2550/10000, Prediction Accuracy = 62.119230769230775%, Loss = 0.00892169658954327
Epoch: 2550, Batch Gradient Norm: 3.896056944300784
Epoch: 2550, Batch Gradient Norm after: 3.896056944300784
Epoch 2551/10000, Prediction Accuracy = 60.896153846153844%, Loss = 0.00930492400836486
Epoch: 2551, Batch Gradient Norm: 3.5562913429793888
Epoch: 2551, Batch Gradient Norm after: 3.5562913429793888
Epoch 2552/10000, Prediction Accuracy = 60.949999999999996%, Loss = 0.009192993076374898
Epoch: 2552, Batch Gradient Norm: 3.3351466251874187
Epoch: 2552, Batch Gradient Norm after: 3.3351466251874187
Epoch 2553/10000, Prediction Accuracy = 61.73461538461538%, Loss = 0.008894230239093304
Epoch: 2553, Batch Gradient Norm: 3.314255289240005
Epoch: 2553, Batch Gradient Norm after: 3.314255289240005
Epoch 2554/10000, Prediction Accuracy = 61.87692307692308%, Loss = 0.008930490280573185
Epoch: 2554, Batch Gradient Norm: 3.648167790648935
Epoch: 2554, Batch Gradient Norm after: 3.648167790648935
Epoch 2555/10000, Prediction Accuracy = 61.99230769230769%, Loss = 0.008968491608706804
Epoch: 2555, Batch Gradient Norm: 3.5959326401596035
Epoch: 2555, Batch Gradient Norm after: 3.5959326401596035
Epoch 2556/10000, Prediction Accuracy = 61.51923076923077%, Loss = 0.009158382622095255
Epoch: 2556, Batch Gradient Norm: 3.3782070975169525
Epoch: 2556, Batch Gradient Norm after: 3.3782070975169525
Epoch 2557/10000, Prediction Accuracy = 61.673076923076934%, Loss = 0.009061424133296195
Epoch: 2557, Batch Gradient Norm: 3.3328110310687786
Epoch: 2557, Batch Gradient Norm after: 3.3328110310687786
Epoch 2558/10000, Prediction Accuracy = 61.78076923076923%, Loss = 0.008968576000860104
Epoch: 2558, Batch Gradient Norm: 3.1635035663917748
Epoch: 2558, Batch Gradient Norm after: 3.1635035663917748
Epoch 2559/10000, Prediction Accuracy = 62.28846153846153%, Loss = 0.008781114808068825
Epoch: 2559, Batch Gradient Norm: 3.4369334199333843
Epoch: 2559, Batch Gradient Norm after: 3.4369334199333843
Epoch 2560/10000, Prediction Accuracy = 62.01153846153846%, Loss = 0.008924390834111433
Epoch: 2560, Batch Gradient Norm: 3.5429655104165727
Epoch: 2560, Batch Gradient Norm after: 3.5429655104165727
Epoch 2561/10000, Prediction Accuracy = 61.734615384615374%, Loss = 0.009018832459472693
Epoch: 2561, Batch Gradient Norm: 3.539300776783197
Epoch: 2561, Batch Gradient Norm after: 3.539300776783197
Epoch 2562/10000, Prediction Accuracy = 61.81923076923076%, Loss = 0.00900025637103961
Epoch: 2562, Batch Gradient Norm: 3.464434122159315
Epoch: 2562, Batch Gradient Norm after: 3.464434122159315
Epoch 2563/10000, Prediction Accuracy = 61.94230769230769%, Loss = 0.009102775142169915
Epoch: 2563, Batch Gradient Norm: 3.292562265266879
Epoch: 2563, Batch Gradient Norm after: 3.292562265266879
Epoch 2564/10000, Prediction Accuracy = 62.273076923076935%, Loss = 0.00889461967520989
Epoch: 2564, Batch Gradient Norm: 3.0480873391229126
Epoch: 2564, Batch Gradient Norm after: 3.0480873391229126
Epoch 2565/10000, Prediction Accuracy = 62.53846153846153%, Loss = 0.008818651191317119
Epoch: 2565, Batch Gradient Norm: 3.222817605681497
Epoch: 2565, Batch Gradient Norm after: 3.222817605681497
Epoch 2566/10000, Prediction Accuracy = 61.81538461538461%, Loss = 0.008929987008181902
Epoch: 2566, Batch Gradient Norm: 3.3310944868277255
Epoch: 2566, Batch Gradient Norm after: 3.3310944868277255
Epoch 2567/10000, Prediction Accuracy = 61.61923076923077%, Loss = 0.008892570837185932
Epoch: 2567, Batch Gradient Norm: 3.566539248353541
Epoch: 2567, Batch Gradient Norm after: 3.566539248353541
Epoch 2568/10000, Prediction Accuracy = 61.650000000000006%, Loss = 0.008983695593017798
Epoch: 2568, Batch Gradient Norm: 3.403514531153709
Epoch: 2568, Batch Gradient Norm after: 3.403514531153709
Epoch 2569/10000, Prediction Accuracy = 61.97307692307691%, Loss = 0.00894500257877203
Epoch: 2569, Batch Gradient Norm: 3.6415081617255076
Epoch: 2569, Batch Gradient Norm after: 3.6415081617255076
Epoch 2570/10000, Prediction Accuracy = 61.861538461538466%, Loss = 0.009049459933661498
Epoch: 2570, Batch Gradient Norm: 3.3442149218710737
Epoch: 2570, Batch Gradient Norm after: 3.3442149218710737
Epoch 2571/10000, Prediction Accuracy = 62.35769230769232%, Loss = 0.008832998143938871
Epoch: 2571, Batch Gradient Norm: 3.3262159794420265
Epoch: 2571, Batch Gradient Norm after: 3.3262159794420265
Epoch 2572/10000, Prediction Accuracy = 61.98076923076923%, Loss = 0.00895834513581716
Epoch: 2572, Batch Gradient Norm: 3.3429329768560843
Epoch: 2572, Batch Gradient Norm after: 3.3429329768560843
Epoch 2573/10000, Prediction Accuracy = 61.71923076923076%, Loss = 0.008978043109751664
Epoch: 2573, Batch Gradient Norm: 3.394945850915527
Epoch: 2573, Batch Gradient Norm after: 3.394945850915527
Epoch 2574/10000, Prediction Accuracy = 62.19230769230769%, Loss = 0.008883352677982587
Epoch: 2574, Batch Gradient Norm: 3.1109862128832164
Epoch: 2574, Batch Gradient Norm after: 3.1109862128832164
Epoch 2575/10000, Prediction Accuracy = 62.396153846153844%, Loss = 0.008761417407255907
Epoch: 2575, Batch Gradient Norm: 3.2569094215304184
Epoch: 2575, Batch Gradient Norm after: 3.2569094215304184
Epoch 2576/10000, Prediction Accuracy = 62.357692307692325%, Loss = 0.008747861075859804
Epoch: 2576, Batch Gradient Norm: 3.123575689936155
Epoch: 2576, Batch Gradient Norm after: 3.123575689936155
Epoch 2577/10000, Prediction Accuracy = 62.27692307692309%, Loss = 0.008765708870039536
Epoch: 2577, Batch Gradient Norm: 3.3326526885778858
Epoch: 2577, Batch Gradient Norm after: 3.3326526885778858
Epoch 2578/10000, Prediction Accuracy = 62.315384615384616%, Loss = 0.008805891498923302
Epoch: 2578, Batch Gradient Norm: 3.833655485839787
Epoch: 2578, Batch Gradient Norm after: 3.833655485839787
Epoch 2579/10000, Prediction Accuracy = 61.40384615384615%, Loss = 0.0090937906732926
Epoch: 2579, Batch Gradient Norm: 3.870319955969997
Epoch: 2579, Batch Gradient Norm after: 3.870319955969997
Epoch 2580/10000, Prediction Accuracy = 61.30384615384615%, Loss = 0.00918525572006519
Epoch: 2580, Batch Gradient Norm: 3.5779995624613514
Epoch: 2580, Batch Gradient Norm after: 3.5779995624613514
Epoch 2581/10000, Prediction Accuracy = 62.16538461538461%, Loss = 0.008911665385732284
Epoch: 2581, Batch Gradient Norm: 3.312553901234209
Epoch: 2581, Batch Gradient Norm after: 3.312553901234209
Epoch 2582/10000, Prediction Accuracy = 61.75769230769232%, Loss = 0.00892181981068391
Epoch: 2582, Batch Gradient Norm: 3.476373916977021
Epoch: 2582, Batch Gradient Norm after: 3.476373916977021
Epoch 2583/10000, Prediction Accuracy = 61.80384615384615%, Loss = 0.008929276982179055
Epoch: 2583, Batch Gradient Norm: 3.297309027248394
Epoch: 2583, Batch Gradient Norm after: 3.297309027248394
Epoch 2584/10000, Prediction Accuracy = 62.292307692307695%, Loss = 0.008836874451774817
Epoch: 2584, Batch Gradient Norm: 3.650754534764565
Epoch: 2584, Batch Gradient Norm after: 3.650754534764565
Epoch 2585/10000, Prediction Accuracy = 61.834615384615375%, Loss = 0.009029906028165268
Epoch: 2585, Batch Gradient Norm: 3.6047120788117635
Epoch: 2585, Batch Gradient Norm after: 3.6047120788117635
Epoch 2586/10000, Prediction Accuracy = 61.73846153846154%, Loss = 0.009035028875447236
Epoch: 2586, Batch Gradient Norm: 3.3067516329136435
Epoch: 2586, Batch Gradient Norm after: 3.3067516329136435
Epoch 2587/10000, Prediction Accuracy = 62.46153846153847%, Loss = 0.008829214108678011
Epoch: 2587, Batch Gradient Norm: 3.437746159390846
Epoch: 2587, Batch Gradient Norm after: 3.437746159390846
Epoch 2588/10000, Prediction Accuracy = 62.06923076923076%, Loss = 0.008857243264523836
Epoch: 2588, Batch Gradient Norm: 3.424374338311434
Epoch: 2588, Batch Gradient Norm after: 3.424374338311434
Epoch 2589/10000, Prediction Accuracy = 61.80769230769231%, Loss = 0.008913834292728167
Epoch: 2589, Batch Gradient Norm: 3.6045110059958834
Epoch: 2589, Batch Gradient Norm after: 3.6045110059958834
Epoch 2590/10000, Prediction Accuracy = 61.31923076923077%, Loss = 0.008937587818274131
Epoch: 2590, Batch Gradient Norm: 3.4869703461341355
Epoch: 2590, Batch Gradient Norm after: 3.4869703461341355
Epoch 2591/10000, Prediction Accuracy = 61.834615384615375%, Loss = 0.008875151236469928
Epoch: 2591, Batch Gradient Norm: 3.4170836226724326
Epoch: 2591, Batch Gradient Norm after: 3.4170836226724326
Epoch 2592/10000, Prediction Accuracy = 61.95384615384615%, Loss = 0.008874451240094809
Epoch: 2592, Batch Gradient Norm: 3.8292262005681215
Epoch: 2592, Batch Gradient Norm after: 3.8292262005681215
Epoch 2593/10000, Prediction Accuracy = 61.79230769230769%, Loss = 0.009052585452221908
Epoch: 2593, Batch Gradient Norm: 3.6977742819673205
Epoch: 2593, Batch Gradient Norm after: 3.6977742819673205
Epoch 2594/10000, Prediction Accuracy = 61.60384615384617%, Loss = 0.009134478652133392
Epoch: 2594, Batch Gradient Norm: 3.7519914502522553
Epoch: 2594, Batch Gradient Norm after: 3.7519914502522553
Epoch 2595/10000, Prediction Accuracy = 61.12307692307692%, Loss = 0.009182612483318035
Epoch: 2595, Batch Gradient Norm: 4.079934844761601
Epoch: 2595, Batch Gradient Norm after: 4.079934844761601
Epoch 2596/10000, Prediction Accuracy = 60.96538461538462%, Loss = 0.00931838147628766
Epoch: 2596, Batch Gradient Norm: 3.878693914580422
Epoch: 2596, Batch Gradient Norm after: 3.878693914580422
Epoch 2597/10000, Prediction Accuracy = 60.965384615384615%, Loss = 0.009314855918861352
Epoch: 2597, Batch Gradient Norm: 3.694143605125063
Epoch: 2597, Batch Gradient Norm after: 3.694143605125063
Epoch 2598/10000, Prediction Accuracy = 61.3423076923077%, Loss = 0.009249920813510051
Epoch: 2598, Batch Gradient Norm: 3.413299216226848
Epoch: 2598, Batch Gradient Norm after: 3.413299216226848
Epoch 2599/10000, Prediction Accuracy = 61.48461538461538%, Loss = 0.00897265483553593
Epoch: 2599, Batch Gradient Norm: 3.708613601412786
Epoch: 2599, Batch Gradient Norm after: 3.708613601412786
Epoch 2600/10000, Prediction Accuracy = 61.49615384615385%, Loss = 0.009128018353994075
Epoch: 2600, Batch Gradient Norm: 2.985774817106765
Epoch: 2600, Batch Gradient Norm after: 2.985774817106765
Epoch 2601/10000, Prediction Accuracy = 62.3%, Loss = 0.008676954545080662
Epoch: 2601, Batch Gradient Norm: 3.4165428146681767
Epoch: 2601, Batch Gradient Norm after: 3.4165428146681767
Epoch 2602/10000, Prediction Accuracy = 62.18076923076922%, Loss = 0.008872355549381329
Epoch: 2602, Batch Gradient Norm: 3.4785867073940064
Epoch: 2602, Batch Gradient Norm after: 3.4785867073940064
Epoch 2603/10000, Prediction Accuracy = 62.119230769230775%, Loss = 0.008880510424765257
Epoch: 2603, Batch Gradient Norm: 3.1659559926127985
Epoch: 2603, Batch Gradient Norm after: 3.1659559926127985
Epoch 2604/10000, Prediction Accuracy = 62.56538461538462%, Loss = 0.008714805930279769
Epoch: 2604, Batch Gradient Norm: 3.276347109296141
Epoch: 2604, Batch Gradient Norm after: 3.276347109296141
Epoch 2605/10000, Prediction Accuracy = 62.173076923076934%, Loss = 0.008830823505727144
Epoch: 2605, Batch Gradient Norm: 3.5141899335785856
Epoch: 2605, Batch Gradient Norm after: 3.5141899335785856
Epoch 2606/10000, Prediction Accuracy = 61.92307692307691%, Loss = 0.008890814935931792
Epoch: 2606, Batch Gradient Norm: 3.5691075034776336
Epoch: 2606, Batch Gradient Norm after: 3.5691075034776336
Epoch 2607/10000, Prediction Accuracy = 61.434615384615384%, Loss = 0.008984863686446961
Epoch: 2607, Batch Gradient Norm: 3.096089670293897
Epoch: 2607, Batch Gradient Norm after: 3.096089670293897
Epoch 2608/10000, Prediction Accuracy = 62.380769230769225%, Loss = 0.008763759611890866
Epoch: 2608, Batch Gradient Norm: 3.484148897610095
Epoch: 2608, Batch Gradient Norm after: 3.484148897610095
Epoch 2609/10000, Prediction Accuracy = 62.33076923076923%, Loss = 0.00887704210785719
Epoch: 2609, Batch Gradient Norm: 3.5757628458733994
Epoch: 2609, Batch Gradient Norm after: 3.5757628458733994
Epoch 2610/10000, Prediction Accuracy = 62.06153846153845%, Loss = 0.008983241824003367
Epoch: 2610, Batch Gradient Norm: 3.570162779708092
Epoch: 2610, Batch Gradient Norm after: 3.570162779708092
Epoch 2611/10000, Prediction Accuracy = 61.44615384615384%, Loss = 0.009036830769708524
Epoch: 2611, Batch Gradient Norm: 3.3620625440003424
Epoch: 2611, Batch Gradient Norm after: 3.3620625440003424
Epoch 2612/10000, Prediction Accuracy = 61.97307692307693%, Loss = 0.008854096253904013
Epoch: 2612, Batch Gradient Norm: 3.460333520068053
Epoch: 2612, Batch Gradient Norm after: 3.460333520068053
Epoch 2613/10000, Prediction Accuracy = 62.18461538461539%, Loss = 0.008818789671819944
Epoch: 2613, Batch Gradient Norm: 3.282114871828321
Epoch: 2613, Batch Gradient Norm after: 3.282114871828321
Epoch 2614/10000, Prediction Accuracy = 62.33076923076922%, Loss = 0.00882053360916101
Epoch: 2614, Batch Gradient Norm: 3.2350881584756315
Epoch: 2614, Batch Gradient Norm after: 3.2350881584756315
Epoch 2615/10000, Prediction Accuracy = 62.15384615384615%, Loss = 0.008783635826638112
Epoch: 2615, Batch Gradient Norm: 3.424879592468816
Epoch: 2615, Batch Gradient Norm after: 3.424879592468816
Epoch 2616/10000, Prediction Accuracy = 61.98846153846154%, Loss = 0.008904065793523422
Epoch: 2616, Batch Gradient Norm: 3.2556637247255216
Epoch: 2616, Batch Gradient Norm after: 3.2556637247255216
Epoch 2617/10000, Prediction Accuracy = 62.14615384615385%, Loss = 0.008733587984282237
Epoch: 2617, Batch Gradient Norm: 3.6023075653645145
Epoch: 2617, Batch Gradient Norm after: 3.6023075653645145
Epoch 2618/10000, Prediction Accuracy = 62.33461538461539%, Loss = 0.00881253913618051
Epoch: 2618, Batch Gradient Norm: 3.526008816124414
Epoch: 2618, Batch Gradient Norm after: 3.526008816124414
Epoch 2619/10000, Prediction Accuracy = 61.87692307692306%, Loss = 0.00894505695368235
Epoch: 2619, Batch Gradient Norm: 3.4957986102055174
Epoch: 2619, Batch Gradient Norm after: 3.4957986102055174
Epoch 2620/10000, Prediction Accuracy = 62.18461538461538%, Loss = 0.008914352537920842
Epoch: 2620, Batch Gradient Norm: 3.9560791386008334
Epoch: 2620, Batch Gradient Norm after: 3.9560791386008334
Epoch 2621/10000, Prediction Accuracy = 61.08461538461539%, Loss = 0.009252938943413587
Epoch: 2621, Batch Gradient Norm: 3.596045451505893
Epoch: 2621, Batch Gradient Norm after: 3.596045451505893
Epoch 2622/10000, Prediction Accuracy = 61.907692307692315%, Loss = 0.009013341954694344
Epoch: 2622, Batch Gradient Norm: 3.5746982664145333
Epoch: 2622, Batch Gradient Norm after: 3.5746982664145333
Epoch 2623/10000, Prediction Accuracy = 61.63461538461539%, Loss = 0.008960347909193773
Epoch: 2623, Batch Gradient Norm: 3.590419111979839
Epoch: 2623, Batch Gradient Norm after: 3.590419111979839
Epoch 2624/10000, Prediction Accuracy = 62.280769230769224%, Loss = 0.008983606902452616
Epoch: 2624, Batch Gradient Norm: 3.2425224879882713
Epoch: 2624, Batch Gradient Norm after: 3.2425224879882713
Epoch 2625/10000, Prediction Accuracy = 62.173076923076934%, Loss = 0.008770467283634039
Epoch: 2625, Batch Gradient Norm: 3.17752955357036
Epoch: 2625, Batch Gradient Norm after: 3.17752955357036
Epoch 2626/10000, Prediction Accuracy = 62.25000000000001%, Loss = 0.00888325610699562
Epoch: 2626, Batch Gradient Norm: 3.459401040514739
Epoch: 2626, Batch Gradient Norm after: 3.459401040514739
Epoch 2627/10000, Prediction Accuracy = 62.08846153846153%, Loss = 0.008879436681476923
Epoch: 2627, Batch Gradient Norm: 3.266606827636154
Epoch: 2627, Batch Gradient Norm after: 3.266606827636154
Epoch 2628/10000, Prediction Accuracy = 62.08076923076924%, Loss = 0.008866632715440713
Epoch: 2628, Batch Gradient Norm: 3.4590783376994967
Epoch: 2628, Batch Gradient Norm after: 3.4590783376994967
Epoch 2629/10000, Prediction Accuracy = 61.561538461538476%, Loss = 0.008899273637395639
Epoch: 2629, Batch Gradient Norm: 3.7367458682364285
Epoch: 2629, Batch Gradient Norm after: 3.7367458682364285
Epoch 2630/10000, Prediction Accuracy = 61.653846153846146%, Loss = 0.009107220129897961
Epoch: 2630, Batch Gradient Norm: 3.424745681829709
Epoch: 2630, Batch Gradient Norm after: 3.424745681829709
Epoch 2631/10000, Prediction Accuracy = 61.54615384615385%, Loss = 0.008931720056212865
Epoch: 2631, Batch Gradient Norm: 3.4378562276440054
Epoch: 2631, Batch Gradient Norm after: 3.4378562276440054
Epoch 2632/10000, Prediction Accuracy = 62.05000000000002%, Loss = 0.008903717120679526
Epoch: 2632, Batch Gradient Norm: 3.4979181573138733
Epoch: 2632, Batch Gradient Norm after: 3.4979181573138733
Epoch 2633/10000, Prediction Accuracy = 62.14999999999999%, Loss = 0.008769854616660338
Epoch: 2633, Batch Gradient Norm: 3.6954308297850837
Epoch: 2633, Batch Gradient Norm after: 3.6954308297850837
Epoch 2634/10000, Prediction Accuracy = 61.280769230769224%, Loss = 0.009054697405260343
Epoch: 2634, Batch Gradient Norm: 3.6469894263609905
Epoch: 2634, Batch Gradient Norm after: 3.6469894263609905
Epoch 2635/10000, Prediction Accuracy = 61.338461538461544%, Loss = 0.009005615774255533
Epoch: 2635, Batch Gradient Norm: 3.566736427951063
Epoch: 2635, Batch Gradient Norm after: 3.566736427951063
Epoch 2636/10000, Prediction Accuracy = 62.111538461538466%, Loss = 0.008908847991663676
Epoch: 2636, Batch Gradient Norm: 3.113531858520921
Epoch: 2636, Batch Gradient Norm after: 3.113531858520921
Epoch 2637/10000, Prediction Accuracy = 62.599999999999994%, Loss = 0.00862793459628637
Epoch: 2637, Batch Gradient Norm: 3.327410795906332
Epoch: 2637, Batch Gradient Norm after: 3.327410795906332
Epoch 2638/10000, Prediction Accuracy = 62.13461538461537%, Loss = 0.0087253307350553
Epoch: 2638, Batch Gradient Norm: 3.420305192761301
Epoch: 2638, Batch Gradient Norm after: 3.420305192761301
Epoch 2639/10000, Prediction Accuracy = 62.323076923076925%, Loss = 0.00877573978728973
Epoch: 2639, Batch Gradient Norm: 3.1742151884115914
Epoch: 2639, Batch Gradient Norm after: 3.1742151884115914
Epoch 2640/10000, Prediction Accuracy = 61.82307692307692%, Loss = 0.008835930090684157
Epoch: 2640, Batch Gradient Norm: 3.5479991024412723
Epoch: 2640, Batch Gradient Norm after: 3.5479991024412723
Epoch 2641/10000, Prediction Accuracy = 61.76538461538461%, Loss = 0.008956533570129138
Epoch: 2641, Batch Gradient Norm: 3.282182571968028
Epoch: 2641, Batch Gradient Norm after: 3.282182571968028
Epoch 2642/10000, Prediction Accuracy = 62.38461538461539%, Loss = 0.008795222840630092
Epoch: 2642, Batch Gradient Norm: 3.45139055793254
Epoch: 2642, Batch Gradient Norm after: 3.45139055793254
Epoch 2643/10000, Prediction Accuracy = 62.68461538461538%, Loss = 0.008713867228764754
Epoch: 2643, Batch Gradient Norm: 3.3221526175495484
Epoch: 2643, Batch Gradient Norm after: 3.3221526175495484
Epoch 2644/10000, Prediction Accuracy = 62.565384615384616%, Loss = 0.008686492649408488
Epoch: 2644, Batch Gradient Norm: 3.588376084636088
Epoch: 2644, Batch Gradient Norm after: 3.588376084636088
Epoch 2645/10000, Prediction Accuracy = 62.27692307692307%, Loss = 0.00889928495654693
Epoch: 2645, Batch Gradient Norm: 3.642621604137927
Epoch: 2645, Batch Gradient Norm after: 3.642621604137927
Epoch 2646/10000, Prediction Accuracy = 61.80384615384616%, Loss = 0.008917090841210805
Epoch: 2646, Batch Gradient Norm: 3.2909222887409006
Epoch: 2646, Batch Gradient Norm after: 3.2909222887409006
Epoch 2647/10000, Prediction Accuracy = 62.676923076923075%, Loss = 0.008672008434167275
Epoch: 2647, Batch Gradient Norm: 3.2742103983190876
Epoch: 2647, Batch Gradient Norm after: 3.2742103983190876
Epoch 2648/10000, Prediction Accuracy = 62.615384615384606%, Loss = 0.008736653611637078
Epoch: 2648, Batch Gradient Norm: 3.473651972849653
Epoch: 2648, Batch Gradient Norm after: 3.473651972849653
Epoch 2649/10000, Prediction Accuracy = 62.18846153846154%, Loss = 0.008802045065049943
Epoch: 2649, Batch Gradient Norm: 3.386795047669179
Epoch: 2649, Batch Gradient Norm after: 3.386795047669179
Epoch 2650/10000, Prediction Accuracy = 62.31923076923077%, Loss = 0.008814095304562496
Epoch: 2650, Batch Gradient Norm: 3.616572495242668
Epoch: 2650, Batch Gradient Norm after: 3.616572495242668
Epoch 2651/10000, Prediction Accuracy = 61.94615384615385%, Loss = 0.008770057358420812
Epoch: 2651, Batch Gradient Norm: 3.258860987551028
Epoch: 2651, Batch Gradient Norm after: 3.258860987551028
Epoch 2652/10000, Prediction Accuracy = 62.530769230769224%, Loss = 0.008693400483865004
Epoch: 2652, Batch Gradient Norm: 3.4553341061884413
Epoch: 2652, Batch Gradient Norm after: 3.4553341061884413
Epoch 2653/10000, Prediction Accuracy = 62.17307692307692%, Loss = 0.0086714388945928
Epoch: 2653, Batch Gradient Norm: 3.6766235393281805
Epoch: 2653, Batch Gradient Norm after: 3.6766235393281805
Epoch 2654/10000, Prediction Accuracy = 61.723076923076924%, Loss = 0.00884126377506898
Epoch: 2654, Batch Gradient Norm: 3.702162258714502
Epoch: 2654, Batch Gradient Norm after: 3.702162258714502
Epoch 2655/10000, Prediction Accuracy = 61.81153846153846%, Loss = 0.008958140459771339
Epoch: 2655, Batch Gradient Norm: 3.83009297369745
Epoch: 2655, Batch Gradient Norm after: 3.83009297369745
Epoch 2656/10000, Prediction Accuracy = 61.54615384615385%, Loss = 0.008961872197687626
Epoch: 2656, Batch Gradient Norm: 3.5735976733951964
Epoch: 2656, Batch Gradient Norm after: 3.5735976733951964
Epoch 2657/10000, Prediction Accuracy = 61.90384615384615%, Loss = 0.008874111522275668
Epoch: 2657, Batch Gradient Norm: 3.4119872074306272
Epoch: 2657, Batch Gradient Norm after: 3.4119872074306272
Epoch 2658/10000, Prediction Accuracy = 62.4423076923077%, Loss = 0.008683849914142719
Epoch: 2658, Batch Gradient Norm: 3.0558678682173572
Epoch: 2658, Batch Gradient Norm after: 3.0558678682173572
Epoch 2659/10000, Prediction Accuracy = 62.93846153846153%, Loss = 0.008537618228449272
Epoch: 2659, Batch Gradient Norm: 3.417961684255165
Epoch: 2659, Batch Gradient Norm after: 3.417961684255165
Epoch 2660/10000, Prediction Accuracy = 62.423076923076934%, Loss = 0.008768018621664781
Epoch: 2660, Batch Gradient Norm: 3.501416710368359
Epoch: 2660, Batch Gradient Norm after: 3.501416710368359
Epoch 2661/10000, Prediction Accuracy = 61.74230769230769%, Loss = 0.008879948765612565
Epoch: 2661, Batch Gradient Norm: 3.359890000236626
Epoch: 2661, Batch Gradient Norm after: 3.359890000236626
Epoch 2662/10000, Prediction Accuracy = 62.707692307692305%, Loss = 0.008750461400128327
Epoch: 2662, Batch Gradient Norm: 3.3025381829865172
Epoch: 2662, Batch Gradient Norm after: 3.3025381829865172
Epoch 2663/10000, Prediction Accuracy = 61.96538461538462%, Loss = 0.008717711871633163
Epoch: 2663, Batch Gradient Norm: 3.5061441553320942
Epoch: 2663, Batch Gradient Norm after: 3.5061441553320942
Epoch 2664/10000, Prediction Accuracy = 62.06923076923078%, Loss = 0.008911989557628449
Epoch: 2664, Batch Gradient Norm: 3.8132865915543386
Epoch: 2664, Batch Gradient Norm after: 3.8132865915543386
Epoch 2665/10000, Prediction Accuracy = 61.24230769230769%, Loss = 0.009144671332950775
Epoch: 2665, Batch Gradient Norm: 3.5904494801037354
Epoch: 2665, Batch Gradient Norm after: 3.5904494801037354
Epoch 2666/10000, Prediction Accuracy = 61.973076923076924%, Loss = 0.008911604563204141
Epoch: 2666, Batch Gradient Norm: 3.455076176093205
Epoch: 2666, Batch Gradient Norm after: 3.455076176093205
Epoch 2667/10000, Prediction Accuracy = 62.16153846153846%, Loss = 0.008813166775955604
Epoch: 2667, Batch Gradient Norm: 3.3288986509593417
Epoch: 2667, Batch Gradient Norm after: 3.3288986509593417
Epoch 2668/10000, Prediction Accuracy = 62.28846153846154%, Loss = 0.008725844968396883
Epoch: 2668, Batch Gradient Norm: 3.2204957836953554
Epoch: 2668, Batch Gradient Norm after: 3.2204957836953554
Epoch 2669/10000, Prediction Accuracy = 62.53076923076924%, Loss = 0.008610352157400204
Epoch: 2669, Batch Gradient Norm: 3.213476873990844
Epoch: 2669, Batch Gradient Norm after: 3.213476873990844
Epoch 2670/10000, Prediction Accuracy = 62.91538461538463%, Loss = 0.008605933246704249
Epoch: 2670, Batch Gradient Norm: 3.3233972932199918
Epoch: 2670, Batch Gradient Norm after: 3.3233972932199918
Epoch 2671/10000, Prediction Accuracy = 62.51538461538462%, Loss = 0.008724024734244896
Epoch: 2671, Batch Gradient Norm: 3.314153065487137
Epoch: 2671, Batch Gradient Norm after: 3.314153065487137
Epoch 2672/10000, Prediction Accuracy = 62.48461538461539%, Loss = 0.008702214019229779
Epoch: 2672, Batch Gradient Norm: 3.337440946438695
Epoch: 2672, Batch Gradient Norm after: 3.337440946438695
Epoch 2673/10000, Prediction Accuracy = 62.41153846153845%, Loss = 0.00869151340940824
Epoch: 2673, Batch Gradient Norm: 3.395687910221175
Epoch: 2673, Batch Gradient Norm after: 3.395687910221175
Epoch 2674/10000, Prediction Accuracy = 62.353846153846156%, Loss = 0.00868673214259056
Epoch: 2674, Batch Gradient Norm: 3.5126235850908394
Epoch: 2674, Batch Gradient Norm after: 3.5126235850908394
Epoch 2675/10000, Prediction Accuracy = 62.76538461538462%, Loss = 0.008760109615440551
Epoch: 2675, Batch Gradient Norm: 3.8631459421279737
Epoch: 2675, Batch Gradient Norm after: 3.8631459421279737
Epoch 2676/10000, Prediction Accuracy = 61.72307692307691%, Loss = 0.008978866255627228
Epoch: 2676, Batch Gradient Norm: 3.812286452292875
Epoch: 2676, Batch Gradient Norm after: 3.812286452292875
Epoch 2677/10000, Prediction Accuracy = 61.68076923076922%, Loss = 0.008999909632481061
Epoch: 2677, Batch Gradient Norm: 3.537152132449914
Epoch: 2677, Batch Gradient Norm after: 3.537152132449914
Epoch 2678/10000, Prediction Accuracy = 62.46923076923076%, Loss = 0.008822659603678264
Epoch: 2678, Batch Gradient Norm: 3.796299112906693
Epoch: 2678, Batch Gradient Norm after: 3.796299112906693
Epoch 2679/10000, Prediction Accuracy = 61.87692307692308%, Loss = 0.008982578077568458
Epoch: 2679, Batch Gradient Norm: 3.7527027059059956
Epoch: 2679, Batch Gradient Norm after: 3.7527027059059956
Epoch 2680/10000, Prediction Accuracy = 61.723076923076924%, Loss = 0.009034323649337659
Epoch: 2680, Batch Gradient Norm: 4.023897022887039
Epoch: 2680, Batch Gradient Norm after: 4.023897022887039
Epoch 2681/10000, Prediction Accuracy = 60.94615384615385%, Loss = 0.009127903156555615
Epoch: 2681, Batch Gradient Norm: 3.9256152022835202
Epoch: 2681, Batch Gradient Norm after: 3.9256152022835202
Epoch 2682/10000, Prediction Accuracy = 61.26538461538462%, Loss = 0.009205207085380187
Epoch: 2682, Batch Gradient Norm: 3.8934813987383796
Epoch: 2682, Batch Gradient Norm after: 3.8934813987383796
Epoch 2683/10000, Prediction Accuracy = 61.26538461538461%, Loss = 0.009284400954269446
Epoch: 2683, Batch Gradient Norm: 3.3489490930455017
Epoch: 2683, Batch Gradient Norm after: 3.3489490930455017
Epoch 2684/10000, Prediction Accuracy = 61.77692307692309%, Loss = 0.008900688101465885
Epoch: 2684, Batch Gradient Norm: 3.596088610149107
Epoch: 2684, Batch Gradient Norm after: 3.596088610149107
Epoch 2685/10000, Prediction Accuracy = 61.28846153846153%, Loss = 0.009005917021288322
Epoch: 2685, Batch Gradient Norm: 3.128605931096313
Epoch: 2685, Batch Gradient Norm after: 3.128605931096313
Epoch 2686/10000, Prediction Accuracy = 62.803846153846166%, Loss = 0.00865850755228446
Epoch: 2686, Batch Gradient Norm: 3.4250783563477976
Epoch: 2686, Batch Gradient Norm after: 3.4250783563477976
Epoch 2687/10000, Prediction Accuracy = 62.24999999999999%, Loss = 0.00881579310561602
Epoch: 2687, Batch Gradient Norm: 3.584005940017466
Epoch: 2687, Batch Gradient Norm after: 3.584005940017466
Epoch 2688/10000, Prediction Accuracy = 62.46153846153846%, Loss = 0.00886987830297305
Epoch: 2688, Batch Gradient Norm: 3.2469017200503014
Epoch: 2688, Batch Gradient Norm after: 3.2469017200503014
Epoch 2689/10000, Prediction Accuracy = 62.59999999999999%, Loss = 0.008732407353818417
Epoch: 2689, Batch Gradient Norm: 3.496612283697169
Epoch: 2689, Batch Gradient Norm after: 3.496612283697169
Epoch 2690/10000, Prediction Accuracy = 61.9423076923077%, Loss = 0.00882985106167885
Epoch: 2690, Batch Gradient Norm: 3.388432392822934
Epoch: 2690, Batch Gradient Norm after: 3.388432392822934
Epoch 2691/10000, Prediction Accuracy = 62.17307692307691%, Loss = 0.008801339265818778
Epoch: 2691, Batch Gradient Norm: 3.229909234396121
Epoch: 2691, Batch Gradient Norm after: 3.229909234396121
Epoch 2692/10000, Prediction Accuracy = 62.43076923076923%, Loss = 0.00871890145712174
Epoch: 2692, Batch Gradient Norm: 3.9084178973767587
Epoch: 2692, Batch Gradient Norm after: 3.9084178973767587
Epoch 2693/10000, Prediction Accuracy = 61.776923076923076%, Loss = 0.009012577123939991
Epoch: 2693, Batch Gradient Norm: 3.4874590710186975
Epoch: 2693, Batch Gradient Norm after: 3.4874590710186975
Epoch 2694/10000, Prediction Accuracy = 62.05769230769231%, Loss = 0.00878268200904131
Epoch: 2694, Batch Gradient Norm: 3.7261027342047757
Epoch: 2694, Batch Gradient Norm after: 3.7261027342047757
Epoch 2695/10000, Prediction Accuracy = 61.78846153846154%, Loss = 0.008951031817839695
Epoch: 2695, Batch Gradient Norm: 3.650432913540114
Epoch: 2695, Batch Gradient Norm after: 3.650432913540114
Epoch 2696/10000, Prediction Accuracy = 61.86538461538461%, Loss = 0.008868663858335752
Epoch: 2696, Batch Gradient Norm: 3.8987602962971577
Epoch: 2696, Batch Gradient Norm after: 3.8987602962971577
Epoch 2697/10000, Prediction Accuracy = 61.29230769230769%, Loss = 0.009094565462034482
Epoch: 2697, Batch Gradient Norm: 3.5120375391577143
Epoch: 2697, Batch Gradient Norm after: 3.5120375391577143
Epoch 2698/10000, Prediction Accuracy = 62.015384615384626%, Loss = 0.008803366181942133
Epoch: 2698, Batch Gradient Norm: 3.3995835668452754
Epoch: 2698, Batch Gradient Norm after: 3.3995835668452754
Epoch 2699/10000, Prediction Accuracy = 62.384615384615394%, Loss = 0.00882335057338843
Epoch: 2699, Batch Gradient Norm: 3.2820418547758794
Epoch: 2699, Batch Gradient Norm after: 3.2820418547758794
Epoch 2700/10000, Prediction Accuracy = 62.81153846153846%, Loss = 0.008623707394760389
Epoch: 2700, Batch Gradient Norm: 3.2099102377476907
Epoch: 2700, Batch Gradient Norm after: 3.2099102377476907
Epoch 2701/10000, Prediction Accuracy = 62.52307692307692%, Loss = 0.008723245073969547
Epoch: 2701, Batch Gradient Norm: 3.8472458074265448
Epoch: 2701, Batch Gradient Norm after: 3.8472458074265448
Epoch 2702/10000, Prediction Accuracy = 61.57307692307693%, Loss = 0.009032549193272224
Epoch: 2702, Batch Gradient Norm: 3.6742029299985903
Epoch: 2702, Batch Gradient Norm after: 3.6742029299985903
Epoch 2703/10000, Prediction Accuracy = 61.50769230769231%, Loss = 0.008985618129372597
Epoch: 2703, Batch Gradient Norm: 3.105321953329378
Epoch: 2703, Batch Gradient Norm after: 3.105321953329378
Epoch 2704/10000, Prediction Accuracy = 62.76153846153845%, Loss = 0.008563573543842021
Epoch: 2704, Batch Gradient Norm: 3.270698951856248
Epoch: 2704, Batch Gradient Norm after: 3.270698951856248
Epoch 2705/10000, Prediction Accuracy = 62.43076923076924%, Loss = 0.00868317255607018
Epoch: 2705, Batch Gradient Norm: 3.4066722802572116
Epoch: 2705, Batch Gradient Norm after: 3.4066722802572116
Epoch 2706/10000, Prediction Accuracy = 62.49615384615385%, Loss = 0.008780506439507008
Epoch: 2706, Batch Gradient Norm: 3.4263639459071387
Epoch: 2706, Batch Gradient Norm after: 3.4263639459071387
Epoch 2707/10000, Prediction Accuracy = 62.36923076923077%, Loss = 0.008800751457993802
Epoch: 2707, Batch Gradient Norm: 3.503446885536812
Epoch: 2707, Batch Gradient Norm after: 3.503446885536812
Epoch 2708/10000, Prediction Accuracy = 62.18076923076923%, Loss = 0.008777737330931883
Epoch: 2708, Batch Gradient Norm: 3.3596114794366323
Epoch: 2708, Batch Gradient Norm after: 3.3596114794366323
Epoch 2709/10000, Prediction Accuracy = 62.46923076923076%, Loss = 0.008686868473887444
Epoch: 2709, Batch Gradient Norm: 3.5308682411550674
Epoch: 2709, Batch Gradient Norm after: 3.5308682411550674
Epoch 2710/10000, Prediction Accuracy = 62.69230769230769%, Loss = 0.00875987270130561
Epoch: 2710, Batch Gradient Norm: 3.1237196060135726
Epoch: 2710, Batch Gradient Norm after: 3.1237196060135726
Epoch 2711/10000, Prediction Accuracy = 62.64230769230768%, Loss = 0.008481907300077952
Epoch: 2711, Batch Gradient Norm: 3.349913176698488
Epoch: 2711, Batch Gradient Norm after: 3.349913176698488
Epoch 2712/10000, Prediction Accuracy = 62.63846153846154%, Loss = 0.008622194067216836
Epoch: 2712, Batch Gradient Norm: 3.440432413297026
Epoch: 2712, Batch Gradient Norm after: 3.440432413297026
Epoch 2713/10000, Prediction Accuracy = 62.04615384615384%, Loss = 0.008664623404351564
Epoch: 2713, Batch Gradient Norm: 3.673224569284922
Epoch: 2713, Batch Gradient Norm after: 3.673224569284922
Epoch 2714/10000, Prediction Accuracy = 62.68461538461538%, Loss = 0.008823084000211496
Epoch: 2714, Batch Gradient Norm: 3.4813310385583502
Epoch: 2714, Batch Gradient Norm after: 3.4813310385583502
Epoch 2715/10000, Prediction Accuracy = 62.32692307692308%, Loss = 0.00876568744962032
Epoch: 2715, Batch Gradient Norm: 3.7294374628505707
Epoch: 2715, Batch Gradient Norm after: 3.7294374628505707
Epoch 2716/10000, Prediction Accuracy = 62.134615384615394%, Loss = 0.008804168552160263
Epoch: 2716, Batch Gradient Norm: 3.844891435652693
Epoch: 2716, Batch Gradient Norm after: 3.844891435652693
Epoch 2717/10000, Prediction Accuracy = 61.34615384615385%, Loss = 0.009013477641229447
Epoch: 2717, Batch Gradient Norm: 3.356959536737796
Epoch: 2717, Batch Gradient Norm after: 3.356959536737796
Epoch 2718/10000, Prediction Accuracy = 62.61538461538463%, Loss = 0.008816411432165366
Epoch: 2718, Batch Gradient Norm: 3.5865007467467285
Epoch: 2718, Batch Gradient Norm after: 3.5865007467467285
Epoch 2719/10000, Prediction Accuracy = 62.16923076923077%, Loss = 0.008849146131139535
Epoch: 2719, Batch Gradient Norm: 3.440531273682686
Epoch: 2719, Batch Gradient Norm after: 3.440531273682686
Epoch 2720/10000, Prediction Accuracy = 62.265384615384626%, Loss = 0.008844030232956776
Epoch: 2720, Batch Gradient Norm: 3.6182242849606085
Epoch: 2720, Batch Gradient Norm after: 3.6182242849606085
Epoch 2721/10000, Prediction Accuracy = 62.199999999999996%, Loss = 0.008875949594836969
Epoch: 2721, Batch Gradient Norm: 3.3898543219309394
Epoch: 2721, Batch Gradient Norm after: 3.3898543219309394
Epoch 2722/10000, Prediction Accuracy = 62.43461538461539%, Loss = 0.008729957617246188
Epoch: 2722, Batch Gradient Norm: 3.2998885990903823
Epoch: 2722, Batch Gradient Norm after: 3.2998885990903823
Epoch 2723/10000, Prediction Accuracy = 62.70384615384614%, Loss = 0.008663956649028338
Epoch: 2723, Batch Gradient Norm: 3.4074558499894767
Epoch: 2723, Batch Gradient Norm after: 3.4074558499894767
Epoch 2724/10000, Prediction Accuracy = 62.31153846153847%, Loss = 0.008799709093112212
Epoch: 2724, Batch Gradient Norm: 3.472051328428766
Epoch: 2724, Batch Gradient Norm after: 3.472051328428766
Epoch 2725/10000, Prediction Accuracy = 62.38846153846154%, Loss = 0.008719538839963766
Epoch: 2725, Batch Gradient Norm: 3.5687997531790736
Epoch: 2725, Batch Gradient Norm after: 3.5687997531790736
Epoch 2726/10000, Prediction Accuracy = 62.42307692307692%, Loss = 0.008859263733029366
Epoch: 2726, Batch Gradient Norm: 3.7098688096759926
Epoch: 2726, Batch Gradient Norm after: 3.7098688096759926
Epoch 2727/10000, Prediction Accuracy = 61.896153846153844%, Loss = 0.008886059746146202
Epoch: 2727, Batch Gradient Norm: 3.7942040510175428
Epoch: 2727, Batch Gradient Norm after: 3.7942040510175428
Epoch 2728/10000, Prediction Accuracy = 61.8423076923077%, Loss = 0.008950179227842735
Epoch: 2728, Batch Gradient Norm: 3.5519623303987125
Epoch: 2728, Batch Gradient Norm after: 3.5519623303987125
Epoch 2729/10000, Prediction Accuracy = 62.30769230769231%, Loss = 0.008883043550528012
Epoch: 2729, Batch Gradient Norm: 3.2055905862603047
Epoch: 2729, Batch Gradient Norm after: 3.2055905862603047
Epoch 2730/10000, Prediction Accuracy = 62.63461538461539%, Loss = 0.008634718779761057
Epoch: 2730, Batch Gradient Norm: 3.412397922496216
Epoch: 2730, Batch Gradient Norm after: 3.412397922496216
Epoch 2731/10000, Prediction Accuracy = 62.57692307692308%, Loss = 0.008741469480670415
Epoch: 2731, Batch Gradient Norm: 3.8894935768192456
Epoch: 2731, Batch Gradient Norm after: 3.8894935768192456
Epoch 2732/10000, Prediction Accuracy = 61.36153846153846%, Loss = 0.009098717154791722
Epoch: 2732, Batch Gradient Norm: 3.793144885290007
Epoch: 2732, Batch Gradient Norm after: 3.793144885290007
Epoch 2733/10000, Prediction Accuracy = 61.68461538461539%, Loss = 0.009026261834570995
Epoch: 2733, Batch Gradient Norm: 3.7771259676342788
Epoch: 2733, Batch Gradient Norm after: 3.7771259676342788
Epoch 2734/10000, Prediction Accuracy = 61.630769230769246%, Loss = 0.009022692791544475
Epoch: 2734, Batch Gradient Norm: 3.438692840088354
Epoch: 2734, Batch Gradient Norm after: 3.438692840088354
Epoch 2735/10000, Prediction Accuracy = 62.71538461538462%, Loss = 0.00865256585753881
Epoch: 2735, Batch Gradient Norm: 3.8512424776862897
Epoch: 2735, Batch Gradient Norm after: 3.8512424776862897
Epoch 2736/10000, Prediction Accuracy = 61.634615384615394%, Loss = 0.00908620053758988
Epoch: 2736, Batch Gradient Norm: 3.5700938697267617
Epoch: 2736, Batch Gradient Norm after: 3.5700938697267617
Epoch 2737/10000, Prediction Accuracy = 62.22692307692308%, Loss = 0.008900302032438608
Epoch: 2737, Batch Gradient Norm: 3.5970459061399698
Epoch: 2737, Batch Gradient Norm after: 3.5970459061399698
Epoch 2738/10000, Prediction Accuracy = 62.28461538461538%, Loss = 0.008824952878057957
Epoch: 2738, Batch Gradient Norm: 3.3807934580907077
Epoch: 2738, Batch Gradient Norm after: 3.3807934580907077
Epoch 2739/10000, Prediction Accuracy = 63.0%, Loss = 0.008682997897267342
Epoch: 2739, Batch Gradient Norm: 3.090253046496997
Epoch: 2739, Batch Gradient Norm after: 3.090253046496997
Epoch 2740/10000, Prediction Accuracy = 62.715384615384615%, Loss = 0.008625382127670141
Epoch: 2740, Batch Gradient Norm: 3.481438609015848
Epoch: 2740, Batch Gradient Norm after: 3.481438609015848
Epoch 2741/10000, Prediction Accuracy = 62.01153846153846%, Loss = 0.008751463503218614
Epoch: 2741, Batch Gradient Norm: 3.6174693145972316
Epoch: 2741, Batch Gradient Norm after: 3.6174693145972316
Epoch 2742/10000, Prediction Accuracy = 62.215384615384615%, Loss = 0.008827108101776013
Epoch: 2742, Batch Gradient Norm: 3.911514953588381
Epoch: 2742, Batch Gradient Norm after: 3.911514953588381
Epoch 2743/10000, Prediction Accuracy = 61.9076923076923%, Loss = 0.008988365889168702
Epoch: 2743, Batch Gradient Norm: 3.290455616451471
Epoch: 2743, Batch Gradient Norm after: 3.290455616451471
Epoch 2744/10000, Prediction Accuracy = 62.32307692307692%, Loss = 0.008721063629939007
Epoch: 2744, Batch Gradient Norm: 3.316967873836332
Epoch: 2744, Batch Gradient Norm after: 3.316967873836332
Epoch 2745/10000, Prediction Accuracy = 62.45%, Loss = 0.008638350078119682
Epoch: 2745, Batch Gradient Norm: 3.4652972109079427
Epoch: 2745, Batch Gradient Norm after: 3.4652972109079427
Epoch 2746/10000, Prediction Accuracy = 62.23846153846153%, Loss = 0.008782900798206147
Epoch: 2746, Batch Gradient Norm: 3.45397463361705
Epoch: 2746, Batch Gradient Norm after: 3.45397463361705
Epoch 2747/10000, Prediction Accuracy = 62.361538461538444%, Loss = 0.008846616014265098
Epoch: 2747, Batch Gradient Norm: 3.4586857570877374
Epoch: 2747, Batch Gradient Norm after: 3.4586857570877374
Epoch 2748/10000, Prediction Accuracy = 62.373076923076916%, Loss = 0.008712882964083781
Epoch: 2748, Batch Gradient Norm: 3.5694851617896877
Epoch: 2748, Batch Gradient Norm after: 3.5694851617896877
Epoch 2749/10000, Prediction Accuracy = 62.57307692307692%, Loss = 0.008719544786100205
Epoch: 2749, Batch Gradient Norm: 3.7209340535347737
Epoch: 2749, Batch Gradient Norm after: 3.7209340535347737
Epoch 2750/10000, Prediction Accuracy = 62.43846153846154%, Loss = 0.008742936600286227
Epoch: 2750, Batch Gradient Norm: 3.8611407329862466
Epoch: 2750, Batch Gradient Norm after: 3.8611407329862466
Epoch 2751/10000, Prediction Accuracy = 61.98846153846154%, Loss = 0.00898121390491724
Epoch: 2751, Batch Gradient Norm: 3.3749806557940722
Epoch: 2751, Batch Gradient Norm after: 3.3749806557940722
Epoch 2752/10000, Prediction Accuracy = 62.284615384615385%, Loss = 0.008740203741651315
Epoch: 2752, Batch Gradient Norm: 3.539128891326297
Epoch: 2752, Batch Gradient Norm after: 3.539128891326297
Epoch 2753/10000, Prediction Accuracy = 62.51923076923076%, Loss = 0.008773666448318042
Epoch: 2753, Batch Gradient Norm: 3.6628445720513354
Epoch: 2753, Batch Gradient Norm after: 3.6628445720513354
Epoch 2754/10000, Prediction Accuracy = 61.61923076923077%, Loss = 0.008914988273038315
Epoch: 2754, Batch Gradient Norm: 3.465751570731452
Epoch: 2754, Batch Gradient Norm after: 3.465751570731452
Epoch 2755/10000, Prediction Accuracy = 62.22692307692307%, Loss = 0.008767882576928688
Epoch: 2755, Batch Gradient Norm: 3.5196224185411165
Epoch: 2755, Batch Gradient Norm after: 3.5196224185411165
Epoch 2756/10000, Prediction Accuracy = 62.300000000000004%, Loss = 0.008714199137802307
Epoch: 2756, Batch Gradient Norm: 3.6844492222161627
Epoch: 2756, Batch Gradient Norm after: 3.6844492222161627
Epoch 2757/10000, Prediction Accuracy = 62.29615384615385%, Loss = 0.008756112522230698
Epoch: 2757, Batch Gradient Norm: 3.5383317318136975
Epoch: 2757, Batch Gradient Norm after: 3.5383317318136975
Epoch 2758/10000, Prediction Accuracy = 62.49230769230769%, Loss = 0.008724478359978933
Epoch: 2758, Batch Gradient Norm: 3.6090712541173966
Epoch: 2758, Batch Gradient Norm after: 3.6090712541173966
Epoch 2759/10000, Prediction Accuracy = 62.43461538461538%, Loss = 0.008815493434667587
Epoch: 2759, Batch Gradient Norm: 3.6809780155081024
Epoch: 2759, Batch Gradient Norm after: 3.6809780155081024
Epoch 2760/10000, Prediction Accuracy = 62.073076923076925%, Loss = 0.008795317692252306
Epoch: 2760, Batch Gradient Norm: 3.5641812057125466
Epoch: 2760, Batch Gradient Norm after: 3.5641812057125466
Epoch 2761/10000, Prediction Accuracy = 62.349999999999994%, Loss = 0.008833084112176528
Epoch: 2761, Batch Gradient Norm: 3.8817133088241733
Epoch: 2761, Batch Gradient Norm after: 3.8817133088241733
Epoch 2762/10000, Prediction Accuracy = 61.9153846153846%, Loss = 0.008950952297219863
Epoch: 2762, Batch Gradient Norm: 3.686462649931905
Epoch: 2762, Batch Gradient Norm after: 3.686462649931905
Epoch 2763/10000, Prediction Accuracy = 61.650000000000006%, Loss = 0.00896887954037923
Epoch: 2763, Batch Gradient Norm: 4.0279858591659865
Epoch: 2763, Batch Gradient Norm after: 4.0279858591659865
Epoch 2764/10000, Prediction Accuracy = 61.223076923076924%, Loss = 0.009176753676281525
Epoch: 2764, Batch Gradient Norm: 3.564947894887805
Epoch: 2764, Batch Gradient Norm after: 3.564947894887805
Epoch 2765/10000, Prediction Accuracy = 61.91923076923077%, Loss = 0.00890196687900103
Epoch: 2765, Batch Gradient Norm: 3.5340149890992767
Epoch: 2765, Batch Gradient Norm after: 3.5340149890992767
Epoch 2766/10000, Prediction Accuracy = 62.21153846153846%, Loss = 0.0088200386470327
Epoch: 2766, Batch Gradient Norm: 3.3962297741311085
Epoch: 2766, Batch Gradient Norm after: 3.3962297741311085
Epoch 2767/10000, Prediction Accuracy = 62.184615384615384%, Loss = 0.008787140966607975
Epoch: 2767, Batch Gradient Norm: 3.4892629092793617
Epoch: 2767, Batch Gradient Norm after: 3.4892629092793617
Epoch 2768/10000, Prediction Accuracy = 62.08846153846154%, Loss = 0.008788516816611473
Epoch: 2768, Batch Gradient Norm: 3.5076509861355465
Epoch: 2768, Batch Gradient Norm after: 3.5076509861355465
Epoch 2769/10000, Prediction Accuracy = 62.434615384615384%, Loss = 0.008817470345932703
Epoch: 2769, Batch Gradient Norm: 3.7380359330017745
Epoch: 2769, Batch Gradient Norm after: 3.7380359330017745
Epoch 2770/10000, Prediction Accuracy = 61.7423076923077%, Loss = 0.008976371887211617
Epoch: 2770, Batch Gradient Norm: 3.5464677263976836
Epoch: 2770, Batch Gradient Norm after: 3.5464677263976836
Epoch 2771/10000, Prediction Accuracy = 62.057692307692314%, Loss = 0.008824663451657845
Epoch: 2771, Batch Gradient Norm: 3.414087810087602
Epoch: 2771, Batch Gradient Norm after: 3.414087810087602
Epoch 2772/10000, Prediction Accuracy = 62.16923076923077%, Loss = 0.00881474744528532
Epoch: 2772, Batch Gradient Norm: 3.4963300441629546
Epoch: 2772, Batch Gradient Norm after: 3.4963300441629546
Epoch 2773/10000, Prediction Accuracy = 62.85769230769232%, Loss = 0.00871382918781959
Epoch: 2773, Batch Gradient Norm: 3.4163209018589686
Epoch: 2773, Batch Gradient Norm after: 3.4163209018589686
Epoch 2774/10000, Prediction Accuracy = 62.23076923076923%, Loss = 0.00875774434266182
Epoch: 2774, Batch Gradient Norm: 3.6000533952502387
Epoch: 2774, Batch Gradient Norm after: 3.6000533952502387
Epoch 2775/10000, Prediction Accuracy = 61.73846153846153%, Loss = 0.008804195202313937
Epoch: 2775, Batch Gradient Norm: 3.7906881349465946
Epoch: 2775, Batch Gradient Norm after: 3.7906881349465946
Epoch 2776/10000, Prediction Accuracy = 62.01538461538461%, Loss = 0.008868224632281523
Epoch: 2776, Batch Gradient Norm: 3.715697365945607
Epoch: 2776, Batch Gradient Norm after: 3.715697365945607
Epoch 2777/10000, Prediction Accuracy = 61.87692307692308%, Loss = 0.008817039358501252
Epoch: 2777, Batch Gradient Norm: 3.5386983516079358
Epoch: 2777, Batch Gradient Norm after: 3.5386983516079358
Epoch 2778/10000, Prediction Accuracy = 62.06153846153847%, Loss = 0.008775210294585962
Epoch: 2778, Batch Gradient Norm: 3.4118800428448646
Epoch: 2778, Batch Gradient Norm after: 3.4118800428448646
Epoch 2779/10000, Prediction Accuracy = 62.69615384615385%, Loss = 0.008576251494769867
Epoch: 2779, Batch Gradient Norm: 3.6111672176011185
Epoch: 2779, Batch Gradient Norm after: 3.6111672176011185
Epoch 2780/10000, Prediction Accuracy = 62.96923076923077%, Loss = 0.008618309162557125
Epoch: 2780, Batch Gradient Norm: 3.699493452553759
Epoch: 2780, Batch Gradient Norm after: 3.699493452553759
Epoch 2781/10000, Prediction Accuracy = 62.161538461538456%, Loss = 0.008785220866019908
Epoch: 2781, Batch Gradient Norm: 3.312202530104432
Epoch: 2781, Batch Gradient Norm after: 3.312202530104432
Epoch 2782/10000, Prediction Accuracy = 62.86923076923077%, Loss = 0.008546269212204676
Epoch: 2782, Batch Gradient Norm: 3.1818603876099067
Epoch: 2782, Batch Gradient Norm after: 3.1818603876099067
Epoch 2783/10000, Prediction Accuracy = 63.26923076923078%, Loss = 0.008470576041593002
Epoch: 2783, Batch Gradient Norm: 3.6601080519648264
Epoch: 2783, Batch Gradient Norm after: 3.6601080519648264
Epoch 2784/10000, Prediction Accuracy = 62.70384615384616%, Loss = 0.008674246975435661
Epoch: 2784, Batch Gradient Norm: 3.7671331028540718
Epoch: 2784, Batch Gradient Norm after: 3.7671331028540718
Epoch 2785/10000, Prediction Accuracy = 62.12307692307692%, Loss = 0.008810643751460772
Epoch: 2785, Batch Gradient Norm: 3.6648818523179223
Epoch: 2785, Batch Gradient Norm after: 3.6648818523179223
Epoch 2786/10000, Prediction Accuracy = 62.51538461538461%, Loss = 0.008746080172176544
Epoch: 2786, Batch Gradient Norm: 3.4042578707081703
Epoch: 2786, Batch Gradient Norm after: 3.4042578707081703
Epoch 2787/10000, Prediction Accuracy = 63.00769230769232%, Loss = 0.008578723368163291
Epoch: 2787, Batch Gradient Norm: 3.245483406162241
Epoch: 2787, Batch Gradient Norm after: 3.245483406162241
Epoch 2788/10000, Prediction Accuracy = 63.16153846153847%, Loss = 0.0084951024215955
Epoch: 2788, Batch Gradient Norm: 3.395929877136666
Epoch: 2788, Batch Gradient Norm after: 3.395929877136666
Epoch 2789/10000, Prediction Accuracy = 63.0846153846154%, Loss = 0.008565926637787085
Epoch: 2789, Batch Gradient Norm: 3.613130360649229
Epoch: 2789, Batch Gradient Norm after: 3.613130360649229
Epoch 2790/10000, Prediction Accuracy = 62.48461538461538%, Loss = 0.008656773501290725
Epoch: 2790, Batch Gradient Norm: 3.2195696107381773
Epoch: 2790, Batch Gradient Norm after: 3.2195696107381773
Epoch 2791/10000, Prediction Accuracy = 63.05%, Loss = 0.0084652526017565
Epoch: 2791, Batch Gradient Norm: 3.4284867989800025
Epoch: 2791, Batch Gradient Norm after: 3.4284867989800025
Epoch 2792/10000, Prediction Accuracy = 62.42307692307691%, Loss = 0.00861061464708585
Epoch: 2792, Batch Gradient Norm: 3.2679693837787887
Epoch: 2792, Batch Gradient Norm after: 3.2679693837787887
Epoch 2793/10000, Prediction Accuracy = 62.86538461538461%, Loss = 0.00848475370842677
Epoch: 2793, Batch Gradient Norm: 3.6433168798417066
Epoch: 2793, Batch Gradient Norm after: 3.6433168798417066
Epoch 2794/10000, Prediction Accuracy = 62.31153846153846%, Loss = 0.008747513191058086
Epoch: 2794, Batch Gradient Norm: 3.400556404972571
Epoch: 2794, Batch Gradient Norm after: 3.400556404972571
Epoch 2795/10000, Prediction Accuracy = 62.842307692307685%, Loss = 0.00864826192936072
Epoch: 2795, Batch Gradient Norm: 3.4023958621612467
Epoch: 2795, Batch Gradient Norm after: 3.4023958621612467
Epoch 2796/10000, Prediction Accuracy = 62.18461538461539%, Loss = 0.00873473694977852
Epoch: 2796, Batch Gradient Norm: 3.480877841963138
Epoch: 2796, Batch Gradient Norm after: 3.480877841963138
Epoch 2797/10000, Prediction Accuracy = 62.3076923076923%, Loss = 0.00872993254317687
Epoch: 2797, Batch Gradient Norm: 3.4806158987673395
Epoch: 2797, Batch Gradient Norm after: 3.4806158987673395
Epoch 2798/10000, Prediction Accuracy = 62.088461538461544%, Loss = 0.008670076871147523
Epoch: 2798, Batch Gradient Norm: 3.7845412534941736
Epoch: 2798, Batch Gradient Norm after: 3.7845412534941736
Epoch 2799/10000, Prediction Accuracy = 62.23076923076924%, Loss = 0.008842774308644809
Epoch: 2799, Batch Gradient Norm: 3.79119798946008
Epoch: 2799, Batch Gradient Norm after: 3.79119798946008
Epoch 2800/10000, Prediction Accuracy = 62.284615384615385%, Loss = 0.008782938695870914
Epoch: 2800, Batch Gradient Norm: 4.065770441703749
Epoch: 2800, Batch Gradient Norm after: 4.065770441703749
Epoch 2801/10000, Prediction Accuracy = 62.25769230769231%, Loss = 0.008910843959221473
Epoch: 2801, Batch Gradient Norm: 3.707433915644789
Epoch: 2801, Batch Gradient Norm after: 3.707433915644789
Epoch 2802/10000, Prediction Accuracy = 62.334615384615375%, Loss = 0.008784221341976753
Epoch: 2802, Batch Gradient Norm: 3.4788216144567503
Epoch: 2802, Batch Gradient Norm after: 3.4788216144567503
Epoch 2803/10000, Prediction Accuracy = 62.16538461538461%, Loss = 0.008707375122377506
Epoch: 2803, Batch Gradient Norm: 3.895383209975977
Epoch: 2803, Batch Gradient Norm after: 3.895383209975977
Epoch 2804/10000, Prediction Accuracy = 62.01538461538461%, Loss = 0.00884902928597652
Epoch: 2804, Batch Gradient Norm: 3.5246896843376287
Epoch: 2804, Batch Gradient Norm after: 3.5246896843376287
Epoch 2805/10000, Prediction Accuracy = 62.87692307692308%, Loss = 0.008665001378036462
Epoch: 2805, Batch Gradient Norm: 3.3827185289370156
Epoch: 2805, Batch Gradient Norm after: 3.3827185289370156
Epoch 2806/10000, Prediction Accuracy = 62.74999999999999%, Loss = 0.008650460853599586
Epoch: 2806, Batch Gradient Norm: 3.683281230781748
Epoch: 2806, Batch Gradient Norm after: 3.683281230781748
Epoch 2807/10000, Prediction Accuracy = 62.034615384615385%, Loss = 0.008819189065924058
Epoch: 2807, Batch Gradient Norm: 3.98301296751003
Epoch: 2807, Batch Gradient Norm after: 3.98301296751003
Epoch 2808/10000, Prediction Accuracy = 61.55%, Loss = 0.00901533871029432
Epoch: 2808, Batch Gradient Norm: 3.5677160107610875
Epoch: 2808, Batch Gradient Norm after: 3.5677160107610875
Epoch 2809/10000, Prediction Accuracy = 62.41153846153846%, Loss = 0.008753333885509234
Epoch: 2809, Batch Gradient Norm: 3.6163694637531676
Epoch: 2809, Batch Gradient Norm after: 3.6163694637531676
Epoch 2810/10000, Prediction Accuracy = 62.25384615384615%, Loss = 0.008768045271818455
Epoch: 2810, Batch Gradient Norm: 3.64471168409266
Epoch: 2810, Batch Gradient Norm after: 3.64471168409266
Epoch 2811/10000, Prediction Accuracy = 62.065384615384616%, Loss = 0.008800604309027012
Epoch: 2811, Batch Gradient Norm: 3.632760433710956
Epoch: 2811, Batch Gradient Norm after: 3.632760433710956
Epoch 2812/10000, Prediction Accuracy = 62.12307692307692%, Loss = 0.008765623116722474
Epoch: 2812, Batch Gradient Norm: 3.9593559505842983
Epoch: 2812, Batch Gradient Norm after: 3.9593559505842983
Epoch 2813/10000, Prediction Accuracy = 61.67692307692308%, Loss = 0.00896524559133328
Epoch: 2813, Batch Gradient Norm: 3.41086738417655
Epoch: 2813, Batch Gradient Norm after: 3.41086738417655
Epoch 2814/10000, Prediction Accuracy = 62.12692307692308%, Loss = 0.008795365118063413
Epoch: 2814, Batch Gradient Norm: 3.980001026606815
Epoch: 2814, Batch Gradient Norm after: 3.980001026606815
Epoch 2815/10000, Prediction Accuracy = 61.78461538461538%, Loss = 0.008967747625250082
Epoch: 2815, Batch Gradient Norm: 3.849962200200582
Epoch: 2815, Batch Gradient Norm after: 3.849962200200582
Epoch 2816/10000, Prediction Accuracy = 61.80384615384615%, Loss = 0.008920200312366853
Epoch: 2816, Batch Gradient Norm: 3.632890564608649
Epoch: 2816, Batch Gradient Norm after: 3.632890564608649
Epoch 2817/10000, Prediction Accuracy = 62.153846153846146%, Loss = 0.008819166284341078
Epoch: 2817, Batch Gradient Norm: 3.45024638173157
Epoch: 2817, Batch Gradient Norm after: 3.45024638173157
Epoch 2818/10000, Prediction Accuracy = 62.442307692307686%, Loss = 0.008738391029720124
Epoch: 2818, Batch Gradient Norm: 3.16653884464756
Epoch: 2818, Batch Gradient Norm after: 3.16653884464756
Epoch 2819/10000, Prediction Accuracy = 63.01923076923077%, Loss = 0.008483823675375719
Epoch: 2819, Batch Gradient Norm: 3.3724538228258503
Epoch: 2819, Batch Gradient Norm after: 3.3724538228258503
Epoch 2820/10000, Prediction Accuracy = 62.965384615384615%, Loss = 0.008509763158284701
Epoch: 2820, Batch Gradient Norm: 3.5020155821901535
Epoch: 2820, Batch Gradient Norm after: 3.5020155821901535
Epoch 2821/10000, Prediction Accuracy = 62.13461538461539%, Loss = 0.008768610942822237
Epoch: 2821, Batch Gradient Norm: 3.5306745726578947
Epoch: 2821, Batch Gradient Norm after: 3.5306745726578947
Epoch 2822/10000, Prediction Accuracy = 62.09615384615385%, Loss = 0.00881960873420422
Epoch: 2822, Batch Gradient Norm: 3.5541164664154064
Epoch: 2822, Batch Gradient Norm after: 3.5541164664154064
Epoch 2823/10000, Prediction Accuracy = 62.54615384615385%, Loss = 0.008768732946079511
Epoch: 2823, Batch Gradient Norm: 3.3187236865020644
Epoch: 2823, Batch Gradient Norm after: 3.3187236865020644
Epoch 2824/10000, Prediction Accuracy = 62.45769230769231%, Loss = 0.008617053309885355
Epoch: 2824, Batch Gradient Norm: 3.3644840794055044
Epoch: 2824, Batch Gradient Norm after: 3.3644840794055044
Epoch 2825/10000, Prediction Accuracy = 62.89999999999999%, Loss = 0.008541344306789912
Epoch: 2825, Batch Gradient Norm: 3.5899898795284684
Epoch: 2825, Batch Gradient Norm after: 3.5899898795284684
Epoch 2826/10000, Prediction Accuracy = 62.28076923076923%, Loss = 0.00869288589232243
Epoch: 2826, Batch Gradient Norm: 3.4728219589814597
Epoch: 2826, Batch Gradient Norm after: 3.4728219589814597
Epoch 2827/10000, Prediction Accuracy = 62.838461538461544%, Loss = 0.008590533039890803
Epoch: 2827, Batch Gradient Norm: 3.6328304156758713
Epoch: 2827, Batch Gradient Norm after: 3.6328304156758713
Epoch 2828/10000, Prediction Accuracy = 62.23461538461538%, Loss = 0.00873540399166254
Epoch: 2828, Batch Gradient Norm: 3.3125897792982975
Epoch: 2828, Batch Gradient Norm after: 3.3125897792982975
Epoch 2829/10000, Prediction Accuracy = 62.66923076923077%, Loss = 0.008555480995430397
Epoch: 2829, Batch Gradient Norm: 3.425886969727265
Epoch: 2829, Batch Gradient Norm after: 3.425886969727265
Epoch 2830/10000, Prediction Accuracy = 62.51153846153846%, Loss = 0.008572432785653152
Epoch: 2830, Batch Gradient Norm: 3.4226193209478732
Epoch: 2830, Batch Gradient Norm after: 3.4226193209478732
Epoch 2831/10000, Prediction Accuracy = 63.088461538461544%, Loss = 0.008576389760352097
Epoch: 2831, Batch Gradient Norm: 3.8112560619794724
Epoch: 2831, Batch Gradient Norm after: 3.8112560619794724
Epoch 2832/10000, Prediction Accuracy = 62.26923076923077%, Loss = 0.008821157380365409
Epoch: 2832, Batch Gradient Norm: 3.3048671425417084
Epoch: 2832, Batch Gradient Norm after: 3.3048671425417084
Epoch 2833/10000, Prediction Accuracy = 62.838461538461544%, Loss = 0.008554849415444411
Epoch: 2833, Batch Gradient Norm: 3.684549709671258
Epoch: 2833, Batch Gradient Norm after: 3.684549709671258
Epoch 2834/10000, Prediction Accuracy = 62.38076923076923%, Loss = 0.008674468200367231
Epoch: 2834, Batch Gradient Norm: 3.532391070534696
Epoch: 2834, Batch Gradient Norm after: 3.532391070534696
Epoch 2835/10000, Prediction Accuracy = 62.62307692307692%, Loss = 0.008647235468603097
Epoch: 2835, Batch Gradient Norm: 4.131227939486091
Epoch: 2835, Batch Gradient Norm after: 4.131227939486091
Epoch 2836/10000, Prediction Accuracy = 62.06153846153846%, Loss = 0.008977168024732517
Epoch: 2836, Batch Gradient Norm: 3.946086859948034
Epoch: 2836, Batch Gradient Norm after: 3.946086859948034
Epoch 2837/10000, Prediction Accuracy = 61.90384615384616%, Loss = 0.008949588411129437
Epoch: 2837, Batch Gradient Norm: 3.73647055191597
Epoch: 2837, Batch Gradient Norm after: 3.73647055191597
Epoch 2838/10000, Prediction Accuracy = 62.26923076923077%, Loss = 0.008877660004565349
Epoch: 2838, Batch Gradient Norm: 3.416561784035142
Epoch: 2838, Batch Gradient Norm after: 3.416561784035142
Epoch 2839/10000, Prediction Accuracy = 62.457692307692305%, Loss = 0.008648191005564652
Epoch: 2839, Batch Gradient Norm: 3.932524504777825
Epoch: 2839, Batch Gradient Norm after: 3.932524504777825
Epoch 2840/10000, Prediction Accuracy = 62.50769230769231%, Loss = 0.008842859058999099
Epoch: 2840, Batch Gradient Norm: 3.514915989684781
Epoch: 2840, Batch Gradient Norm after: 3.514915989684781
Epoch 2841/10000, Prediction Accuracy = 62.55%, Loss = 0.008730083632354554
Epoch: 2841, Batch Gradient Norm: 3.290340246454451
Epoch: 2841, Batch Gradient Norm after: 3.290340246454451
Epoch 2842/10000, Prediction Accuracy = 62.59615384615385%, Loss = 0.008553594780656008
Epoch: 2842, Batch Gradient Norm: 3.6909377501687595
Epoch: 2842, Batch Gradient Norm after: 3.6909377501687595
Epoch 2843/10000, Prediction Accuracy = 62.53076923076923%, Loss = 0.008754802008087818
Epoch: 2843, Batch Gradient Norm: 3.6139339261671664
Epoch: 2843, Batch Gradient Norm after: 3.6139339261671664
Epoch 2844/10000, Prediction Accuracy = 62.80384615384616%, Loss = 0.008705507462414412
Epoch: 2844, Batch Gradient Norm: 3.723009246423313
Epoch: 2844, Batch Gradient Norm after: 3.723009246423313
Epoch 2845/10000, Prediction Accuracy = 62.11153846153846%, Loss = 0.008757291146768974
Epoch: 2845, Batch Gradient Norm: 3.4820007347733433
Epoch: 2845, Batch Gradient Norm after: 3.4820007347733433
Epoch 2846/10000, Prediction Accuracy = 62.38461538461539%, Loss = 0.008608204312622547
Epoch: 2846, Batch Gradient Norm: 3.453182166036877
Epoch: 2846, Batch Gradient Norm after: 3.453182166036877
Epoch 2847/10000, Prediction Accuracy = 62.58461538461539%, Loss = 0.008624787585666547
Epoch: 2847, Batch Gradient Norm: 3.6010456650422946
Epoch: 2847, Batch Gradient Norm after: 3.6010456650422946
Epoch 2848/10000, Prediction Accuracy = 62.00000000000001%, Loss = 0.008684505063753862
Epoch: 2848, Batch Gradient Norm: 3.6606019786083728
Epoch: 2848, Batch Gradient Norm after: 3.6606019786083728
Epoch 2849/10000, Prediction Accuracy = 62.10000000000001%, Loss = 0.008792306726368574
Epoch: 2849, Batch Gradient Norm: 3.5867329155568064
Epoch: 2849, Batch Gradient Norm after: 3.5867329155568064
Epoch 2850/10000, Prediction Accuracy = 62.396153846153844%, Loss = 0.008758816724786391
Epoch: 2850, Batch Gradient Norm: 3.552178525085673
Epoch: 2850, Batch Gradient Norm after: 3.552178525085673
Epoch 2851/10000, Prediction Accuracy = 62.923076923076934%, Loss = 0.008628274027544718
Epoch: 2851, Batch Gradient Norm: 3.460128384871067
Epoch: 2851, Batch Gradient Norm after: 3.460128384871067
Epoch 2852/10000, Prediction Accuracy = 62.74230769230769%, Loss = 0.00863837694319395
Epoch: 2852, Batch Gradient Norm: 3.403845294792544
Epoch: 2852, Batch Gradient Norm after: 3.403845294792544
Epoch 2853/10000, Prediction Accuracy = 62.53461538461538%, Loss = 0.008614475265718423
Epoch: 2853, Batch Gradient Norm: 3.842185188558943
Epoch: 2853, Batch Gradient Norm after: 3.842185188558943
Epoch 2854/10000, Prediction Accuracy = 62.01923076923077%, Loss = 0.008787180511997296
Epoch: 2854, Batch Gradient Norm: 3.732547805629597
Epoch: 2854, Batch Gradient Norm after: 3.732547805629597
Epoch 2855/10000, Prediction Accuracy = 62.5076923076923%, Loss = 0.008741694717453076
Epoch: 2855, Batch Gradient Norm: 3.806063736247205
Epoch: 2855, Batch Gradient Norm after: 3.806063736247205
Epoch 2856/10000, Prediction Accuracy = 62.33076923076923%, Loss = 0.008828148747292848
Epoch: 2856, Batch Gradient Norm: 3.7259508176326857
Epoch: 2856, Batch Gradient Norm after: 3.7259508176326857
Epoch 2857/10000, Prediction Accuracy = 62.03461538461538%, Loss = 0.00877301968061007
Epoch: 2857, Batch Gradient Norm: 3.7275688332985912
Epoch: 2857, Batch Gradient Norm after: 3.7275688332985912
Epoch 2858/10000, Prediction Accuracy = 62.32692307692308%, Loss = 0.008825982061143104
Epoch: 2858, Batch Gradient Norm: 3.4528202426816432
Epoch: 2858, Batch Gradient Norm after: 3.4528202426816432
Epoch 2859/10000, Prediction Accuracy = 62.91923076923077%, Loss = 0.0085567465911691
Epoch: 2859, Batch Gradient Norm: 3.7361200505575103
Epoch: 2859, Batch Gradient Norm after: 3.7361200505575103
Epoch 2860/10000, Prediction Accuracy = 62.665384615384625%, Loss = 0.0086816015581672
Epoch: 2860, Batch Gradient Norm: 3.759889388142741
Epoch: 2860, Batch Gradient Norm after: 3.759889388142741
Epoch 2861/10000, Prediction Accuracy = 62.01153846153846%, Loss = 0.008835576044825407
Epoch: 2861, Batch Gradient Norm: 3.6532897925072865
Epoch: 2861, Batch Gradient Norm after: 3.6532897925072865
Epoch 2862/10000, Prediction Accuracy = 62.126923076923084%, Loss = 0.008780242087176213
Epoch: 2862, Batch Gradient Norm: 3.5293218699163864
Epoch: 2862, Batch Gradient Norm after: 3.5293218699163864
Epoch 2863/10000, Prediction Accuracy = 62.75384615384614%, Loss = 0.008589019139225666
Epoch: 2863, Batch Gradient Norm: 3.5444320141895203
Epoch: 2863, Batch Gradient Norm after: 3.5444320141895203
Epoch 2864/10000, Prediction Accuracy = 62.565384615384616%, Loss = 0.008619503046457585
Epoch: 2864, Batch Gradient Norm: 3.4483329634779114
Epoch: 2864, Batch Gradient Norm after: 3.4483329634779114
Epoch 2865/10000, Prediction Accuracy = 62.7576923076923%, Loss = 0.008540740594840966
Epoch: 2865, Batch Gradient Norm: 3.6927107598314266
Epoch: 2865, Batch Gradient Norm after: 3.6927107598314266
Epoch 2866/10000, Prediction Accuracy = 62.47307692307691%, Loss = 0.008734550040501814
Epoch: 2866, Batch Gradient Norm: 3.882669452586401
Epoch: 2866, Batch Gradient Norm after: 3.882669452586401
Epoch 2867/10000, Prediction Accuracy = 62.223076923076924%, Loss = 0.008789828476997523
Epoch: 2867, Batch Gradient Norm: 3.5520053440371386
Epoch: 2867, Batch Gradient Norm after: 3.5520053440371386
Epoch 2868/10000, Prediction Accuracy = 62.86538461538463%, Loss = 0.008657327709862819
Epoch: 2868, Batch Gradient Norm: 3.832740049526887
Epoch: 2868, Batch Gradient Norm after: 3.832740049526887
Epoch 2869/10000, Prediction Accuracy = 62.103846153846156%, Loss = 0.00876532423381622
Epoch: 2869, Batch Gradient Norm: 3.6411001531944938
Epoch: 2869, Batch Gradient Norm after: 3.6411001531944938
Epoch 2870/10000, Prediction Accuracy = 62.484615384615374%, Loss = 0.008686064957426144
Epoch: 2870, Batch Gradient Norm: 3.6984542312035287
Epoch: 2870, Batch Gradient Norm after: 3.6984542312035287
Epoch 2871/10000, Prediction Accuracy = 61.911538461538456%, Loss = 0.008826999996717159
Epoch: 2871, Batch Gradient Norm: 3.5960595818864416
Epoch: 2871, Batch Gradient Norm after: 3.5960595818864416
Epoch 2872/10000, Prediction Accuracy = 62.02307692307693%, Loss = 0.008852270073615588
Epoch: 2872, Batch Gradient Norm: 3.8946081030658473
Epoch: 2872, Batch Gradient Norm after: 3.8946081030658473
Epoch 2873/10000, Prediction Accuracy = 62.16923076923078%, Loss = 0.008923353627324104
Epoch: 2873, Batch Gradient Norm: 3.9536954521749306
Epoch: 2873, Batch Gradient Norm after: 3.9536954521749306
Epoch 2874/10000, Prediction Accuracy = 61.18846153846155%, Loss = 0.00904965608452375
Epoch: 2874, Batch Gradient Norm: 3.5130577196719948
Epoch: 2874, Batch Gradient Norm after: 3.5130577196719948
Epoch 2875/10000, Prediction Accuracy = 62.34615384615385%, Loss = 0.008664984399309525
Epoch: 2875, Batch Gradient Norm: 3.630219835359144
Epoch: 2875, Batch Gradient Norm after: 3.630219835359144
Epoch 2876/10000, Prediction Accuracy = 62.115384615384635%, Loss = 0.008733664137812762
Epoch: 2876, Batch Gradient Norm: 3.743661239534345
Epoch: 2876, Batch Gradient Norm after: 3.743661239534345
Epoch 2877/10000, Prediction Accuracy = 62.61538461538463%, Loss = 0.008796949297762834
Epoch: 2877, Batch Gradient Norm: 3.3047423934315816
Epoch: 2877, Batch Gradient Norm after: 3.3047423934315816
Epoch 2878/10000, Prediction Accuracy = 63.25769230769231%, Loss = 0.008546270358447846
Epoch: 2878, Batch Gradient Norm: 3.3450515944535444
Epoch: 2878, Batch Gradient Norm after: 3.3450515944535444
Epoch 2879/10000, Prediction Accuracy = 63.51923076923077%, Loss = 0.00847552028986124
Epoch: 2879, Batch Gradient Norm: 3.539156318606174
Epoch: 2879, Batch Gradient Norm after: 3.539156318606174
Epoch 2880/10000, Prediction Accuracy = 62.81153846153847%, Loss = 0.008588081010832237
Epoch: 2880, Batch Gradient Norm: 3.640988143277665
Epoch: 2880, Batch Gradient Norm after: 3.640988143277665
Epoch 2881/10000, Prediction Accuracy = 62.80384615384615%, Loss = 0.008716886361631064
Epoch: 2881, Batch Gradient Norm: 3.654886145900109
Epoch: 2881, Batch Gradient Norm after: 3.654886145900109
Epoch 2882/10000, Prediction Accuracy = 62.46538461538463%, Loss = 0.008768620041127387
Epoch: 2882, Batch Gradient Norm: 3.6706124850817536
Epoch: 2882, Batch Gradient Norm after: 3.6706124850817536
Epoch 2883/10000, Prediction Accuracy = 62.607692307692304%, Loss = 0.008610024475134335
Epoch: 2883, Batch Gradient Norm: 3.5212163027734813
Epoch: 2883, Batch Gradient Norm after: 3.5212163027734813
Epoch 2884/10000, Prediction Accuracy = 62.56923076923076%, Loss = 0.00860244881075162
Epoch: 2884, Batch Gradient Norm: 3.6688359791393665
Epoch: 2884, Batch Gradient Norm after: 3.6688359791393665
Epoch 2885/10000, Prediction Accuracy = 62.919230769230765%, Loss = 0.008675952728551168
Epoch: 2885, Batch Gradient Norm: 3.5540528085323246
Epoch: 2885, Batch Gradient Norm after: 3.5540528085323246
Epoch 2886/10000, Prediction Accuracy = 62.82692307692309%, Loss = 0.008575887347643193
Epoch: 2886, Batch Gradient Norm: 3.7086447135695897
Epoch: 2886, Batch Gradient Norm after: 3.7086447135695897
Epoch 2887/10000, Prediction Accuracy = 62.48076923076923%, Loss = 0.008676077955617355
Epoch: 2887, Batch Gradient Norm: 3.4684296637646943
Epoch: 2887, Batch Gradient Norm after: 3.4684296637646943
Epoch 2888/10000, Prediction Accuracy = 62.765384615384605%, Loss = 0.00857248673072228
Epoch: 2888, Batch Gradient Norm: 3.344315755618284
Epoch: 2888, Batch Gradient Norm after: 3.344315755618284
Epoch 2889/10000, Prediction Accuracy = 63.06153846153846%, Loss = 0.008522812348718826
Epoch: 2889, Batch Gradient Norm: 3.731581410178575
Epoch: 2889, Batch Gradient Norm after: 3.731581410178575
Epoch 2890/10000, Prediction Accuracy = 61.96153846153846%, Loss = 0.008741376061852161
Epoch: 2890, Batch Gradient Norm: 3.7813926046804833
Epoch: 2890, Batch Gradient Norm after: 3.7813926046804833
Epoch 2891/10000, Prediction Accuracy = 62.165384615384625%, Loss = 0.008754898005953202
Epoch: 2891, Batch Gradient Norm: 3.650270473491238
Epoch: 2891, Batch Gradient Norm after: 3.650270473491238
Epoch 2892/10000, Prediction Accuracy = 62.215384615384615%, Loss = 0.00870758044318511
Epoch: 2892, Batch Gradient Norm: 3.681076334878748
Epoch: 2892, Batch Gradient Norm after: 3.681076334878748
Epoch 2893/10000, Prediction Accuracy = 62.407692307692294%, Loss = 0.008732181400633775
Epoch: 2893, Batch Gradient Norm: 3.4278756063859466
Epoch: 2893, Batch Gradient Norm after: 3.4278756063859466
Epoch 2894/10000, Prediction Accuracy = 62.97692307692307%, Loss = 0.008571786877627555
Epoch: 2894, Batch Gradient Norm: 3.377637040002091
Epoch: 2894, Batch Gradient Norm after: 3.377637040002091
Epoch 2895/10000, Prediction Accuracy = 63.199999999999996%, Loss = 0.008582491642580582
Epoch: 2895, Batch Gradient Norm: 3.5808201918753504
Epoch: 2895, Batch Gradient Norm after: 3.5808201918753504
Epoch 2896/10000, Prediction Accuracy = 62.55%, Loss = 0.00861854342600474
Epoch: 2896, Batch Gradient Norm: 3.681848859228693
Epoch: 2896, Batch Gradient Norm after: 3.681848859228693
Epoch 2897/10000, Prediction Accuracy = 62.62307692307692%, Loss = 0.008566139910656672
Epoch: 2897, Batch Gradient Norm: 3.675580732728853
Epoch: 2897, Batch Gradient Norm after: 3.675580732728853
Epoch 2898/10000, Prediction Accuracy = 62.51153846153846%, Loss = 0.0086479471423305
Epoch: 2898, Batch Gradient Norm: 3.723567857574211
Epoch: 2898, Batch Gradient Norm after: 3.723567857574211
Epoch 2899/10000, Prediction Accuracy = 62.442307692307686%, Loss = 0.008670777655564822
Epoch: 2899, Batch Gradient Norm: 3.926125203756752
Epoch: 2899, Batch Gradient Norm after: 3.926125203756752
Epoch 2900/10000, Prediction Accuracy = 61.96153846153846%, Loss = 0.008865783062691871
Epoch: 2900, Batch Gradient Norm: 3.6121324199267364
Epoch: 2900, Batch Gradient Norm after: 3.6121324199267364
Epoch 2901/10000, Prediction Accuracy = 62.00384615384616%, Loss = 0.008701381345207874
Epoch: 2901, Batch Gradient Norm: 3.7895553461175884
Epoch: 2901, Batch Gradient Norm after: 3.7895553461175884
Epoch 2902/10000, Prediction Accuracy = 62.12307692307691%, Loss = 0.008812521011210404
Epoch: 2902, Batch Gradient Norm: 3.5532697132330746
Epoch: 2902, Batch Gradient Norm after: 3.5532697132330746
Epoch 2903/10000, Prediction Accuracy = 62.942307692307686%, Loss = 0.008584849464778718
Epoch: 2903, Batch Gradient Norm: 3.6373426633558714
Epoch: 2903, Batch Gradient Norm after: 3.6373426633558714
Epoch 2904/10000, Prediction Accuracy = 62.44230769230769%, Loss = 0.008640646146467099
Epoch: 2904, Batch Gradient Norm: 3.4232182437796355
Epoch: 2904, Batch Gradient Norm after: 3.4232182437796355
Epoch 2905/10000, Prediction Accuracy = 63.00769230769231%, Loss = 0.008513546763704373
Epoch: 2905, Batch Gradient Norm: 3.957027102878783
Epoch: 2905, Batch Gradient Norm after: 3.957027102878783
Epoch 2906/10000, Prediction Accuracy = 62.01923076923077%, Loss = 0.008806213664893921
Epoch: 2906, Batch Gradient Norm: 3.778752740809913
Epoch: 2906, Batch Gradient Norm after: 3.778752740809913
Epoch 2907/10000, Prediction Accuracy = 62.103846153846156%, Loss = 0.00875847707860745
Epoch: 2907, Batch Gradient Norm: 3.736679165980112
Epoch: 2907, Batch Gradient Norm after: 3.736679165980112
Epoch 2908/10000, Prediction Accuracy = 62.06923076923078%, Loss = 0.00876115570561244
Epoch: 2908, Batch Gradient Norm: 3.5909482676011484
Epoch: 2908, Batch Gradient Norm after: 3.5909482676011484
Epoch 2909/10000, Prediction Accuracy = 62.396153846153844%, Loss = 0.008688597223506523
Epoch: 2909, Batch Gradient Norm: 3.623485353718011
Epoch: 2909, Batch Gradient Norm after: 3.623485353718011
Epoch 2910/10000, Prediction Accuracy = 62.42307692307692%, Loss = 0.0087023636756035
Epoch: 2910, Batch Gradient Norm: 3.484854376822548
Epoch: 2910, Batch Gradient Norm after: 3.484854376822548
Epoch 2911/10000, Prediction Accuracy = 62.73461538461539%, Loss = 0.008582555115796052
Epoch: 2911, Batch Gradient Norm: 3.8014259127716277
Epoch: 2911, Batch Gradient Norm after: 3.8014259127716277
Epoch 2912/10000, Prediction Accuracy = 62.58846153846154%, Loss = 0.008752355495324502
Epoch: 2912, Batch Gradient Norm: 3.705244196477292
Epoch: 2912, Batch Gradient Norm after: 3.705244196477292
Epoch 2913/10000, Prediction Accuracy = 62.300000000000004%, Loss = 0.008785125656196704
Epoch: 2913, Batch Gradient Norm: 3.5178230302207427
Epoch: 2913, Batch Gradient Norm after: 3.5178230302207427
Epoch 2914/10000, Prediction Accuracy = 62.9653846153846%, Loss = 0.008571534274289241
Epoch: 2914, Batch Gradient Norm: 3.4414085703805726
Epoch: 2914, Batch Gradient Norm after: 3.4414085703805726
Epoch 2915/10000, Prediction Accuracy = 62.98076923076923%, Loss = 0.008518659509718418
Epoch: 2915, Batch Gradient Norm: 3.8350677883156408
Epoch: 2915, Batch Gradient Norm after: 3.8350677883156408
Epoch 2916/10000, Prediction Accuracy = 62.523076923076935%, Loss = 0.008699122028282056
Epoch: 2916, Batch Gradient Norm: 3.600739462176585
Epoch: 2916, Batch Gradient Norm after: 3.600739462176585
Epoch 2917/10000, Prediction Accuracy = 62.43846153846153%, Loss = 0.008566592819988728
Epoch: 2917, Batch Gradient Norm: 3.6066791170588535
Epoch: 2917, Batch Gradient Norm after: 3.6066791170588535
Epoch 2918/10000, Prediction Accuracy = 62.81538461538461%, Loss = 0.008497485461143347
Epoch: 2918, Batch Gradient Norm: 3.8466620222230623
Epoch: 2918, Batch Gradient Norm after: 3.8466620222230623
Epoch 2919/10000, Prediction Accuracy = 62.19615384615384%, Loss = 0.008817405869754462
Epoch: 2919, Batch Gradient Norm: 3.4909357145951097
Epoch: 2919, Batch Gradient Norm after: 3.4909357145951097
Epoch 2920/10000, Prediction Accuracy = 62.365384615384606%, Loss = 0.008710580161557747
Epoch: 2920, Batch Gradient Norm: 3.3430463029589834
Epoch: 2920, Batch Gradient Norm after: 3.3430463029589834
Epoch 2921/10000, Prediction Accuracy = 62.869230769230775%, Loss = 0.008527578571094917
Epoch: 2921, Batch Gradient Norm: 3.5665270462413106
Epoch: 2921, Batch Gradient Norm after: 3.5665270462413106
Epoch 2922/10000, Prediction Accuracy = 62.792307692307695%, Loss = 0.008642806528279414
Epoch: 2922, Batch Gradient Norm: 3.435998846870992
Epoch: 2922, Batch Gradient Norm after: 3.435998846870992
Epoch 2923/10000, Prediction Accuracy = 62.90384615384615%, Loss = 0.008526451312578641
Epoch: 2923, Batch Gradient Norm: 3.650958243392868
Epoch: 2923, Batch Gradient Norm after: 3.650958243392868
Epoch 2924/10000, Prediction Accuracy = 62.80384615384615%, Loss = 0.008655131579591678
Epoch: 2924, Batch Gradient Norm: 3.5371736952079442
Epoch: 2924, Batch Gradient Norm after: 3.5371736952079442
Epoch 2925/10000, Prediction Accuracy = 63.14615384615384%, Loss = 0.008566113475423593
Epoch: 2925, Batch Gradient Norm: 3.549034512235148
Epoch: 2925, Batch Gradient Norm after: 3.549034512235148
Epoch 2926/10000, Prediction Accuracy = 62.75384615384616%, Loss = 0.008631502994551109
Epoch: 2926, Batch Gradient Norm: 3.756489126181624
Epoch: 2926, Batch Gradient Norm after: 3.756489126181624
Epoch 2927/10000, Prediction Accuracy = 62.43846153846155%, Loss = 0.008661776064680172
Epoch: 2927, Batch Gradient Norm: 3.306310216614105
Epoch: 2927, Batch Gradient Norm after: 3.306310216614105
Epoch 2928/10000, Prediction Accuracy = 63.092307692307706%, Loss = 0.00852096016303851
Epoch: 2928, Batch Gradient Norm: 3.656676108523909
Epoch: 2928, Batch Gradient Norm after: 3.656676108523909
Epoch 2929/10000, Prediction Accuracy = 62.70384615384615%, Loss = 0.008714784080019364
Epoch: 2929, Batch Gradient Norm: 3.820815111831019
Epoch: 2929, Batch Gradient Norm after: 3.820815111831019
Epoch 2930/10000, Prediction Accuracy = 62.79615384615385%, Loss = 0.008684522902163176
Epoch: 2930, Batch Gradient Norm: 3.5185276292038017
Epoch: 2930, Batch Gradient Norm after: 3.5185276292038017
Epoch 2931/10000, Prediction Accuracy = 62.646153846153844%, Loss = 0.00858246492078671
Epoch: 2931, Batch Gradient Norm: 3.90163068402491
Epoch: 2931, Batch Gradient Norm after: 3.90163068402491
Epoch 2932/10000, Prediction Accuracy = 62.03461538461538%, Loss = 0.008743213919492869
Epoch: 2932, Batch Gradient Norm: 3.744274349104471
Epoch: 2932, Batch Gradient Norm after: 3.744274349104471
Epoch 2933/10000, Prediction Accuracy = 62.2423076923077%, Loss = 0.008683733068979703
Epoch: 2933, Batch Gradient Norm: 3.5451152457517456
Epoch: 2933, Batch Gradient Norm after: 3.5451152457517456
Epoch 2934/10000, Prediction Accuracy = 62.71923076923077%, Loss = 0.008559800684452057
Epoch: 2934, Batch Gradient Norm: 3.610272862356142
Epoch: 2934, Batch Gradient Norm after: 3.610272862356142
Epoch 2935/10000, Prediction Accuracy = 63.073076923076925%, Loss = 0.00851864403543564
Epoch: 2935, Batch Gradient Norm: 3.7973939271720485
Epoch: 2935, Batch Gradient Norm after: 3.7973939271720485
Epoch 2936/10000, Prediction Accuracy = 62.92307692307692%, Loss = 0.00855872923365006
Epoch: 2936, Batch Gradient Norm: 3.5513156922759403
Epoch: 2936, Batch Gradient Norm after: 3.5513156922759403
Epoch 2937/10000, Prediction Accuracy = 62.49615384615385%, Loss = 0.008568858871093163
Epoch: 2937, Batch Gradient Norm: 3.4308200694161863
Epoch: 2937, Batch Gradient Norm after: 3.4308200694161863
Epoch 2938/10000, Prediction Accuracy = 62.67307692307691%, Loss = 0.008483773957078274
Epoch: 2938, Batch Gradient Norm: 3.7818518202345732
Epoch: 2938, Batch Gradient Norm after: 3.7818518202345732
Epoch 2939/10000, Prediction Accuracy = 62.41923076923078%, Loss = 0.008643732406198978
Epoch: 2939, Batch Gradient Norm: 3.710491841680236
Epoch: 2939, Batch Gradient Norm after: 3.710491841680236
Epoch 2940/10000, Prediction Accuracy = 62.70384615384616%, Loss = 0.008662862058442373
Epoch: 2940, Batch Gradient Norm: 3.5665400604871462
Epoch: 2940, Batch Gradient Norm after: 3.5665400604871462
Epoch 2941/10000, Prediction Accuracy = 62.63461538461539%, Loss = 0.008578575072953334
Epoch: 2941, Batch Gradient Norm: 4.047893560695134
Epoch: 2941, Batch Gradient Norm after: 4.047893560695134
Epoch 2942/10000, Prediction Accuracy = 62.20769230769231%, Loss = 0.008867825381457806
Epoch: 2942, Batch Gradient Norm: 3.9101657194748682
Epoch: 2942, Batch Gradient Norm after: 3.9101657194748682
Epoch 2943/10000, Prediction Accuracy = 61.95000000000001%, Loss = 0.008939810956899937
Epoch: 2943, Batch Gradient Norm: 3.473472794707068
Epoch: 2943, Batch Gradient Norm after: 3.473472794707068
Epoch 2944/10000, Prediction Accuracy = 62.37692307692308%, Loss = 0.008651593914971901
Epoch: 2944, Batch Gradient Norm: 3.362130526092877
Epoch: 2944, Batch Gradient Norm after: 3.362130526092877
Epoch 2945/10000, Prediction Accuracy = 62.82307692307692%, Loss = 0.008408892541550674
Epoch: 2945, Batch Gradient Norm: 3.7698564485989925
Epoch: 2945, Batch Gradient Norm after: 3.7698564485989925
Epoch 2946/10000, Prediction Accuracy = 62.70384615384616%, Loss = 0.00868521759716364
Epoch: 2946, Batch Gradient Norm: 3.6210346399433924
Epoch: 2946, Batch Gradient Norm after: 3.6210346399433924
Epoch 2947/10000, Prediction Accuracy = 62.76153846153846%, Loss = 0.008593087944273766
Epoch: 2947, Batch Gradient Norm: 4.241803577643815
Epoch: 2947, Batch Gradient Norm after: 4.241803577643815
Epoch 2948/10000, Prediction Accuracy = 62.18846153846154%, Loss = 0.00895066767071302
Epoch: 2948, Batch Gradient Norm: 4.102076143066796
Epoch: 2948, Batch Gradient Norm after: 4.102076143066796
Epoch 2949/10000, Prediction Accuracy = 62.11153846153846%, Loss = 0.008927215822041035
Epoch: 2949, Batch Gradient Norm: 3.9690618793363175
Epoch: 2949, Batch Gradient Norm after: 3.9690618793363175
Epoch 2950/10000, Prediction Accuracy = 61.849999999999994%, Loss = 0.008868831424758984
Epoch: 2950, Batch Gradient Norm: 3.6077197063387407
Epoch: 2950, Batch Gradient Norm after: 3.6077197063387407
Epoch 2951/10000, Prediction Accuracy = 62.70769230769231%, Loss = 0.008688350279743854
Epoch: 2951, Batch Gradient Norm: 3.4967465664597257
Epoch: 2951, Batch Gradient Norm after: 3.4967465664597257
Epoch 2952/10000, Prediction Accuracy = 62.130769230769225%, Loss = 0.008588541227464493
Epoch: 2952, Batch Gradient Norm: 3.348720189262319
Epoch: 2952, Batch Gradient Norm after: 3.348720189262319
Epoch 2953/10000, Prediction Accuracy = 63.05769230769231%, Loss = 0.008550573283663163
Epoch: 2953, Batch Gradient Norm: 3.5747484867394053
Epoch: 2953, Batch Gradient Norm after: 3.5747484867394053
Epoch 2954/10000, Prediction Accuracy = 63.07307692307692%, Loss = 0.008538140986974422
Epoch: 2954, Batch Gradient Norm: 3.8027287813722075
Epoch: 2954, Batch Gradient Norm after: 3.8027287813722075
Epoch 2955/10000, Prediction Accuracy = 62.79615384615384%, Loss = 0.008670545039841762
Epoch: 2955, Batch Gradient Norm: 3.461962471815874
Epoch: 2955, Batch Gradient Norm after: 3.461962471815874
Epoch 2956/10000, Prediction Accuracy = 62.74615384615386%, Loss = 0.008526540003143825
Epoch: 2956, Batch Gradient Norm: 3.7403613029865435
Epoch: 2956, Batch Gradient Norm after: 3.7403613029865435
Epoch 2957/10000, Prediction Accuracy = 62.33076923076923%, Loss = 0.008705719660681028
Epoch: 2957, Batch Gradient Norm: 3.6131176861440357
Epoch: 2957, Batch Gradient Norm after: 3.6131176861440357
Epoch 2958/10000, Prediction Accuracy = 62.573076923076925%, Loss = 0.008528087073220657
Epoch: 2958, Batch Gradient Norm: 3.539364872064754
Epoch: 2958, Batch Gradient Norm after: 3.539364872064754
Epoch 2959/10000, Prediction Accuracy = 62.76538461538461%, Loss = 0.008620336866722656
Epoch: 2959, Batch Gradient Norm: 3.6436262114019904
Epoch: 2959, Batch Gradient Norm after: 3.6436262114019904
Epoch 2960/10000, Prediction Accuracy = 62.86538461538461%, Loss = 0.00863528004489266
Epoch: 2960, Batch Gradient Norm: 3.950665113942575
Epoch: 2960, Batch Gradient Norm after: 3.950665113942575
Epoch 2961/10000, Prediction Accuracy = 62.369230769230775%, Loss = 0.008792490053635377
Epoch: 2961, Batch Gradient Norm: 3.6211293356371494
Epoch: 2961, Batch Gradient Norm after: 3.6211293356371494
Epoch 2962/10000, Prediction Accuracy = 62.54615384615384%, Loss = 0.008707852102816105
Epoch: 2962, Batch Gradient Norm: 3.974854528221844
Epoch: 2962, Batch Gradient Norm after: 3.974854528221844
Epoch 2963/10000, Prediction Accuracy = 61.81538461538461%, Loss = 0.008863462278476128
Epoch: 2963, Batch Gradient Norm: 3.3082457875503235
Epoch: 2963, Batch Gradient Norm after: 3.3082457875503235
Epoch 2964/10000, Prediction Accuracy = 63.04615384615385%, Loss = 0.008534080277268704
Epoch: 2964, Batch Gradient Norm: 3.4861353339008443
Epoch: 2964, Batch Gradient Norm after: 3.4861353339008443
Epoch 2965/10000, Prediction Accuracy = 62.926923076923075%, Loss = 0.008546334906266285
Epoch: 2965, Batch Gradient Norm: 3.7588629983043202
Epoch: 2965, Batch Gradient Norm after: 3.7588629983043202
Epoch 2966/10000, Prediction Accuracy = 62.33076923076923%, Loss = 0.008679860056592869
Epoch: 2966, Batch Gradient Norm: 3.55000890667851
Epoch: 2966, Batch Gradient Norm after: 3.55000890667851
Epoch 2967/10000, Prediction Accuracy = 62.78461538461537%, Loss = 0.008565115599104991
Epoch: 2967, Batch Gradient Norm: 3.8568725966303656
Epoch: 2967, Batch Gradient Norm after: 3.8568725966303656
Epoch 2968/10000, Prediction Accuracy = 61.715384615384615%, Loss = 0.008832945846594296
Epoch: 2968, Batch Gradient Norm: 3.5778877806768072
Epoch: 2968, Batch Gradient Norm after: 3.5778877806768072
Epoch 2969/10000, Prediction Accuracy = 62.58461538461539%, Loss = 0.00870257537238873
Epoch: 2969, Batch Gradient Norm: 3.4136500788406856
Epoch: 2969, Batch Gradient Norm after: 3.4136500788406856
Epoch 2970/10000, Prediction Accuracy = 62.70384615384616%, Loss = 0.008559291251003742
Epoch: 2970, Batch Gradient Norm: 3.8897679615202136
Epoch: 2970, Batch Gradient Norm after: 3.8897679615202136
Epoch 2971/10000, Prediction Accuracy = 62.53846153846153%, Loss = 0.008753775475689998
Epoch: 2971, Batch Gradient Norm: 3.9794364719500095
Epoch: 2971, Batch Gradient Norm after: 3.9794364719500095
Epoch 2972/10000, Prediction Accuracy = 62.43846153846154%, Loss = 0.008803381011463128
Epoch: 2972, Batch Gradient Norm: 3.6444191856197237
Epoch: 2972, Batch Gradient Norm after: 3.6444191856197237
Epoch 2973/10000, Prediction Accuracy = 62.95384615384615%, Loss = 0.008642852378006164
Epoch: 2973, Batch Gradient Norm: 3.5227153161429836
Epoch: 2973, Batch Gradient Norm after: 3.5227153161429836
Epoch 2974/10000, Prediction Accuracy = 62.588461538461544%, Loss = 0.008546038745687557
Epoch: 2974, Batch Gradient Norm: 3.414881524386708
Epoch: 2974, Batch Gradient Norm after: 3.414881524386708
Epoch 2975/10000, Prediction Accuracy = 62.86923076923077%, Loss = 0.008456910530535074
Epoch: 2975, Batch Gradient Norm: 3.5076015549547734
Epoch: 2975, Batch Gradient Norm after: 3.5076015549547734
Epoch 2976/10000, Prediction Accuracy = 63.376923076923084%, Loss = 0.008491641877648922
Epoch: 2976, Batch Gradient Norm: 4.065887162716806
Epoch: 2976, Batch Gradient Norm after: 4.065887162716806
Epoch 2977/10000, Prediction Accuracy = 62.01538461538462%, Loss = 0.008977598080841394
Epoch: 2977, Batch Gradient Norm: 4.092795387002333
Epoch: 2977, Batch Gradient Norm after: 4.092795387002333
Epoch 2978/10000, Prediction Accuracy = 61.94230769230769%, Loss = 0.008995336193877917
Epoch: 2978, Batch Gradient Norm: 3.9528235892407215
Epoch: 2978, Batch Gradient Norm after: 3.9528235892407215
Epoch 2979/10000, Prediction Accuracy = 62.184615384615384%, Loss = 0.008821907883080153
Epoch: 2979, Batch Gradient Norm: 3.780552376662354
Epoch: 2979, Batch Gradient Norm after: 3.780552376662354
Epoch 2980/10000, Prediction Accuracy = 62.17692307692309%, Loss = 0.008752158341499476
Epoch: 2980, Batch Gradient Norm: 3.2286312926287333
Epoch: 2980, Batch Gradient Norm after: 3.2286312926287333
Epoch 2981/10000, Prediction Accuracy = 62.91538461538463%, Loss = 0.008462854732687656
Epoch: 2981, Batch Gradient Norm: 3.6060277198792208
Epoch: 2981, Batch Gradient Norm after: 3.6060277198792208
Epoch 2982/10000, Prediction Accuracy = 63.20769230769232%, Loss = 0.008464397862553596
Epoch: 2982, Batch Gradient Norm: 4.02123867182182
Epoch: 2982, Batch Gradient Norm after: 4.02123867182182
Epoch 2983/10000, Prediction Accuracy = 62.915384615384625%, Loss = 0.008682888789245715
Epoch: 2983, Batch Gradient Norm: 3.961150784803225
Epoch: 2983, Batch Gradient Norm after: 3.961150784803225
Epoch 2984/10000, Prediction Accuracy = 61.880769230769225%, Loss = 0.008838358550117565
Epoch: 2984, Batch Gradient Norm: 4.21329922520969
Epoch: 2984, Batch Gradient Norm after: 4.21329922520969
Epoch 2985/10000, Prediction Accuracy = 62.00384615384617%, Loss = 0.008965369027394515
Epoch: 2985, Batch Gradient Norm: 4.01432057937937
Epoch: 2985, Batch Gradient Norm after: 4.01432057937937
Epoch 2986/10000, Prediction Accuracy = 62.150000000000006%, Loss = 0.008844875587293735
Epoch: 2986, Batch Gradient Norm: 3.492162977822446
Epoch: 2986, Batch Gradient Norm after: 3.492162977822446
Epoch 2987/10000, Prediction Accuracy = 62.949999999999996%, Loss = 0.008606154113434829
Epoch: 2987, Batch Gradient Norm: 3.754781541198587
Epoch: 2987, Batch Gradient Norm after: 3.754781541198587
Epoch 2988/10000, Prediction Accuracy = 62.47692307692308%, Loss = 0.008706030865701346
Epoch: 2988, Batch Gradient Norm: 3.4570056321523395
Epoch: 2988, Batch Gradient Norm after: 3.4570056321523395
Epoch 2989/10000, Prediction Accuracy = 62.876923076923084%, Loss = 0.008547197454250775
Epoch: 2989, Batch Gradient Norm: 3.4232722333360917
Epoch: 2989, Batch Gradient Norm after: 3.4232722333360917
Epoch 2990/10000, Prediction Accuracy = 63.36153846153847%, Loss = 0.00838775452799522
Epoch: 2990, Batch Gradient Norm: 3.3549994850715796
Epoch: 2990, Batch Gradient Norm after: 3.3549994850715796
Epoch 2991/10000, Prediction Accuracy = 63.22692307692308%, Loss = 0.008448874936080895
Epoch: 2991, Batch Gradient Norm: 3.503498864706926
Epoch: 2991, Batch Gradient Norm after: 3.503498864706926
Epoch 2992/10000, Prediction Accuracy = 62.78461538461538%, Loss = 0.008467065886809276
Epoch: 2992, Batch Gradient Norm: 3.515828209820001
Epoch: 2992, Batch Gradient Norm after: 3.515828209820001
Epoch 2993/10000, Prediction Accuracy = 62.69230769230769%, Loss = 0.008537189891705146
Epoch: 2993, Batch Gradient Norm: 3.1718255040506307
Epoch: 2993, Batch Gradient Norm after: 3.1718255040506307
Epoch 2994/10000, Prediction Accuracy = 63.580769230769235%, Loss = 0.008305141630654152
Epoch: 2994, Batch Gradient Norm: 3.3980393185732862
Epoch: 2994, Batch Gradient Norm after: 3.3980393185732862
Epoch 2995/10000, Prediction Accuracy = 63.23461538461539%, Loss = 0.008366616084598578
Epoch: 2995, Batch Gradient Norm: 3.443525563233076
Epoch: 2995, Batch Gradient Norm after: 3.443525563233076
Epoch 2996/10000, Prediction Accuracy = 63.47307692307691%, Loss = 0.0084033295368919
Epoch: 2996, Batch Gradient Norm: 3.58787194595262
Epoch: 2996, Batch Gradient Norm after: 3.58787194595262
Epoch 2997/10000, Prediction Accuracy = 62.73076923076924%, Loss = 0.008507334913771886
Epoch: 2997, Batch Gradient Norm: 3.6294432636112424
Epoch: 2997, Batch Gradient Norm after: 3.6294432636112424
Epoch 2998/10000, Prediction Accuracy = 63.146153846153844%, Loss = 0.008556083561136173
Epoch: 2998, Batch Gradient Norm: 3.477577853452624
Epoch: 2998, Batch Gradient Norm after: 3.477577853452624
Epoch 2999/10000, Prediction Accuracy = 63.20769230769231%, Loss = 0.008482948733636966
Epoch: 2999, Batch Gradient Norm: 3.9462087661199785
Epoch: 2999, Batch Gradient Norm after: 3.9462087661199785
Epoch 3000/10000, Prediction Accuracy = 62.23846153846154%, Loss = 0.008608412642318469
Epoch: 3000, Batch Gradient Norm: 3.8435337413255946
Epoch: 3000, Batch Gradient Norm after: 3.8435337413255946
Epoch 3001/10000, Prediction Accuracy = 62.77307692307693%, Loss = 0.008623303487323798
Epoch: 3001, Batch Gradient Norm: 3.6592573281982186
Epoch: 3001, Batch Gradient Norm after: 3.6592573281982186
Epoch 3002/10000, Prediction Accuracy = 62.76923076923078%, Loss = 0.008545810858217569
Epoch: 3002, Batch Gradient Norm: 3.990663066551472
Epoch: 3002, Batch Gradient Norm after: 3.990663066551472
Epoch 3003/10000, Prediction Accuracy = 62.57307692307695%, Loss = 0.008719198119181853
Epoch: 3003, Batch Gradient Norm: 3.921256503458587
Epoch: 3003, Batch Gradient Norm after: 3.921256503458587
Epoch 3004/10000, Prediction Accuracy = 62.54615384615385%, Loss = 0.008695428904432517
Epoch: 3004, Batch Gradient Norm: 3.4744338557626726
Epoch: 3004, Batch Gradient Norm after: 3.4744338557626726
Epoch 3005/10000, Prediction Accuracy = 62.86538461538461%, Loss = 0.008541711892646093
Epoch: 3005, Batch Gradient Norm: 3.8209309327063967
Epoch: 3005, Batch Gradient Norm after: 3.8209309327063967
Epoch 3006/10000, Prediction Accuracy = 62.088461538461544%, Loss = 0.008753368989206277
Epoch: 3006, Batch Gradient Norm: 3.7506712887480513
Epoch: 3006, Batch Gradient Norm after: 3.7506712887480513
Epoch 3007/10000, Prediction Accuracy = 62.18076923076923%, Loss = 0.008689094764681963
Epoch: 3007, Batch Gradient Norm: 3.9509043337083303
Epoch: 3007, Batch Gradient Norm after: 3.9509043337083303
Epoch 3008/10000, Prediction Accuracy = 62.26538461538461%, Loss = 0.008763530864738502
Epoch: 3008, Batch Gradient Norm: 3.682209675107445
Epoch: 3008, Batch Gradient Norm after: 3.682209675107445
Epoch 3009/10000, Prediction Accuracy = 62.50384615384615%, Loss = 0.008581910067452835
Epoch: 3009, Batch Gradient Norm: 3.681568132083642
Epoch: 3009, Batch Gradient Norm after: 3.681568132083642
Epoch 3010/10000, Prediction Accuracy = 62.74230769230768%, Loss = 0.00853976091513267
Epoch: 3010, Batch Gradient Norm: 3.6206327891680923
Epoch: 3010, Batch Gradient Norm after: 3.6206327891680923
Epoch 3011/10000, Prediction Accuracy = 62.78461538461538%, Loss = 0.008574554768319313
Epoch: 3011, Batch Gradient Norm: 3.5907269815274794
Epoch: 3011, Batch Gradient Norm after: 3.5907269815274794
Epoch 3012/10000, Prediction Accuracy = 62.873076923076916%, Loss = 0.008555692477295032
Epoch: 3012, Batch Gradient Norm: 3.426778583131813
Epoch: 3012, Batch Gradient Norm after: 3.426778583131813
Epoch 3013/10000, Prediction Accuracy = 62.880769230769225%, Loss = 0.008530398902411643
Epoch: 3013, Batch Gradient Norm: 3.533207308509309
Epoch: 3013, Batch Gradient Norm after: 3.533207308509309
Epoch 3014/10000, Prediction Accuracy = 63.09615384615385%, Loss = 0.008527783247140737
Epoch: 3014, Batch Gradient Norm: 3.435443442123499
Epoch: 3014, Batch Gradient Norm after: 3.435443442123499
Epoch 3015/10000, Prediction Accuracy = 63.14230769230768%, Loss = 0.0085133220284031
Epoch: 3015, Batch Gradient Norm: 3.8814003010020093
Epoch: 3015, Batch Gradient Norm after: 3.8814003010020093
Epoch 3016/10000, Prediction Accuracy = 62.64999999999999%, Loss = 0.008686947636306286
Epoch: 3016, Batch Gradient Norm: 3.4795956805889587
Epoch: 3016, Batch Gradient Norm after: 3.4795956805889587
Epoch 3017/10000, Prediction Accuracy = 63.31153846153847%, Loss = 0.008411364056743108
Epoch: 3017, Batch Gradient Norm: 3.8783379232649704
Epoch: 3017, Batch Gradient Norm after: 3.8783379232649704
Epoch 3018/10000, Prediction Accuracy = 62.49615384615385%, Loss = 0.008605216773083577
Epoch: 3018, Batch Gradient Norm: 3.2592480270853224
Epoch: 3018, Batch Gradient Norm after: 3.2592480270853224
Epoch 3019/10000, Prediction Accuracy = 63.588461538461544%, Loss = 0.00829408740481505
Epoch: 3019, Batch Gradient Norm: 3.7082944875594657
Epoch: 3019, Batch Gradient Norm after: 3.7082944875594657
Epoch 3020/10000, Prediction Accuracy = 63.18846153846153%, Loss = 0.00847734295977996
Epoch: 3020, Batch Gradient Norm: 3.5613854861614733
Epoch: 3020, Batch Gradient Norm after: 3.5613854861614733
Epoch 3021/10000, Prediction Accuracy = 63.20769230769232%, Loss = 0.008416885080245825
Epoch: 3021, Batch Gradient Norm: 3.5975717818175768
Epoch: 3021, Batch Gradient Norm after: 3.5975717818175768
Epoch 3022/10000, Prediction Accuracy = 63.165384615384625%, Loss = 0.008421452930913521
Epoch: 3022, Batch Gradient Norm: 4.0793145993144915
Epoch: 3022, Batch Gradient Norm after: 4.0793145993144915
Epoch 3023/10000, Prediction Accuracy = 62.36923076923077%, Loss = 0.008619420803510226
Epoch: 3023, Batch Gradient Norm: 4.282783253983939
Epoch: 3023, Batch Gradient Norm after: 4.282783253983939
Epoch 3024/10000, Prediction Accuracy = 62.096153846153854%, Loss = 0.008873654242891531
Epoch: 3024, Batch Gradient Norm: 4.014575850474935
Epoch: 3024, Batch Gradient Norm after: 4.014575850474935
Epoch 3025/10000, Prediction Accuracy = 61.96923076923077%, Loss = 0.008856688626110554
Epoch: 3025, Batch Gradient Norm: 3.7185174512265653
Epoch: 3025, Batch Gradient Norm after: 3.7185174512265653
Epoch 3026/10000, Prediction Accuracy = 63.22692307692308%, Loss = 0.008525535679207398
Epoch: 3026, Batch Gradient Norm: 3.996797065332929
Epoch: 3026, Batch Gradient Norm after: 3.996797065332929
Epoch 3027/10000, Prediction Accuracy = 62.349999999999994%, Loss = 0.008622431626113562
Epoch: 3027, Batch Gradient Norm: 3.631594771983331
Epoch: 3027, Batch Gradient Norm after: 3.631594771983331
Epoch 3028/10000, Prediction Accuracy = 62.51153846153847%, Loss = 0.008631030312524391
Epoch: 3028, Batch Gradient Norm: 3.7038438011249335
Epoch: 3028, Batch Gradient Norm after: 3.7038438011249335
Epoch 3029/10000, Prediction Accuracy = 63.192307692307686%, Loss = 0.008574429111411938
Epoch: 3029, Batch Gradient Norm: 3.5052338095369637
Epoch: 3029, Batch Gradient Norm after: 3.5052338095369637
Epoch 3030/10000, Prediction Accuracy = 62.73076923076924%, Loss = 0.00845554256095336
Epoch: 3030, Batch Gradient Norm: 3.6065647055541676
Epoch: 3030, Batch Gradient Norm after: 3.6065647055541676
Epoch 3031/10000, Prediction Accuracy = 63.06153846153847%, Loss = 0.008449548139021946
Epoch: 3031, Batch Gradient Norm: 3.9410796558458907
Epoch: 3031, Batch Gradient Norm after: 3.9410796558458907
Epoch 3032/10000, Prediction Accuracy = 62.43076923076923%, Loss = 0.008618387751854382
Epoch: 3032, Batch Gradient Norm: 3.4328309431564565
Epoch: 3032, Batch Gradient Norm after: 3.4328309431564565
Epoch 3033/10000, Prediction Accuracy = 63.31153846153847%, Loss = 0.00841669007562674
Epoch: 3033, Batch Gradient Norm: 3.648040303853734
Epoch: 3033, Batch Gradient Norm after: 3.648040303853734
Epoch 3034/10000, Prediction Accuracy = 62.93461538461539%, Loss = 0.008479551555445561
Epoch: 3034, Batch Gradient Norm: 3.8069750920017205
Epoch: 3034, Batch Gradient Norm after: 3.8069750920017205
Epoch 3035/10000, Prediction Accuracy = 62.64615384615384%, Loss = 0.008605073349407086
Epoch: 3035, Batch Gradient Norm: 4.1056284703718715
Epoch: 3035, Batch Gradient Norm after: 4.1056284703718715
Epoch 3036/10000, Prediction Accuracy = 61.98461538461539%, Loss = 0.008779451179389771
Epoch: 3036, Batch Gradient Norm: 3.874866484798781
Epoch: 3036, Batch Gradient Norm after: 3.874866484798781
Epoch 3037/10000, Prediction Accuracy = 62.292307692307695%, Loss = 0.008689651982142376
Epoch: 3037, Batch Gradient Norm: 3.372357793980264
Epoch: 3037, Batch Gradient Norm after: 3.372357793980264
Epoch 3038/10000, Prediction Accuracy = 63.18846153846154%, Loss = 0.00838474091142416
Epoch: 3038, Batch Gradient Norm: 3.6460836568160984
Epoch: 3038, Batch Gradient Norm after: 3.6460836568160984
Epoch 3039/10000, Prediction Accuracy = 63.13846153846154%, Loss = 0.008500499650835991
Epoch: 3039, Batch Gradient Norm: 3.7622164788392825
Epoch: 3039, Batch Gradient Norm after: 3.7622164788392825
Epoch 3040/10000, Prediction Accuracy = 62.96923076923077%, Loss = 0.0085715724585148
Epoch: 3040, Batch Gradient Norm: 3.6664410434288754
Epoch: 3040, Batch Gradient Norm after: 3.6664410434288754
Epoch 3041/10000, Prediction Accuracy = 63.14999999999999%, Loss = 0.008600268942805437
Epoch: 3041, Batch Gradient Norm: 3.518044264007123
Epoch: 3041, Batch Gradient Norm after: 3.518044264007123
Epoch 3042/10000, Prediction Accuracy = 63.12307692307694%, Loss = 0.008471951461755313
Epoch: 3042, Batch Gradient Norm: 3.4752255086047725
Epoch: 3042, Batch Gradient Norm after: 3.4752255086047725
Epoch 3043/10000, Prediction Accuracy = 63.28076923076924%, Loss = 0.008464533334168104
Epoch: 3043, Batch Gradient Norm: 3.4581306884966265
Epoch: 3043, Batch Gradient Norm after: 3.4581306884966265
Epoch 3044/10000, Prediction Accuracy = 63.05384615384614%, Loss = 0.00846903477437221
Epoch: 3044, Batch Gradient Norm: 3.4725618297441367
Epoch: 3044, Batch Gradient Norm after: 3.4725618297441367
Epoch 3045/10000, Prediction Accuracy = 63.48846153846154%, Loss = 0.008402024109203082
Epoch: 3045, Batch Gradient Norm: 3.7735581403863523
Epoch: 3045, Batch Gradient Norm after: 3.7735581403863523
Epoch 3046/10000, Prediction Accuracy = 62.71153846153847%, Loss = 0.008572425693273544
Epoch: 3046, Batch Gradient Norm: 3.412386984460526
Epoch: 3046, Batch Gradient Norm after: 3.412386984460526
Epoch 3047/10000, Prediction Accuracy = 63.55%, Loss = 0.008350674779369282
Epoch: 3047, Batch Gradient Norm: 3.7195321884141332
Epoch: 3047, Batch Gradient Norm after: 3.7195321884141332
Epoch 3048/10000, Prediction Accuracy = 62.642307692307696%, Loss = 0.008558550061514745
Epoch: 3048, Batch Gradient Norm: 3.6874388013146886
Epoch: 3048, Batch Gradient Norm after: 3.6874388013146886
Epoch 3049/10000, Prediction Accuracy = 62.565384615384616%, Loss = 0.008508475712285591
Epoch: 3049, Batch Gradient Norm: 3.707757919922812
Epoch: 3049, Batch Gradient Norm after: 3.707757919922812
Epoch 3050/10000, Prediction Accuracy = 63.00384615384615%, Loss = 0.008473898140856853
Epoch: 3050, Batch Gradient Norm: 4.068276944711282
Epoch: 3050, Batch Gradient Norm after: 4.068276944711282
Epoch 3051/10000, Prediction Accuracy = 62.00769230769232%, Loss = 0.008743231184780598
Epoch: 3051, Batch Gradient Norm: 4.061072683484313
Epoch: 3051, Batch Gradient Norm after: 4.061072683484313
Epoch 3052/10000, Prediction Accuracy = 62.30384615384614%, Loss = 0.00883431166697007
Epoch: 3052, Batch Gradient Norm: 3.656661232877443
Epoch: 3052, Batch Gradient Norm after: 3.656661232877443
Epoch 3053/10000, Prediction Accuracy = 62.71538461538462%, Loss = 0.008528750461454574
Epoch: 3053, Batch Gradient Norm: 4.094365644609235
Epoch: 3053, Batch Gradient Norm after: 4.094365644609235
Epoch 3054/10000, Prediction Accuracy = 62.18076923076923%, Loss = 0.008796049353594963
Epoch: 3054, Batch Gradient Norm: 3.8300796984108825
Epoch: 3054, Batch Gradient Norm after: 3.8300796984108825
Epoch 3055/10000, Prediction Accuracy = 62.36923076923077%, Loss = 0.008628528636808578
Epoch: 3055, Batch Gradient Norm: 3.4368586639329255
Epoch: 3055, Batch Gradient Norm after: 3.4368586639329255
Epoch 3056/10000, Prediction Accuracy = 63.25769230769231%, Loss = 0.008429157404372325
Epoch: 3056, Batch Gradient Norm: 3.5325174178684247
Epoch: 3056, Batch Gradient Norm after: 3.5325174178684247
Epoch 3057/10000, Prediction Accuracy = 63.00000000000001%, Loss = 0.008450142537745146
Epoch: 3057, Batch Gradient Norm: 3.65783637704371
Epoch: 3057, Batch Gradient Norm after: 3.65783637704371
Epoch 3058/10000, Prediction Accuracy = 62.75384615384615%, Loss = 0.008524511009454727
Epoch: 3058, Batch Gradient Norm: 3.848808745758739
Epoch: 3058, Batch Gradient Norm after: 3.848808745758739
Epoch 3059/10000, Prediction Accuracy = 62.107692307692304%, Loss = 0.008703709580004215
Epoch: 3059, Batch Gradient Norm: 3.462389433845198
Epoch: 3059, Batch Gradient Norm after: 3.462389433845198
Epoch 3060/10000, Prediction Accuracy = 63.22307692307691%, Loss = 0.00840267796929066
Epoch: 3060, Batch Gradient Norm: 4.08798662983587
Epoch: 3060, Batch Gradient Norm after: 4.08798662983587
Epoch 3061/10000, Prediction Accuracy = 62.02692307692307%, Loss = 0.008760541677474976
Epoch: 3061, Batch Gradient Norm: 4.068108859066549
Epoch: 3061, Batch Gradient Norm after: 4.068108859066549
Epoch 3062/10000, Prediction Accuracy = 61.853846153846156%, Loss = 0.008859713776753498
Epoch: 3062, Batch Gradient Norm: 3.9490221853948606
Epoch: 3062, Batch Gradient Norm after: 3.9490221853948606
Epoch 3063/10000, Prediction Accuracy = 62.04615384615384%, Loss = 0.00878023449331522
Epoch: 3063, Batch Gradient Norm: 4.038334422874736
Epoch: 3063, Batch Gradient Norm after: 4.038334422874736
Epoch 3064/10000, Prediction Accuracy = 62.08076923076923%, Loss = 0.008817617781460285
Epoch: 3064, Batch Gradient Norm: 4.099887409691723
Epoch: 3064, Batch Gradient Norm after: 4.099887409691723
Epoch 3065/10000, Prediction Accuracy = 61.63076923076923%, Loss = 0.008960645359296065
Epoch: 3065, Batch Gradient Norm: 3.5818516394271835
Epoch: 3065, Batch Gradient Norm after: 3.5818516394271835
Epoch 3066/10000, Prediction Accuracy = 62.51153846153846%, Loss = 0.008596817389703713
Epoch: 3066, Batch Gradient Norm: 3.832682449869717
Epoch: 3066, Batch Gradient Norm after: 3.832682449869717
Epoch 3067/10000, Prediction Accuracy = 62.392307692307696%, Loss = 0.008638190392118234
Epoch: 3067, Batch Gradient Norm: 3.760695321073547
Epoch: 3067, Batch Gradient Norm after: 3.760695321073547
Epoch 3068/10000, Prediction Accuracy = 63.22307692307694%, Loss = 0.00851797742339281
Epoch: 3068, Batch Gradient Norm: 3.283690231646635
Epoch: 3068, Batch Gradient Norm after: 3.283690231646635
Epoch 3069/10000, Prediction Accuracy = 63.26153846153846%, Loss = 0.008355573321191164
Epoch: 3069, Batch Gradient Norm: 3.2657494763139274
Epoch: 3069, Batch Gradient Norm after: 3.2657494763139274
Epoch 3070/10000, Prediction Accuracy = 63.580769230769235%, Loss = 0.008297964930534363
Epoch: 3070, Batch Gradient Norm: 3.34095800368622
Epoch: 3070, Batch Gradient Norm after: 3.34095800368622
Epoch 3071/10000, Prediction Accuracy = 63.4076923076923%, Loss = 0.008310350517813977
Epoch: 3071, Batch Gradient Norm: 3.638631434012672
Epoch: 3071, Batch Gradient Norm after: 3.638631434012672
Epoch 3072/10000, Prediction Accuracy = 63.27307692307692%, Loss = 0.008417409844696522
Epoch: 3072, Batch Gradient Norm: 3.6150923054093016
Epoch: 3072, Batch Gradient Norm after: 3.6150923054093016
Epoch 3073/10000, Prediction Accuracy = 63.29230769230771%, Loss = 0.008379551796958996
Epoch: 3073, Batch Gradient Norm: 3.6172405221996726
Epoch: 3073, Batch Gradient Norm after: 3.6172405221996726
Epoch 3074/10000, Prediction Accuracy = 63.0%, Loss = 0.008383217769173475
Epoch: 3074, Batch Gradient Norm: 3.8057028427673503
Epoch: 3074, Batch Gradient Norm after: 3.8057028427673503
Epoch 3075/10000, Prediction Accuracy = 62.800000000000004%, Loss = 0.008534807425278883
Epoch: 3075, Batch Gradient Norm: 3.8357545430379165
Epoch: 3075, Batch Gradient Norm after: 3.8357545430379165
Epoch 3076/10000, Prediction Accuracy = 62.60769230769232%, Loss = 0.008656043845873613
Epoch: 3076, Batch Gradient Norm: 3.605964943479907
Epoch: 3076, Batch Gradient Norm after: 3.605964943479907
Epoch 3077/10000, Prediction Accuracy = 62.900000000000006%, Loss = 0.008471017989974756
Epoch: 3077, Batch Gradient Norm: 3.765009930051682
Epoch: 3077, Batch Gradient Norm after: 3.765009930051682
Epoch 3078/10000, Prediction Accuracy = 62.684615384615384%, Loss = 0.008568126063507337
Epoch: 3078, Batch Gradient Norm: 3.6151860169225816
Epoch: 3078, Batch Gradient Norm after: 3.6151860169225816
Epoch 3079/10000, Prediction Accuracy = 62.78846153846154%, Loss = 0.00852683286827344
Epoch: 3079, Batch Gradient Norm: 3.633527550278253
Epoch: 3079, Batch Gradient Norm after: 3.633527550278253
Epoch 3080/10000, Prediction Accuracy = 63.16923076923077%, Loss = 0.008429577430853477
Epoch: 3080, Batch Gradient Norm: 4.082915008413348
Epoch: 3080, Batch Gradient Norm after: 4.082915008413348
Epoch 3081/10000, Prediction Accuracy = 62.23461538461538%, Loss = 0.008673812692555098
Epoch: 3081, Batch Gradient Norm: 4.002285840232952
Epoch: 3081, Batch Gradient Norm after: 4.002285840232952
Epoch 3082/10000, Prediction Accuracy = 62.29615384615384%, Loss = 0.008687621340728723
Epoch: 3082, Batch Gradient Norm: 3.8850870857977355
Epoch: 3082, Batch Gradient Norm after: 3.8850870857977355
Epoch 3083/10000, Prediction Accuracy = 63.04999999999999%, Loss = 0.008579190318974165
Epoch: 3083, Batch Gradient Norm: 3.80350580915709
Epoch: 3083, Batch Gradient Norm after: 3.80350580915709
Epoch 3084/10000, Prediction Accuracy = 63.31538461538462%, Loss = 0.008514503876750287
Epoch: 3084, Batch Gradient Norm: 3.8793184588095007
Epoch: 3084, Batch Gradient Norm after: 3.8793184588095007
Epoch 3085/10000, Prediction Accuracy = 62.48461538461538%, Loss = 0.008594351175885934
Epoch: 3085, Batch Gradient Norm: 3.7297676934182906
Epoch: 3085, Batch Gradient Norm after: 3.7297676934182906
Epoch 3086/10000, Prediction Accuracy = 62.49999999999999%, Loss = 0.008495641514085807
Epoch: 3086, Batch Gradient Norm: 3.727265677626318
Epoch: 3086, Batch Gradient Norm after: 3.727265677626318
Epoch 3087/10000, Prediction Accuracy = 62.95%, Loss = 0.008495300864944091
Epoch: 3087, Batch Gradient Norm: 3.8486966319283757
Epoch: 3087, Batch Gradient Norm after: 3.8486966319283757
Epoch 3088/10000, Prediction Accuracy = 62.849999999999994%, Loss = 0.00851356854232458
Epoch: 3088, Batch Gradient Norm: 3.7118683744494083
Epoch: 3088, Batch Gradient Norm after: 3.7118683744494083
Epoch 3089/10000, Prediction Accuracy = 62.82692307692309%, Loss = 0.00850139006685752
Epoch: 3089, Batch Gradient Norm: 3.829708317315343
Epoch: 3089, Batch Gradient Norm after: 3.829708317315343
Epoch 3090/10000, Prediction Accuracy = 62.33846153846154%, Loss = 0.008649261095202886
Epoch: 3090, Batch Gradient Norm: 3.46266632625687
Epoch: 3090, Batch Gradient Norm after: 3.46266632625687
Epoch 3091/10000, Prediction Accuracy = 63.30384615384615%, Loss = 0.008432973176240921
Epoch: 3091, Batch Gradient Norm: 3.481530427152619
Epoch: 3091, Batch Gradient Norm after: 3.481530427152619
Epoch 3092/10000, Prediction Accuracy = 62.99615384615384%, Loss = 0.008358878585008474
Epoch: 3092, Batch Gradient Norm: 3.411757532594592
Epoch: 3092, Batch Gradient Norm after: 3.411757532594592
Epoch 3093/10000, Prediction Accuracy = 63.138461538461534%, Loss = 0.00837631502117102
Epoch: 3093, Batch Gradient Norm: 3.3509871832123204
Epoch: 3093, Batch Gradient Norm after: 3.3509871832123204
Epoch 3094/10000, Prediction Accuracy = 63.74999999999999%, Loss = 0.008271248617137853
Epoch: 3094, Batch Gradient Norm: 3.753467151455588
Epoch: 3094, Batch Gradient Norm after: 3.753467151455588
Epoch 3095/10000, Prediction Accuracy = 62.73846153846152%, Loss = 0.008548061649959821
Epoch: 3095, Batch Gradient Norm: 3.7320787776836464
Epoch: 3095, Batch Gradient Norm after: 3.7320787776836464
Epoch 3096/10000, Prediction Accuracy = 63.05384615384616%, Loss = 0.00850885920226574
Epoch: 3096, Batch Gradient Norm: 3.7586986888058105
Epoch: 3096, Batch Gradient Norm after: 3.7586986888058105
Epoch 3097/10000, Prediction Accuracy = 62.94615384615384%, Loss = 0.008503513124126654
Epoch: 3097, Batch Gradient Norm: 3.5845553209450736
Epoch: 3097, Batch Gradient Norm after: 3.5845553209450736
Epoch 3098/10000, Prediction Accuracy = 63.138461538461534%, Loss = 0.00840277117318832
Epoch: 3098, Batch Gradient Norm: 3.334140652367564
Epoch: 3098, Batch Gradient Norm after: 3.334140652367564
Epoch 3099/10000, Prediction Accuracy = 63.52307692307693%, Loss = 0.00830117419648629
Epoch: 3099, Batch Gradient Norm: 3.7087024366679064
Epoch: 3099, Batch Gradient Norm after: 3.7087024366679064
Epoch 3100/10000, Prediction Accuracy = 63.1653846153846%, Loss = 0.008456944273068355
Epoch: 3100, Batch Gradient Norm: 3.9333374211406404
Epoch: 3100, Batch Gradient Norm after: 3.9333374211406404
Epoch 3101/10000, Prediction Accuracy = 62.59999999999999%, Loss = 0.008561877891994439
Epoch: 3101, Batch Gradient Norm: 3.5325567470198305
Epoch: 3101, Batch Gradient Norm after: 3.5325567470198305
Epoch 3102/10000, Prediction Accuracy = 63.096153846153854%, Loss = 0.008389326099019784
Epoch: 3102, Batch Gradient Norm: 3.4401858044504414
Epoch: 3102, Batch Gradient Norm after: 3.4401858044504414
Epoch 3103/10000, Prediction Accuracy = 63.965384615384615%, Loss = 0.008284226274834229
Epoch: 3103, Batch Gradient Norm: 3.644519365699476
Epoch: 3103, Batch Gradient Norm after: 3.644519365699476
Epoch 3104/10000, Prediction Accuracy = 63.71153846153847%, Loss = 0.008386068189373383
Epoch: 3104, Batch Gradient Norm: 4.116341054664474
Epoch: 3104, Batch Gradient Norm after: 4.116341054664474
Epoch 3105/10000, Prediction Accuracy = 63.123076923076916%, Loss = 0.008687914850620123
Epoch: 3105, Batch Gradient Norm: 4.139221074967655
Epoch: 3105, Batch Gradient Norm after: 4.139221074967655
Epoch 3106/10000, Prediction Accuracy = 62.08846153846153%, Loss = 0.008790640518642388
Epoch: 3106, Batch Gradient Norm: 3.7650298169918406
Epoch: 3106, Batch Gradient Norm after: 3.7650298169918406
Epoch 3107/10000, Prediction Accuracy = 62.39615384615384%, Loss = 0.008577101290799104
Epoch: 3107, Batch Gradient Norm: 3.982312231217667
Epoch: 3107, Batch Gradient Norm after: 3.982312231217667
Epoch 3108/10000, Prediction Accuracy = 62.36538461538461%, Loss = 0.008682824599628266
Epoch: 3108, Batch Gradient Norm: 3.8684171576772894
Epoch: 3108, Batch Gradient Norm after: 3.8684171576772894
Epoch 3109/10000, Prediction Accuracy = 62.56538461538462%, Loss = 0.008605098208555808
Epoch: 3109, Batch Gradient Norm: 3.7815211842174787
Epoch: 3109, Batch Gradient Norm after: 3.7815211842174787
Epoch 3110/10000, Prediction Accuracy = 62.80384615384616%, Loss = 0.008592019000878701
Epoch: 3110, Batch Gradient Norm: 3.7178408042618454
Epoch: 3110, Batch Gradient Norm after: 3.7178408042618454
Epoch 3111/10000, Prediction Accuracy = 62.7153846153846%, Loss = 0.00856316046646008
Epoch: 3111, Batch Gradient Norm: 4.105096775786481
Epoch: 3111, Batch Gradient Norm after: 4.105096775786481
Epoch 3112/10000, Prediction Accuracy = 61.8%, Loss = 0.008785123721911358
Epoch: 3112, Batch Gradient Norm: 3.593302485303018
Epoch: 3112, Batch Gradient Norm after: 3.593302485303018
Epoch 3113/10000, Prediction Accuracy = 62.43846153846154%, Loss = 0.008574029072546042
Epoch: 3113, Batch Gradient Norm: 3.444958540456463
Epoch: 3113, Batch Gradient Norm after: 3.444958540456463
Epoch 3114/10000, Prediction Accuracy = 63.361538461538466%, Loss = 0.008387234276876999
Epoch: 3114, Batch Gradient Norm: 3.5773560411318517
Epoch: 3114, Batch Gradient Norm after: 3.5773560411318517
Epoch 3115/10000, Prediction Accuracy = 63.21923076923077%, Loss = 0.008430587772566538
Epoch: 3115, Batch Gradient Norm: 3.623552278510357
Epoch: 3115, Batch Gradient Norm after: 3.623552278510357
Epoch 3116/10000, Prediction Accuracy = 62.9423076923077%, Loss = 0.008472299489837427
Epoch: 3116, Batch Gradient Norm: 3.5828597431818148
Epoch: 3116, Batch Gradient Norm after: 3.5828597431818148
Epoch 3117/10000, Prediction Accuracy = 63.38461538461539%, Loss = 0.00837414783353989
Epoch: 3117, Batch Gradient Norm: 3.608909541320316
Epoch: 3117, Batch Gradient Norm after: 3.608909541320316
Epoch 3118/10000, Prediction Accuracy = 62.892307692307696%, Loss = 0.008476515873693503
Epoch: 3118, Batch Gradient Norm: 3.877063432608483
Epoch: 3118, Batch Gradient Norm after: 3.877063432608483
Epoch 3119/10000, Prediction Accuracy = 62.669230769230765%, Loss = 0.008672901572516331
Epoch: 3119, Batch Gradient Norm: 3.7256991894696165
Epoch: 3119, Batch Gradient Norm after: 3.7256991894696165
Epoch 3120/10000, Prediction Accuracy = 62.65384615384616%, Loss = 0.008560643961223273
Epoch: 3120, Batch Gradient Norm: 3.8419414810914754
Epoch: 3120, Batch Gradient Norm after: 3.8419414810914754
Epoch 3121/10000, Prediction Accuracy = 62.803846153846166%, Loss = 0.008515785519893352
Epoch: 3121, Batch Gradient Norm: 3.779038922922214
Epoch: 3121, Batch Gradient Norm after: 3.779038922922214
Epoch 3122/10000, Prediction Accuracy = 62.94615384615384%, Loss = 0.00857183738396718
Epoch: 3122, Batch Gradient Norm: 3.703253332035686
Epoch: 3122, Batch Gradient Norm after: 3.703253332035686
Epoch 3123/10000, Prediction Accuracy = 62.87307692307694%, Loss = 0.008480425422581343
Epoch: 3123, Batch Gradient Norm: 3.8429607701930646
Epoch: 3123, Batch Gradient Norm after: 3.8429607701930646
Epoch 3124/10000, Prediction Accuracy = 62.74230769230768%, Loss = 0.008522974255566414
Epoch: 3124, Batch Gradient Norm: 3.8906800750553376
Epoch: 3124, Batch Gradient Norm after: 3.8906800750553376
Epoch 3125/10000, Prediction Accuracy = 62.91538461538461%, Loss = 0.008591570175037934
Epoch: 3125, Batch Gradient Norm: 3.6491634998071314
Epoch: 3125, Batch Gradient Norm after: 3.6491634998071314
Epoch 3126/10000, Prediction Accuracy = 63.392307692307696%, Loss = 0.008420055803771202
Epoch: 3126, Batch Gradient Norm: 3.4618909857268623
Epoch: 3126, Batch Gradient Norm after: 3.4618909857268623
Epoch 3127/10000, Prediction Accuracy = 63.4076923076923%, Loss = 0.00833787926687644
Epoch: 3127, Batch Gradient Norm: 3.738175303378603
Epoch: 3127, Batch Gradient Norm after: 3.738175303378603
Epoch 3128/10000, Prediction Accuracy = 63.41153846153846%, Loss = 0.00839326147419902
Epoch: 3128, Batch Gradient Norm: 4.2109271852169305
Epoch: 3128, Batch Gradient Norm after: 4.2109271852169305
Epoch 3129/10000, Prediction Accuracy = 62.642307692307696%, Loss = 0.008656261632075677
Epoch: 3129, Batch Gradient Norm: 3.986163428061535
Epoch: 3129, Batch Gradient Norm after: 3.986163428061535
Epoch 3130/10000, Prediction Accuracy = 62.61538461538461%, Loss = 0.008639904956978101
Epoch: 3130, Batch Gradient Norm: 3.8729570627977976
Epoch: 3130, Batch Gradient Norm after: 3.8729570627977976
Epoch 3131/10000, Prediction Accuracy = 62.95384615384615%, Loss = 0.00844560842961073
Epoch: 3131, Batch Gradient Norm: 3.798526691462102
Epoch: 3131, Batch Gradient Norm after: 3.798526691462102
Epoch 3132/10000, Prediction Accuracy = 62.26923076923076%, Loss = 0.008620965437820325
Epoch: 3132, Batch Gradient Norm: 3.9359526216322895
Epoch: 3132, Batch Gradient Norm after: 3.9359526216322895
Epoch 3133/10000, Prediction Accuracy = 62.72692307692308%, Loss = 0.008620121086446138
Epoch: 3133, Batch Gradient Norm: 3.9570125671170775
Epoch: 3133, Batch Gradient Norm after: 3.9570125671170775
Epoch 3134/10000, Prediction Accuracy = 62.78846153846155%, Loss = 0.008638564568872634
Epoch: 3134, Batch Gradient Norm: 3.9954778619618914
Epoch: 3134, Batch Gradient Norm after: 3.9954778619618914
Epoch 3135/10000, Prediction Accuracy = 62.01153846153847%, Loss = 0.008736299279217537
Epoch: 3135, Batch Gradient Norm: 3.885159032783246
Epoch: 3135, Batch Gradient Norm after: 3.885159032783246
Epoch 3136/10000, Prediction Accuracy = 62.45%, Loss = 0.008582176139148382
Epoch: 3136, Batch Gradient Norm: 3.7938411252981443
Epoch: 3136, Batch Gradient Norm after: 3.7938411252981443
Epoch 3137/10000, Prediction Accuracy = 63.09999999999999%, Loss = 0.008507684088097168
Epoch: 3137, Batch Gradient Norm: 3.4447611905542215
Epoch: 3137, Batch Gradient Norm after: 3.4447611905542215
Epoch 3138/10000, Prediction Accuracy = 63.26153846153846%, Loss = 0.008421175898267673
Epoch: 3138, Batch Gradient Norm: 3.32164369037197
Epoch: 3138, Batch Gradient Norm after: 3.32164369037197
Epoch 3139/10000, Prediction Accuracy = 63.76923076923077%, Loss = 0.008246112793970566
Epoch: 3139, Batch Gradient Norm: 3.4377384739785986
Epoch: 3139, Batch Gradient Norm after: 3.4377384739785986
Epoch 3140/10000, Prediction Accuracy = 63.51153846153846%, Loss = 0.008314049372879358
Epoch: 3140, Batch Gradient Norm: 3.4209405712615313
Epoch: 3140, Batch Gradient Norm after: 3.4209405712615313
Epoch 3141/10000, Prediction Accuracy = 63.46923076923077%, Loss = 0.008324579120828556
Epoch: 3141, Batch Gradient Norm: 3.8071535154697806
Epoch: 3141, Batch Gradient Norm after: 3.8071535154697806
Epoch 3142/10000, Prediction Accuracy = 62.87307692307692%, Loss = 0.00843628252354952
Epoch: 3142, Batch Gradient Norm: 3.714745287053267
Epoch: 3142, Batch Gradient Norm after: 3.714745287053267
Epoch 3143/10000, Prediction Accuracy = 63.49615384615385%, Loss = 0.008417957247449802
Epoch: 3143, Batch Gradient Norm: 3.9836631597131493
Epoch: 3143, Batch Gradient Norm after: 3.9836631597131493
Epoch 3144/10000, Prediction Accuracy = 63.138461538461534%, Loss = 0.008498855006809417
Epoch: 3144, Batch Gradient Norm: 4.348983357101445
Epoch: 3144, Batch Gradient Norm after: 4.348983357101445
Epoch 3145/10000, Prediction Accuracy = 61.90384615384615%, Loss = 0.008889397964454614
Epoch: 3145, Batch Gradient Norm: 3.687929733403976
Epoch: 3145, Batch Gradient Norm after: 3.687929733403976
Epoch 3146/10000, Prediction Accuracy = 62.68076923076924%, Loss = 0.008494029466349345
Epoch: 3146, Batch Gradient Norm: 3.8261158208799544
Epoch: 3146, Batch Gradient Norm after: 3.8261158208799544
Epoch 3147/10000, Prediction Accuracy = 62.33846153846154%, Loss = 0.008603583233287701
Epoch: 3147, Batch Gradient Norm: 3.6692279302122737
Epoch: 3147, Batch Gradient Norm after: 3.6692279302122737
Epoch 3148/10000, Prediction Accuracy = 62.93461538461539%, Loss = 0.008472788720749892
Epoch: 3148, Batch Gradient Norm: 4.145403236857191
Epoch: 3148, Batch Gradient Norm after: 4.145403236857191
Epoch 3149/10000, Prediction Accuracy = 61.93076923076923%, Loss = 0.008797985429947194
Epoch: 3149, Batch Gradient Norm: 4.145191997837064
Epoch: 3149, Batch Gradient Norm after: 4.145191997837064
Epoch 3150/10000, Prediction Accuracy = 61.734615384615374%, Loss = 0.008923100594144601
Epoch: 3150, Batch Gradient Norm: 3.9226559266697443
Epoch: 3150, Batch Gradient Norm after: 3.9226559266697443
Epoch 3151/10000, Prediction Accuracy = 62.407692307692315%, Loss = 0.008784903643222956
Epoch: 3151, Batch Gradient Norm: 3.8669916387504077
Epoch: 3151, Batch Gradient Norm after: 3.8669916387504077
Epoch 3152/10000, Prediction Accuracy = 62.74615384615384%, Loss = 0.00866366342569773
Epoch: 3152, Batch Gradient Norm: 3.5130031569206146
Epoch: 3152, Batch Gradient Norm after: 3.5130031569206146
Epoch 3153/10000, Prediction Accuracy = 63.08076923076922%, Loss = 0.008571856870101048
Epoch: 3153, Batch Gradient Norm: 3.9096688328282125
Epoch: 3153, Batch Gradient Norm after: 3.9096688328282125
Epoch 3154/10000, Prediction Accuracy = 62.27307692307692%, Loss = 0.008707770074789341
Epoch: 3154, Batch Gradient Norm: 3.8888148700068323
Epoch: 3154, Batch Gradient Norm after: 3.8888148700068323
Epoch 3155/10000, Prediction Accuracy = 61.97692307692307%, Loss = 0.008735941364788093
Epoch: 3155, Batch Gradient Norm: 3.6339027587448562
Epoch: 3155, Batch Gradient Norm after: 3.6339027587448562
Epoch 3156/10000, Prediction Accuracy = 62.73846153846155%, Loss = 0.008520987028112778
Epoch: 3156, Batch Gradient Norm: 3.395710058856623
Epoch: 3156, Batch Gradient Norm after: 3.395710058856623
Epoch 3157/10000, Prediction Accuracy = 63.45%, Loss = 0.008297030169230241
Epoch: 3157, Batch Gradient Norm: 3.3455792697066506
Epoch: 3157, Batch Gradient Norm after: 3.3455792697066506
Epoch 3158/10000, Prediction Accuracy = 63.553846153846166%, Loss = 0.008199994989599172
Epoch: 3158, Batch Gradient Norm: 3.526697688461849
Epoch: 3158, Batch Gradient Norm after: 3.526697688461849
Epoch 3159/10000, Prediction Accuracy = 63.31923076923076%, Loss = 0.008298005622166853
Epoch: 3159, Batch Gradient Norm: 3.550934910223528
Epoch: 3159, Batch Gradient Norm after: 3.550934910223528
Epoch 3160/10000, Prediction Accuracy = 62.94615384615385%, Loss = 0.008359551859589724
Epoch: 3160, Batch Gradient Norm: 3.792798167294069
Epoch: 3160, Batch Gradient Norm after: 3.792798167294069
Epoch 3161/10000, Prediction Accuracy = 62.984615384615395%, Loss = 0.008496668691245409
Epoch: 3161, Batch Gradient Norm: 3.5409374786831314
Epoch: 3161, Batch Gradient Norm after: 3.5409374786831314
Epoch 3162/10000, Prediction Accuracy = 63.55%, Loss = 0.0083731642136207
Epoch: 3162, Batch Gradient Norm: 3.7233309514824158
Epoch: 3162, Batch Gradient Norm after: 3.7233309514824158
Epoch 3163/10000, Prediction Accuracy = 63.12307692307692%, Loss = 0.008384756457347136
Epoch: 3163, Batch Gradient Norm: 3.566418468696477
Epoch: 3163, Batch Gradient Norm after: 3.566418468696477
Epoch 3164/10000, Prediction Accuracy = 63.51153846153845%, Loss = 0.008390660397708416
Epoch: 3164, Batch Gradient Norm: 3.992432943129768
Epoch: 3164, Batch Gradient Norm after: 3.992432943129768
Epoch 3165/10000, Prediction Accuracy = 62.71153846153845%, Loss = 0.008646800540960752
Epoch: 3165, Batch Gradient Norm: 4.020723206371137
Epoch: 3165, Batch Gradient Norm after: 4.020723206371137
Epoch 3166/10000, Prediction Accuracy = 62.81923076923077%, Loss = 0.008612166517055951
Epoch: 3166, Batch Gradient Norm: 3.7980418380077627
Epoch: 3166, Batch Gradient Norm after: 3.7980418380077627
Epoch 3167/10000, Prediction Accuracy = 62.52692307692306%, Loss = 0.008507081808952184
Epoch: 3167, Batch Gradient Norm: 3.467826549768372
Epoch: 3167, Batch Gradient Norm after: 3.467826549768372
Epoch 3168/10000, Prediction Accuracy = 63.28846153846153%, Loss = 0.008333650274345508
Epoch: 3168, Batch Gradient Norm: 3.5443582577261763
Epoch: 3168, Batch Gradient Norm after: 3.5443582577261763
Epoch 3169/10000, Prediction Accuracy = 63.1423076923077%, Loss = 0.00833505610577189
Epoch: 3169, Batch Gradient Norm: 3.7290933012480014
Epoch: 3169, Batch Gradient Norm after: 3.7290933012480014
Epoch 3170/10000, Prediction Accuracy = 62.926923076923075%, Loss = 0.008493461144658236
Epoch: 3170, Batch Gradient Norm: 3.8919551175329627
Epoch: 3170, Batch Gradient Norm after: 3.8919551175329627
Epoch 3171/10000, Prediction Accuracy = 62.83846153846154%, Loss = 0.008587747812271118
Epoch: 3171, Batch Gradient Norm: 3.8009230078315515
Epoch: 3171, Batch Gradient Norm after: 3.8009230078315515
Epoch 3172/10000, Prediction Accuracy = 62.56538461538462%, Loss = 0.00854341800396259
Epoch: 3172, Batch Gradient Norm: 3.7618542076156745
Epoch: 3172, Batch Gradient Norm after: 3.7618542076156745
Epoch 3173/10000, Prediction Accuracy = 63.25384615384616%, Loss = 0.008404262507191071
Epoch: 3173, Batch Gradient Norm: 3.46436138481771
Epoch: 3173, Batch Gradient Norm after: 3.46436138481771
Epoch 3174/10000, Prediction Accuracy = 63.388461538461534%, Loss = 0.008280666258472662
Epoch: 3174, Batch Gradient Norm: 3.5264701131168166
Epoch: 3174, Batch Gradient Norm after: 3.5264701131168166
Epoch 3175/10000, Prediction Accuracy = 63.349999999999994%, Loss = 0.008283383212983608
Epoch: 3175, Batch Gradient Norm: 3.5936311212994227
Epoch: 3175, Batch Gradient Norm after: 3.5936311212994227
Epoch 3176/10000, Prediction Accuracy = 63.165384615384625%, Loss = 0.008287289860443426
Epoch: 3176, Batch Gradient Norm: 3.8367295250127524
Epoch: 3176, Batch Gradient Norm after: 3.8367295250127524
Epoch 3177/10000, Prediction Accuracy = 62.869230769230775%, Loss = 0.00851030325373778
Epoch: 3177, Batch Gradient Norm: 3.965293914181445
Epoch: 3177, Batch Gradient Norm after: 3.965293914181445
Epoch 3178/10000, Prediction Accuracy = 62.86153846153847%, Loss = 0.008657590127908267
Epoch: 3178, Batch Gradient Norm: 3.5457131797898462
Epoch: 3178, Batch Gradient Norm after: 3.5457131797898462
Epoch 3179/10000, Prediction Accuracy = 62.81923076923077%, Loss = 0.008467368351725431
Epoch: 3179, Batch Gradient Norm: 3.8253513426722323
Epoch: 3179, Batch Gradient Norm after: 3.8253513426722323
Epoch 3180/10000, Prediction Accuracy = 62.51923076923076%, Loss = 0.008496973377007704
Epoch: 3180, Batch Gradient Norm: 3.710222594590152
Epoch: 3180, Batch Gradient Norm after: 3.710222594590152
Epoch 3181/10000, Prediction Accuracy = 63.12307692307692%, Loss = 0.008399128197477413
Epoch: 3181, Batch Gradient Norm: 3.9725514757524762
Epoch: 3181, Batch Gradient Norm after: 3.9725514757524762
Epoch 3182/10000, Prediction Accuracy = 62.99230769230769%, Loss = 0.008553267241670536
Epoch: 3182, Batch Gradient Norm: 3.8714859671894994
Epoch: 3182, Batch Gradient Norm after: 3.8714859671894994
Epoch 3183/10000, Prediction Accuracy = 62.65384615384615%, Loss = 0.008490329679961387
Epoch: 3183, Batch Gradient Norm: 4.0990835250828415
Epoch: 3183, Batch Gradient Norm after: 4.0990835250828415
Epoch 3184/10000, Prediction Accuracy = 62.103846153846156%, Loss = 0.008671163079830317
Epoch: 3184, Batch Gradient Norm: 3.666573474920342
Epoch: 3184, Batch Gradient Norm after: 3.666573474920342
Epoch 3185/10000, Prediction Accuracy = 63.06153846153847%, Loss = 0.008404086558864666
Epoch: 3185, Batch Gradient Norm: 3.8394168352906415
Epoch: 3185, Batch Gradient Norm after: 3.8394168352906415
Epoch 3186/10000, Prediction Accuracy = 63.27307692307693%, Loss = 0.008394717489584135
Epoch: 3186, Batch Gradient Norm: 3.9266621275309608
Epoch: 3186, Batch Gradient Norm after: 3.9266621275309608
Epoch 3187/10000, Prediction Accuracy = 62.96538461538462%, Loss = 0.008465301460371567
Epoch: 3187, Batch Gradient Norm: 3.805166966708397
Epoch: 3187, Batch Gradient Norm after: 3.805166966708397
Epoch 3188/10000, Prediction Accuracy = 63.015384615384626%, Loss = 0.008427775823152982
Epoch: 3188, Batch Gradient Norm: 3.90089281816815
Epoch: 3188, Batch Gradient Norm after: 3.90089281816815
Epoch 3189/10000, Prediction Accuracy = 62.70769230769231%, Loss = 0.008557874709367752
Epoch: 3189, Batch Gradient Norm: 3.9351990118373745
Epoch: 3189, Batch Gradient Norm after: 3.9351990118373745
Epoch 3190/10000, Prediction Accuracy = 62.473076923076924%, Loss = 0.008613957163806144
Epoch: 3190, Batch Gradient Norm: 3.858206022957332
Epoch: 3190, Batch Gradient Norm after: 3.858206022957332
Epoch 3191/10000, Prediction Accuracy = 62.873076923076916%, Loss = 0.008435267417763289
Epoch: 3191, Batch Gradient Norm: 3.6745745237976437
Epoch: 3191, Batch Gradient Norm after: 3.6745745237976437
Epoch 3192/10000, Prediction Accuracy = 63.26923076923076%, Loss = 0.008340931927355437
Epoch: 3192, Batch Gradient Norm: 4.036785117217733
Epoch: 3192, Batch Gradient Norm after: 4.036785117217733
Epoch 3193/10000, Prediction Accuracy = 63.0%, Loss = 0.00845887683905088
Epoch: 3193, Batch Gradient Norm: 4.078341488708604
Epoch: 3193, Batch Gradient Norm after: 4.078341488708604
Epoch 3194/10000, Prediction Accuracy = 62.68076923076923%, Loss = 0.008633485063910484
Epoch: 3194, Batch Gradient Norm: 3.6799774235918132
Epoch: 3194, Batch Gradient Norm after: 3.6799774235918132
Epoch 3195/10000, Prediction Accuracy = 62.923076923076934%, Loss = 0.008402953282571755
Epoch: 3195, Batch Gradient Norm: 3.8163505488738787
Epoch: 3195, Batch Gradient Norm after: 3.8163505488738787
Epoch 3196/10000, Prediction Accuracy = 63.07692307692309%, Loss = 0.00842237279105645
Epoch: 3196, Batch Gradient Norm: 3.809475957880405
Epoch: 3196, Batch Gradient Norm after: 3.809475957880405
Epoch 3197/10000, Prediction Accuracy = 62.81153846153845%, Loss = 0.008441604530582061
Epoch: 3197, Batch Gradient Norm: 4.043892607617607
Epoch: 3197, Batch Gradient Norm after: 4.043892607617607
Epoch 3198/10000, Prediction Accuracy = 62.14230769230768%, Loss = 0.008726512726682883
Epoch: 3198, Batch Gradient Norm: 3.7065151187255796
Epoch: 3198, Batch Gradient Norm after: 3.7065151187255796
Epoch 3199/10000, Prediction Accuracy = 62.800000000000004%, Loss = 0.008528459029128918
Epoch: 3199, Batch Gradient Norm: 3.5278341259861064
Epoch: 3199, Batch Gradient Norm after: 3.5278341259861064
Epoch 3200/10000, Prediction Accuracy = 63.603846153846156%, Loss = 0.00827586056234745
Epoch: 3200, Batch Gradient Norm: 3.842651030337932
Epoch: 3200, Batch Gradient Norm after: 3.842651030337932
Epoch 3201/10000, Prediction Accuracy = 63.04230769230771%, Loss = 0.008414218632074503
Epoch: 3201, Batch Gradient Norm: 3.6791601498051727
Epoch: 3201, Batch Gradient Norm after: 3.6791601498051727
Epoch 3202/10000, Prediction Accuracy = 63.1653846153846%, Loss = 0.008417496672616554
Epoch: 3202, Batch Gradient Norm: 4.075765502862271
Epoch: 3202, Batch Gradient Norm after: 4.075765502862271
Epoch 3203/10000, Prediction Accuracy = 62.18846153846154%, Loss = 0.00866055080237297
Epoch: 3203, Batch Gradient Norm: 4.119063233851248
Epoch: 3203, Batch Gradient Norm after: 4.119063233851248
Epoch 3204/10000, Prediction Accuracy = 61.842307692307706%, Loss = 0.008782952235868344
Epoch: 3204, Batch Gradient Norm: 4.26701407956773
Epoch: 3204, Batch Gradient Norm after: 4.26701407956773
Epoch 3205/10000, Prediction Accuracy = 62.29230769230769%, Loss = 0.008805302544855155
Epoch: 3205, Batch Gradient Norm: 3.8288291627207194
Epoch: 3205, Batch Gradient Norm after: 3.8288291627207194
Epoch 3206/10000, Prediction Accuracy = 63.17692307692309%, Loss = 0.008527577997973332
Epoch: 3206, Batch Gradient Norm: 3.61828743019441
Epoch: 3206, Batch Gradient Norm after: 3.61828743019441
Epoch 3207/10000, Prediction Accuracy = 63.21153846153845%, Loss = 0.008361691179183813
Epoch: 3207, Batch Gradient Norm: 3.653516705566662
Epoch: 3207, Batch Gradient Norm after: 3.653516705566662
Epoch 3208/10000, Prediction Accuracy = 63.06923076923078%, Loss = 0.008396087859112483
Epoch: 3208, Batch Gradient Norm: 4.140904341433641
Epoch: 3208, Batch Gradient Norm after: 4.140904341433641
Epoch 3209/10000, Prediction Accuracy = 62.80384615384615%, Loss = 0.008565622381865978
Epoch: 3209, Batch Gradient Norm: 3.778302064015784
Epoch: 3209, Batch Gradient Norm after: 3.778302064015784
Epoch 3210/10000, Prediction Accuracy = 62.98846153846154%, Loss = 0.008521352536403216
Epoch: 3210, Batch Gradient Norm: 3.6675309451631852
Epoch: 3210, Batch Gradient Norm after: 3.6675309451631852
Epoch 3211/10000, Prediction Accuracy = 63.619230769230775%, Loss = 0.00836644758685277
Epoch: 3211, Batch Gradient Norm: 3.448494102540132
Epoch: 3211, Batch Gradient Norm after: 3.448494102540132
Epoch 3212/10000, Prediction Accuracy = 63.46923076923077%, Loss = 0.008373958560136648
Epoch: 3212, Batch Gradient Norm: 3.4611778220373934
Epoch: 3212, Batch Gradient Norm after: 3.4611778220373934
Epoch 3213/10000, Prediction Accuracy = 63.523076923076914%, Loss = 0.008244031968598183
Epoch: 3213, Batch Gradient Norm: 3.8090981724146147
Epoch: 3213, Batch Gradient Norm after: 3.8090981724146147
Epoch 3214/10000, Prediction Accuracy = 63.361538461538444%, Loss = 0.00835019271247662
Epoch: 3214, Batch Gradient Norm: 3.755386264042777
Epoch: 3214, Batch Gradient Norm after: 3.755386264042777
Epoch 3215/10000, Prediction Accuracy = 63.20000000000001%, Loss = 0.008463941872693025
Epoch: 3215, Batch Gradient Norm: 3.4793986689939107
Epoch: 3215, Batch Gradient Norm after: 3.4793986689939107
Epoch 3216/10000, Prediction Accuracy = 63.265384615384605%, Loss = 0.008363981946156574
Epoch: 3216, Batch Gradient Norm: 3.6153905778482835
Epoch: 3216, Batch Gradient Norm after: 3.6153905778482835
Epoch 3217/10000, Prediction Accuracy = 63.18076923076923%, Loss = 0.008336664786419043
Epoch: 3217, Batch Gradient Norm: 3.623471698830907
Epoch: 3217, Batch Gradient Norm after: 3.623471698830907
Epoch 3218/10000, Prediction Accuracy = 63.307692307692314%, Loss = 0.008359803388325067
Epoch: 3218, Batch Gradient Norm: 3.7308189335646356
Epoch: 3218, Batch Gradient Norm after: 3.7308189335646356
Epoch 3219/10000, Prediction Accuracy = 63.33076923076924%, Loss = 0.008407353781736814
Epoch: 3219, Batch Gradient Norm: 3.5807391368733725
Epoch: 3219, Batch Gradient Norm after: 3.5807391368733725
Epoch 3220/10000, Prediction Accuracy = 63.45769230769231%, Loss = 0.008286123522199117
Epoch: 3220, Batch Gradient Norm: 3.326355402963597
Epoch: 3220, Batch Gradient Norm after: 3.326355402963597
Epoch 3221/10000, Prediction Accuracy = 63.67307692307692%, Loss = 0.0081383681927736
Epoch: 3221, Batch Gradient Norm: 3.5022988165737297
Epoch: 3221, Batch Gradient Norm after: 3.5022988165737297
Epoch 3222/10000, Prediction Accuracy = 63.673076923076934%, Loss = 0.008144483328438722
Epoch: 3222, Batch Gradient Norm: 3.9878291175044667
Epoch: 3222, Batch Gradient Norm after: 3.9878291175044667
Epoch 3223/10000, Prediction Accuracy = 62.65384615384615%, Loss = 0.008477891293855814
Epoch: 3223, Batch Gradient Norm: 3.8733053189338715
Epoch: 3223, Batch Gradient Norm after: 3.8733053189338715
Epoch 3224/10000, Prediction Accuracy = 62.699999999999996%, Loss = 0.008395338932482095
Epoch: 3224, Batch Gradient Norm: 4.4316394706357745
Epoch: 3224, Batch Gradient Norm after: 4.4316394706357745
Epoch 3225/10000, Prediction Accuracy = 62.51153846153847%, Loss = 0.008693434441318879
Epoch: 3225, Batch Gradient Norm: 4.281248095309269
Epoch: 3225, Batch Gradient Norm after: 4.281248095309269
Epoch 3226/10000, Prediction Accuracy = 62.676923076923075%, Loss = 0.008696915366901802
Epoch: 3226, Batch Gradient Norm: 3.8390824073434104
Epoch: 3226, Batch Gradient Norm after: 3.8390824073434104
Epoch 3227/10000, Prediction Accuracy = 62.72692307692308%, Loss = 0.008458879203177415
Epoch: 3227, Batch Gradient Norm: 3.611174262764321
Epoch: 3227, Batch Gradient Norm after: 3.611174262764321
Epoch 3228/10000, Prediction Accuracy = 63.142307692307696%, Loss = 0.008385987235949589
Epoch: 3228, Batch Gradient Norm: 3.2371522911821256
Epoch: 3228, Batch Gradient Norm after: 3.2371522911821256
Epoch 3229/10000, Prediction Accuracy = 63.73076923076923%, Loss = 0.008177718470016351
Epoch: 3229, Batch Gradient Norm: 4.161659204017019
Epoch: 3229, Batch Gradient Norm after: 4.161659204017019
Epoch 3230/10000, Prediction Accuracy = 62.6423076923077%, Loss = 0.008565981585818987
Epoch: 3230, Batch Gradient Norm: 4.255021354822189
Epoch: 3230, Batch Gradient Norm after: 4.255021354822189
Epoch 3231/10000, Prediction Accuracy = 62.126923076923084%, Loss = 0.008805482648313046
Epoch: 3231, Batch Gradient Norm: 3.872058297534928
Epoch: 3231, Batch Gradient Norm after: 3.872058297534928
Epoch 3232/10000, Prediction Accuracy = 62.349999999999994%, Loss = 0.008624476595566822
Epoch: 3232, Batch Gradient Norm: 3.601463496015545
Epoch: 3232, Batch Gradient Norm after: 3.601463496015545
Epoch 3233/10000, Prediction Accuracy = 63.19615384615384%, Loss = 0.008426297814227067
Epoch: 3233, Batch Gradient Norm: 4.056945179930183
Epoch: 3233, Batch Gradient Norm after: 4.056945179930183
Epoch 3234/10000, Prediction Accuracy = 62.96538461538462%, Loss = 0.008499268800593339
Epoch: 3234, Batch Gradient Norm: 3.7979162209975352
Epoch: 3234, Batch Gradient Norm after: 3.7979162209975352
Epoch 3235/10000, Prediction Accuracy = 63.34615384615385%, Loss = 0.008365121741707508
Epoch: 3235, Batch Gradient Norm: 4.003317380635393
Epoch: 3235, Batch Gradient Norm after: 4.003317380635393
Epoch 3236/10000, Prediction Accuracy = 62.892307692307696%, Loss = 0.008503758491804967
Epoch: 3236, Batch Gradient Norm: 4.141780224529995
Epoch: 3236, Batch Gradient Norm after: 4.141780224529995
Epoch 3237/10000, Prediction Accuracy = 62.71923076923077%, Loss = 0.008707594556304125
Epoch: 3237, Batch Gradient Norm: 3.5886180423469987
Epoch: 3237, Batch Gradient Norm after: 3.5886180423469987
Epoch 3238/10000, Prediction Accuracy = 63.17692307692308%, Loss = 0.0084325630361071
Epoch: 3238, Batch Gradient Norm: 3.5921379926927046
Epoch: 3238, Batch Gradient Norm after: 3.5921379926927046
Epoch 3239/10000, Prediction Accuracy = 63.67307692307692%, Loss = 0.008368589055652801
Epoch: 3239, Batch Gradient Norm: 3.7078425652083613
Epoch: 3239, Batch Gradient Norm after: 3.7078425652083613
Epoch 3240/10000, Prediction Accuracy = 63.20769230769231%, Loss = 0.00836741945777948
Epoch: 3240, Batch Gradient Norm: 3.5625407222574155
Epoch: 3240, Batch Gradient Norm after: 3.5625407222574155
Epoch 3241/10000, Prediction Accuracy = 63.07307692307692%, Loss = 0.008335273497952865
Epoch: 3241, Batch Gradient Norm: 3.7130748170292907
Epoch: 3241, Batch Gradient Norm after: 3.7130748170292907
Epoch 3242/10000, Prediction Accuracy = 63.307692307692314%, Loss = 0.008442318783356594
Epoch: 3242, Batch Gradient Norm: 3.8946741857594622
Epoch: 3242, Batch Gradient Norm after: 3.8946741857594622
Epoch 3243/10000, Prediction Accuracy = 63.0923076923077%, Loss = 0.008458971045911312
Epoch: 3243, Batch Gradient Norm: 3.7515290888841912
Epoch: 3243, Batch Gradient Norm after: 3.7515290888841912
Epoch 3244/10000, Prediction Accuracy = 63.4423076923077%, Loss = 0.008405567791599493
Epoch: 3244, Batch Gradient Norm: 3.984636276976356
Epoch: 3244, Batch Gradient Norm after: 3.984636276976356
Epoch 3245/10000, Prediction Accuracy = 62.81153846153846%, Loss = 0.00846302559456
Epoch: 3245, Batch Gradient Norm: 3.895878116361996
Epoch: 3245, Batch Gradient Norm after: 3.895878116361996
Epoch 3246/10000, Prediction Accuracy = 63.4076923076923%, Loss = 0.008429543759960394
Epoch: 3246, Batch Gradient Norm: 4.024224844462152
Epoch: 3246, Batch Gradient Norm after: 4.024224844462152
Epoch 3247/10000, Prediction Accuracy = 62.98076923076924%, Loss = 0.008561693346844269
Epoch: 3247, Batch Gradient Norm: 3.6525462396208677
Epoch: 3247, Batch Gradient Norm after: 3.6525462396208677
Epoch 3248/10000, Prediction Accuracy = 63.07307692307692%, Loss = 0.008436922163057786
Epoch: 3248, Batch Gradient Norm: 3.8287259930214064
Epoch: 3248, Batch Gradient Norm after: 3.8287259930214064
Epoch 3249/10000, Prediction Accuracy = 62.73076923076924%, Loss = 0.00846282965861834
Epoch: 3249, Batch Gradient Norm: 3.582774868006156
Epoch: 3249, Batch Gradient Norm after: 3.582774868006156
Epoch 3250/10000, Prediction Accuracy = 62.934615384615384%, Loss = 0.008356048940466
Epoch: 3250, Batch Gradient Norm: 3.6153971045248405
Epoch: 3250, Batch Gradient Norm after: 3.6153971045248405
Epoch 3251/10000, Prediction Accuracy = 63.46923076923077%, Loss = 0.008336168427306872
Epoch: 3251, Batch Gradient Norm: 3.8596095806013504
Epoch: 3251, Batch Gradient Norm after: 3.8596095806013504
Epoch 3252/10000, Prediction Accuracy = 63.0%, Loss = 0.008414214262022423
Epoch: 3252, Batch Gradient Norm: 3.961158672610062
Epoch: 3252, Batch Gradient Norm after: 3.961158672610062
Epoch 3253/10000, Prediction Accuracy = 62.857692307692304%, Loss = 0.008394542508400403
Epoch: 3253, Batch Gradient Norm: 3.886596374934617
Epoch: 3253, Batch Gradient Norm after: 3.886596374934617
Epoch 3254/10000, Prediction Accuracy = 62.67692307692307%, Loss = 0.00856272539553734
Epoch: 3254, Batch Gradient Norm: 3.896382693797389
Epoch: 3254, Batch Gradient Norm after: 3.896382693797389
Epoch 3255/10000, Prediction Accuracy = 63.2576923076923%, Loss = 0.00845997494000655
Epoch: 3255, Batch Gradient Norm: 3.7879761706934474
Epoch: 3255, Batch Gradient Norm after: 3.7879761706934474
Epoch 3256/10000, Prediction Accuracy = 63.403846153846146%, Loss = 0.008423873438284947
Epoch: 3256, Batch Gradient Norm: 3.727623079835187
Epoch: 3256, Batch Gradient Norm after: 3.727623079835187
Epoch 3257/10000, Prediction Accuracy = 63.14999999999999%, Loss = 0.0084328601996486
Epoch: 3257, Batch Gradient Norm: 3.998339993316382
Epoch: 3257, Batch Gradient Norm after: 3.998339993316382
Epoch 3258/10000, Prediction Accuracy = 62.35000000000001%, Loss = 0.008537850557611538
Epoch: 3258, Batch Gradient Norm: 3.6426089254142235
Epoch: 3258, Batch Gradient Norm after: 3.6426089254142235
Epoch 3259/10000, Prediction Accuracy = 62.98076923076923%, Loss = 0.00837405534604421
Epoch: 3259, Batch Gradient Norm: 3.998971827328754
Epoch: 3259, Batch Gradient Norm after: 3.998971827328754
Epoch 3260/10000, Prediction Accuracy = 62.28846153846154%, Loss = 0.008604969399479719
Epoch: 3260, Batch Gradient Norm: 3.644004329015787
Epoch: 3260, Batch Gradient Norm after: 3.644004329015787
Epoch 3261/10000, Prediction Accuracy = 63.25384615384615%, Loss = 0.008255859335454611
Epoch: 3261, Batch Gradient Norm: 3.9321204866320745
Epoch: 3261, Batch Gradient Norm after: 3.9321204866320745
Epoch 3262/10000, Prediction Accuracy = 63.08461538461539%, Loss = 0.00845871686648864
Epoch: 3262, Batch Gradient Norm: 3.9400045213238135
Epoch: 3262, Batch Gradient Norm after: 3.9400045213238135
Epoch 3263/10000, Prediction Accuracy = 62.93846153846153%, Loss = 0.00842781887891201
Epoch: 3263, Batch Gradient Norm: 3.5184326672884265
Epoch: 3263, Batch Gradient Norm after: 3.5184326672884265
Epoch 3264/10000, Prediction Accuracy = 63.4923076923077%, Loss = 0.008236713349246062
Epoch: 3264, Batch Gradient Norm: 3.593429631566416
Epoch: 3264, Batch Gradient Norm after: 3.593429631566416
Epoch 3265/10000, Prediction Accuracy = 63.57692307692308%, Loss = 0.008314623067585321
Epoch: 3265, Batch Gradient Norm: 3.8069440473019758
Epoch: 3265, Batch Gradient Norm after: 3.8069440473019758
Epoch 3266/10000, Prediction Accuracy = 63.23076923076923%, Loss = 0.00851776680121055
Epoch: 3266, Batch Gradient Norm: 3.972326988144421
Epoch: 3266, Batch Gradient Norm after: 3.972326988144421
Epoch 3267/10000, Prediction Accuracy = 62.71153846153846%, Loss = 0.008544889708551077
Epoch: 3267, Batch Gradient Norm: 3.3449026008915617
Epoch: 3267, Batch Gradient Norm after: 3.3449026008915617
Epoch 3268/10000, Prediction Accuracy = 63.63076923076923%, Loss = 0.008222534894370116
Epoch: 3268, Batch Gradient Norm: 3.946481155928023
Epoch: 3268, Batch Gradient Norm after: 3.946481155928023
Epoch 3269/10000, Prediction Accuracy = 62.75384615384615%, Loss = 0.008394636142139252
Epoch: 3269, Batch Gradient Norm: 4.265240670702627
Epoch: 3269, Batch Gradient Norm after: 4.265240670702627
Epoch 3270/10000, Prediction Accuracy = 62.33461538461539%, Loss = 0.008649056347516866
Epoch: 3270, Batch Gradient Norm: 4.122325199126496
Epoch: 3270, Batch Gradient Norm after: 4.122325199126496
Epoch 3271/10000, Prediction Accuracy = 62.91153846153846%, Loss = 0.008494642419883838
Epoch: 3271, Batch Gradient Norm: 3.6873315408338985
Epoch: 3271, Batch Gradient Norm after: 3.6873315408338985
Epoch 3272/10000, Prediction Accuracy = 63.361538461538466%, Loss = 0.008384836121247364
Epoch: 3272, Batch Gradient Norm: 3.7372719959025864
Epoch: 3272, Batch Gradient Norm after: 3.7372719959025864
Epoch 3273/10000, Prediction Accuracy = 63.31923076923077%, Loss = 0.008350599915362321
Epoch: 3273, Batch Gradient Norm: 4.261493314669244
Epoch: 3273, Batch Gradient Norm after: 4.261493314669244
Epoch 3274/10000, Prediction Accuracy = 62.823076923076925%, Loss = 0.008667968285198394
Epoch: 3274, Batch Gradient Norm: 3.9568373084033137
Epoch: 3274, Batch Gradient Norm after: 3.9568373084033137
Epoch 3275/10000, Prediction Accuracy = 63.08076923076923%, Loss = 0.00852658750059513
Epoch: 3275, Batch Gradient Norm: 3.6982352013230226
Epoch: 3275, Batch Gradient Norm after: 3.6982352013230226
Epoch 3276/10000, Prediction Accuracy = 63.55769230769231%, Loss = 0.008348996106248636
Epoch: 3276, Batch Gradient Norm: 3.4820575889840266
Epoch: 3276, Batch Gradient Norm after: 3.4820575889840266
Epoch 3277/10000, Prediction Accuracy = 63.53846153846155%, Loss = 0.00823255323876555
Epoch: 3277, Batch Gradient Norm: 3.667108909016119
Epoch: 3277, Batch Gradient Norm after: 3.667108909016119
Epoch 3278/10000, Prediction Accuracy = 63.099999999999994%, Loss = 0.008362741925968574
Epoch: 3278, Batch Gradient Norm: 3.6731878205519695
Epoch: 3278, Batch Gradient Norm after: 3.6731878205519695
Epoch 3279/10000, Prediction Accuracy = 62.90384615384616%, Loss = 0.008367571048438549
Epoch: 3279, Batch Gradient Norm: 3.70744547255442
Epoch: 3279, Batch Gradient Norm after: 3.70744547255442
Epoch 3280/10000, Prediction Accuracy = 63.23461538461539%, Loss = 0.008357492848657645
Epoch: 3280, Batch Gradient Norm: 3.6481488629654986
Epoch: 3280, Batch Gradient Norm after: 3.6481488629654986
Epoch 3281/10000, Prediction Accuracy = 63.39230769230768%, Loss = 0.00822768546640873
Epoch: 3281, Batch Gradient Norm: 3.8857234305890422
Epoch: 3281, Batch Gradient Norm after: 3.8857234305890422
Epoch 3282/10000, Prediction Accuracy = 62.949999999999996%, Loss = 0.008375819557561325
Epoch: 3282, Batch Gradient Norm: 4.214062695552806
Epoch: 3282, Batch Gradient Norm after: 4.214062695552806
Epoch 3283/10000, Prediction Accuracy = 62.68461538461539%, Loss = 0.008658867257718857
Epoch: 3283, Batch Gradient Norm: 4.050209856466854
Epoch: 3283, Batch Gradient Norm after: 4.050209856466854
Epoch 3284/10000, Prediction Accuracy = 62.44230769230769%, Loss = 0.008541010964948397
Epoch: 3284, Batch Gradient Norm: 3.9940729098055816
Epoch: 3284, Batch Gradient Norm after: 3.9940729098055816
Epoch 3285/10000, Prediction Accuracy = 62.62692307692306%, Loss = 0.008510477840900421
Epoch: 3285, Batch Gradient Norm: 3.939916519662931
Epoch: 3285, Batch Gradient Norm after: 3.939916519662931
Epoch 3286/10000, Prediction Accuracy = 62.90384615384615%, Loss = 0.008523183301664315
Epoch: 3286, Batch Gradient Norm: 3.9454399215812104
Epoch: 3286, Batch Gradient Norm after: 3.9454399215812104
Epoch 3287/10000, Prediction Accuracy = 62.715384615384615%, Loss = 0.008507255393152054
Epoch: 3287, Batch Gradient Norm: 3.851397491149015
Epoch: 3287, Batch Gradient Norm after: 3.851397491149015
Epoch 3288/10000, Prediction Accuracy = 62.946153846153834%, Loss = 0.008515278737132367
Epoch: 3288, Batch Gradient Norm: 3.786707595793423
Epoch: 3288, Batch Gradient Norm after: 3.786707595793423
Epoch 3289/10000, Prediction Accuracy = 63.21153846153847%, Loss = 0.008488266155696832
Epoch: 3289, Batch Gradient Norm: 3.8116001944313678
Epoch: 3289, Batch Gradient Norm after: 3.8116001944313678
Epoch 3290/10000, Prediction Accuracy = 62.634615384615394%, Loss = 0.008524199159672627
Epoch: 3290, Batch Gradient Norm: 3.8303204491631058
Epoch: 3290, Batch Gradient Norm after: 3.8303204491631058
Epoch 3291/10000, Prediction Accuracy = 62.99615384615383%, Loss = 0.00854605078124083
Epoch: 3291, Batch Gradient Norm: 3.705879389137031
Epoch: 3291, Batch Gradient Norm after: 3.705879389137031
Epoch 3292/10000, Prediction Accuracy = 63.05%, Loss = 0.008428407259858571
Epoch: 3292, Batch Gradient Norm: 3.471181488232109
Epoch: 3292, Batch Gradient Norm after: 3.471181488232109
Epoch 3293/10000, Prediction Accuracy = 63.50384615384616%, Loss = 0.008309589698910713
Epoch: 3293, Batch Gradient Norm: 3.7736737899458026
Epoch: 3293, Batch Gradient Norm after: 3.7736737899458026
Epoch 3294/10000, Prediction Accuracy = 63.403846153846146%, Loss = 0.00843121799138876
Epoch: 3294, Batch Gradient Norm: 4.101208618660884
Epoch: 3294, Batch Gradient Norm after: 4.101208618660884
Epoch 3295/10000, Prediction Accuracy = 62.70000000000001%, Loss = 0.00863166146266919
Epoch: 3295, Batch Gradient Norm: 3.869393711924486
Epoch: 3295, Batch Gradient Norm after: 3.869393711924486
Epoch 3296/10000, Prediction Accuracy = 63.076923076923066%, Loss = 0.008531139160578068
Epoch: 3296, Batch Gradient Norm: 4.092987244081952
Epoch: 3296, Batch Gradient Norm after: 4.092987244081952
Epoch 3297/10000, Prediction Accuracy = 62.815384615384616%, Loss = 0.008561205262174973
Epoch: 3297, Batch Gradient Norm: 4.063573135663354
Epoch: 3297, Batch Gradient Norm after: 4.063573135663354
Epoch 3298/10000, Prediction Accuracy = 62.63076923076923%, Loss = 0.008626211864443926
Epoch: 3298, Batch Gradient Norm: 3.9621358369455852
Epoch: 3298, Batch Gradient Norm after: 3.9621358369455852
Epoch 3299/10000, Prediction Accuracy = 62.74615384615384%, Loss = 0.008498861454427242
Epoch: 3299, Batch Gradient Norm: 3.773810103266607
Epoch: 3299, Batch Gradient Norm after: 3.773810103266607
Epoch 3300/10000, Prediction Accuracy = 62.97692307692307%, Loss = 0.008415928038840111
Epoch: 3300, Batch Gradient Norm: 3.6644758641099906
Epoch: 3300, Batch Gradient Norm after: 3.6644758641099906
Epoch 3301/10000, Prediction Accuracy = 62.86538461538461%, Loss = 0.008452575152310042
Epoch: 3301, Batch Gradient Norm: 3.6254571461364797
Epoch: 3301, Batch Gradient Norm after: 3.6254571461364797
Epoch 3302/10000, Prediction Accuracy = 63.29230769230768%, Loss = 0.008314380064033546
Epoch: 3302, Batch Gradient Norm: 3.7744666554417257
Epoch: 3302, Batch Gradient Norm after: 3.7744666554417257
Epoch 3303/10000, Prediction Accuracy = 63.650000000000006%, Loss = 0.00826659995632676
Epoch: 3303, Batch Gradient Norm: 4.102392167188874
Epoch: 3303, Batch Gradient Norm after: 4.102392167188874
Epoch 3304/10000, Prediction Accuracy = 63.36923076923077%, Loss = 0.008571673686114641
Epoch: 3304, Batch Gradient Norm: 3.9057128172174878
Epoch: 3304, Batch Gradient Norm after: 3.9057128172174878
Epoch 3305/10000, Prediction Accuracy = 62.75384615384617%, Loss = 0.008459277021197172
Epoch: 3305, Batch Gradient Norm: 3.3037830201412794
Epoch: 3305, Batch Gradient Norm after: 3.3037830201412794
Epoch 3306/10000, Prediction Accuracy = 63.215384615384615%, Loss = 0.008243042832383743
Epoch: 3306, Batch Gradient Norm: 3.4790834675559443
Epoch: 3306, Batch Gradient Norm after: 3.4790834675559443
Epoch 3307/10000, Prediction Accuracy = 63.45%, Loss = 0.008302165947567958
Epoch: 3307, Batch Gradient Norm: 3.657948942285248
Epoch: 3307, Batch Gradient Norm after: 3.657948942285248
Epoch 3308/10000, Prediction Accuracy = 62.95384615384615%, Loss = 0.008316215629187914
Epoch: 3308, Batch Gradient Norm: 3.7057913991158746
Epoch: 3308, Batch Gradient Norm after: 3.7057913991158746
Epoch 3309/10000, Prediction Accuracy = 63.96538461538462%, Loss = 0.008178887960429374
Epoch: 3309, Batch Gradient Norm: 3.9274933621142996
Epoch: 3309, Batch Gradient Norm after: 3.9274933621142996
Epoch 3310/10000, Prediction Accuracy = 62.726923076923065%, Loss = 0.008449003745156985
Epoch: 3310, Batch Gradient Norm: 3.8277158420056447
Epoch: 3310, Batch Gradient Norm after: 3.8277158420056447
Epoch 3311/10000, Prediction Accuracy = 63.06538461538461%, Loss = 0.008334545561900506
Epoch: 3311, Batch Gradient Norm: 3.769240340690128
Epoch: 3311, Batch Gradient Norm after: 3.769240340690128
Epoch 3312/10000, Prediction Accuracy = 63.61538461538461%, Loss = 0.008384955975298699
Epoch: 3312, Batch Gradient Norm: 3.6207193371859936
Epoch: 3312, Batch Gradient Norm after: 3.6207193371859936
Epoch 3313/10000, Prediction Accuracy = 63.11923076923077%, Loss = 0.008330397952634554
Epoch: 3313, Batch Gradient Norm: 3.3941637812439516
Epoch: 3313, Batch Gradient Norm after: 3.3941637812439516
Epoch 3314/10000, Prediction Accuracy = 63.68846153846154%, Loss = 0.0081823870826226
Epoch: 3314, Batch Gradient Norm: 3.7393986650872058
Epoch: 3314, Batch Gradient Norm after: 3.7393986650872058
Epoch 3315/10000, Prediction Accuracy = 63.27692307692309%, Loss = 0.00825503934174776
Epoch: 3315, Batch Gradient Norm: 3.6670890084065233
Epoch: 3315, Batch Gradient Norm after: 3.6670890084065233
Epoch 3316/10000, Prediction Accuracy = 63.53076923076923%, Loss = 0.00823338136363488
Epoch: 3316, Batch Gradient Norm: 3.712491891471782
Epoch: 3316, Batch Gradient Norm after: 3.712491891471782
Epoch 3317/10000, Prediction Accuracy = 63.434615384615384%, Loss = 0.008342299467095962
Epoch: 3317, Batch Gradient Norm: 3.786797865464779
Epoch: 3317, Batch Gradient Norm after: 3.786797865464779
Epoch 3318/10000, Prediction Accuracy = 62.95769230769231%, Loss = 0.008461997700998416
Epoch: 3318, Batch Gradient Norm: 4.016444852422298
Epoch: 3318, Batch Gradient Norm after: 4.016444852422298
Epoch 3319/10000, Prediction Accuracy = 63.29230769230769%, Loss = 0.008396574367697422
Epoch: 3319, Batch Gradient Norm: 3.955146713075873
Epoch: 3319, Batch Gradient Norm after: 3.955146713075873
Epoch 3320/10000, Prediction Accuracy = 63.29615384615384%, Loss = 0.00836677559149953
Epoch: 3320, Batch Gradient Norm: 3.9507378896680416
Epoch: 3320, Batch Gradient Norm after: 3.9507378896680416
Epoch 3321/10000, Prediction Accuracy = 62.55769230769231%, Loss = 0.008476786315441132
Epoch: 3321, Batch Gradient Norm: 3.584393816525396
Epoch: 3321, Batch Gradient Norm after: 3.584393816525396
Epoch 3322/10000, Prediction Accuracy = 63.26923076923076%, Loss = 0.00826276559382677
Epoch: 3322, Batch Gradient Norm: 3.7461509672469933
Epoch: 3322, Batch Gradient Norm after: 3.7461509672469933
Epoch 3323/10000, Prediction Accuracy = 63.29615384615386%, Loss = 0.008291111041146975
Epoch: 3323, Batch Gradient Norm: 3.860465368578788
Epoch: 3323, Batch Gradient Norm after: 3.860465368578788
Epoch 3324/10000, Prediction Accuracy = 63.580769230769235%, Loss = 0.008377398507526288
Epoch: 3324, Batch Gradient Norm: 3.8691208352602993
Epoch: 3324, Batch Gradient Norm after: 3.8691208352602993
Epoch 3325/10000, Prediction Accuracy = 63.02307692307693%, Loss = 0.008385624306706281
Epoch: 3325, Batch Gradient Norm: 3.6364806112903705
Epoch: 3325, Batch Gradient Norm after: 3.6364806112903705
Epoch 3326/10000, Prediction Accuracy = 63.73461538461539%, Loss = 0.008304684781111203
Epoch: 3326, Batch Gradient Norm: 3.7867422932445303
Epoch: 3326, Batch Gradient Norm after: 3.7867422932445303
Epoch 3327/10000, Prediction Accuracy = 63.43846153846154%, Loss = 0.008298813795241026
Epoch: 3327, Batch Gradient Norm: 3.869681432096536
Epoch: 3327, Batch Gradient Norm after: 3.869681432096536
Epoch 3328/10000, Prediction Accuracy = 63.21923076923076%, Loss = 0.00828021177305625
Epoch: 3328, Batch Gradient Norm: 3.5903465082493082
Epoch: 3328, Batch Gradient Norm after: 3.5903465082493082
Epoch 3329/10000, Prediction Accuracy = 63.59615384615385%, Loss = 0.00822599045932293
Epoch: 3329, Batch Gradient Norm: 3.5267085315386493
Epoch: 3329, Batch Gradient Norm after: 3.5267085315386493
Epoch 3330/10000, Prediction Accuracy = 63.59999999999999%, Loss = 0.00807712642619243
Epoch: 3330, Batch Gradient Norm: 3.4990864746543053
Epoch: 3330, Batch Gradient Norm after: 3.4990864746543053
Epoch 3331/10000, Prediction Accuracy = 63.93076923076924%, Loss = 0.008182309567928314
Epoch: 3331, Batch Gradient Norm: 3.863201611997796
Epoch: 3331, Batch Gradient Norm after: 3.863201611997796
Epoch 3332/10000, Prediction Accuracy = 63.42692307692308%, Loss = 0.00833241999722444
Epoch: 3332, Batch Gradient Norm: 3.977376977912017
Epoch: 3332, Batch Gradient Norm after: 3.977376977912017
Epoch 3333/10000, Prediction Accuracy = 62.55769230769233%, Loss = 0.008584327207734952
Epoch: 3333, Batch Gradient Norm: 3.8704793870931105
Epoch: 3333, Batch Gradient Norm after: 3.8704793870931105
Epoch 3334/10000, Prediction Accuracy = 63.19615384615384%, Loss = 0.008485847224409763
Epoch: 3334, Batch Gradient Norm: 3.6674538923417708
Epoch: 3334, Batch Gradient Norm after: 3.6674538923417708
Epoch 3335/10000, Prediction Accuracy = 63.199999999999996%, Loss = 0.008336700427417573
Epoch: 3335, Batch Gradient Norm: 4.006023735845116
Epoch: 3335, Batch Gradient Norm after: 4.006023735845116
Epoch 3336/10000, Prediction Accuracy = 62.94615384615384%, Loss = 0.008423748354499157
Epoch: 3336, Batch Gradient Norm: 4.276820102711099
Epoch: 3336, Batch Gradient Norm after: 4.276820102711099
Epoch 3337/10000, Prediction Accuracy = 62.68846153846153%, Loss = 0.008589443965600086
Epoch: 3337, Batch Gradient Norm: 4.411964231223208
Epoch: 3337, Batch Gradient Norm after: 4.411964231223208
Epoch 3338/10000, Prediction Accuracy = 62.61538461538461%, Loss = 0.00869366225714867
Epoch: 3338, Batch Gradient Norm: 3.7844022978033856
Epoch: 3338, Batch Gradient Norm after: 3.7844022978033856
Epoch 3339/10000, Prediction Accuracy = 62.87307692307692%, Loss = 0.008443515891065964
Epoch: 3339, Batch Gradient Norm: 3.435636177038716
Epoch: 3339, Batch Gradient Norm after: 3.435636177038716
Epoch 3340/10000, Prediction Accuracy = 63.161538461538456%, Loss = 0.008307153717256509
Epoch: 3340, Batch Gradient Norm: 3.897072744279867
Epoch: 3340, Batch Gradient Norm after: 3.897072744279867
Epoch 3341/10000, Prediction Accuracy = 62.98461538461539%, Loss = 0.00845504473321713
Epoch: 3341, Batch Gradient Norm: 3.483155279271519
Epoch: 3341, Batch Gradient Norm after: 3.483155279271519
Epoch 3342/10000, Prediction Accuracy = 64.0923076923077%, Loss = 0.008243919278566655
Epoch: 3342, Batch Gradient Norm: 3.943605383131927
Epoch: 3342, Batch Gradient Norm after: 3.943605383131927
Epoch 3343/10000, Prediction Accuracy = 63.17307692307692%, Loss = 0.008475286671175407
Epoch: 3343, Batch Gradient Norm: 3.6671842876265712
Epoch: 3343, Batch Gradient Norm after: 3.6671842876265712
Epoch 3344/10000, Prediction Accuracy = 62.95%, Loss = 0.00833266436193998
Epoch: 3344, Batch Gradient Norm: 3.606801043075578
Epoch: 3344, Batch Gradient Norm after: 3.606801043075578
Epoch 3345/10000, Prediction Accuracy = 63.46153846153845%, Loss = 0.008272922239624537
Epoch: 3345, Batch Gradient Norm: 3.6463308349083214
Epoch: 3345, Batch Gradient Norm after: 3.6463308349083214
Epoch 3346/10000, Prediction Accuracy = 63.207692307692305%, Loss = 0.008236839113613734
Epoch: 3346, Batch Gradient Norm: 3.6898499706168697
Epoch: 3346, Batch Gradient Norm after: 3.6898499706168697
Epoch 3347/10000, Prediction Accuracy = 63.79615384615386%, Loss = 0.008189765270799398
Epoch: 3347, Batch Gradient Norm: 3.4049711113865824
Epoch: 3347, Batch Gradient Norm after: 3.4049711113865824
Epoch 3348/10000, Prediction Accuracy = 63.93076923076923%, Loss = 0.008064934267447544
Epoch: 3348, Batch Gradient Norm: 3.3469439723366685
Epoch: 3348, Batch Gradient Norm after: 3.3469439723366685
Epoch 3349/10000, Prediction Accuracy = 63.64999999999999%, Loss = 0.008056926935051497
Epoch: 3349, Batch Gradient Norm: 3.5608803837677163
Epoch: 3349, Batch Gradient Norm after: 3.5608803837677163
Epoch 3350/10000, Prediction Accuracy = 63.6076923076923%, Loss = 0.008193937237732686
Epoch: 3350, Batch Gradient Norm: 4.446272574278535
Epoch: 3350, Batch Gradient Norm after: 4.446272574278535
Epoch 3351/10000, Prediction Accuracy = 62.69230769230769%, Loss = 0.00865413542263783
Epoch: 3351, Batch Gradient Norm: 4.518665937023797
Epoch: 3351, Batch Gradient Norm after: 4.518665937023797
Epoch 3352/10000, Prediction Accuracy = 62.23846153846154%, Loss = 0.008752732322766231
Epoch: 3352, Batch Gradient Norm: 3.95332406278254
Epoch: 3352, Batch Gradient Norm after: 3.95332406278254
Epoch 3353/10000, Prediction Accuracy = 63.09230769230768%, Loss = 0.008412175381985994
Epoch: 3353, Batch Gradient Norm: 3.9092453280918704
Epoch: 3353, Batch Gradient Norm after: 3.9092453280918704
Epoch 3354/10000, Prediction Accuracy = 63.192307692307686%, Loss = 0.008487472095741676
Epoch: 3354, Batch Gradient Norm: 3.797947840842102
Epoch: 3354, Batch Gradient Norm after: 3.797947840842102
Epoch 3355/10000, Prediction Accuracy = 63.03076923076924%, Loss = 0.008489328651474072
Epoch: 3355, Batch Gradient Norm: 3.772554628772644
Epoch: 3355, Batch Gradient Norm after: 3.772554628772644
Epoch 3356/10000, Prediction Accuracy = 63.25384615384616%, Loss = 0.008405158224587258
Epoch: 3356, Batch Gradient Norm: 4.144822721686841
Epoch: 3356, Batch Gradient Norm after: 4.144822721686841
Epoch 3357/10000, Prediction Accuracy = 62.52692307692307%, Loss = 0.008635709205499062
Epoch: 3357, Batch Gradient Norm: 4.5708255086245595
Epoch: 3357, Batch Gradient Norm after: 4.5708255086245595
Epoch 3358/10000, Prediction Accuracy = 62.307692307692314%, Loss = 0.008881973245969186
Epoch: 3358, Batch Gradient Norm: 3.6447937606551704
Epoch: 3358, Batch Gradient Norm after: 3.6447937606551704
Epoch 3359/10000, Prediction Accuracy = 63.307692307692314%, Loss = 0.008448115406701198
Epoch: 3359, Batch Gradient Norm: 3.9472219759319707
Epoch: 3359, Batch Gradient Norm after: 3.9472219759319707
Epoch 3360/10000, Prediction Accuracy = 62.68076923076923%, Loss = 0.00854687879864986
Epoch: 3360, Batch Gradient Norm: 3.600033284639671
Epoch: 3360, Batch Gradient Norm after: 3.600033284639671
Epoch 3361/10000, Prediction Accuracy = 63.47692307692307%, Loss = 0.008290248242421793
Epoch: 3361, Batch Gradient Norm: 4.014667572396246
Epoch: 3361, Batch Gradient Norm after: 4.014667572396246
Epoch 3362/10000, Prediction Accuracy = 63.57692307692309%, Loss = 0.008442932095092077
Epoch: 3362, Batch Gradient Norm: 4.151885903851005
Epoch: 3362, Batch Gradient Norm after: 4.151885903851005
Epoch 3363/10000, Prediction Accuracy = 62.68846153846154%, Loss = 0.00854893594693679
Epoch: 3363, Batch Gradient Norm: 3.776603582558864
Epoch: 3363, Batch Gradient Norm after: 3.776603582558864
Epoch 3364/10000, Prediction Accuracy = 63.11923076923077%, Loss = 0.008360089662556466
Epoch: 3364, Batch Gradient Norm: 3.877531226436568
Epoch: 3364, Batch Gradient Norm after: 3.877531226436568
Epoch 3365/10000, Prediction Accuracy = 62.71923076923077%, Loss = 0.0084596428876886
Epoch: 3365, Batch Gradient Norm: 3.5760040564380575
Epoch: 3365, Batch Gradient Norm after: 3.5760040564380575
Epoch 3366/10000, Prediction Accuracy = 63.57692307692308%, Loss = 0.00823419440824252
Epoch: 3366, Batch Gradient Norm: 3.720294147969348
Epoch: 3366, Batch Gradient Norm after: 3.720294147969348
Epoch 3367/10000, Prediction Accuracy = 63.02307692307692%, Loss = 0.008327158096318062
Epoch: 3367, Batch Gradient Norm: 4.103523876560741
Epoch: 3367, Batch Gradient Norm after: 4.103523876560741
Epoch 3368/10000, Prediction Accuracy = 62.66538461538461%, Loss = 0.008628730089045487
Epoch: 3368, Batch Gradient Norm: 3.9541077871963672
Epoch: 3368, Batch Gradient Norm after: 3.9541077871963672
Epoch 3369/10000, Prediction Accuracy = 62.48846153846155%, Loss = 0.00853301097567265
Epoch: 3369, Batch Gradient Norm: 3.6486716642592203
Epoch: 3369, Batch Gradient Norm after: 3.6486716642592203
Epoch 3370/10000, Prediction Accuracy = 63.192307692307686%, Loss = 0.00835825947041695
Epoch: 3370, Batch Gradient Norm: 3.7711327410473325
Epoch: 3370, Batch Gradient Norm after: 3.7711327410473325
Epoch 3371/10000, Prediction Accuracy = 63.3%, Loss = 0.008328611532656046
Epoch: 3371, Batch Gradient Norm: 3.5946197434644733
Epoch: 3371, Batch Gradient Norm after: 3.5946197434644733
Epoch 3372/10000, Prediction Accuracy = 63.276923076923076%, Loss = 0.008217526671405021
Epoch: 3372, Batch Gradient Norm: 3.8877506705282303
Epoch: 3372, Batch Gradient Norm after: 3.8877506705282303
Epoch 3373/10000, Prediction Accuracy = 63.42307692307691%, Loss = 0.008332401585693542
Epoch: 3373, Batch Gradient Norm: 3.7890669797596104
Epoch: 3373, Batch Gradient Norm after: 3.7890669797596104
Epoch 3374/10000, Prediction Accuracy = 63.79615384615386%, Loss = 0.008279906012690984
Epoch: 3374, Batch Gradient Norm: 3.9149693119346765
Epoch: 3374, Batch Gradient Norm after: 3.9149693119346765
Epoch 3375/10000, Prediction Accuracy = 62.965384615384615%, Loss = 0.008424887935129495
Epoch: 3375, Batch Gradient Norm: 4.045378758124371
Epoch: 3375, Batch Gradient Norm after: 4.045378758124371
Epoch 3376/10000, Prediction Accuracy = 62.54230769230769%, Loss = 0.008555591751176577
Epoch: 3376, Batch Gradient Norm: 3.7213717743922445
Epoch: 3376, Batch Gradient Norm after: 3.7213717743922445
Epoch 3377/10000, Prediction Accuracy = 62.973076923076924%, Loss = 0.00841347729930511
Epoch: 3377, Batch Gradient Norm: 3.9376480893015677
Epoch: 3377, Batch Gradient Norm after: 3.9376480893015677
Epoch 3378/10000, Prediction Accuracy = 62.82692307692308%, Loss = 0.008436665941889469
Epoch: 3378, Batch Gradient Norm: 3.8477435765937527
Epoch: 3378, Batch Gradient Norm after: 3.8477435765937527
Epoch 3379/10000, Prediction Accuracy = 63.01153846153847%, Loss = 0.008376104255708365
Epoch: 3379, Batch Gradient Norm: 3.7118689962751454
Epoch: 3379, Batch Gradient Norm after: 3.7118689962751454
Epoch 3380/10000, Prediction Accuracy = 63.646153846153844%, Loss = 0.008285473244121442
Epoch: 3380, Batch Gradient Norm: 3.730719630577327
Epoch: 3380, Batch Gradient Norm after: 3.730719630577327
Epoch 3381/10000, Prediction Accuracy = 63.61538461538461%, Loss = 0.008192876067299109
Epoch: 3381, Batch Gradient Norm: 3.800376456590227
Epoch: 3381, Batch Gradient Norm after: 3.800376456590227
Epoch 3382/10000, Prediction Accuracy = 63.6076923076923%, Loss = 0.008245339402212547
Epoch: 3382, Batch Gradient Norm: 3.960585087651702
Epoch: 3382, Batch Gradient Norm after: 3.960585087651702
Epoch 3383/10000, Prediction Accuracy = 63.1923076923077%, Loss = 0.008387992194352241
Epoch: 3383, Batch Gradient Norm: 4.067664100243814
Epoch: 3383, Batch Gradient Norm after: 4.067664100243814
Epoch 3384/10000, Prediction Accuracy = 62.76153846153847%, Loss = 0.008472531317518307
Epoch: 3384, Batch Gradient Norm: 3.7497110315254942
Epoch: 3384, Batch Gradient Norm after: 3.7497110315254942
Epoch 3385/10000, Prediction Accuracy = 63.61153846153846%, Loss = 0.008343729405448986
Epoch: 3385, Batch Gradient Norm: 4.206511901368765
Epoch: 3385, Batch Gradient Norm after: 4.206511901368765
Epoch 3386/10000, Prediction Accuracy = 62.95769230769232%, Loss = 0.00853683534436501
Epoch: 3386, Batch Gradient Norm: 4.076966031239873
Epoch: 3386, Batch Gradient Norm after: 4.076966031239873
Epoch 3387/10000, Prediction Accuracy = 62.45769230769231%, Loss = 0.008572959197828403
Epoch: 3387, Batch Gradient Norm: 4.123400833552367
Epoch: 3387, Batch Gradient Norm after: 4.123400833552367
Epoch 3388/10000, Prediction Accuracy = 62.56153846153847%, Loss = 0.008578438311815262
Epoch: 3388, Batch Gradient Norm: 3.5312454672944393
Epoch: 3388, Batch Gradient Norm after: 3.5312454672944393
Epoch 3389/10000, Prediction Accuracy = 63.60384615384615%, Loss = 0.0082076105217521
Epoch: 3389, Batch Gradient Norm: 3.5806533525152835
Epoch: 3389, Batch Gradient Norm after: 3.5806533525152835
Epoch 3390/10000, Prediction Accuracy = 63.54615384615385%, Loss = 0.008294007167793237
Epoch: 3390, Batch Gradient Norm: 3.6039004202256892
Epoch: 3390, Batch Gradient Norm after: 3.6039004202256892
Epoch 3391/10000, Prediction Accuracy = 63.04615384615385%, Loss = 0.008340068268947877
Epoch: 3391, Batch Gradient Norm: 4.095998956539216
Epoch: 3391, Batch Gradient Norm after: 4.095998956539216
Epoch 3392/10000, Prediction Accuracy = 62.68461538461539%, Loss = 0.008493913480868706
Epoch: 3392, Batch Gradient Norm: 4.392161135293997
Epoch: 3392, Batch Gradient Norm after: 4.392161135293997
Epoch 3393/10000, Prediction Accuracy = 61.8576923076923%, Loss = 0.008721927610727457
Epoch: 3393, Batch Gradient Norm: 3.5579670461448902
Epoch: 3393, Batch Gradient Norm after: 3.5579670461448902
Epoch 3394/10000, Prediction Accuracy = 63.965384615384615%, Loss = 0.008233019544814642
Epoch: 3394, Batch Gradient Norm: 3.6304377505558167
Epoch: 3394, Batch Gradient Norm after: 3.6304377505558167
Epoch 3395/10000, Prediction Accuracy = 63.919230769230765%, Loss = 0.008217436619676076
Epoch: 3395, Batch Gradient Norm: 3.488294661215759
Epoch: 3395, Batch Gradient Norm after: 3.488294661215759
Epoch 3396/10000, Prediction Accuracy = 63.676923076923075%, Loss = 0.008167771013596883
Epoch: 3396, Batch Gradient Norm: 3.864413043867221
Epoch: 3396, Batch Gradient Norm after: 3.864413043867221
Epoch 3397/10000, Prediction Accuracy = 63.965384615384615%, Loss = 0.008307852782309055
Epoch: 3397, Batch Gradient Norm: 4.11418142809519
Epoch: 3397, Batch Gradient Norm after: 4.11418142809519
Epoch 3398/10000, Prediction Accuracy = 62.91153846153847%, Loss = 0.008458936085494665
Epoch: 3398, Batch Gradient Norm: 3.891673748092096
Epoch: 3398, Batch Gradient Norm after: 3.891673748092096
Epoch 3399/10000, Prediction Accuracy = 63.01923076923078%, Loss = 0.008505663333030848
Epoch: 3399, Batch Gradient Norm: 3.980779728360554
Epoch: 3399, Batch Gradient Norm after: 3.980779728360554
Epoch 3400/10000, Prediction Accuracy = 63.176923076923075%, Loss = 0.008418582738018952
Epoch: 3400, Batch Gradient Norm: 4.327247589603647
Epoch: 3400, Batch Gradient Norm after: 4.327247589603647
Epoch 3401/10000, Prediction Accuracy = 62.669230769230765%, Loss = 0.008610973636118265
Epoch: 3401, Batch Gradient Norm: 4.110262856787478
Epoch: 3401, Batch Gradient Norm after: 4.110262856787478
Epoch 3402/10000, Prediction Accuracy = 62.96153846153846%, Loss = 0.008494648652581068
Epoch: 3402, Batch Gradient Norm: 4.318838804888538
Epoch: 3402, Batch Gradient Norm after: 4.318838804888538
Epoch 3403/10000, Prediction Accuracy = 62.31153846153845%, Loss = 0.008705321556100478
Epoch: 3403, Batch Gradient Norm: 3.706738033764719
Epoch: 3403, Batch Gradient Norm after: 3.706738033764719
Epoch 3404/10000, Prediction Accuracy = 62.557692307692314%, Loss = 0.008459189978356544
Epoch: 3404, Batch Gradient Norm: 3.2433265958980226
Epoch: 3404, Batch Gradient Norm after: 3.2433265958980226
Epoch 3405/10000, Prediction Accuracy = 64.0153846153846%, Loss = 0.008118372947837297
Epoch: 3405, Batch Gradient Norm: 3.899145395486769
Epoch: 3405, Batch Gradient Norm after: 3.899145395486769
Epoch 3406/10000, Prediction Accuracy = 63.32692307692308%, Loss = 0.008361638774378942
Epoch: 3406, Batch Gradient Norm: 3.723484389121274
Epoch: 3406, Batch Gradient Norm after: 3.723484389121274
Epoch 3407/10000, Prediction Accuracy = 63.19615384615385%, Loss = 0.00833729414555889
Epoch: 3407, Batch Gradient Norm: 3.6224589634289788
Epoch: 3407, Batch Gradient Norm after: 3.6224589634289788
Epoch 3408/10000, Prediction Accuracy = 63.442307692307686%, Loss = 0.008194910004161872
Epoch: 3408, Batch Gradient Norm: 3.765981581966231
Epoch: 3408, Batch Gradient Norm after: 3.765981581966231
Epoch 3409/10000, Prediction Accuracy = 63.45384615384615%, Loss = 0.008248376158567576
Epoch: 3409, Batch Gradient Norm: 3.7400267220339334
Epoch: 3409, Batch Gradient Norm after: 3.7400267220339334
Epoch 3410/10000, Prediction Accuracy = 63.19230769230769%, Loss = 0.008292767577446424
Epoch: 3410, Batch Gradient Norm: 3.9128158846537273
Epoch: 3410, Batch Gradient Norm after: 3.9128158846537273
Epoch 3411/10000, Prediction Accuracy = 63.19230769230769%, Loss = 0.00838909663546544
Epoch: 3411, Batch Gradient Norm: 3.8711425610357506
Epoch: 3411, Batch Gradient Norm after: 3.8711425610357506
Epoch 3412/10000, Prediction Accuracy = 62.823076923076925%, Loss = 0.008408050052821636
Epoch: 3412, Batch Gradient Norm: 3.9380590917564717
Epoch: 3412, Batch Gradient Norm after: 3.9380590917564717
Epoch 3413/10000, Prediction Accuracy = 63.63461538461539%, Loss = 0.008272334145238766
Epoch: 3413, Batch Gradient Norm: 3.804427025638315
Epoch: 3413, Batch Gradient Norm after: 3.804427025638315
Epoch 3414/10000, Prediction Accuracy = 63.14230769230768%, Loss = 0.008358161717366714
Epoch: 3414, Batch Gradient Norm: 3.879773994827004
Epoch: 3414, Batch Gradient Norm after: 3.879773994827004
Epoch 3415/10000, Prediction Accuracy = 63.52307692307692%, Loss = 0.008329039439558983
Epoch: 3415, Batch Gradient Norm: 3.660799365657609
Epoch: 3415, Batch Gradient Norm after: 3.660799365657609
Epoch 3416/10000, Prediction Accuracy = 63.54615384615384%, Loss = 0.008247000881685661
Epoch: 3416, Batch Gradient Norm: 3.578125235356644
Epoch: 3416, Batch Gradient Norm after: 3.578125235356644
Epoch 3417/10000, Prediction Accuracy = 63.365384615384606%, Loss = 0.008204371811678777
Epoch: 3417, Batch Gradient Norm: 3.7124988927439713
Epoch: 3417, Batch Gradient Norm after: 3.7124988927439713
Epoch 3418/10000, Prediction Accuracy = 63.834615384615375%, Loss = 0.008090937044471502
Epoch: 3418, Batch Gradient Norm: 4.0807881865380375
Epoch: 3418, Batch Gradient Norm after: 4.0807881865380375
Epoch 3419/10000, Prediction Accuracy = 63.29615384615385%, Loss = 0.008346140957795657
Epoch: 3419, Batch Gradient Norm: 3.8232634031746513
Epoch: 3419, Batch Gradient Norm after: 3.8232634031746513
Epoch 3420/10000, Prediction Accuracy = 63.376923076923084%, Loss = 0.008347711454217251
Epoch: 3420, Batch Gradient Norm: 3.6602698414280375
Epoch: 3420, Batch Gradient Norm after: 3.6602698414280375
Epoch 3421/10000, Prediction Accuracy = 63.346153846153854%, Loss = 0.008298361208289862
Epoch: 3421, Batch Gradient Norm: 3.4717309495675694
Epoch: 3421, Batch Gradient Norm after: 3.4717309495675694
Epoch 3422/10000, Prediction Accuracy = 64.30769230769229%, Loss = 0.008083488505620223
Epoch: 3422, Batch Gradient Norm: 3.914517479966816
Epoch: 3422, Batch Gradient Norm after: 3.914517479966816
Epoch 3423/10000, Prediction Accuracy = 63.43461538461539%, Loss = 0.008220448731802978
Epoch: 3423, Batch Gradient Norm: 3.9702462057141443
Epoch: 3423, Batch Gradient Norm after: 3.9702462057141443
Epoch 3424/10000, Prediction Accuracy = 63.11538461538461%, Loss = 0.008363675612669725
Epoch: 3424, Batch Gradient Norm: 4.219798394733823
Epoch: 3424, Batch Gradient Norm after: 4.219798394733823
Epoch 3425/10000, Prediction Accuracy = 63.14615384615384%, Loss = 0.008402831207674284
Epoch: 3425, Batch Gradient Norm: 4.1983706481570415
Epoch: 3425, Batch Gradient Norm after: 4.1983706481570415
Epoch 3426/10000, Prediction Accuracy = 63.02692307692307%, Loss = 0.008496207758211173
Epoch: 3426, Batch Gradient Norm: 3.8364628646118217
Epoch: 3426, Batch Gradient Norm after: 3.8364628646118217
Epoch 3427/10000, Prediction Accuracy = 63.349999999999994%, Loss = 0.008345296391500877
Epoch: 3427, Batch Gradient Norm: 3.6510623974460374
Epoch: 3427, Batch Gradient Norm after: 3.6510623974460374
Epoch 3428/10000, Prediction Accuracy = 63.11923076923077%, Loss = 0.008242062794474455
Epoch: 3428, Batch Gradient Norm: 4.008030254468268
Epoch: 3428, Batch Gradient Norm after: 4.008030254468268
Epoch 3429/10000, Prediction Accuracy = 63.02692307692307%, Loss = 0.008433878206862854
Epoch: 3429, Batch Gradient Norm: 3.9666762878669224
Epoch: 3429, Batch Gradient Norm after: 3.9666762878669224
Epoch 3430/10000, Prediction Accuracy = 62.942307692307686%, Loss = 0.00843572630905188
Epoch: 3430, Batch Gradient Norm: 3.9865352628797326
Epoch: 3430, Batch Gradient Norm after: 3.9865352628797326
Epoch 3431/10000, Prediction Accuracy = 63.54615384615384%, Loss = 0.008303192659066273
Epoch: 3431, Batch Gradient Norm: 3.811687435915578
Epoch: 3431, Batch Gradient Norm after: 3.811687435915578
Epoch 3432/10000, Prediction Accuracy = 63.411538461538456%, Loss = 0.008291127160191536
Epoch: 3432, Batch Gradient Norm: 3.5728252099938027
Epoch: 3432, Batch Gradient Norm after: 3.5728252099938027
Epoch 3433/10000, Prediction Accuracy = 64.08846153846154%, Loss = 0.008118610900755111
Epoch: 3433, Batch Gradient Norm: 4.0005025597655175
Epoch: 3433, Batch Gradient Norm after: 4.0005025597655175
Epoch 3434/10000, Prediction Accuracy = 63.11538461538461%, Loss = 0.008451945148408413
Epoch: 3434, Batch Gradient Norm: 3.799949052869393
Epoch: 3434, Batch Gradient Norm after: 3.799949052869393
Epoch 3435/10000, Prediction Accuracy = 63.3346153846154%, Loss = 0.008456722546655398
Epoch: 3435, Batch Gradient Norm: 4.090447690744913
Epoch: 3435, Batch Gradient Norm after: 4.090447690744913
Epoch 3436/10000, Prediction Accuracy = 62.97307692307693%, Loss = 0.008520343985695105
Epoch: 3436, Batch Gradient Norm: 3.9259313868634074
Epoch: 3436, Batch Gradient Norm after: 3.9259313868634074
Epoch 3437/10000, Prediction Accuracy = 63.28846153846154%, Loss = 0.008407439105212688
Epoch: 3437, Batch Gradient Norm: 3.6928002200599526
Epoch: 3437, Batch Gradient Norm after: 3.6928002200599526
Epoch 3438/10000, Prediction Accuracy = 63.80384615384616%, Loss = 0.008231994624321278
Epoch: 3438, Batch Gradient Norm: 3.702903803088333
Epoch: 3438, Batch Gradient Norm after: 3.702903803088333
Epoch 3439/10000, Prediction Accuracy = 63.599999999999994%, Loss = 0.008230872523899261
Epoch: 3439, Batch Gradient Norm: 3.8980136642366046
Epoch: 3439, Batch Gradient Norm after: 3.8980136642366046
Epoch 3440/10000, Prediction Accuracy = 63.426923076923075%, Loss = 0.008313380110149201
Epoch: 3440, Batch Gradient Norm: 3.879557101088754
Epoch: 3440, Batch Gradient Norm after: 3.879557101088754
Epoch 3441/10000, Prediction Accuracy = 63.53846153846154%, Loss = 0.008351965735738095
Epoch: 3441, Batch Gradient Norm: 3.657184480757943
Epoch: 3441, Batch Gradient Norm after: 3.657184480757943
Epoch 3442/10000, Prediction Accuracy = 63.884615384615394%, Loss = 0.008163211365731863
Epoch: 3442, Batch Gradient Norm: 3.523256275655613
Epoch: 3442, Batch Gradient Norm after: 3.523256275655613
Epoch 3443/10000, Prediction Accuracy = 64.08076923076923%, Loss = 0.008099196657824975
Epoch: 3443, Batch Gradient Norm: 3.8030326361839375
Epoch: 3443, Batch Gradient Norm after: 3.8030326361839375
Epoch 3444/10000, Prediction Accuracy = 63.87692307692308%, Loss = 0.008197673918822637
Epoch: 3444, Batch Gradient Norm: 3.218243739821312
Epoch: 3444, Batch Gradient Norm after: 3.218243739821312
Epoch 3445/10000, Prediction Accuracy = 64.46923076923076%, Loss = 0.007946188203417338
Epoch: 3446, Batch Gradient Norm: 3.9501387977686275
Epoch: 3446, Batch Gradient Norm after: 3.9501387977686275
Epoch 3447/10000, Prediction Accuracy = 63.71923076923076%, Loss = 0.008218683015841704
Epoch: 3447, Batch Gradient Norm: 4.378261816746111
Epoch: 3447, Batch Gradient Norm after: 4.378261816746111
Epoch 3448/10000, Prediction Accuracy = 62.94230769230769%, Loss = 0.008469562476071028
Epoch: 3448, Batch Gradient Norm: 4.2338954879909725
Epoch: 3448, Batch Gradient Norm after: 4.2338954879909725
Epoch 3449/10000, Prediction Accuracy = 62.830769230769235%, Loss = 0.008536323403509764
Epoch: 3449, Batch Gradient Norm: 3.803315610414864
Epoch: 3449, Batch Gradient Norm after: 3.803315610414864
Epoch 3450/10000, Prediction Accuracy = 63.130769230769225%, Loss = 0.008349237605356254
Epoch: 3450, Batch Gradient Norm: 3.5846247085775884
Epoch: 3450, Batch Gradient Norm after: 3.5846247085775884
Epoch 3451/10000, Prediction Accuracy = 63.69615384615384%, Loss = 0.008221560945877662
Epoch: 3451, Batch Gradient Norm: 3.4489785649415974
Epoch: 3451, Batch Gradient Norm after: 3.4489785649415974
Epoch 3452/10000, Prediction Accuracy = 63.65384615384615%, Loss = 0.008062196608919363
Epoch: 3452, Batch Gradient Norm: 4.2371807261309336
Epoch: 3452, Batch Gradient Norm after: 4.2371807261309336
Epoch 3453/10000, Prediction Accuracy = 63.3346153846154%, Loss = 0.008452409591812354
Epoch: 3453, Batch Gradient Norm: 3.853194770598549
Epoch: 3453, Batch Gradient Norm after: 3.853194770598549
Epoch 3454/10000, Prediction Accuracy = 63.51538461538462%, Loss = 0.00828782906039403
Epoch: 3454, Batch Gradient Norm: 3.9183482609113907
Epoch: 3454, Batch Gradient Norm after: 3.9183482609113907
Epoch 3455/10000, Prediction Accuracy = 63.30384615384616%, Loss = 0.008381414155547436
Epoch: 3455, Batch Gradient Norm: 3.906721260493434
Epoch: 3455, Batch Gradient Norm after: 3.906721260493434
Epoch 3456/10000, Prediction Accuracy = 63.05769230769231%, Loss = 0.008388244726050358
Epoch: 3456, Batch Gradient Norm: 3.958671265221956
Epoch: 3456, Batch Gradient Norm after: 3.958671265221956
Epoch 3457/10000, Prediction Accuracy = 63.25384615384616%, Loss = 0.008344626842209926
Epoch: 3457, Batch Gradient Norm: 3.802657572388338
Epoch: 3457, Batch Gradient Norm after: 3.802657572388338
Epoch 3458/10000, Prediction Accuracy = 63.565384615384616%, Loss = 0.00827861505632217
Epoch: 3458, Batch Gradient Norm: 3.887005535216923
Epoch: 3458, Batch Gradient Norm after: 3.887005535216923
Epoch 3459/10000, Prediction Accuracy = 63.62307692307694%, Loss = 0.008326130560957469
Epoch: 3459, Batch Gradient Norm: 3.702035748168271
Epoch: 3459, Batch Gradient Norm after: 3.702035748168271
Epoch 3460/10000, Prediction Accuracy = 63.861538461538466%, Loss = 0.008182232017413927
Epoch: 3460, Batch Gradient Norm: 3.6965708433872657
Epoch: 3460, Batch Gradient Norm after: 3.6965708433872657
Epoch 3461/10000, Prediction Accuracy = 63.93461538461538%, Loss = 0.008119089815479059
Epoch: 3461, Batch Gradient Norm: 3.8489841581972026
Epoch: 3461, Batch Gradient Norm after: 3.8489841581972026
Epoch 3462/10000, Prediction Accuracy = 63.853846153846156%, Loss = 0.008201544853643728
Epoch: 3462, Batch Gradient Norm: 4.096614503287881
Epoch: 3462, Batch Gradient Norm after: 4.096614503287881
Epoch 3463/10000, Prediction Accuracy = 63.361538461538444%, Loss = 0.008440458000852512
Epoch: 3463, Batch Gradient Norm: 3.8352823674769043
Epoch: 3463, Batch Gradient Norm after: 3.8352823674769043
Epoch 3464/10000, Prediction Accuracy = 63.37692307692306%, Loss = 0.008238584806139652
Epoch: 3464, Batch Gradient Norm: 3.8120599879159096
Epoch: 3464, Batch Gradient Norm after: 3.8120599879159096
Epoch 3465/10000, Prediction Accuracy = 63.384615384615394%, Loss = 0.00831154354203206
Epoch: 3465, Batch Gradient Norm: 4.048878131707603
Epoch: 3465, Batch Gradient Norm after: 4.048878131707603
Epoch 3466/10000, Prediction Accuracy = 62.64999999999999%, Loss = 0.008416958798009615
Epoch: 3466, Batch Gradient Norm: 3.703538681739014
Epoch: 3466, Batch Gradient Norm after: 3.703538681739014
Epoch 3467/10000, Prediction Accuracy = 63.48076923076924%, Loss = 0.008197297557042195
Epoch: 3467, Batch Gradient Norm: 3.865611576632792
Epoch: 3467, Batch Gradient Norm after: 3.865611576632792
Epoch 3468/10000, Prediction Accuracy = 63.29230769230769%, Loss = 0.008356173809331197
Epoch: 3468, Batch Gradient Norm: 3.5671874797729193
Epoch: 3468, Batch Gradient Norm after: 3.5671874797729193
Epoch 3469/10000, Prediction Accuracy = 63.68076923076923%, Loss = 0.008186479887137046
Epoch: 3469, Batch Gradient Norm: 3.925721957261592
Epoch: 3469, Batch Gradient Norm after: 3.925721957261592
Epoch 3470/10000, Prediction Accuracy = 63.71153846153847%, Loss = 0.00826530889249765
Epoch: 3470, Batch Gradient Norm: 3.879549948858003
Epoch: 3470, Batch Gradient Norm after: 3.879549948858003
Epoch 3471/10000, Prediction Accuracy = 63.457692307692305%, Loss = 0.008298471928215943
Epoch: 3471, Batch Gradient Norm: 3.86527380269015
Epoch: 3471, Batch Gradient Norm after: 3.86527380269015
Epoch 3472/10000, Prediction Accuracy = 63.900000000000006%, Loss = 0.00819396535651042
Epoch: 3472, Batch Gradient Norm: 3.9707006388203996
Epoch: 3472, Batch Gradient Norm after: 3.9707006388203996
Epoch 3473/10000, Prediction Accuracy = 63.49230769230768%, Loss = 0.008310726987054715
Epoch: 3473, Batch Gradient Norm: 3.8751323559051487
Epoch: 3473, Batch Gradient Norm after: 3.8751323559051487
Epoch 3474/10000, Prediction Accuracy = 63.74230769230769%, Loss = 0.008149034558580471
Epoch: 3474, Batch Gradient Norm: 3.8388165720055416
Epoch: 3474, Batch Gradient Norm after: 3.8388165720055416
Epoch 3475/10000, Prediction Accuracy = 63.53076923076924%, Loss = 0.008264789859262796
Epoch: 3475, Batch Gradient Norm: 3.8869479915969793
Epoch: 3475, Batch Gradient Norm after: 3.8869479915969793
Epoch 3476/10000, Prediction Accuracy = 63.43076923076922%, Loss = 0.008298461146366138
Epoch: 3476, Batch Gradient Norm: 4.076632685827724
Epoch: 3476, Batch Gradient Norm after: 4.076632685827724
Epoch 3477/10000, Prediction Accuracy = 63.08846153846154%, Loss = 0.008427717651312169
Epoch: 3477, Batch Gradient Norm: 3.99111501582221
Epoch: 3477, Batch Gradient Norm after: 3.99111501582221
Epoch 3478/10000, Prediction Accuracy = 63.27692307692306%, Loss = 0.008358946858117213
Epoch: 3478, Batch Gradient Norm: 4.276307375726699
Epoch: 3478, Batch Gradient Norm after: 4.276307375726699
Epoch 3479/10000, Prediction Accuracy = 62.80769230769231%, Loss = 0.008507426613225387
Epoch: 3479, Batch Gradient Norm: 3.911633100861578
Epoch: 3479, Batch Gradient Norm after: 3.911633100861578
Epoch 3480/10000, Prediction Accuracy = 62.800000000000004%, Loss = 0.00835509394080593
Epoch: 3480, Batch Gradient Norm: 3.9996733706043126
Epoch: 3480, Batch Gradient Norm after: 3.9996733706043126
Epoch 3481/10000, Prediction Accuracy = 63.407692307692315%, Loss = 0.008386161249990646
Epoch: 3481, Batch Gradient Norm: 3.821322867102052
Epoch: 3481, Batch Gradient Norm after: 3.821322867102052
Epoch 3482/10000, Prediction Accuracy = 63.06153846153847%, Loss = 0.008362437526767071
Epoch: 3482, Batch Gradient Norm: 3.969997437966731
Epoch: 3482, Batch Gradient Norm after: 3.969997437966731
Epoch 3483/10000, Prediction Accuracy = 63.26923076923078%, Loss = 0.008351906560934506
Epoch: 3483, Batch Gradient Norm: 4.12092574134283
Epoch: 3483, Batch Gradient Norm after: 4.12092574134283
Epoch 3484/10000, Prediction Accuracy = 63.05384615384615%, Loss = 0.00845240092334839
Epoch: 3484, Batch Gradient Norm: 3.9005916345031846
Epoch: 3484, Batch Gradient Norm after: 3.9005916345031846
Epoch 3485/10000, Prediction Accuracy = 62.76538461538461%, Loss = 0.008425793395592617
Epoch: 3485, Batch Gradient Norm: 3.850902320247545
Epoch: 3485, Batch Gradient Norm after: 3.850902320247545
Epoch 3486/10000, Prediction Accuracy = 63.5%, Loss = 0.008213211710636433
Epoch: 3486, Batch Gradient Norm: 3.927460563772105
Epoch: 3486, Batch Gradient Norm after: 3.927460563772105
Epoch 3487/10000, Prediction Accuracy = 63.650000000000006%, Loss = 0.008287685994918529
Epoch: 3487, Batch Gradient Norm: 3.6054308604426746
Epoch: 3487, Batch Gradient Norm after: 3.6054308604426746
Epoch 3488/10000, Prediction Accuracy = 63.865384615384606%, Loss = 0.008106565461135827
Epoch: 3488, Batch Gradient Norm: 3.5217650930061395
Epoch: 3488, Batch Gradient Norm after: 3.5217650930061395
Epoch 3489/10000, Prediction Accuracy = 63.903846153846146%, Loss = 0.00813413174966207
Epoch: 3489, Batch Gradient Norm: 3.5382807237680742
Epoch: 3489, Batch Gradient Norm after: 3.5382807237680742
Epoch 3490/10000, Prediction Accuracy = 63.56153846153847%, Loss = 0.008132580058792463
Epoch: 3490, Batch Gradient Norm: 3.899958441609499
Epoch: 3490, Batch Gradient Norm after: 3.899958441609499
Epoch 3491/10000, Prediction Accuracy = 63.41923076923077%, Loss = 0.008272037769739445
Epoch: 3491, Batch Gradient Norm: 4.251297409653397
Epoch: 3491, Batch Gradient Norm after: 4.251297409653397
Epoch 3492/10000, Prediction Accuracy = 63.042307692307695%, Loss = 0.008398876382181278
Epoch: 3492, Batch Gradient Norm: 4.044366316011144
Epoch: 3492, Batch Gradient Norm after: 4.044366316011144
Epoch 3493/10000, Prediction Accuracy = 63.20384615384616%, Loss = 0.008398534873357186
Epoch: 3493, Batch Gradient Norm: 3.6833597766303736
Epoch: 3493, Batch Gradient Norm after: 3.6833597766303736
Epoch 3494/10000, Prediction Accuracy = 63.43846153846153%, Loss = 0.008162521578084964
Epoch: 3494, Batch Gradient Norm: 3.82682105173819
Epoch: 3494, Batch Gradient Norm after: 3.82682105173819
Epoch 3495/10000, Prediction Accuracy = 63.80384615384616%, Loss = 0.008138019018448316
Epoch: 3495, Batch Gradient Norm: 3.901788292352976
Epoch: 3495, Batch Gradient Norm after: 3.901788292352976
Epoch 3496/10000, Prediction Accuracy = 63.31153846153847%, Loss = 0.008286820008204533
Epoch: 3496, Batch Gradient Norm: 4.3286077521009485
Epoch: 3496, Batch Gradient Norm after: 4.3286077521009485
Epoch 3497/10000, Prediction Accuracy = 63.06538461538462%, Loss = 0.008528866733496007
Epoch: 3497, Batch Gradient Norm: 4.3180167576673245
Epoch: 3497, Batch Gradient Norm after: 4.3180167576673245
Epoch 3498/10000, Prediction Accuracy = 62.80384615384616%, Loss = 0.008628509580515899
Epoch: 3498, Batch Gradient Norm: 4.101224690746479
Epoch: 3498, Batch Gradient Norm after: 4.101224690746479
Epoch 3499/10000, Prediction Accuracy = 62.74615384615384%, Loss = 0.008574480620714335
Epoch: 3499, Batch Gradient Norm: 3.8471910918867054
Epoch: 3499, Batch Gradient Norm after: 3.8471910918867054
Epoch 3500/10000, Prediction Accuracy = 63.20769230769231%, Loss = 0.0084049878641963
Epoch: 3500, Batch Gradient Norm: 3.805892680195793
Epoch: 3500, Batch Gradient Norm after: 3.805892680195793
Epoch 3501/10000, Prediction Accuracy = 63.63461538461537%, Loss = 0.00826357419674213
Epoch: 3501, Batch Gradient Norm: 3.8020214605886715
Epoch: 3501, Batch Gradient Norm after: 3.8020214605886715
Epoch 3502/10000, Prediction Accuracy = 63.18846153846154%, Loss = 0.008281223153552184
Epoch: 3502, Batch Gradient Norm: 3.8187042320917204
Epoch: 3502, Batch Gradient Norm after: 3.8187042320917204
Epoch 3503/10000, Prediction Accuracy = 63.184615384615384%, Loss = 0.00828170937557633
Epoch: 3503, Batch Gradient Norm: 3.8222641369366057
Epoch: 3503, Batch Gradient Norm after: 3.8222641369366057
Epoch 3504/10000, Prediction Accuracy = 63.45769230769231%, Loss = 0.008294383923594769
Epoch: 3504, Batch Gradient Norm: 3.418169627698884
Epoch: 3504, Batch Gradient Norm after: 3.418169627698884
Epoch 3505/10000, Prediction Accuracy = 63.407692307692315%, Loss = 0.00811603070738224
Epoch: 3505, Batch Gradient Norm: 3.713158981013779
Epoch: 3505, Batch Gradient Norm after: 3.713158981013779
Epoch 3506/10000, Prediction Accuracy = 63.48846153846154%, Loss = 0.00823567041124289
Epoch: 3506, Batch Gradient Norm: 3.7503165095857116
Epoch: 3506, Batch Gradient Norm after: 3.7503165095857116
Epoch 3507/10000, Prediction Accuracy = 63.600000000000016%, Loss = 0.008194681436110001
Epoch: 3507, Batch Gradient Norm: 3.9226790793807322
Epoch: 3507, Batch Gradient Norm after: 3.9226790793807322
Epoch 3508/10000, Prediction Accuracy = 63.3423076923077%, Loss = 0.008312997981332816
Epoch: 3508, Batch Gradient Norm: 3.9134667572854154
Epoch: 3508, Batch Gradient Norm after: 3.9134667572854154
Epoch 3509/10000, Prediction Accuracy = 63.134615384615394%, Loss = 0.008332562310477862
Epoch: 3509, Batch Gradient Norm: 3.9810385093703737
Epoch: 3509, Batch Gradient Norm after: 3.9810385093703737
Epoch 3510/10000, Prediction Accuracy = 63.023076923076935%, Loss = 0.008315983801507033
Epoch: 3510, Batch Gradient Norm: 3.8510837982032173
Epoch: 3510, Batch Gradient Norm after: 3.8510837982032173
Epoch 3511/10000, Prediction Accuracy = 63.346153846153854%, Loss = 0.00823763833166315
Epoch: 3511, Batch Gradient Norm: 3.8141479100531246
Epoch: 3511, Batch Gradient Norm after: 3.8141479100531246
Epoch 3512/10000, Prediction Accuracy = 63.56538461538461%, Loss = 0.008243926478406558
Epoch: 3512, Batch Gradient Norm: 4.018827951074509
Epoch: 3512, Batch Gradient Norm after: 4.018827951074509
Epoch 3513/10000, Prediction Accuracy = 63.01923076923077%, Loss = 0.008475065231323242
Epoch: 3513, Batch Gradient Norm: 3.6517001010090757
Epoch: 3513, Batch Gradient Norm after: 3.6517001010090757
Epoch 3514/10000, Prediction Accuracy = 63.41538461538461%, Loss = 0.008131999594087783
Epoch: 3514, Batch Gradient Norm: 3.7002163708250344
Epoch: 3514, Batch Gradient Norm after: 3.7002163708250344
Epoch 3515/10000, Prediction Accuracy = 63.73846153846154%, Loss = 0.008157756895973133
Epoch: 3515, Batch Gradient Norm: 3.9478770380740795
Epoch: 3515, Batch Gradient Norm after: 3.9478770380740795
Epoch 3516/10000, Prediction Accuracy = 63.01538461538462%, Loss = 0.008352580695198132
Epoch: 3516, Batch Gradient Norm: 3.7724571920217445
Epoch: 3516, Batch Gradient Norm after: 3.7724571920217445
Epoch 3517/10000, Prediction Accuracy = 63.630769230769225%, Loss = 0.008239826868073298
Epoch: 3517, Batch Gradient Norm: 3.6128685541512855
Epoch: 3517, Batch Gradient Norm after: 3.6128685541512855
Epoch 3518/10000, Prediction Accuracy = 63.95%, Loss = 0.008100263093813108
Epoch: 3518, Batch Gradient Norm: 3.5377629316597927
Epoch: 3518, Batch Gradient Norm after: 3.5377629316597927
Epoch 3519/10000, Prediction Accuracy = 64.30384615384615%, Loss = 0.008025641123262735
Epoch: 3519, Batch Gradient Norm: 3.8993771855921264
Epoch: 3519, Batch Gradient Norm after: 3.8993771855921264
Epoch 3520/10000, Prediction Accuracy = 64.05384615384615%, Loss = 0.008197297449581899
Epoch: 3520, Batch Gradient Norm: 3.9960371220527766
Epoch: 3520, Batch Gradient Norm after: 3.9960371220527766
Epoch 3521/10000, Prediction Accuracy = 63.48461538461538%, Loss = 0.00831012657055488
Epoch: 3521, Batch Gradient Norm: 4.183661904405448
Epoch: 3521, Batch Gradient Norm after: 4.183661904405448
Epoch 3522/10000, Prediction Accuracy = 62.47692307692308%, Loss = 0.008537974495154161
Epoch: 3522, Batch Gradient Norm: 3.937279151170309
Epoch: 3522, Batch Gradient Norm after: 3.937279151170309
Epoch 3523/10000, Prediction Accuracy = 62.98461538461538%, Loss = 0.008420831237274867
Epoch: 3523, Batch Gradient Norm: 4.033400377176859
Epoch: 3523, Batch Gradient Norm after: 4.033400377176859
Epoch 3524/10000, Prediction Accuracy = 63.28076923076923%, Loss = 0.008348378281180676
Epoch: 3524, Batch Gradient Norm: 3.7658430486274628
Epoch: 3524, Batch Gradient Norm after: 3.7658430486274628
Epoch 3525/10000, Prediction Accuracy = 63.396153846153844%, Loss = 0.008349857651270352
Epoch: 3525, Batch Gradient Norm: 3.9624436096761135
Epoch: 3525, Batch Gradient Norm after: 3.9624436096761135
Epoch 3526/10000, Prediction Accuracy = 62.76153846153846%, Loss = 0.008363006242479269
Epoch: 3526, Batch Gradient Norm: 4.007945700783916
Epoch: 3526, Batch Gradient Norm after: 4.007945700783916
Epoch 3527/10000, Prediction Accuracy = 63.46153846153846%, Loss = 0.008244923459222684
Epoch: 3527, Batch Gradient Norm: 3.9764254220574085
Epoch: 3527, Batch Gradient Norm after: 3.9764254220574085
Epoch 3528/10000, Prediction Accuracy = 63.50769230769231%, Loss = 0.008284928133854499
Epoch: 3528, Batch Gradient Norm: 3.9686681993023543
Epoch: 3528, Batch Gradient Norm after: 3.9686681993023543
Epoch 3529/10000, Prediction Accuracy = 63.38461538461539%, Loss = 0.008320879907562183
Epoch: 3529, Batch Gradient Norm: 3.871900242463971
Epoch: 3529, Batch Gradient Norm after: 3.871900242463971
Epoch 3530/10000, Prediction Accuracy = 63.388461538461534%, Loss = 0.008295010417126693
Epoch: 3530, Batch Gradient Norm: 3.8796559945970426
Epoch: 3530, Batch Gradient Norm after: 3.8796559945970426
Epoch 3531/10000, Prediction Accuracy = 63.48076923076922%, Loss = 0.008257709980870668
Epoch: 3531, Batch Gradient Norm: 4.146274318393463
Epoch: 3531, Batch Gradient Norm after: 4.146274318393463
Epoch 3532/10000, Prediction Accuracy = 62.86153846153847%, Loss = 0.008450218118154086
Epoch: 3532, Batch Gradient Norm: 3.7393820939494593
Epoch: 3532, Batch Gradient Norm after: 3.7393820939494593
Epoch 3533/10000, Prediction Accuracy = 63.02307692307692%, Loss = 0.00829316432086321
Epoch: 3533, Batch Gradient Norm: 4.033333829773939
Epoch: 3533, Batch Gradient Norm after: 4.033333829773939
Epoch 3534/10000, Prediction Accuracy = 63.4346153846154%, Loss = 0.00830098596186592
Epoch: 3534, Batch Gradient Norm: 3.549109104437101
Epoch: 3534, Batch Gradient Norm after: 3.549109104437101
Epoch 3535/10000, Prediction Accuracy = 63.892307692307675%, Loss = 0.008112624609986177
Epoch: 3535, Batch Gradient Norm: 3.639284052707166
Epoch: 3535, Batch Gradient Norm after: 3.639284052707166
Epoch 3536/10000, Prediction Accuracy = 63.87307692307694%, Loss = 0.008110310094287762
Epoch: 3536, Batch Gradient Norm: 3.412290836628476
Epoch: 3536, Batch Gradient Norm after: 3.412290836628476
Epoch 3537/10000, Prediction Accuracy = 64.55%, Loss = 0.007977777984566413
Epoch: 3537, Batch Gradient Norm: 3.6977429519433285
Epoch: 3537, Batch Gradient Norm after: 3.6977429519433285
Epoch 3538/10000, Prediction Accuracy = 64.0%, Loss = 0.008118018293036865
Epoch: 3538, Batch Gradient Norm: 3.9402614143826686
Epoch: 3538, Batch Gradient Norm after: 3.9402614143826686
Epoch 3539/10000, Prediction Accuracy = 63.73076923076922%, Loss = 0.008245045534120156
Epoch: 3539, Batch Gradient Norm: 3.8327276122027216
Epoch: 3539, Batch Gradient Norm after: 3.8327276122027216
Epoch 3540/10000, Prediction Accuracy = 63.63846153846154%, Loss = 0.008237971351123773
Epoch: 3540, Batch Gradient Norm: 3.522420347540265
Epoch: 3540, Batch Gradient Norm after: 3.522420347540265
Epoch 3541/10000, Prediction Accuracy = 64.28461538461539%, Loss = 0.007984453454040565
Epoch: 3541, Batch Gradient Norm: 3.703495211082229
Epoch: 3541, Batch Gradient Norm after: 3.703495211082229
Epoch 3542/10000, Prediction Accuracy = 64.16153846153847%, Loss = 0.008033757993521599
Epoch: 3542, Batch Gradient Norm: 4.097902453296046
Epoch: 3542, Batch Gradient Norm after: 4.097902453296046
Epoch 3543/10000, Prediction Accuracy = 63.380769230769225%, Loss = 0.008299985613960486
Epoch: 3543, Batch Gradient Norm: 4.0960258279794495
Epoch: 3543, Batch Gradient Norm after: 4.0960258279794495
Epoch 3544/10000, Prediction Accuracy = 63.284615384615385%, Loss = 0.008385574158567648
Epoch: 3544, Batch Gradient Norm: 3.7704973608016203
Epoch: 3544, Batch Gradient Norm after: 3.7704973608016203
Epoch 3545/10000, Prediction Accuracy = 63.98461538461538%, Loss = 0.008149082199312173
Epoch: 3545, Batch Gradient Norm: 3.871364841221168
Epoch: 3545, Batch Gradient Norm after: 3.871364841221168
Epoch 3546/10000, Prediction Accuracy = 63.64999999999999%, Loss = 0.008205192951628795
Epoch: 3546, Batch Gradient Norm: 3.808054020685663
Epoch: 3546, Batch Gradient Norm after: 3.808054020685663
Epoch 3547/10000, Prediction Accuracy = 63.77307692307692%, Loss = 0.008097751854130855
Epoch: 3547, Batch Gradient Norm: 3.588254038606158
Epoch: 3547, Batch Gradient Norm after: 3.588254038606158
Epoch 3548/10000, Prediction Accuracy = 64.11153846153846%, Loss = 0.00800585954521711
Epoch: 3548, Batch Gradient Norm: 3.848330847090388
Epoch: 3548, Batch Gradient Norm after: 3.848330847090388
Epoch 3549/10000, Prediction Accuracy = 63.56538461538462%, Loss = 0.008235537017194124
Epoch: 3549, Batch Gradient Norm: 4.169958302051766
Epoch: 3549, Batch Gradient Norm after: 4.169958302051766
Epoch 3550/10000, Prediction Accuracy = 63.5%, Loss = 0.00834566462211884
Epoch: 3550, Batch Gradient Norm: 3.6722674696568554
Epoch: 3550, Batch Gradient Norm after: 3.6722674696568554
Epoch 3551/10000, Prediction Accuracy = 64.19615384615385%, Loss = 0.008147879432027157
Epoch: 3551, Batch Gradient Norm: 3.707189021733687
Epoch: 3551, Batch Gradient Norm after: 3.707189021733687
Epoch 3552/10000, Prediction Accuracy = 63.56153846153847%, Loss = 0.008080041071829887
Epoch: 3552, Batch Gradient Norm: 3.8818859078523387
Epoch: 3552, Batch Gradient Norm after: 3.8818859078523387
Epoch 3553/10000, Prediction Accuracy = 64.01923076923076%, Loss = 0.0082104832220536
Epoch: 3553, Batch Gradient Norm: 3.898382118284796
Epoch: 3553, Batch Gradient Norm after: 3.898382118284796
Epoch 3554/10000, Prediction Accuracy = 63.40384615384614%, Loss = 0.008234162958195576
Epoch: 3554, Batch Gradient Norm: 3.9535360069913286
Epoch: 3554, Batch Gradient Norm after: 3.9535360069913286
Epoch 3555/10000, Prediction Accuracy = 64.0%, Loss = 0.00817443269233291
Epoch: 3555, Batch Gradient Norm: 3.874142283835509
Epoch: 3555, Batch Gradient Norm after: 3.874142283835509
Epoch 3556/10000, Prediction Accuracy = 63.96923076923076%, Loss = 0.008133157801169615
Epoch: 3556, Batch Gradient Norm: 3.6628777030478235
Epoch: 3556, Batch Gradient Norm after: 3.6628777030478235
Epoch 3557/10000, Prediction Accuracy = 63.70769230769231%, Loss = 0.00811645882920577
Epoch: 3557, Batch Gradient Norm: 3.965229109165216
Epoch: 3557, Batch Gradient Norm after: 3.965229109165216
Epoch 3558/10000, Prediction Accuracy = 63.388461538461534%, Loss = 0.00823687196064454
Epoch: 3558, Batch Gradient Norm: 3.773285995378868
Epoch: 3558, Batch Gradient Norm after: 3.773285995378868
Epoch 3559/10000, Prediction Accuracy = 63.888461538461534%, Loss = 0.008168760615472611
Epoch: 3559, Batch Gradient Norm: 3.911106389200938
Epoch: 3559, Batch Gradient Norm after: 3.911106389200938
Epoch 3560/10000, Prediction Accuracy = 63.36153846153846%, Loss = 0.00818451028317213
Epoch: 3560, Batch Gradient Norm: 4.268273284087368
Epoch: 3560, Batch Gradient Norm after: 4.268273284087368
Epoch 3561/10000, Prediction Accuracy = 62.76923076923078%, Loss = 0.00837523927195714
Epoch: 3561, Batch Gradient Norm: 4.530102704767262
Epoch: 3561, Batch Gradient Norm after: 4.530102704767262
Epoch 3562/10000, Prediction Accuracy = 62.83846153846154%, Loss = 0.008605999155686451
Epoch: 3562, Batch Gradient Norm: 4.145612817521901
Epoch: 3562, Batch Gradient Norm after: 4.145612817521901
Epoch 3563/10000, Prediction Accuracy = 62.83846153846154%, Loss = 0.008380476456995193
Epoch: 3563, Batch Gradient Norm: 3.936790384898922
Epoch: 3563, Batch Gradient Norm after: 3.936790384898922
Epoch 3564/10000, Prediction Accuracy = 63.81923076923078%, Loss = 0.008168781104569253
Epoch: 3564, Batch Gradient Norm: 3.6993350921483015
Epoch: 3564, Batch Gradient Norm after: 3.6993350921483015
Epoch 3565/10000, Prediction Accuracy = 63.90384615384615%, Loss = 0.00809857421196424
Epoch: 3565, Batch Gradient Norm: 3.8995858717042875
Epoch: 3565, Batch Gradient Norm after: 3.8995858717042875
Epoch 3566/10000, Prediction Accuracy = 63.60769230769232%, Loss = 0.00822664381792912
Epoch: 3566, Batch Gradient Norm: 4.281096283839394
Epoch: 3566, Batch Gradient Norm after: 4.281096283839394
Epoch 3567/10000, Prediction Accuracy = 62.684615384615384%, Loss = 0.008501993205684882
Epoch: 3567, Batch Gradient Norm: 4.138305640200292
Epoch: 3567, Batch Gradient Norm after: 4.138305640200292
Epoch 3568/10000, Prediction Accuracy = 63.130769230769225%, Loss = 0.008447837156171981
Epoch: 3568, Batch Gradient Norm: 3.8967617024413777
Epoch: 3568, Batch Gradient Norm after: 3.8967617024413777
Epoch 3569/10000, Prediction Accuracy = 63.665384615384625%, Loss = 0.008279521913769154
Epoch: 3569, Batch Gradient Norm: 3.857812031841428
Epoch: 3569, Batch Gradient Norm after: 3.857812031841428
Epoch 3570/10000, Prediction Accuracy = 63.82692307692308%, Loss = 0.008151949490778722
Epoch: 3570, Batch Gradient Norm: 3.78098573826893
Epoch: 3570, Batch Gradient Norm after: 3.78098573826893
Epoch 3571/10000, Prediction Accuracy = 63.43846153846153%, Loss = 0.008170798850747256
Epoch: 3571, Batch Gradient Norm: 3.7354607581391672
Epoch: 3571, Batch Gradient Norm after: 3.7354607581391672
Epoch 3572/10000, Prediction Accuracy = 63.52307692307692%, Loss = 0.008147609849961905
Epoch: 3572, Batch Gradient Norm: 4.010757263028449
Epoch: 3572, Batch Gradient Norm after: 4.010757263028449
Epoch 3573/10000, Prediction Accuracy = 63.22692307692307%, Loss = 0.008302186365024401
Epoch: 3573, Batch Gradient Norm: 3.819497077293357
Epoch: 3573, Batch Gradient Norm after: 3.819497077293357
Epoch 3574/10000, Prediction Accuracy = 63.18846153846153%, Loss = 0.008225885685533285
Epoch: 3574, Batch Gradient Norm: 4.052207388483538
Epoch: 3574, Batch Gradient Norm after: 4.052207388483538
Epoch 3575/10000, Prediction Accuracy = 63.26538461538462%, Loss = 0.008364711171732498
Epoch: 3575, Batch Gradient Norm: 3.88622158810656
Epoch: 3575, Batch Gradient Norm after: 3.88622158810656
Epoch 3576/10000, Prediction Accuracy = 63.665384615384625%, Loss = 0.008262257234981427
Epoch: 3576, Batch Gradient Norm: 3.58888483537567
Epoch: 3576, Batch Gradient Norm after: 3.58888483537567
Epoch 3577/10000, Prediction Accuracy = 63.68846153846154%, Loss = 0.00807440191364059
Epoch: 3577, Batch Gradient Norm: 3.8370643504363966
Epoch: 3577, Batch Gradient Norm after: 3.8370643504363966
Epoch 3578/10000, Prediction Accuracy = 63.89230769230768%, Loss = 0.008143758866935968
Epoch: 3578, Batch Gradient Norm: 3.6403455415084487
Epoch: 3578, Batch Gradient Norm after: 3.6403455415084487
Epoch 3579/10000, Prediction Accuracy = 63.5%, Loss = 0.00810215507562344
Epoch: 3579, Batch Gradient Norm: 3.5820392439258466
Epoch: 3579, Batch Gradient Norm after: 3.5820392439258466
Epoch 3580/10000, Prediction Accuracy = 64.31538461538463%, Loss = 0.007995781918557791
Epoch: 3580, Batch Gradient Norm: 3.486478156075963
Epoch: 3580, Batch Gradient Norm after: 3.486478156075963
Epoch 3581/10000, Prediction Accuracy = 64.26923076923077%, Loss = 0.007979585824964138
Epoch: 3581, Batch Gradient Norm: 3.7460003854989705
Epoch: 3581, Batch Gradient Norm after: 3.7460003854989705
Epoch 3582/10000, Prediction Accuracy = 64.00000000000001%, Loss = 0.00802768412261055
Epoch: 3582, Batch Gradient Norm: 4.108093380940747
Epoch: 3582, Batch Gradient Norm after: 4.108093380940747
Epoch 3583/10000, Prediction Accuracy = 63.40384615384615%, Loss = 0.008245273851431333
Epoch: 3583, Batch Gradient Norm: 3.8843834992431554
Epoch: 3583, Batch Gradient Norm after: 3.8843834992431554
Epoch 3584/10000, Prediction Accuracy = 63.857692307692304%, Loss = 0.008100182820971195
Epoch: 3584, Batch Gradient Norm: 4.180746454457651
Epoch: 3584, Batch Gradient Norm after: 4.180746454457651
Epoch 3585/10000, Prediction Accuracy = 63.41153846153847%, Loss = 0.00821758692081158
Epoch: 3585, Batch Gradient Norm: 4.130912124257485
Epoch: 3585, Batch Gradient Norm after: 4.130912124257485
Epoch 3586/10000, Prediction Accuracy = 63.37692307692308%, Loss = 0.008266185768521749
Epoch: 3586, Batch Gradient Norm: 4.082107295313996
Epoch: 3586, Batch Gradient Norm after: 4.082107295313996
Epoch 3587/10000, Prediction Accuracy = 63.442307692307686%, Loss = 0.008310121484100819
Epoch: 3587, Batch Gradient Norm: 3.9486513107213916
Epoch: 3587, Batch Gradient Norm after: 3.9486513107213916
Epoch 3588/10000, Prediction Accuracy = 63.40384615384616%, Loss = 0.008322208260114376
Epoch: 3588, Batch Gradient Norm: 3.8849821964826132
Epoch: 3588, Batch Gradient Norm after: 3.8849821964826132
Epoch 3589/10000, Prediction Accuracy = 63.16153846153847%, Loss = 0.008323791365210827
Epoch: 3589, Batch Gradient Norm: 4.218559268387874
Epoch: 3589, Batch Gradient Norm after: 4.218559268387874
Epoch 3590/10000, Prediction Accuracy = 62.88461538461539%, Loss = 0.008436708137966119
Epoch: 3590, Batch Gradient Norm: 4.286909673700462
Epoch: 3590, Batch Gradient Norm after: 4.286909673700462
Epoch 3591/10000, Prediction Accuracy = 63.05384615384616%, Loss = 0.008467150637163566
Epoch: 3591, Batch Gradient Norm: 3.7482727006855834
Epoch: 3591, Batch Gradient Norm after: 3.7482727006855834
Epoch 3592/10000, Prediction Accuracy = 63.51538461538462%, Loss = 0.008143787487195088
Epoch: 3592, Batch Gradient Norm: 3.797225397111664
Epoch: 3592, Batch Gradient Norm after: 3.797225397111664
Epoch 3593/10000, Prediction Accuracy = 63.81923076923077%, Loss = 0.008084828034043312
Epoch: 3593, Batch Gradient Norm: 3.72793045846994
Epoch: 3593, Batch Gradient Norm after: 3.72793045846994
Epoch 3594/10000, Prediction Accuracy = 64.03076923076922%, Loss = 0.008096921902436476
Epoch: 3594, Batch Gradient Norm: 4.253289952801018
Epoch: 3594, Batch Gradient Norm after: 4.253289952801018
Epoch 3595/10000, Prediction Accuracy = 62.969230769230755%, Loss = 0.008453271495035062
Epoch: 3595, Batch Gradient Norm: 4.122879058489825
Epoch: 3595, Batch Gradient Norm after: 4.122879058489825
Epoch 3596/10000, Prediction Accuracy = 63.66538461538461%, Loss = 0.008384581726904098
Epoch: 3596, Batch Gradient Norm: 3.8380173644998927
Epoch: 3596, Batch Gradient Norm after: 3.8380173644998927
Epoch 3597/10000, Prediction Accuracy = 63.434615384615384%, Loss = 0.008198750205338001
Epoch: 3597, Batch Gradient Norm: 3.9752715909184015
Epoch: 3597, Batch Gradient Norm after: 3.9752715909184015
Epoch 3598/10000, Prediction Accuracy = 63.53846153846154%, Loss = 0.008253319833714228
Epoch: 3598, Batch Gradient Norm: 4.09799035434575
Epoch: 3598, Batch Gradient Norm after: 4.09799035434575
Epoch 3599/10000, Prediction Accuracy = 63.48076923076924%, Loss = 0.008366427455957118
Epoch: 3599, Batch Gradient Norm: 3.3664981359158923
Epoch: 3599, Batch Gradient Norm after: 3.3664981359158923
Epoch 3600/10000, Prediction Accuracy = 64.07307692307691%, Loss = 0.008041789611944785
Epoch: 3600, Batch Gradient Norm: 3.726446300379692
Epoch: 3600, Batch Gradient Norm after: 3.726446300379692
Epoch 3601/10000, Prediction Accuracy = 64.22307692307692%, Loss = 0.008023735064153489
Epoch: 3601, Batch Gradient Norm: 3.8144541234725295
Epoch: 3601, Batch Gradient Norm after: 3.8144541234725295
Epoch 3602/10000, Prediction Accuracy = 63.61538461538463%, Loss = 0.008132610828257524
Epoch: 3602, Batch Gradient Norm: 4.0465158178575225
Epoch: 3602, Batch Gradient Norm after: 4.0465158178575225
Epoch 3603/10000, Prediction Accuracy = 63.157692307692315%, Loss = 0.008235247304233221
Epoch: 3603, Batch Gradient Norm: 4.0474587801575375
Epoch: 3603, Batch Gradient Norm after: 4.0474587801575375
Epoch 3604/10000, Prediction Accuracy = 63.37307692307692%, Loss = 0.008248516215154758
Epoch: 3604, Batch Gradient Norm: 3.8772377658382555
Epoch: 3604, Batch Gradient Norm after: 3.8772377658382555
Epoch 3605/10000, Prediction Accuracy = 63.67307692307691%, Loss = 0.008191315743785638
Epoch: 3605, Batch Gradient Norm: 4.040205389401955
Epoch: 3605, Batch Gradient Norm after: 4.040205389401955
Epoch 3606/10000, Prediction Accuracy = 63.169230769230765%, Loss = 0.00832393249640098
Epoch: 3606, Batch Gradient Norm: 4.131063352942243
Epoch: 3606, Batch Gradient Norm after: 4.131063352942243
Epoch 3607/10000, Prediction Accuracy = 63.05%, Loss = 0.008280304475472523
Epoch: 3607, Batch Gradient Norm: 3.819690914369633
Epoch: 3607, Batch Gradient Norm after: 3.819690914369633
Epoch 3608/10000, Prediction Accuracy = 63.75384615384615%, Loss = 0.008152729330154566
Epoch: 3608, Batch Gradient Norm: 3.70291768325639
Epoch: 3608, Batch Gradient Norm after: 3.70291768325639
Epoch 3609/10000, Prediction Accuracy = 63.99615384615385%, Loss = 0.008080073703940097
Epoch: 3609, Batch Gradient Norm: 3.354391032126694
Epoch: 3609, Batch Gradient Norm after: 3.354391032126694
Epoch 3610/10000, Prediction Accuracy = 64.21153846153845%, Loss = 0.007856527486672768
Epoch: 3610, Batch Gradient Norm: 3.843849540296511
Epoch: 3610, Batch Gradient Norm after: 3.843849540296511
Epoch 3611/10000, Prediction Accuracy = 63.74615384615386%, Loss = 0.008205392397940159
Epoch: 3611, Batch Gradient Norm: 3.915831187866954
Epoch: 3611, Batch Gradient Norm after: 3.915831187866954
Epoch 3612/10000, Prediction Accuracy = 64.01538461538463%, Loss = 0.008116004701990347
Epoch: 3612, Batch Gradient Norm: 3.6895746864764343
Epoch: 3612, Batch Gradient Norm after: 3.6895746864764343
Epoch 3613/10000, Prediction Accuracy = 63.66923076923078%, Loss = 0.00806899404583069
Epoch: 3613, Batch Gradient Norm: 3.4396513604677375
Epoch: 3613, Batch Gradient Norm after: 3.4396513604677375
Epoch 3614/10000, Prediction Accuracy = 64.63076923076923%, Loss = 0.007890203681129675
Epoch: 3614, Batch Gradient Norm: 3.8226445910573434
Epoch: 3614, Batch Gradient Norm after: 3.8226445910573434
Epoch 3615/10000, Prediction Accuracy = 63.79615384615384%, Loss = 0.008078200026200367
Epoch: 3615, Batch Gradient Norm: 3.767688597030776
Epoch: 3615, Batch Gradient Norm after: 3.767688597030776
Epoch 3616/10000, Prediction Accuracy = 63.776923076923076%, Loss = 0.008011538929377612
Epoch: 3616, Batch Gradient Norm: 3.762379653468944
Epoch: 3616, Batch Gradient Norm after: 3.762379653468944
Epoch 3617/10000, Prediction Accuracy = 64.6076923076923%, Loss = 0.007992852873240527
Epoch: 3617, Batch Gradient Norm: 4.011292584110802
Epoch: 3617, Batch Gradient Norm after: 4.011292584110802
Epoch 3618/10000, Prediction Accuracy = 63.87692307692308%, Loss = 0.008124626349084653
Epoch: 3618, Batch Gradient Norm: 4.2580702604759155
Epoch: 3618, Batch Gradient Norm after: 4.2580702604759155
Epoch 3619/10000, Prediction Accuracy = 63.51538461538461%, Loss = 0.008291496537052669
Epoch: 3619, Batch Gradient Norm: 3.8421288553487978
Epoch: 3619, Batch Gradient Norm after: 3.8421288553487978
Epoch 3620/10000, Prediction Accuracy = 63.907692307692315%, Loss = 0.008101279453302804
Epoch: 3620, Batch Gradient Norm: 3.860269907022939
Epoch: 3620, Batch Gradient Norm after: 3.860269907022939
Epoch 3621/10000, Prediction Accuracy = 63.40384615384616%, Loss = 0.00822487953477181
Epoch: 3621, Batch Gradient Norm: 3.6208461759185666
Epoch: 3621, Batch Gradient Norm after: 3.6208461759185666
Epoch 3622/10000, Prediction Accuracy = 64.56153846153845%, Loss = 0.00792372663720296
Epoch: 3622, Batch Gradient Norm: 3.7297463338206174
Epoch: 3622, Batch Gradient Norm after: 3.7297463338206174
Epoch 3623/10000, Prediction Accuracy = 64.24615384615385%, Loss = 0.007955097844107794
Epoch: 3623, Batch Gradient Norm: 3.8485652833787816
Epoch: 3623, Batch Gradient Norm after: 3.8485652833787816
Epoch 3624/10000, Prediction Accuracy = 64.26153846153845%, Loss = 0.0080145404745753
Epoch: 3624, Batch Gradient Norm: 4.151091587189479
Epoch: 3624, Batch Gradient Norm after: 4.151091587189479
Epoch 3625/10000, Prediction Accuracy = 63.534615384615385%, Loss = 0.008275273900765639
Epoch: 3625, Batch Gradient Norm: 4.259179075469873
Epoch: 3625, Batch Gradient Norm after: 4.259179075469873
Epoch 3626/10000, Prediction Accuracy = 62.91923076923077%, Loss = 0.008486751037148329
Epoch: 3626, Batch Gradient Norm: 4.088484880551174
Epoch: 3626, Batch Gradient Norm after: 4.088484880551174
Epoch 3627/10000, Prediction Accuracy = 63.21923076923077%, Loss = 0.008254618992885718
Epoch: 3627, Batch Gradient Norm: 4.109131074529344
Epoch: 3627, Batch Gradient Norm after: 4.109131074529344
Epoch 3628/10000, Prediction Accuracy = 63.81923076923078%, Loss = 0.008246910829956714
Epoch: 3628, Batch Gradient Norm: 4.20847095733717
Epoch: 3628, Batch Gradient Norm after: 4.20847095733717
Epoch 3629/10000, Prediction Accuracy = 62.880769230769246%, Loss = 0.008522542766653575
Epoch: 3629, Batch Gradient Norm: 3.9912940043164182
Epoch: 3629, Batch Gradient Norm after: 3.9912940043164182
Epoch 3630/10000, Prediction Accuracy = 63.63076923076923%, Loss = 0.008290585202093307
Epoch: 3630, Batch Gradient Norm: 3.7854075885581877
Epoch: 3630, Batch Gradient Norm after: 3.7854075885581877
Epoch 3631/10000, Prediction Accuracy = 63.92692307692307%, Loss = 0.008091996817921217
Epoch: 3631, Batch Gradient Norm: 3.9674449451547726
Epoch: 3631, Batch Gradient Norm after: 3.9674449451547726
Epoch 3632/10000, Prediction Accuracy = 63.376923076923084%, Loss = 0.008153657285639873
Epoch: 3632, Batch Gradient Norm: 4.584384877098026
Epoch: 3632, Batch Gradient Norm after: 4.584384877098026
Epoch 3633/10000, Prediction Accuracy = 63.05384615384616%, Loss = 0.008560365280852867
Epoch: 3633, Batch Gradient Norm: 4.293860790761524
Epoch: 3633, Batch Gradient Norm after: 4.293860790761524
Epoch 3634/10000, Prediction Accuracy = 62.91923076923077%, Loss = 0.00848461572940533
Epoch: 3634, Batch Gradient Norm: 3.721092689056795
Epoch: 3634, Batch Gradient Norm after: 3.721092689056795
Epoch 3635/10000, Prediction Accuracy = 63.74615384615385%, Loss = 0.008196175635720674
Epoch: 3635, Batch Gradient Norm: 3.6700358855973807
Epoch: 3635, Batch Gradient Norm after: 3.6700358855973807
Epoch 3636/10000, Prediction Accuracy = 63.68076923076924%, Loss = 0.008127616073649663
Epoch: 3636, Batch Gradient Norm: 3.7760066329469115
Epoch: 3636, Batch Gradient Norm after: 3.7760066329469115
Epoch 3637/10000, Prediction Accuracy = 63.81538461538461%, Loss = 0.008098848056621276
Epoch: 3637, Batch Gradient Norm: 3.8336339804694517
Epoch: 3637, Batch Gradient Norm after: 3.8336339804694517
Epoch 3638/10000, Prediction Accuracy = 63.92692307692308%, Loss = 0.008097770194021555
Epoch: 3638, Batch Gradient Norm: 4.17986874139566
Epoch: 3638, Batch Gradient Norm after: 4.17986874139566
Epoch 3639/10000, Prediction Accuracy = 63.33846153846154%, Loss = 0.008323535430603303
Epoch: 3639, Batch Gradient Norm: 3.940606206051391
Epoch: 3639, Batch Gradient Norm after: 3.940606206051391
Epoch 3640/10000, Prediction Accuracy = 63.615384615384606%, Loss = 0.008278358082931776
Epoch: 3640, Batch Gradient Norm: 3.7571773434966036
Epoch: 3640, Batch Gradient Norm after: 3.7571773434966036
Epoch 3641/10000, Prediction Accuracy = 63.88076923076923%, Loss = 0.008096555677744059
Epoch: 3641, Batch Gradient Norm: 3.810975493203596
Epoch: 3641, Batch Gradient Norm after: 3.810975493203596
Epoch 3642/10000, Prediction Accuracy = 63.82692307692308%, Loss = 0.008175662288872095
Epoch: 3642, Batch Gradient Norm: 3.8756041788047426
Epoch: 3642, Batch Gradient Norm after: 3.8756041788047426
Epoch 3643/10000, Prediction Accuracy = 63.807692307692314%, Loss = 0.008076960758234445
Epoch: 3643, Batch Gradient Norm: 4.098226938096225
Epoch: 3643, Batch Gradient Norm after: 4.098226938096225
Epoch 3644/10000, Prediction Accuracy = 63.46153846153846%, Loss = 0.008330116549936624
Epoch: 3644, Batch Gradient Norm: 4.135630901524305
Epoch: 3644, Batch Gradient Norm after: 4.135630901524305
Epoch 3645/10000, Prediction Accuracy = 63.4423076923077%, Loss = 0.008286625397606539
Epoch: 3645, Batch Gradient Norm: 3.8790359018792264
Epoch: 3645, Batch Gradient Norm after: 3.8790359018792264
Epoch 3646/10000, Prediction Accuracy = 63.8346153846154%, Loss = 0.008209803499854527
Epoch: 3646, Batch Gradient Norm: 4.020793470630614
Epoch: 3646, Batch Gradient Norm after: 4.020793470630614
Epoch 3647/10000, Prediction Accuracy = 63.36923076923077%, Loss = 0.008213197669157615
Epoch: 3647, Batch Gradient Norm: 4.080417192281902
Epoch: 3647, Batch Gradient Norm after: 4.080417192281902
Epoch 3648/10000, Prediction Accuracy = 63.27692307692307%, Loss = 0.00830129562662198
Epoch: 3648, Batch Gradient Norm: 3.8626765447976648
Epoch: 3648, Batch Gradient Norm after: 3.8626765447976648
Epoch 3649/10000, Prediction Accuracy = 63.53076923076924%, Loss = 0.008206429246526498
Epoch: 3649, Batch Gradient Norm: 4.154015792110043
Epoch: 3649, Batch Gradient Norm after: 4.154015792110043
Epoch 3650/10000, Prediction Accuracy = 63.54615384615384%, Loss = 0.008351650948707875
Epoch: 3650, Batch Gradient Norm: 4.152216540837847
Epoch: 3650, Batch Gradient Norm after: 4.152216540837847
Epoch 3651/10000, Prediction Accuracy = 63.76538461538462%, Loss = 0.00828163863088076
Epoch: 3651, Batch Gradient Norm: 3.8246383033822093
Epoch: 3651, Batch Gradient Norm after: 3.8246383033822093
Epoch 3652/10000, Prediction Accuracy = 63.46153846153845%, Loss = 0.008172507541110883
Epoch: 3652, Batch Gradient Norm: 3.9215114524129526
Epoch: 3652, Batch Gradient Norm after: 3.9215114524129526
Epoch 3653/10000, Prediction Accuracy = 63.934615384615384%, Loss = 0.008206401378489457
Epoch: 3653, Batch Gradient Norm: 3.9362762663239192
Epoch: 3653, Batch Gradient Norm after: 3.9362762663239192
Epoch 3654/10000, Prediction Accuracy = 63.869230769230775%, Loss = 0.008163461819864236
Epoch: 3654, Batch Gradient Norm: 4.375439531252136
Epoch: 3654, Batch Gradient Norm after: 4.375439531252136
Epoch 3655/10000, Prediction Accuracy = 63.00769230769231%, Loss = 0.008449636041544951
Epoch: 3655, Batch Gradient Norm: 4.283002097039934
Epoch: 3655, Batch Gradient Norm after: 4.283002097039934
Epoch 3656/10000, Prediction Accuracy = 63.150000000000006%, Loss = 0.00842314983646457
Epoch: 3656, Batch Gradient Norm: 3.6307516908333572
Epoch: 3656, Batch Gradient Norm after: 3.6307516908333572
Epoch 3657/10000, Prediction Accuracy = 64.00384615384615%, Loss = 0.008150689482975464
Epoch: 3657, Batch Gradient Norm: 3.716422209527771
Epoch: 3657, Batch Gradient Norm after: 3.716422209527771
Epoch 3658/10000, Prediction Accuracy = 63.70769230769232%, Loss = 0.008151488235363593
Epoch: 3658, Batch Gradient Norm: 3.761893079503082
Epoch: 3658, Batch Gradient Norm after: 3.761893079503082
Epoch 3659/10000, Prediction Accuracy = 64.25384615384615%, Loss = 0.00802139461470338
Epoch: 3659, Batch Gradient Norm: 3.911176585653783
Epoch: 3659, Batch Gradient Norm after: 3.911176585653783
Epoch 3660/10000, Prediction Accuracy = 63.657692307692315%, Loss = 0.008150572566172251
Epoch: 3660, Batch Gradient Norm: 3.658388811963147
Epoch: 3660, Batch Gradient Norm after: 3.658388811963147
Epoch 3661/10000, Prediction Accuracy = 63.96923076923076%, Loss = 0.008082237309561325
Epoch: 3661, Batch Gradient Norm: 3.9107212815490966
Epoch: 3661, Batch Gradient Norm after: 3.9107212815490966
Epoch 3662/10000, Prediction Accuracy = 63.75384615384616%, Loss = 0.008154159877449274
Epoch: 3662, Batch Gradient Norm: 3.919923877429875
Epoch: 3662, Batch Gradient Norm after: 3.919923877429875
Epoch 3663/10000, Prediction Accuracy = 63.89999999999999%, Loss = 0.008250145420718651
Epoch: 3663, Batch Gradient Norm: 4.011401606310032
Epoch: 3663, Batch Gradient Norm after: 4.011401606310032
Epoch 3664/10000, Prediction Accuracy = 63.1423076923077%, Loss = 0.008287588134407997
Epoch: 3664, Batch Gradient Norm: 3.9345249773758035
Epoch: 3664, Batch Gradient Norm after: 3.9345249773758035
Epoch 3665/10000, Prediction Accuracy = 63.01923076923078%, Loss = 0.008312739646778656
Epoch: 3665, Batch Gradient Norm: 3.531994523918515
Epoch: 3665, Batch Gradient Norm after: 3.531994523918515
Epoch 3666/10000, Prediction Accuracy = 64.17307692307693%, Loss = 0.008027710701124026
Epoch: 3666, Batch Gradient Norm: 3.7082740415910616
Epoch: 3666, Batch Gradient Norm after: 3.7082740415910616
Epoch 3667/10000, Prediction Accuracy = 64.05384615384615%, Loss = 0.008123591506423859
Epoch: 3667, Batch Gradient Norm: 3.7168230342314263
Epoch: 3667, Batch Gradient Norm after: 3.7168230342314263
Epoch 3668/10000, Prediction Accuracy = 64.02307692307693%, Loss = 0.008024633897898288
Epoch: 3668, Batch Gradient Norm: 4.1688205987859455
Epoch: 3668, Batch Gradient Norm after: 4.1688205987859455
Epoch 3669/10000, Prediction Accuracy = 62.71153846153847%, Loss = 0.008235388435423374
Epoch: 3669, Batch Gradient Norm: 4.055464743441934
Epoch: 3669, Batch Gradient Norm after: 4.055464743441934
Epoch 3670/10000, Prediction Accuracy = 63.43846153846154%, Loss = 0.008325404272629665
Epoch: 3670, Batch Gradient Norm: 3.9422900034098554
Epoch: 3670, Batch Gradient Norm after: 3.9422900034098554
Epoch 3671/10000, Prediction Accuracy = 63.357692307692304%, Loss = 0.008279296605346294
Epoch: 3671, Batch Gradient Norm: 3.986415863178419
Epoch: 3671, Batch Gradient Norm after: 3.986415863178419
Epoch 3672/10000, Prediction Accuracy = 63.623076923076916%, Loss = 0.008281862005018271
Epoch: 3672, Batch Gradient Norm: 3.9124493298746486
Epoch: 3672, Batch Gradient Norm after: 3.9124493298746486
Epoch 3673/10000, Prediction Accuracy = 63.665384615384625%, Loss = 0.008199758003824033
Epoch: 3673, Batch Gradient Norm: 3.9904067671450707
Epoch: 3673, Batch Gradient Norm after: 3.9904067671450707
Epoch 3674/10000, Prediction Accuracy = 63.63846153846154%, Loss = 0.00814644512362205
Epoch: 3674, Batch Gradient Norm: 3.794982917436702
Epoch: 3674, Batch Gradient Norm after: 3.794982917436702
Epoch 3675/10000, Prediction Accuracy = 63.830769230769235%, Loss = 0.008026706878668986
Epoch: 3675, Batch Gradient Norm: 4.330446636195188
Epoch: 3675, Batch Gradient Norm after: 4.330446636195188
Epoch 3676/10000, Prediction Accuracy = 63.51923076923077%, Loss = 0.008273553461409532
Epoch: 3676, Batch Gradient Norm: 4.451929500194816
Epoch: 3676, Batch Gradient Norm after: 4.451929500194816
Epoch 3677/10000, Prediction Accuracy = 63.326923076923066%, Loss = 0.008438594352740508
Epoch: 3677, Batch Gradient Norm: 3.9139392987736734
Epoch: 3677, Batch Gradient Norm after: 3.9139392987736734
Epoch 3678/10000, Prediction Accuracy = 63.38461538461539%, Loss = 0.008198423454394707
Epoch: 3678, Batch Gradient Norm: 4.1821133242464255
Epoch: 3678, Batch Gradient Norm after: 4.1821133242464255
Epoch 3679/10000, Prediction Accuracy = 63.62692307692308%, Loss = 0.0081998509211609
Epoch: 3679, Batch Gradient Norm: 3.8630626575996865
Epoch: 3679, Batch Gradient Norm after: 3.8630626575996865
Epoch 3680/10000, Prediction Accuracy = 63.74230769230769%, Loss = 0.008214430453685613
Epoch: 3680, Batch Gradient Norm: 3.936615834105305
Epoch: 3680, Batch Gradient Norm after: 3.936615834105305
Epoch 3681/10000, Prediction Accuracy = 63.13461538461539%, Loss = 0.008289894232383141
Epoch: 3681, Batch Gradient Norm: 4.222710030952681
Epoch: 3681, Batch Gradient Norm after: 4.222710030952681
Epoch 3682/10000, Prediction Accuracy = 63.07307692307692%, Loss = 0.008424199974307647
Epoch: 3682, Batch Gradient Norm: 3.8259186922235595
Epoch: 3682, Batch Gradient Norm after: 3.8259186922235595
Epoch 3683/10000, Prediction Accuracy = 63.56153846153846%, Loss = 0.008152060819646487
Epoch: 3683, Batch Gradient Norm: 3.881499115540372
Epoch: 3683, Batch Gradient Norm after: 3.881499115540372
Epoch 3684/10000, Prediction Accuracy = 63.27692307692309%, Loss = 0.008243717324848358
Epoch: 3684, Batch Gradient Norm: 4.1255411542065055
Epoch: 3684, Batch Gradient Norm after: 4.1255411542065055
Epoch 3685/10000, Prediction Accuracy = 63.13846153846154%, Loss = 0.00833687881151071
Epoch: 3685, Batch Gradient Norm: 3.9902892710572204
Epoch: 3685, Batch Gradient Norm after: 3.9902892710572204
Epoch 3686/10000, Prediction Accuracy = 63.25384615384616%, Loss = 0.008243696549190925
Epoch: 3686, Batch Gradient Norm: 3.9147945199754424
Epoch: 3686, Batch Gradient Norm after: 3.9147945199754424
Epoch 3687/10000, Prediction Accuracy = 64.05000000000001%, Loss = 0.008183201524214102
Epoch: 3687, Batch Gradient Norm: 4.110296336897223
Epoch: 3687, Batch Gradient Norm after: 4.110296336897223
Epoch 3688/10000, Prediction Accuracy = 63.96923076923077%, Loss = 0.00822915111740048
Epoch: 3688, Batch Gradient Norm: 4.057239509961965
Epoch: 3688, Batch Gradient Norm after: 4.057239509961965
Epoch 3689/10000, Prediction Accuracy = 63.39999999999999%, Loss = 0.008217022002029877
Epoch: 3689, Batch Gradient Norm: 3.814082968925346
Epoch: 3689, Batch Gradient Norm after: 3.814082968925346
Epoch 3690/10000, Prediction Accuracy = 63.82692307692308%, Loss = 0.008193395422914853
Epoch: 3690, Batch Gradient Norm: 4.256380274587927
Epoch: 3690, Batch Gradient Norm after: 4.256380274587927
Epoch 3691/10000, Prediction Accuracy = 63.04999999999999%, Loss = 0.0082908789985455
Epoch: 3691, Batch Gradient Norm: 3.970202538317703
Epoch: 3691, Batch Gradient Norm after: 3.970202538317703
Epoch 3692/10000, Prediction Accuracy = 63.6923076923077%, Loss = 0.008099840094263736
Epoch: 3692, Batch Gradient Norm: 4.116548721171242
Epoch: 3692, Batch Gradient Norm after: 4.116548721171242
Epoch 3693/10000, Prediction Accuracy = 63.215384615384615%, Loss = 0.008349392491464432
Epoch: 3693, Batch Gradient Norm: 4.294676120550996
Epoch: 3693, Batch Gradient Norm after: 4.294676120550996
Epoch 3694/10000, Prediction Accuracy = 63.03076923076924%, Loss = 0.008401798084378242
Epoch: 3694, Batch Gradient Norm: 4.3839729255110464
Epoch: 3694, Batch Gradient Norm after: 4.3839729255110464
Epoch 3695/10000, Prediction Accuracy = 63.39615384615385%, Loss = 0.008456613080432782
Epoch: 3695, Batch Gradient Norm: 3.5561365484377023
Epoch: 3695, Batch Gradient Norm after: 3.5561365484377023
Epoch 3696/10000, Prediction Accuracy = 64.03461538461539%, Loss = 0.008021899140798129
Epoch: 3696, Batch Gradient Norm: 3.8665449760884463
Epoch: 3696, Batch Gradient Norm after: 3.8665449760884463
Epoch 3697/10000, Prediction Accuracy = 63.83846153846153%, Loss = 0.00808601976873783
Epoch: 3697, Batch Gradient Norm: 3.9291911837999964
Epoch: 3697, Batch Gradient Norm after: 3.9291911837999964
Epoch 3698/10000, Prediction Accuracy = 63.86923076923077%, Loss = 0.008130555363515249
Epoch: 3698, Batch Gradient Norm: 3.914882279516427
Epoch: 3698, Batch Gradient Norm after: 3.914882279516427
Epoch 3699/10000, Prediction Accuracy = 63.734615384615374%, Loss = 0.008149730793845195
Epoch: 3699, Batch Gradient Norm: 4.243668218678333
Epoch: 3699, Batch Gradient Norm after: 4.243668218678333
Epoch 3700/10000, Prediction Accuracy = 63.66153846153846%, Loss = 0.008366003274344481
Epoch: 3700, Batch Gradient Norm: 3.7984282456441996
Epoch: 3700, Batch Gradient Norm after: 3.7984282456441996
Epoch 3701/10000, Prediction Accuracy = 64.01923076923077%, Loss = 0.008153265306296257
Epoch: 3701, Batch Gradient Norm: 4.0881599704089835
Epoch: 3701, Batch Gradient Norm after: 4.0881599704089835
Epoch 3702/10000, Prediction Accuracy = 63.1576923076923%, Loss = 0.008361958934424015
Epoch: 3702, Batch Gradient Norm: 3.886782967078966
Epoch: 3702, Batch Gradient Norm after: 3.886782967078966
Epoch 3703/10000, Prediction Accuracy = 63.18461538461539%, Loss = 0.008248020500804368
Epoch: 3703, Batch Gradient Norm: 3.875328089493897
Epoch: 3703, Batch Gradient Norm after: 3.875328089493897
Epoch 3704/10000, Prediction Accuracy = 63.50000000000001%, Loss = 0.00819495080325466
Epoch: 3704, Batch Gradient Norm: 3.8658756196417
Epoch: 3704, Batch Gradient Norm after: 3.8658756196417
Epoch 3705/10000, Prediction Accuracy = 63.561538461538476%, Loss = 0.008112081254904088
Epoch: 3705, Batch Gradient Norm: 4.189686378450885
Epoch: 3705, Batch Gradient Norm after: 4.189686378450885
Epoch 3706/10000, Prediction Accuracy = 63.3%, Loss = 0.00845493684307887
Epoch: 3706, Batch Gradient Norm: 3.9636474721261865
Epoch: 3706, Batch Gradient Norm after: 3.9636474721261865
Epoch 3707/10000, Prediction Accuracy = 63.27307692307692%, Loss = 0.008260382410998527
Epoch: 3707, Batch Gradient Norm: 3.679644305211125
Epoch: 3707, Batch Gradient Norm after: 3.679644305211125
Epoch 3708/10000, Prediction Accuracy = 63.869230769230775%, Loss = 0.008048617675040778
Epoch: 3708, Batch Gradient Norm: 3.772726447792853
Epoch: 3708, Batch Gradient Norm after: 3.772726447792853
Epoch 3709/10000, Prediction Accuracy = 64.04615384615384%, Loss = 0.008071196910280447
Epoch: 3709, Batch Gradient Norm: 4.026714263590569
Epoch: 3709, Batch Gradient Norm after: 4.026714263590569
Epoch 3710/10000, Prediction Accuracy = 63.48076923076923%, Loss = 0.008330928519941293
Epoch: 3710, Batch Gradient Norm: 4.071616037755021
Epoch: 3710, Batch Gradient Norm after: 4.071616037755021
Epoch 3711/10000, Prediction Accuracy = 63.43076923076922%, Loss = 0.008284431953842823
Epoch: 3711, Batch Gradient Norm: 4.135210000503314
Epoch: 3711, Batch Gradient Norm after: 4.135210000503314
Epoch 3712/10000, Prediction Accuracy = 63.361538461538466%, Loss = 0.008283262355969502
Epoch: 3712, Batch Gradient Norm: 3.895832623610168
Epoch: 3712, Batch Gradient Norm after: 3.895832623610168
Epoch 3713/10000, Prediction Accuracy = 64.26923076923077%, Loss = 0.008089467775649749
Epoch: 3713, Batch Gradient Norm: 4.188430094339991
Epoch: 3713, Batch Gradient Norm after: 4.188430094339991
Epoch 3714/10000, Prediction Accuracy = 63.638461538461534%, Loss = 0.008279281310164012
Epoch: 3714, Batch Gradient Norm: 4.126552151442705
Epoch: 3714, Batch Gradient Norm after: 4.126552151442705
Epoch 3715/10000, Prediction Accuracy = 63.16153846153847%, Loss = 0.00830599543853448
Epoch: 3715, Batch Gradient Norm: 4.053147596532168
Epoch: 3715, Batch Gradient Norm after: 4.053147596532168
Epoch 3716/10000, Prediction Accuracy = 63.48076923076922%, Loss = 0.008292447489041548
Epoch: 3716, Batch Gradient Norm: 4.341326408158856
Epoch: 3716, Batch Gradient Norm after: 4.341326408158856
Epoch 3717/10000, Prediction Accuracy = 63.68076923076923%, Loss = 0.008290087696737967
Epoch: 3717, Batch Gradient Norm: 3.9458164971410956
Epoch: 3717, Batch Gradient Norm after: 3.9458164971410956
Epoch 3718/10000, Prediction Accuracy = 63.66538461538461%, Loss = 0.008239406196830364
Epoch: 3718, Batch Gradient Norm: 3.7296206530683036
Epoch: 3718, Batch Gradient Norm after: 3.7296206530683036
Epoch 3719/10000, Prediction Accuracy = 64.11923076923077%, Loss = 0.008013890268137822
Epoch: 3719, Batch Gradient Norm: 3.700927121676918
Epoch: 3719, Batch Gradient Norm after: 3.700927121676918
Epoch 3720/10000, Prediction Accuracy = 63.846153846153854%, Loss = 0.007966587821451517
Epoch: 3720, Batch Gradient Norm: 3.5462647374507275
Epoch: 3720, Batch Gradient Norm after: 3.5462647374507275
Epoch 3721/10000, Prediction Accuracy = 64.21538461538461%, Loss = 0.007949087482232314
Epoch: 3721, Batch Gradient Norm: 3.7037720786622286
Epoch: 3721, Batch Gradient Norm after: 3.7037720786622286
Epoch 3722/10000, Prediction Accuracy = 64.62307692307694%, Loss = 0.007933602453424381
Epoch: 3722, Batch Gradient Norm: 4.2122410586183765
Epoch: 3722, Batch Gradient Norm after: 4.2122410586183765
Epoch 3723/10000, Prediction Accuracy = 63.276923076923076%, Loss = 0.0083268228201912
Epoch: 3723, Batch Gradient Norm: 3.780288547849197
Epoch: 3723, Batch Gradient Norm after: 3.780288547849197
Epoch 3724/10000, Prediction Accuracy = 64.25384615384615%, Loss = 0.00801618479622098
Epoch: 3724, Batch Gradient Norm: 3.7811441036930775
Epoch: 3724, Batch Gradient Norm after: 3.7811441036930775
Epoch 3725/10000, Prediction Accuracy = 64.12307692307692%, Loss = 0.00809540101685203
Epoch: 3725, Batch Gradient Norm: 3.986670425707696
Epoch: 3725, Batch Gradient Norm after: 3.986670425707696
Epoch 3726/10000, Prediction Accuracy = 63.51923076923077%, Loss = 0.008249835039560612
Epoch: 3726, Batch Gradient Norm: 4.172145088564257
Epoch: 3726, Batch Gradient Norm after: 4.172145088564257
Epoch 3727/10000, Prediction Accuracy = 63.342307692307685%, Loss = 0.008315865523540057
Epoch: 3727, Batch Gradient Norm: 3.6285741996167515
Epoch: 3727, Batch Gradient Norm after: 3.6285741996167515
Epoch 3728/10000, Prediction Accuracy = 64.49615384615385%, Loss = 0.007986656246850124
Epoch: 3728, Batch Gradient Norm: 3.7989551748157484
Epoch: 3728, Batch Gradient Norm after: 3.7989551748157484
Epoch 3729/10000, Prediction Accuracy = 63.79615384615385%, Loss = 0.00804913305462553
Epoch: 3729, Batch Gradient Norm: 3.623286034526381
Epoch: 3729, Batch Gradient Norm after: 3.623286034526381
Epoch 3730/10000, Prediction Accuracy = 64.29230769230769%, Loss = 0.007970784826634022
Epoch: 3730, Batch Gradient Norm: 3.708976975840269
Epoch: 3730, Batch Gradient Norm after: 3.708976975840269
Epoch 3731/10000, Prediction Accuracy = 64.33846153846153%, Loss = 0.008005938492715359
Epoch: 3731, Batch Gradient Norm: 4.075918549891716
Epoch: 3731, Batch Gradient Norm after: 4.075918549891716
Epoch 3732/10000, Prediction Accuracy = 63.90384615384615%, Loss = 0.008156457915902138
Epoch: 3732, Batch Gradient Norm: 4.334280038189458
Epoch: 3732, Batch Gradient Norm after: 4.334280038189458
Epoch 3733/10000, Prediction Accuracy = 63.234615384615395%, Loss = 0.008317589294165373
Epoch: 3733, Batch Gradient Norm: 3.879220686413104
Epoch: 3733, Batch Gradient Norm after: 3.879220686413104
Epoch 3734/10000, Prediction Accuracy = 63.61923076923077%, Loss = 0.008161461589714656
Epoch: 3734, Batch Gradient Norm: 4.039876999778005
Epoch: 3734, Batch Gradient Norm after: 4.039876999778005
Epoch 3735/10000, Prediction Accuracy = 63.57307692307692%, Loss = 0.008191678780489244
Epoch: 3735, Batch Gradient Norm: 4.029341511383093
Epoch: 3735, Batch Gradient Norm after: 4.029341511383093
Epoch 3736/10000, Prediction Accuracy = 63.099999999999994%, Loss = 0.008271226659417152
Epoch: 3736, Batch Gradient Norm: 4.349652124632935
Epoch: 3736, Batch Gradient Norm after: 4.349652124632935
Epoch 3737/10000, Prediction Accuracy = 63.54615384615385%, Loss = 0.008301603536193188
Epoch: 3737, Batch Gradient Norm: 3.8186569132957637
Epoch: 3737, Batch Gradient Norm after: 3.8186569132957637
Epoch 3738/10000, Prediction Accuracy = 63.873076923076916%, Loss = 0.008125662373808714
Epoch: 3738, Batch Gradient Norm: 4.012188372167602
Epoch: 3738, Batch Gradient Norm after: 4.012188372167602
Epoch 3739/10000, Prediction Accuracy = 63.615384615384606%, Loss = 0.008249040119923078
Epoch: 3739, Batch Gradient Norm: 4.009358183595498
Epoch: 3739, Batch Gradient Norm after: 4.009358183595498
Epoch 3740/10000, Prediction Accuracy = 63.657692307692315%, Loss = 0.008156319936880698
Epoch: 3740, Batch Gradient Norm: 3.985198228178179
Epoch: 3740, Batch Gradient Norm after: 3.985198228178179
Epoch 3741/10000, Prediction Accuracy = 63.70384615384614%, Loss = 0.008120399469939562
Epoch: 3741, Batch Gradient Norm: 3.546993535421068
Epoch: 3741, Batch Gradient Norm after: 3.546993535421068
Epoch 3742/10000, Prediction Accuracy = 64.06538461538462%, Loss = 0.007928392061820397
Epoch: 3742, Batch Gradient Norm: 3.6967006761918455
Epoch: 3742, Batch Gradient Norm after: 3.6967006761918455
Epoch 3743/10000, Prediction Accuracy = 64.41923076923077%, Loss = 0.007954440151269618
Epoch: 3743, Batch Gradient Norm: 4.08037140088811
Epoch: 3743, Batch Gradient Norm after: 4.08037140088811
Epoch 3744/10000, Prediction Accuracy = 64.39999999999999%, Loss = 0.008113164633799057
Epoch: 3744, Batch Gradient Norm: 4.543313095542449
Epoch: 3744, Batch Gradient Norm after: 4.543313095542449
Epoch 3745/10000, Prediction Accuracy = 63.00769230769231%, Loss = 0.008391653295033254
Epoch: 3745, Batch Gradient Norm: 4.29060057323473
Epoch: 3745, Batch Gradient Norm after: 4.29060057323473
Epoch 3746/10000, Prediction Accuracy = 63.5846153846154%, Loss = 0.008344138542620035
Epoch: 3746, Batch Gradient Norm: 4.018301601228297
Epoch: 3746, Batch Gradient Norm after: 4.018301601228297
Epoch 3747/10000, Prediction Accuracy = 63.04615384615384%, Loss = 0.008200309239327908
Epoch: 3747, Batch Gradient Norm: 4.259897855532057
Epoch: 3747, Batch Gradient Norm after: 4.259897855532057
Epoch 3748/10000, Prediction Accuracy = 63.19230769230769%, Loss = 0.008406372705044655
Epoch: 3748, Batch Gradient Norm: 4.392190658526664
Epoch: 3748, Batch Gradient Norm after: 4.392190658526664
Epoch 3749/10000, Prediction Accuracy = 62.630769230769246%, Loss = 0.008510514663962217
Epoch: 3749, Batch Gradient Norm: 3.7300949517219477
Epoch: 3749, Batch Gradient Norm after: 3.7300949517219477
Epoch 3750/10000, Prediction Accuracy = 63.69230769230769%, Loss = 0.008092143393766422
Epoch: 3750, Batch Gradient Norm: 3.552449955157533
Epoch: 3750, Batch Gradient Norm after: 3.552449955157533
Epoch 3751/10000, Prediction Accuracy = 64.12692307692308%, Loss = 0.00801352085545659
Epoch: 3751, Batch Gradient Norm: 3.787120892060168
Epoch: 3751, Batch Gradient Norm after: 3.787120892060168
Epoch 3752/10000, Prediction Accuracy = 64.01923076923079%, Loss = 0.00803363097545046
Epoch: 3752, Batch Gradient Norm: 3.891071132316387
Epoch: 3752, Batch Gradient Norm after: 3.891071132316387
Epoch 3753/10000, Prediction Accuracy = 64.14615384615385%, Loss = 0.008089819457381964
Epoch: 3753, Batch Gradient Norm: 3.780762230009277
Epoch: 3753, Batch Gradient Norm after: 3.780762230009277
Epoch 3754/10000, Prediction Accuracy = 64.3576923076923%, Loss = 0.007986270249463044
Epoch: 3754, Batch Gradient Norm: 4.159946585480434
Epoch: 3754, Batch Gradient Norm after: 4.159946585480434
Epoch 3755/10000, Prediction Accuracy = 63.892307692307696%, Loss = 0.008231423222101651
Epoch: 3755, Batch Gradient Norm: 4.1907947203965366
Epoch: 3755, Batch Gradient Norm after: 4.1907947203965366
Epoch 3756/10000, Prediction Accuracy = 62.95769230769231%, Loss = 0.008365192235662388
Epoch: 3756, Batch Gradient Norm: 3.992769563504709
Epoch: 3756, Batch Gradient Norm after: 3.992769563504709
Epoch 3757/10000, Prediction Accuracy = 63.18076923076923%, Loss = 0.00826244822774942
Epoch: 3757, Batch Gradient Norm: 3.6600377299375713
Epoch: 3757, Batch Gradient Norm after: 3.6600377299375713
Epoch 3758/10000, Prediction Accuracy = 63.75769230769231%, Loss = 0.00801131591344109
Epoch: 3758, Batch Gradient Norm: 3.628346897968295
Epoch: 3758, Batch Gradient Norm after: 3.628346897968295
Epoch 3759/10000, Prediction Accuracy = 64.33846153846153%, Loss = 0.007925030990288807
Epoch: 3759, Batch Gradient Norm: 3.635419966033586
Epoch: 3759, Batch Gradient Norm after: 3.635419966033586
Epoch 3760/10000, Prediction Accuracy = 64.18076923076923%, Loss = 0.007970989896700932
Epoch: 3760, Batch Gradient Norm: 3.857531614655424
Epoch: 3760, Batch Gradient Norm after: 3.857531614655424
Epoch 3761/10000, Prediction Accuracy = 63.534615384615385%, Loss = 0.008132946605865773
Epoch: 3761, Batch Gradient Norm: 3.9499890033627656
Epoch: 3761, Batch Gradient Norm after: 3.9499890033627656
Epoch 3762/10000, Prediction Accuracy = 63.780769230769224%, Loss = 0.008199160524572317
Epoch: 3762, Batch Gradient Norm: 4.026040944706308
Epoch: 3762, Batch Gradient Norm after: 4.026040944706308
Epoch 3763/10000, Prediction Accuracy = 63.6923076923077%, Loss = 0.008128357872080345
Epoch: 3763, Batch Gradient Norm: 3.9647101637289976
Epoch: 3763, Batch Gradient Norm after: 3.9647101637289976
Epoch 3764/10000, Prediction Accuracy = 63.45384615384616%, Loss = 0.008182513670852551
Epoch: 3764, Batch Gradient Norm: 4.012903278983757
Epoch: 3764, Batch Gradient Norm after: 4.012903278983757
Epoch 3765/10000, Prediction Accuracy = 63.83461538461539%, Loss = 0.00813112801943834
Epoch: 3765, Batch Gradient Norm: 4.082435052741913
Epoch: 3765, Batch Gradient Norm after: 4.082435052741913
Epoch 3766/10000, Prediction Accuracy = 63.62307692307692%, Loss = 0.008313629418038405
Epoch: 3766, Batch Gradient Norm: 3.9660332115113266
Epoch: 3766, Batch Gradient Norm after: 3.9660332115113266
Epoch 3767/10000, Prediction Accuracy = 63.607692307692304%, Loss = 0.008125762383525189
Epoch: 3767, Batch Gradient Norm: 4.453965117708917
Epoch: 3767, Batch Gradient Norm after: 4.453965117708917
Epoch 3768/10000, Prediction Accuracy = 62.93461538461539%, Loss = 0.008350751792582182
Epoch: 3768, Batch Gradient Norm: 3.666616592401355
Epoch: 3768, Batch Gradient Norm after: 3.666616592401355
Epoch 3769/10000, Prediction Accuracy = 64.31153846153848%, Loss = 0.00796341892475119
Epoch: 3769, Batch Gradient Norm: 3.818936472105624
Epoch: 3769, Batch Gradient Norm after: 3.818936472105624
Epoch 3770/10000, Prediction Accuracy = 64.0153846153846%, Loss = 0.008051666037107889
Epoch: 3770, Batch Gradient Norm: 4.560302674551363
Epoch: 3770, Batch Gradient Norm after: 4.560302674551363
Epoch 3771/10000, Prediction Accuracy = 63.184615384615384%, Loss = 0.008467997710865278
Epoch: 3771, Batch Gradient Norm: 4.198908664384917
Epoch: 3771, Batch Gradient Norm after: 4.198908664384917
Epoch 3772/10000, Prediction Accuracy = 63.37692307692308%, Loss = 0.008284752543729085
Epoch: 3772, Batch Gradient Norm: 4.07815991863683
Epoch: 3772, Batch Gradient Norm after: 4.07815991863683
Epoch 3773/10000, Prediction Accuracy = 63.60384615384616%, Loss = 0.008181383475088157
Epoch: 3773, Batch Gradient Norm: 3.8065071987724513
Epoch: 3773, Batch Gradient Norm after: 3.8065071987724513
Epoch 3774/10000, Prediction Accuracy = 63.807692307692314%, Loss = 0.008074450270774273
Epoch: 3774, Batch Gradient Norm: 4.139378526050228
Epoch: 3774, Batch Gradient Norm after: 4.139378526050228
Epoch 3775/10000, Prediction Accuracy = 63.38461538461539%, Loss = 0.008287355518684937
Epoch: 3775, Batch Gradient Norm: 4.039670456840284
Epoch: 3775, Batch Gradient Norm after: 4.039670456840284
Epoch 3776/10000, Prediction Accuracy = 63.7576923076923%, Loss = 0.008256156642276507
Epoch: 3776, Batch Gradient Norm: 3.8641945209383852
Epoch: 3776, Batch Gradient Norm after: 3.8641945209383852
Epoch 3777/10000, Prediction Accuracy = 63.6576923076923%, Loss = 0.00814263393672613
Epoch: 3777, Batch Gradient Norm: 3.886348731778625
Epoch: 3777, Batch Gradient Norm after: 3.886348731778625
Epoch 3778/10000, Prediction Accuracy = 63.6576923076923%, Loss = 0.008098406108239522
Epoch: 3778, Batch Gradient Norm: 4.332505456685291
Epoch: 3778, Batch Gradient Norm after: 4.332505456685291
Epoch 3779/10000, Prediction Accuracy = 63.00000000000001%, Loss = 0.008382091656900369
Epoch: 3779, Batch Gradient Norm: 3.8432914107775886
Epoch: 3779, Batch Gradient Norm after: 3.8432914107775886
Epoch 3780/10000, Prediction Accuracy = 63.900000000000006%, Loss = 0.008110546865142308
Epoch: 3780, Batch Gradient Norm: 4.1836937425871925
Epoch: 3780, Batch Gradient Norm after: 4.1836937425871925
Epoch 3781/10000, Prediction Accuracy = 63.580769230769235%, Loss = 0.008175743385576285
Epoch: 3781, Batch Gradient Norm: 3.9726229705146503
Epoch: 3781, Batch Gradient Norm after: 3.9726229705146503
Epoch 3782/10000, Prediction Accuracy = 63.76923076923076%, Loss = 0.008183820065684043
Epoch: 3782, Batch Gradient Norm: 3.662965050031289
Epoch: 3782, Batch Gradient Norm after: 3.662965050031289
Epoch 3783/10000, Prediction Accuracy = 64.21153846153847%, Loss = 0.007977341803220602
Epoch: 3783, Batch Gradient Norm: 3.6200824307567174
Epoch: 3783, Batch Gradient Norm after: 3.6200824307567174
Epoch 3784/10000, Prediction Accuracy = 64.05%, Loss = 0.008016514950073682
Epoch: 3784, Batch Gradient Norm: 3.6937200631018117
Epoch: 3784, Batch Gradient Norm after: 3.6937200631018117
Epoch 3785/10000, Prediction Accuracy = 63.76538461538461%, Loss = 0.008076654066546606
Epoch: 3785, Batch Gradient Norm: 4.103425735401813
Epoch: 3785, Batch Gradient Norm after: 4.103425735401813
Epoch 3786/10000, Prediction Accuracy = 63.68076923076923%, Loss = 0.008189516070370492
Epoch: 3786, Batch Gradient Norm: 4.095848583404952
Epoch: 3786, Batch Gradient Norm after: 4.095848583404952
Epoch 3787/10000, Prediction Accuracy = 64.04230769230769%, Loss = 0.008114209219526786
Epoch: 3787, Batch Gradient Norm: 3.7188040155555804
Epoch: 3787, Batch Gradient Norm after: 3.7188040155555804
Epoch 3788/10000, Prediction Accuracy = 63.934615384615384%, Loss = 0.007990424163066424
Epoch: 3788, Batch Gradient Norm: 3.7661052900540133
Epoch: 3788, Batch Gradient Norm after: 3.7661052900540133
Epoch 3789/10000, Prediction Accuracy = 63.82692307692308%, Loss = 0.008036636998160528
Epoch: 3789, Batch Gradient Norm: 4.117129529245867
Epoch: 3789, Batch Gradient Norm after: 4.117129529245867
Epoch 3790/10000, Prediction Accuracy = 63.53846153846154%, Loss = 0.008079142918666968
Epoch: 3790, Batch Gradient Norm: 4.118004563625622
Epoch: 3790, Batch Gradient Norm after: 4.118004563625622
Epoch 3791/10000, Prediction Accuracy = 63.8576923076923%, Loss = 0.00809617885030233
Epoch: 3791, Batch Gradient Norm: 4.535059003017289
Epoch: 3791, Batch Gradient Norm after: 4.535059003017289
Epoch 3792/10000, Prediction Accuracy = 62.95769230769231%, Loss = 0.00851142005278514
Epoch: 3792, Batch Gradient Norm: 4.517196906469017
Epoch: 3792, Batch Gradient Norm after: 4.517196906469017
Epoch 3793/10000, Prediction Accuracy = 62.592307692307685%, Loss = 0.00868298987356516
Epoch: 3793, Batch Gradient Norm: 4.1593646143860985
Epoch: 3793, Batch Gradient Norm after: 4.1593646143860985
Epoch 3794/10000, Prediction Accuracy = 63.276923076923076%, Loss = 0.008359222959440488
Epoch: 3794, Batch Gradient Norm: 4.168430163833153
Epoch: 3794, Batch Gradient Norm after: 4.168430163833153
Epoch 3795/10000, Prediction Accuracy = 63.18076923076923%, Loss = 0.008401958056940483
Epoch: 3795, Batch Gradient Norm: 4.223245894887825
Epoch: 3795, Batch Gradient Norm after: 4.223245894887825
Epoch 3796/10000, Prediction Accuracy = 63.33846153846153%, Loss = 0.008319774141105322
Epoch: 3796, Batch Gradient Norm: 4.042049377542219
Epoch: 3796, Batch Gradient Norm after: 4.042049377542219
Epoch 3797/10000, Prediction Accuracy = 63.665384615384625%, Loss = 0.008263492741836952
Epoch: 3797, Batch Gradient Norm: 3.857566588959243
Epoch: 3797, Batch Gradient Norm after: 3.857566588959243
Epoch 3798/10000, Prediction Accuracy = 63.76923076923077%, Loss = 0.008138471784499975
Epoch: 3798, Batch Gradient Norm: 3.7637385856479812
Epoch: 3798, Batch Gradient Norm after: 3.7637385856479812
Epoch 3799/10000, Prediction Accuracy = 64.11538461538461%, Loss = 0.008067592799376983
Epoch: 3799, Batch Gradient Norm: 4.094875422395307
Epoch: 3799, Batch Gradient Norm after: 4.094875422395307
Epoch 3800/10000, Prediction Accuracy = 63.57307692307691%, Loss = 0.008209663085066356
Epoch: 3800, Batch Gradient Norm: 4.174763165024881
Epoch: 3800, Batch Gradient Norm after: 4.174763165024881
Epoch 3801/10000, Prediction Accuracy = 63.28461538461538%, Loss = 0.008300321033367744
Epoch: 3801, Batch Gradient Norm: 3.973021160229616
Epoch: 3801, Batch Gradient Norm after: 3.973021160229616
Epoch 3802/10000, Prediction Accuracy = 63.93846153846155%, Loss = 0.00815176025319558
Epoch: 3802, Batch Gradient Norm: 4.283613641540926
Epoch: 3802, Batch Gradient Norm after: 4.283613641540926
Epoch 3803/10000, Prediction Accuracy = 62.973076923076924%, Loss = 0.008429143219613112
Epoch: 3803, Batch Gradient Norm: 4.289467379286255
Epoch: 3803, Batch Gradient Norm after: 4.289467379286255
Epoch 3804/10000, Prediction Accuracy = 63.157692307692294%, Loss = 0.008357394558305923
Epoch: 3804, Batch Gradient Norm: 4.178590064241931
Epoch: 3804, Batch Gradient Norm after: 4.178590064241931
Epoch 3805/10000, Prediction Accuracy = 63.43846153846155%, Loss = 0.008259653543623595
Epoch: 3805, Batch Gradient Norm: 4.064751590692839
Epoch: 3805, Batch Gradient Norm after: 4.064751590692839
Epoch 3806/10000, Prediction Accuracy = 63.86538461538461%, Loss = 0.008192464960022615
Epoch: 3806, Batch Gradient Norm: 3.821755581852338
Epoch: 3806, Batch Gradient Norm after: 3.821755581852338
Epoch 3807/10000, Prediction Accuracy = 63.92692307692309%, Loss = 0.008047706662462307
Epoch: 3807, Batch Gradient Norm: 3.786524027717441
Epoch: 3807, Batch Gradient Norm after: 3.786524027717441
Epoch 3808/10000, Prediction Accuracy = 63.99230769230769%, Loss = 0.008015499521906558
Epoch: 3808, Batch Gradient Norm: 4.186408310696195
Epoch: 3808, Batch Gradient Norm after: 4.186408310696195
Epoch 3809/10000, Prediction Accuracy = 63.13076923076923%, Loss = 0.008395921367292222
Epoch: 3809, Batch Gradient Norm: 4.168464456968092
Epoch: 3809, Batch Gradient Norm after: 4.168464456968092
Epoch 3810/10000, Prediction Accuracy = 63.396153846153844%, Loss = 0.008242758635718089
Epoch: 3810, Batch Gradient Norm: 3.8857060785663635
Epoch: 3810, Batch Gradient Norm after: 3.8857060785663635
Epoch 3811/10000, Prediction Accuracy = 63.915384615384625%, Loss = 0.008160618742784629
Epoch: 3811, Batch Gradient Norm: 4.087332097884229
Epoch: 3811, Batch Gradient Norm after: 4.087332097884229
Epoch 3812/10000, Prediction Accuracy = 63.819230769230785%, Loss = 0.008199841930316044
Epoch: 3812, Batch Gradient Norm: 4.1289268431550985
Epoch: 3812, Batch Gradient Norm after: 4.1289268431550985
Epoch 3813/10000, Prediction Accuracy = 63.13076923076922%, Loss = 0.00831729152168219
Epoch: 3813, Batch Gradient Norm: 4.454619706490422
Epoch: 3813, Batch Gradient Norm after: 4.454619706490422
Epoch 3814/10000, Prediction Accuracy = 63.065384615384616%, Loss = 0.008452209715659801
Epoch: 3814, Batch Gradient Norm: 4.021464785021392
Epoch: 3814, Batch Gradient Norm after: 4.021464785021392
Epoch 3815/10000, Prediction Accuracy = 63.807692307692314%, Loss = 0.008270303145624124
Epoch: 3815, Batch Gradient Norm: 4.212420954279486
Epoch: 3815, Batch Gradient Norm after: 4.212420954279486
Epoch 3816/10000, Prediction Accuracy = 62.74999999999999%, Loss = 0.00844719733756322
Epoch: 3816, Batch Gradient Norm: 3.967953057573047
Epoch: 3816, Batch Gradient Norm after: 3.967953057573047
Epoch 3817/10000, Prediction Accuracy = 63.830769230769235%, Loss = 0.008246865051870163
Epoch: 3817, Batch Gradient Norm: 3.779928781072535
Epoch: 3817, Batch Gradient Norm after: 3.779928781072535
Epoch 3818/10000, Prediction Accuracy = 63.81538461538464%, Loss = 0.008099646809009405
Epoch: 3818, Batch Gradient Norm: 3.8779572948570458
Epoch: 3818, Batch Gradient Norm after: 3.8779572948570458
Epoch 3819/10000, Prediction Accuracy = 64.0076923076923%, Loss = 0.008122820765353166
Epoch: 3819, Batch Gradient Norm: 3.908841018860683
Epoch: 3819, Batch Gradient Norm after: 3.908841018860683
Epoch 3820/10000, Prediction Accuracy = 64.23076923076923%, Loss = 0.00799451399451265
Epoch: 3820, Batch Gradient Norm: 3.869244324456405
Epoch: 3820, Batch Gradient Norm after: 3.869244324456405
Epoch 3821/10000, Prediction Accuracy = 64.30769230769232%, Loss = 0.008012635275148429
Epoch: 3821, Batch Gradient Norm: 4.102230613531307
Epoch: 3821, Batch Gradient Norm after: 4.102230613531307
Epoch 3822/10000, Prediction Accuracy = 63.64999999999999%, Loss = 0.008211358521993343
Epoch: 3822, Batch Gradient Norm: 4.095546588014326
Epoch: 3822, Batch Gradient Norm after: 4.095546588014326
Epoch 3823/10000, Prediction Accuracy = 63.557692307692314%, Loss = 0.008226484561768862
Epoch: 3823, Batch Gradient Norm: 3.678184767233923
Epoch: 3823, Batch Gradient Norm after: 3.678184767233923
Epoch 3824/10000, Prediction Accuracy = 64.32307692307694%, Loss = 0.007991728014670886
Epoch: 3824, Batch Gradient Norm: 3.802068421300845
Epoch: 3824, Batch Gradient Norm after: 3.802068421300845
Epoch 3825/10000, Prediction Accuracy = 64.35%, Loss = 0.008023846679582046
Epoch: 3825, Batch Gradient Norm: 4.006292387014652
Epoch: 3825, Batch Gradient Norm after: 4.006292387014652
Epoch 3826/10000, Prediction Accuracy = 63.79999999999999%, Loss = 0.008120289072394371
Epoch: 3826, Batch Gradient Norm: 3.853967919643223
Epoch: 3826, Batch Gradient Norm after: 3.853967919643223
Epoch 3827/10000, Prediction Accuracy = 64.54615384615384%, Loss = 0.007937152117777329
Epoch: 3827, Batch Gradient Norm: 3.806553913453693
Epoch: 3827, Batch Gradient Norm after: 3.806553913453693
Epoch 3828/10000, Prediction Accuracy = 63.776923076923076%, Loss = 0.008094519233474365
Epoch: 3828, Batch Gradient Norm: 4.1235163388867475
Epoch: 3828, Batch Gradient Norm after: 4.1235163388867475
Epoch 3829/10000, Prediction Accuracy = 63.77692307692307%, Loss = 0.00818857393012597
Epoch: 3829, Batch Gradient Norm: 3.804757222837114
Epoch: 3829, Batch Gradient Norm after: 3.804757222837114
Epoch 3830/10000, Prediction Accuracy = 64.09230769230768%, Loss = 0.00800433074339078
Epoch: 3830, Batch Gradient Norm: 3.8657899897981127
Epoch: 3830, Batch Gradient Norm after: 3.8657899897981127
Epoch 3831/10000, Prediction Accuracy = 64.4%, Loss = 0.008089499583897682
Epoch: 3831, Batch Gradient Norm: 4.12679872435242
Epoch: 3831, Batch Gradient Norm after: 4.12679872435242
Epoch 3832/10000, Prediction Accuracy = 63.61538461538461%, Loss = 0.008237973213768922
Epoch: 3832, Batch Gradient Norm: 3.8485049123823276
Epoch: 3832, Batch Gradient Norm after: 3.8485049123823276
Epoch 3833/10000, Prediction Accuracy = 64.09230769230768%, Loss = 0.008026979612902952
Epoch: 3833, Batch Gradient Norm: 4.174315454299975
Epoch: 3833, Batch Gradient Norm after: 4.174315454299975
Epoch 3834/10000, Prediction Accuracy = 63.25384615384616%, Loss = 0.008231683670041652
Epoch: 3834, Batch Gradient Norm: 3.9683096762796644
Epoch: 3834, Batch Gradient Norm after: 3.9683096762796644
Epoch 3835/10000, Prediction Accuracy = 64.16923076923077%, Loss = 0.008072617177206736
Epoch: 3835, Batch Gradient Norm: 3.951673415265823
Epoch: 3835, Batch Gradient Norm after: 3.951673415265823
Epoch 3836/10000, Prediction Accuracy = 64.35000000000001%, Loss = 0.008083569638144512
Epoch: 3836, Batch Gradient Norm: 3.960806297834051
Epoch: 3836, Batch Gradient Norm after: 3.960806297834051
Epoch 3837/10000, Prediction Accuracy = 63.9076923076923%, Loss = 0.00800259798192061
Epoch: 3837, Batch Gradient Norm: 3.8011923627333086
Epoch: 3837, Batch Gradient Norm after: 3.8011923627333086
Epoch 3838/10000, Prediction Accuracy = 63.79230769230771%, Loss = 0.007939766268604077
Epoch: 3838, Batch Gradient Norm: 3.726374125865058
Epoch: 3838, Batch Gradient Norm after: 3.726374125865058
Epoch 3839/10000, Prediction Accuracy = 64.11923076923077%, Loss = 0.007954248442099644
Epoch: 3839, Batch Gradient Norm: 3.775710781816906
Epoch: 3839, Batch Gradient Norm after: 3.775710781816906
Epoch 3840/10000, Prediction Accuracy = 64.21923076923076%, Loss = 0.007980163352420697
Epoch: 3840, Batch Gradient Norm: 3.995116202579796
Epoch: 3840, Batch Gradient Norm after: 3.995116202579796
Epoch 3841/10000, Prediction Accuracy = 64.10384615384615%, Loss = 0.008073881411781678
Epoch: 3841, Batch Gradient Norm: 4.10147741415528
Epoch: 3841, Batch Gradient Norm after: 4.10147741415528
Epoch 3842/10000, Prediction Accuracy = 63.676923076923075%, Loss = 0.00817719424286714
Epoch: 3842, Batch Gradient Norm: 3.979529279241057
Epoch: 3842, Batch Gradient Norm after: 3.979529279241057
Epoch 3843/10000, Prediction Accuracy = 64.10000000000001%, Loss = 0.007979729320280828
Epoch: 3843, Batch Gradient Norm: 3.8113960775428484
Epoch: 3843, Batch Gradient Norm after: 3.8113960775428484
Epoch 3844/10000, Prediction Accuracy = 64.61538461538461%, Loss = 0.007879993878304958
Epoch: 3844, Batch Gradient Norm: 3.755643250799879
Epoch: 3844, Batch Gradient Norm after: 3.755643250799879
Epoch 3845/10000, Prediction Accuracy = 64.82692307692308%, Loss = 0.007905851261546979
Epoch: 3845, Batch Gradient Norm: 4.166982477862901
Epoch: 3845, Batch Gradient Norm after: 4.166982477862901
Epoch 3846/10000, Prediction Accuracy = 63.48076923076922%, Loss = 0.008241546698487721
Epoch: 3846, Batch Gradient Norm: 3.8223200785580866
Epoch: 3846, Batch Gradient Norm after: 3.8223200785580866
Epoch 3847/10000, Prediction Accuracy = 64.32307692307691%, Loss = 0.007926014502747701
Epoch: 3847, Batch Gradient Norm: 3.793104586621673
Epoch: 3847, Batch Gradient Norm after: 3.793104586621673
Epoch 3848/10000, Prediction Accuracy = 64.26153846153846%, Loss = 0.007998237386345863
Epoch: 3848, Batch Gradient Norm: 3.9566816522422608
Epoch: 3848, Batch Gradient Norm after: 3.9566816522422608
Epoch 3849/10000, Prediction Accuracy = 64.38461538461537%, Loss = 0.007931242947681593
Epoch: 3849, Batch Gradient Norm: 4.37205347430094
Epoch: 3849, Batch Gradient Norm after: 4.37205347430094
Epoch 3850/10000, Prediction Accuracy = 63.45%, Loss = 0.008240419260870952
Epoch: 3850, Batch Gradient Norm: 4.639505934996496
Epoch: 3850, Batch Gradient Norm after: 4.639505934996496
Epoch 3851/10000, Prediction Accuracy = 62.94230769230769%, Loss = 0.008415125023860198
Epoch: 3851, Batch Gradient Norm: 4.044068492313686
Epoch: 3851, Batch Gradient Norm after: 4.044068492313686
Epoch 3852/10000, Prediction Accuracy = 63.36923076923077%, Loss = 0.008160344110085415
Epoch: 3852, Batch Gradient Norm: 3.959139147099756
Epoch: 3852, Batch Gradient Norm after: 3.959139147099756
Epoch 3853/10000, Prediction Accuracy = 63.78846153846154%, Loss = 0.00814041133540181
Epoch: 3853, Batch Gradient Norm: 3.7269666992394517
Epoch: 3853, Batch Gradient Norm after: 3.7269666992394517
Epoch 3854/10000, Prediction Accuracy = 64.33461538461539%, Loss = 0.007945316592947794
Epoch: 3854, Batch Gradient Norm: 3.9627848604042666
Epoch: 3854, Batch Gradient Norm after: 3.9627848604042666
Epoch 3855/10000, Prediction Accuracy = 64.17692307692309%, Loss = 0.008008568153644983
Epoch: 3855, Batch Gradient Norm: 3.82725692332271
Epoch: 3855, Batch Gradient Norm after: 3.82725692332271
Epoch 3856/10000, Prediction Accuracy = 63.67307692307691%, Loss = 0.008058077261711542
Epoch: 3856, Batch Gradient Norm: 3.6331641793666902
Epoch: 3856, Batch Gradient Norm after: 3.6331641793666902
Epoch 3857/10000, Prediction Accuracy = 64.33461538461539%, Loss = 0.007970308204396414
Epoch: 3857, Batch Gradient Norm: 4.017467068969394
Epoch: 3857, Batch Gradient Norm after: 4.017467068969394
Epoch 3858/10000, Prediction Accuracy = 63.465384615384615%, Loss = 0.008131403762560625
Epoch: 3858, Batch Gradient Norm: 3.8672194902267805
Epoch: 3858, Batch Gradient Norm after: 3.8672194902267805
Epoch 3859/10000, Prediction Accuracy = 64.00384615384615%, Loss = 0.00803336683804026
Epoch: 3859, Batch Gradient Norm: 3.5805697302333876
Epoch: 3859, Batch Gradient Norm after: 3.5805697302333876
Epoch 3860/10000, Prediction Accuracy = 64.42692307692309%, Loss = 0.00788622499945072
Epoch: 3860, Batch Gradient Norm: 3.7456338786189276
Epoch: 3860, Batch Gradient Norm after: 3.7456338786189276
Epoch 3861/10000, Prediction Accuracy = 64.11923076923077%, Loss = 0.007948106513000451
Epoch: 3861, Batch Gradient Norm: 4.494128726570519
Epoch: 3861, Batch Gradient Norm after: 4.494128726570519
Epoch 3862/10000, Prediction Accuracy = 62.81153846153846%, Loss = 0.008426364582891647
Epoch: 3862, Batch Gradient Norm: 4.16900578204231
Epoch: 3862, Batch Gradient Norm after: 4.16900578204231
Epoch 3863/10000, Prediction Accuracy = 63.607692307692304%, Loss = 0.008167827000411658
Epoch: 3863, Batch Gradient Norm: 3.998050830427097
Epoch: 3863, Batch Gradient Norm after: 3.998050830427097
Epoch 3864/10000, Prediction Accuracy = 63.607692307692304%, Loss = 0.008197421422944618
Epoch: 3864, Batch Gradient Norm: 4.02181417015466
Epoch: 3864, Batch Gradient Norm after: 4.02181417015466
Epoch 3865/10000, Prediction Accuracy = 63.603846153846135%, Loss = 0.008121778722852468
Epoch: 3865, Batch Gradient Norm: 4.223109731149879
Epoch: 3865, Batch Gradient Norm after: 4.223109731149879
Epoch 3866/10000, Prediction Accuracy = 63.68076923076922%, Loss = 0.008205375634133816
Epoch: 3866, Batch Gradient Norm: 3.632508947051581
Epoch: 3866, Batch Gradient Norm after: 3.632508947051581
Epoch 3867/10000, Prediction Accuracy = 64.24615384615386%, Loss = 0.007873449438753037
Epoch: 3867, Batch Gradient Norm: 3.849123209549611
Epoch: 3867, Batch Gradient Norm after: 3.849123209549611
Epoch 3868/10000, Prediction Accuracy = 64.08461538461539%, Loss = 0.008108522814626876
Epoch: 3868, Batch Gradient Norm: 3.7632014323243665
Epoch: 3868, Batch Gradient Norm after: 3.7632014323243665
Epoch 3869/10000, Prediction Accuracy = 64.54230769230769%, Loss = 0.007996356043104943
Epoch: 3869, Batch Gradient Norm: 4.185738275799623
Epoch: 3869, Batch Gradient Norm after: 4.185738275799623
Epoch 3870/10000, Prediction Accuracy = 63.846153846153854%, Loss = 0.00815018409719834
Epoch: 3870, Batch Gradient Norm: 4.357995207982898
Epoch: 3870, Batch Gradient Norm after: 4.357995207982898
Epoch 3871/10000, Prediction Accuracy = 63.51153846153846%, Loss = 0.008262814989743324
Epoch: 3871, Batch Gradient Norm: 4.429448992051224
Epoch: 3871, Batch Gradient Norm after: 4.429448992051224
Epoch 3872/10000, Prediction Accuracy = 62.669230769230765%, Loss = 0.008472404944208952
Epoch: 3872, Batch Gradient Norm: 4.161927748279592
Epoch: 3872, Batch Gradient Norm after: 4.161927748279592
Epoch 3873/10000, Prediction Accuracy = 62.823076923076925%, Loss = 0.008167941875469226
Epoch: 3873, Batch Gradient Norm: 3.985007419536302
Epoch: 3873, Batch Gradient Norm after: 3.985007419536302
Epoch 3874/10000, Prediction Accuracy = 63.32307692307692%, Loss = 0.008205238228233961
Epoch: 3874, Batch Gradient Norm: 3.8048309747178553
Epoch: 3874, Batch Gradient Norm after: 3.8048309747178553
Epoch 3875/10000, Prediction Accuracy = 63.81923076923078%, Loss = 0.008046107151760505
Epoch: 3875, Batch Gradient Norm: 4.045545212726446
Epoch: 3875, Batch Gradient Norm after: 4.045545212726446
Epoch 3876/10000, Prediction Accuracy = 63.85000000000001%, Loss = 0.008093701138232764
Epoch: 3876, Batch Gradient Norm: 4.3535970109268165
Epoch: 3876, Batch Gradient Norm after: 4.3535970109268165
Epoch 3877/10000, Prediction Accuracy = 63.59615384615385%, Loss = 0.008317441034775514
Epoch: 3877, Batch Gradient Norm: 4.246800401629641
Epoch: 3877, Batch Gradient Norm after: 4.246800401629641
Epoch 3878/10000, Prediction Accuracy = 63.54999999999999%, Loss = 0.00824362225830555
Epoch: 3878, Batch Gradient Norm: 4.146881751787447
Epoch: 3878, Batch Gradient Norm after: 4.146881751787447
Epoch 3879/10000, Prediction Accuracy = 63.76923076923076%, Loss = 0.008229519849499831
Epoch: 3879, Batch Gradient Norm: 4.123988368192614
Epoch: 3879, Batch Gradient Norm after: 4.123988368192614
Epoch 3880/10000, Prediction Accuracy = 63.4923076923077%, Loss = 0.008168391238611478
Epoch: 3880, Batch Gradient Norm: 3.9688097118373777
Epoch: 3880, Batch Gradient Norm after: 3.9688097118373777
Epoch 3881/10000, Prediction Accuracy = 63.865384615384606%, Loss = 0.008119389020766202
Epoch: 3881, Batch Gradient Norm: 3.953336753956599
Epoch: 3881, Batch Gradient Norm after: 3.953336753956599
Epoch 3882/10000, Prediction Accuracy = 64.22307692307693%, Loss = 0.00800990922233233
Epoch: 3882, Batch Gradient Norm: 4.143643420207557
Epoch: 3882, Batch Gradient Norm after: 4.143643420207557
Epoch 3883/10000, Prediction Accuracy = 64.01153846153846%, Loss = 0.00807493574057634
Epoch: 3883, Batch Gradient Norm: 4.359981391034164
Epoch: 3883, Batch Gradient Norm after: 4.359981391034164
Epoch 3884/10000, Prediction Accuracy = 63.28076923076924%, Loss = 0.008253939593067536
Epoch: 3884, Batch Gradient Norm: 3.9761775466476754
Epoch: 3884, Batch Gradient Norm after: 3.9761775466476754
Epoch 3885/10000, Prediction Accuracy = 64.02692307692308%, Loss = 0.008064584627460975
Epoch: 3885, Batch Gradient Norm: 3.8519007161577568
Epoch: 3885, Batch Gradient Norm after: 3.8519007161577568
Epoch 3886/10000, Prediction Accuracy = 64.11153846153846%, Loss = 0.00799077247770933
Epoch: 3886, Batch Gradient Norm: 4.122405726903069
Epoch: 3886, Batch Gradient Norm after: 4.122405726903069
Epoch 3887/10000, Prediction Accuracy = 63.75384615384617%, Loss = 0.008155883540614294
Epoch: 3887, Batch Gradient Norm: 4.203368090206174
Epoch: 3887, Batch Gradient Norm after: 4.203368090206174
Epoch 3888/10000, Prediction Accuracy = 63.719230769230776%, Loss = 0.008308604574547363
Epoch: 3888, Batch Gradient Norm: 3.795704624770073
Epoch: 3888, Batch Gradient Norm after: 3.795704624770073
Epoch 3889/10000, Prediction Accuracy = 64.21923076923076%, Loss = 0.007999001070857048
Epoch: 3889, Batch Gradient Norm: 3.9460880719486457
Epoch: 3889, Batch Gradient Norm after: 3.9460880719486457
Epoch 3890/10000, Prediction Accuracy = 64.21538461538461%, Loss = 0.008027730294718193
Epoch: 3890, Batch Gradient Norm: 3.7972469072712194
Epoch: 3890, Batch Gradient Norm after: 3.7972469072712194
Epoch 3891/10000, Prediction Accuracy = 64.18076923076923%, Loss = 0.007994791492819786
Epoch: 3891, Batch Gradient Norm: 4.23383522629696
Epoch: 3891, Batch Gradient Norm after: 4.23383522629696
Epoch 3892/10000, Prediction Accuracy = 63.24230769230769%, Loss = 0.008205695149417106
Epoch: 3892, Batch Gradient Norm: 4.487274510126884
Epoch: 3892, Batch Gradient Norm after: 4.487274510126884
Epoch 3893/10000, Prediction Accuracy = 63.21153846153847%, Loss = 0.008431356830092577
Epoch: 3893, Batch Gradient Norm: 4.264845365205688
Epoch: 3893, Batch Gradient Norm after: 4.264845365205688
Epoch 3894/10000, Prediction Accuracy = 63.396153846153844%, Loss = 0.008389137613658722
Epoch: 3894, Batch Gradient Norm: 4.064860731505024
Epoch: 3894, Batch Gradient Norm after: 4.064860731505024
Epoch 3895/10000, Prediction Accuracy = 63.71923076923076%, Loss = 0.008167110670071382
Epoch: 3895, Batch Gradient Norm: 3.797443167753283
Epoch: 3895, Batch Gradient Norm after: 3.797443167753283
Epoch 3896/10000, Prediction Accuracy = 64.03846153846153%, Loss = 0.008002047677739309
Epoch: 3896, Batch Gradient Norm: 3.656599554078523
Epoch: 3896, Batch Gradient Norm after: 3.656599554078523
Epoch 3897/10000, Prediction Accuracy = 64.40769230769232%, Loss = 0.00783554303388183
Epoch: 3897, Batch Gradient Norm: 4.219889977914418
Epoch: 3897, Batch Gradient Norm after: 4.219889977914418
Epoch 3898/10000, Prediction Accuracy = 63.49230769230769%, Loss = 0.008183059533341574
Epoch: 3898, Batch Gradient Norm: 4.1827872657410685
Epoch: 3898, Batch Gradient Norm after: 4.1827872657410685
Epoch 3899/10000, Prediction Accuracy = 63.41538461538461%, Loss = 0.0083345751493023
Epoch: 3899, Batch Gradient Norm: 4.044743118989534
Epoch: 3899, Batch Gradient Norm after: 4.044743118989534
Epoch 3900/10000, Prediction Accuracy = 63.98076923076924%, Loss = 0.008194089544793734
Epoch: 3900, Batch Gradient Norm: 4.471967815715575
Epoch: 3900, Batch Gradient Norm after: 4.471967815715575
Epoch 3901/10000, Prediction Accuracy = 62.80384615384615%, Loss = 0.008432924890747437
Epoch: 3901, Batch Gradient Norm: 4.433656458242744
Epoch: 3901, Batch Gradient Norm after: 4.433656458242744
Epoch 3902/10000, Prediction Accuracy = 63.3076923076923%, Loss = 0.00835461842899139
Epoch: 3902, Batch Gradient Norm: 4.07667141858666
Epoch: 3902, Batch Gradient Norm after: 4.07667141858666
Epoch 3903/10000, Prediction Accuracy = 63.71923076923077%, Loss = 0.008262610027136711
Epoch: 3903, Batch Gradient Norm: 3.9653743020004897
Epoch: 3903, Batch Gradient Norm after: 3.9653743020004897
Epoch 3904/10000, Prediction Accuracy = 63.91153846153846%, Loss = 0.008148993831127882
Epoch: 3904, Batch Gradient Norm: 4.244401618243199
Epoch: 3904, Batch Gradient Norm after: 4.244401618243199
Epoch 3905/10000, Prediction Accuracy = 63.5%, Loss = 0.008207809645682573
Epoch: 3905, Batch Gradient Norm: 3.8418176958825714
Epoch: 3905, Batch Gradient Norm after: 3.8418176958825714
Epoch 3906/10000, Prediction Accuracy = 63.80384615384616%, Loss = 0.008047038975816507
Epoch: 3906, Batch Gradient Norm: 3.783650338535702
Epoch: 3906, Batch Gradient Norm after: 3.783650338535702
Epoch 3907/10000, Prediction Accuracy = 64.46153846153847%, Loss = 0.007925822041355647
Epoch: 3907, Batch Gradient Norm: 3.696392989040771
Epoch: 3907, Batch Gradient Norm after: 3.696392989040771
Epoch 3908/10000, Prediction Accuracy = 64.46538461538461%, Loss = 0.007950821282485357
Epoch: 3908, Batch Gradient Norm: 4.065857045611803
Epoch: 3908, Batch Gradient Norm after: 4.065857045611803
Epoch 3909/10000, Prediction Accuracy = 63.58076923076922%, Loss = 0.008175921089087542
Epoch: 3909, Batch Gradient Norm: 4.104927455870628
Epoch: 3909, Batch Gradient Norm after: 4.104927455870628
Epoch 3910/10000, Prediction Accuracy = 63.723076923076924%, Loss = 0.008240352456386272
Epoch: 3910, Batch Gradient Norm: 4.015489982912557
Epoch: 3910, Batch Gradient Norm after: 4.015489982912557
Epoch 3911/10000, Prediction Accuracy = 63.64999999999999%, Loss = 0.008193236202574693
Epoch: 3911, Batch Gradient Norm: 4.226373128836673
Epoch: 3911, Batch Gradient Norm after: 4.226373128836673
Epoch 3912/10000, Prediction Accuracy = 63.484615384615374%, Loss = 0.008355109164348016
Epoch: 3912, Batch Gradient Norm: 3.8298763988968996
Epoch: 3912, Batch Gradient Norm after: 3.8298763988968996
Epoch 3913/10000, Prediction Accuracy = 63.48461538461539%, Loss = 0.008147035188113268
Epoch: 3913, Batch Gradient Norm: 3.75626624725433
Epoch: 3913, Batch Gradient Norm after: 3.75626624725433
Epoch 3914/10000, Prediction Accuracy = 64.10769230769232%, Loss = 0.007993569275221
Epoch: 3914, Batch Gradient Norm: 3.504203991875641
Epoch: 3914, Batch Gradient Norm after: 3.504203991875641
Epoch 3915/10000, Prediction Accuracy = 64.60000000000001%, Loss = 0.007879115748577394
Epoch: 3915, Batch Gradient Norm: 4.054448591909026
Epoch: 3915, Batch Gradient Norm after: 4.054448591909026
Epoch 3916/10000, Prediction Accuracy = 63.62692307692306%, Loss = 0.0081390322257693
Epoch: 3916, Batch Gradient Norm: 4.299063766708897
Epoch: 3916, Batch Gradient Norm after: 4.299063766708897
Epoch 3917/10000, Prediction Accuracy = 63.04230769230771%, Loss = 0.008258191474641744
Epoch: 3917, Batch Gradient Norm: 4.218135601587878
Epoch: 3917, Batch Gradient Norm after: 4.218135601587878
Epoch 3918/10000, Prediction Accuracy = 63.13461538461539%, Loss = 0.008213252760469913
Epoch: 3918, Batch Gradient Norm: 4.073074906110143
Epoch: 3918, Batch Gradient Norm after: 4.073074906110143
Epoch 3919/10000, Prediction Accuracy = 64.21538461538461%, Loss = 0.008083721622824669
Epoch: 3919, Batch Gradient Norm: 4.208571370138968
Epoch: 3919, Batch Gradient Norm after: 4.208571370138968
Epoch 3920/10000, Prediction Accuracy = 63.48461538461539%, Loss = 0.008160501002119137
Epoch: 3920, Batch Gradient Norm: 4.391678022372356
Epoch: 3920, Batch Gradient Norm after: 4.391678022372356
Epoch 3921/10000, Prediction Accuracy = 62.96538461538462%, Loss = 0.008295753684181433
Epoch: 3921, Batch Gradient Norm: 4.045510573039226
Epoch: 3921, Batch Gradient Norm after: 4.045510573039226
Epoch 3922/10000, Prediction Accuracy = 63.49615384615384%, Loss = 0.008196371141821146
Epoch: 3922, Batch Gradient Norm: 3.913321518450293
Epoch: 3922, Batch Gradient Norm after: 3.913321518450293
Epoch 3923/10000, Prediction Accuracy = 64.39999999999999%, Loss = 0.00797007934978375
Epoch: 3923, Batch Gradient Norm: 4.396151339627674
Epoch: 3923, Batch Gradient Norm after: 4.396151339627674
Epoch 3924/10000, Prediction Accuracy = 63.573076923076925%, Loss = 0.00823150661129218
Epoch: 3924, Batch Gradient Norm: 4.383277368064087
Epoch: 3924, Batch Gradient Norm after: 4.383277368064087
Epoch 3925/10000, Prediction Accuracy = 63.365384615384606%, Loss = 0.008368609114908256
Epoch: 3925, Batch Gradient Norm: 3.9267285113831525
Epoch: 3925, Batch Gradient Norm after: 3.9267285113831525
Epoch 3926/10000, Prediction Accuracy = 63.830769230769235%, Loss = 0.008105802779587416
Epoch: 3926, Batch Gradient Norm: 4.031406610499778
Epoch: 3926, Batch Gradient Norm after: 4.031406610499778
Epoch 3927/10000, Prediction Accuracy = 63.50384615384617%, Loss = 0.008109040271777373
Epoch: 3927, Batch Gradient Norm: 3.8494746197953726
Epoch: 3927, Batch Gradient Norm after: 3.8494746197953726
Epoch 3928/10000, Prediction Accuracy = 64.18846153846154%, Loss = 0.007976290447494159
Epoch: 3928, Batch Gradient Norm: 3.8344794012446073
Epoch: 3928, Batch Gradient Norm after: 3.8344794012446073
Epoch 3929/10000, Prediction Accuracy = 64.17307692307692%, Loss = 0.007949744136287617
Epoch: 3929, Batch Gradient Norm: 4.006686121299072
Epoch: 3929, Batch Gradient Norm after: 4.006686121299072
Epoch 3930/10000, Prediction Accuracy = 63.400000000000006%, Loss = 0.00809321953700139
Epoch: 3930, Batch Gradient Norm: 3.921503550638416
Epoch: 3930, Batch Gradient Norm after: 3.921503550638416
Epoch 3931/10000, Prediction Accuracy = 63.873076923076916%, Loss = 0.008034483422167026
Epoch: 3931, Batch Gradient Norm: 3.8260679086280667
Epoch: 3931, Batch Gradient Norm after: 3.8260679086280667
Epoch 3932/10000, Prediction Accuracy = 64.27307692307691%, Loss = 0.007928001837661633
Epoch: 3932, Batch Gradient Norm: 3.9829813802692517
Epoch: 3932, Batch Gradient Norm after: 3.9829813802692517
Epoch 3933/10000, Prediction Accuracy = 63.111538461538466%, Loss = 0.008187627849670557
Epoch: 3933, Batch Gradient Norm: 3.7923793554377347
Epoch: 3933, Batch Gradient Norm after: 3.7923793554377347
Epoch 3934/10000, Prediction Accuracy = 64.0076923076923%, Loss = 0.007968388497829437
Epoch: 3934, Batch Gradient Norm: 3.9356249598487913
Epoch: 3934, Batch Gradient Norm after: 3.9356249598487913
Epoch 3935/10000, Prediction Accuracy = 63.834615384615375%, Loss = 0.008072710058723506
Epoch: 3935, Batch Gradient Norm: 3.9728866273468895
Epoch: 3935, Batch Gradient Norm after: 3.9728866273468895
Epoch 3936/10000, Prediction Accuracy = 64.15384615384616%, Loss = 0.00795966934842559
Epoch: 3936, Batch Gradient Norm: 4.482368447870383
Epoch: 3936, Batch Gradient Norm after: 4.482368447870383
Epoch 3937/10000, Prediction Accuracy = 63.27307692307692%, Loss = 0.008374361392970268
Epoch: 3937, Batch Gradient Norm: 4.211666302132712
Epoch: 3937, Batch Gradient Norm after: 4.211666302132712
Epoch 3938/10000, Prediction Accuracy = 63.415384615384625%, Loss = 0.008288455518105855
Epoch: 3938, Batch Gradient Norm: 4.037100668818358
Epoch: 3938, Batch Gradient Norm after: 4.037100668818358
Epoch 3939/10000, Prediction Accuracy = 63.684615384615384%, Loss = 0.008158783858212141
Epoch: 3939, Batch Gradient Norm: 4.100777340114028
Epoch: 3939, Batch Gradient Norm after: 4.100777340114028
Epoch 3940/10000, Prediction Accuracy = 63.330769230769235%, Loss = 0.008243647117454272
Epoch: 3940, Batch Gradient Norm: 4.04459558646893
Epoch: 3940, Batch Gradient Norm after: 4.04459558646893
Epoch 3941/10000, Prediction Accuracy = 63.623076923076944%, Loss = 0.008216182020707773
Epoch: 3941, Batch Gradient Norm: 3.6984397570374576
Epoch: 3941, Batch Gradient Norm after: 3.6984397570374576
Epoch 3942/10000, Prediction Accuracy = 64.10384615384615%, Loss = 0.008011271568158498
Epoch: 3942, Batch Gradient Norm: 4.1785287727854445
Epoch: 3942, Batch Gradient Norm after: 4.1785287727854445
Epoch 3943/10000, Prediction Accuracy = 63.4423076923077%, Loss = 0.00827542355713936
Epoch: 3943, Batch Gradient Norm: 4.107594010194199
Epoch: 3943, Batch Gradient Norm after: 4.107594010194199
Epoch 3944/10000, Prediction Accuracy = 64.11153846153844%, Loss = 0.008082491703904592
Epoch: 3944, Batch Gradient Norm: 4.267630221302826
Epoch: 3944, Batch Gradient Norm after: 4.267630221302826
Epoch 3945/10000, Prediction Accuracy = 63.58461538461539%, Loss = 0.00823578990709323
Epoch: 3945, Batch Gradient Norm: 4.160940669779728
Epoch: 3945, Batch Gradient Norm after: 4.160940669779728
Epoch 3946/10000, Prediction Accuracy = 63.150000000000006%, Loss = 0.008213629516271444
Epoch: 3946, Batch Gradient Norm: 4.092191698949258
Epoch: 3946, Batch Gradient Norm after: 4.092191698949258
Epoch 3947/10000, Prediction Accuracy = 63.576923076923066%, Loss = 0.008195236898385562
Epoch: 3947, Batch Gradient Norm: 4.013446998879992
Epoch: 3947, Batch Gradient Norm after: 4.013446998879992
Epoch 3948/10000, Prediction Accuracy = 63.9423076923077%, Loss = 0.008116045966744423
Epoch: 3948, Batch Gradient Norm: 4.0201439414529485
Epoch: 3948, Batch Gradient Norm after: 4.0201439414529485
Epoch 3949/10000, Prediction Accuracy = 64.07307692307691%, Loss = 0.008141281119046303
Epoch: 3949, Batch Gradient Norm: 4.203334423756886
Epoch: 3949, Batch Gradient Norm after: 4.203334423756886
Epoch 3950/10000, Prediction Accuracy = 63.69615384615384%, Loss = 0.0081590642221272
Epoch: 3950, Batch Gradient Norm: 3.918156748848083
Epoch: 3950, Batch Gradient Norm after: 3.918156748848083
Epoch 3951/10000, Prediction Accuracy = 63.723076923076924%, Loss = 0.008058305793943314
Epoch: 3951, Batch Gradient Norm: 3.6058187358913343
Epoch: 3951, Batch Gradient Norm after: 3.6058187358913343
Epoch 3952/10000, Prediction Accuracy = 64.45769230769233%, Loss = 0.007794100755395798
Epoch: 3952, Batch Gradient Norm: 3.6464763375733096
Epoch: 3952, Batch Gradient Norm after: 3.6464763375733096
Epoch 3953/10000, Prediction Accuracy = 64.50384615384615%, Loss = 0.00787564367055893
Epoch: 3953, Batch Gradient Norm: 3.9937803641276792
Epoch: 3953, Batch Gradient Norm after: 3.9937803641276792
Epoch 3954/10000, Prediction Accuracy = 64.14615384615385%, Loss = 0.00800170387642888
Epoch: 3954, Batch Gradient Norm: 4.171555580171576
Epoch: 3954, Batch Gradient Norm after: 4.171555580171576
Epoch 3955/10000, Prediction Accuracy = 63.92692307692307%, Loss = 0.008168702479451895
Epoch: 3955, Batch Gradient Norm: 4.085013201131827
Epoch: 3955, Batch Gradient Norm after: 4.085013201131827
Epoch 3956/10000, Prediction Accuracy = 63.84999999999999%, Loss = 0.008073074850611962
Epoch: 3956, Batch Gradient Norm: 4.125271268951645
Epoch: 3956, Batch Gradient Norm after: 4.125271268951645
Epoch 3957/10000, Prediction Accuracy = 63.91923076923077%, Loss = 0.008024017792195082
Epoch: 3957, Batch Gradient Norm: 4.297754411813597
Epoch: 3957, Batch Gradient Norm after: 4.297754411813597
Epoch 3958/10000, Prediction Accuracy = 63.62692307692308%, Loss = 0.008201818232639478
Epoch: 3958, Batch Gradient Norm: 4.226142370128109
Epoch: 3958, Batch Gradient Norm after: 4.226142370128109
Epoch 3959/10000, Prediction Accuracy = 63.619230769230775%, Loss = 0.008208669507159637
Epoch: 3959, Batch Gradient Norm: 4.165466996824207
Epoch: 3959, Batch Gradient Norm after: 4.165466996824207
Epoch 3960/10000, Prediction Accuracy = 63.45384615384615%, Loss = 0.008202718606648536
Epoch: 3960, Batch Gradient Norm: 4.104738202752967
Epoch: 3960, Batch Gradient Norm after: 4.104738202752967
Epoch 3961/10000, Prediction Accuracy = 63.18461538461539%, Loss = 0.008181675838736387
Epoch: 3961, Batch Gradient Norm: 3.8575151017932425
Epoch: 3961, Batch Gradient Norm after: 3.8575151017932425
Epoch 3962/10000, Prediction Accuracy = 64.07307692307693%, Loss = 0.007967728190124035
Epoch: 3962, Batch Gradient Norm: 4.13278072631022
Epoch: 3962, Batch Gradient Norm after: 4.13278072631022
Epoch 3963/10000, Prediction Accuracy = 63.94615384615384%, Loss = 0.008088528823394042
Epoch: 3963, Batch Gradient Norm: 3.7706206953621355
Epoch: 3963, Batch Gradient Norm after: 3.7706206953621355
Epoch 3964/10000, Prediction Accuracy = 64.23846153846155%, Loss = 0.00797872793359252
Epoch: 3964, Batch Gradient Norm: 4.17187251682244
Epoch: 3964, Batch Gradient Norm after: 4.17187251682244
Epoch 3965/10000, Prediction Accuracy = 63.64615384615385%, Loss = 0.008152247119981509
Epoch: 3965, Batch Gradient Norm: 3.851868013512902
Epoch: 3965, Batch Gradient Norm after: 3.851868013512902
Epoch 3966/10000, Prediction Accuracy = 64.51923076923077%, Loss = 0.00803455925331666
Epoch: 3966, Batch Gradient Norm: 3.7598333744596206
Epoch: 3966, Batch Gradient Norm after: 3.7598333744596206
Epoch 3967/10000, Prediction Accuracy = 64.56923076923077%, Loss = 0.007921620164639674
Epoch: 3967, Batch Gradient Norm: 3.8804823987153876
Epoch: 3967, Batch Gradient Norm after: 3.8804823987153876
Epoch 3968/10000, Prediction Accuracy = 64.21923076923078%, Loss = 0.007998793744123898
Epoch: 3968, Batch Gradient Norm: 3.7012141499527624
Epoch: 3968, Batch Gradient Norm after: 3.7012141499527624
Epoch 3969/10000, Prediction Accuracy = 64.62692307692306%, Loss = 0.007874612732288929
Epoch: 3969, Batch Gradient Norm: 4.334341280630442
Epoch: 3969, Batch Gradient Norm after: 4.334341280630442
Epoch 3970/10000, Prediction Accuracy = 63.576923076923066%, Loss = 0.008165543110897908
Epoch: 3970, Batch Gradient Norm: 4.247827956740459
Epoch: 3970, Batch Gradient Norm after: 4.247827956740459
Epoch 3971/10000, Prediction Accuracy = 63.665384615384625%, Loss = 0.008120869393818654
Epoch: 3971, Batch Gradient Norm: 3.8144585625356227
Epoch: 3971, Batch Gradient Norm after: 3.8144585625356227
Epoch 3972/10000, Prediction Accuracy = 64.1%, Loss = 0.007944769870776396
Epoch: 3972, Batch Gradient Norm: 4.0441190632410535
Epoch: 3972, Batch Gradient Norm after: 4.0441190632410535
Epoch 3973/10000, Prediction Accuracy = 63.45384615384615%, Loss = 0.008078869575491318
Epoch: 3973, Batch Gradient Norm: 4.219406578698178
Epoch: 3973, Batch Gradient Norm after: 4.219406578698178
Epoch 3974/10000, Prediction Accuracy = 63.30384615384615%, Loss = 0.00821960624307394
Epoch: 3974, Batch Gradient Norm: 4.115359397811171
Epoch: 3974, Batch Gradient Norm after: 4.115359397811171
Epoch 3975/10000, Prediction Accuracy = 63.55%, Loss = 0.008044362605477754
Epoch: 3975, Batch Gradient Norm: 3.8436100742158668
Epoch: 3975, Batch Gradient Norm after: 3.8436100742158668
Epoch 3976/10000, Prediction Accuracy = 63.55384615384615%, Loss = 0.00802984145971445
Epoch: 3976, Batch Gradient Norm: 4.286857199098243
Epoch: 3976, Batch Gradient Norm after: 4.286857199098243
Epoch 3977/10000, Prediction Accuracy = 63.26538461538461%, Loss = 0.008262085549246807
Epoch: 3977, Batch Gradient Norm: 4.383416265425423
Epoch: 3977, Batch Gradient Norm after: 4.383416265425423
Epoch 3978/10000, Prediction Accuracy = 63.099999999999994%, Loss = 0.00827294996438118
Epoch: 3978, Batch Gradient Norm: 4.013668732675104
Epoch: 3978, Batch Gradient Norm after: 4.013668732675104
Epoch 3979/10000, Prediction Accuracy = 63.538461538461554%, Loss = 0.008146276339315452
Epoch: 3979, Batch Gradient Norm: 4.06361128713181
Epoch: 3979, Batch Gradient Norm after: 4.06361128713181
Epoch 3980/10000, Prediction Accuracy = 64.15%, Loss = 0.008001066995068239
Epoch: 3980, Batch Gradient Norm: 3.7988152201539074
Epoch: 3980, Batch Gradient Norm after: 3.7988152201539074
Epoch 3981/10000, Prediction Accuracy = 64.6076923076923%, Loss = 0.007870618468866898
Epoch: 3981, Batch Gradient Norm: 3.759673868772938
Epoch: 3981, Batch Gradient Norm after: 3.759673868772938
Epoch 3982/10000, Prediction Accuracy = 64.35384615384615%, Loss = 0.007889890291083317
Epoch: 3982, Batch Gradient Norm: 3.952430437479709
Epoch: 3982, Batch Gradient Norm after: 3.952430437479709
Epoch 3983/10000, Prediction Accuracy = 64.02692307692308%, Loss = 0.00794785924685689
Epoch: 3983, Batch Gradient Norm: 4.110576971359043
Epoch: 3983, Batch Gradient Norm after: 4.110576971359043
Epoch 3984/10000, Prediction Accuracy = 64.12692307692308%, Loss = 0.0080605699465825
Epoch: 3984, Batch Gradient Norm: 3.9076486670147244
Epoch: 3984, Batch Gradient Norm after: 3.9076486670147244
Epoch 3985/10000, Prediction Accuracy = 64.2923076923077%, Loss = 0.007850388136620704
Epoch: 3985, Batch Gradient Norm: 4.180143620329179
Epoch: 3985, Batch Gradient Norm after: 4.180143620329179
Epoch 3986/10000, Prediction Accuracy = 63.81923076923078%, Loss = 0.008041091908056002
Epoch: 3986, Batch Gradient Norm: 3.8087517378934357
Epoch: 3986, Batch Gradient Norm after: 3.8087517378934357
Epoch 3987/10000, Prediction Accuracy = 64.5923076923077%, Loss = 0.007906967057631565
Epoch: 3987, Batch Gradient Norm: 3.7839126577280995
Epoch: 3987, Batch Gradient Norm after: 3.7839126577280995
Epoch 3988/10000, Prediction Accuracy = 64.14615384615385%, Loss = 0.007984275607248912
Epoch: 3988, Batch Gradient Norm: 4.191000348589752
Epoch: 3988, Batch Gradient Norm after: 4.191000348589752
Epoch 3989/10000, Prediction Accuracy = 63.68461538461539%, Loss = 0.008101644746672649
Epoch: 3989, Batch Gradient Norm: 4.007924003435167
Epoch: 3989, Batch Gradient Norm after: 4.007924003435167
Epoch 3990/10000, Prediction Accuracy = 63.79230769230769%, Loss = 0.008005512412637472
Epoch: 3990, Batch Gradient Norm: 3.9217853282719775
Epoch: 3990, Batch Gradient Norm after: 3.9217853282719775
Epoch 3991/10000, Prediction Accuracy = 64.20384615384616%, Loss = 0.007911202103759233
Epoch: 3991, Batch Gradient Norm: 4.090455670929297
Epoch: 3991, Batch Gradient Norm after: 4.090455670929297
Epoch 3992/10000, Prediction Accuracy = 63.80384615384614%, Loss = 0.008097574759561282
Epoch: 3992, Batch Gradient Norm: 4.360473335617648
Epoch: 3992, Batch Gradient Norm after: 4.360473335617648
Epoch 3993/10000, Prediction Accuracy = 63.73461538461538%, Loss = 0.008200509294580955
Epoch: 3993, Batch Gradient Norm: 3.777318782555191
Epoch: 3993, Batch Gradient Norm after: 3.777318782555191
Epoch 3994/10000, Prediction Accuracy = 64.1076923076923%, Loss = 0.007939273419861611
Epoch: 3994, Batch Gradient Norm: 4.273294700335194
Epoch: 3994, Batch Gradient Norm after: 4.273294700335194
Epoch 3995/10000, Prediction Accuracy = 63.31923076923077%, Loss = 0.008264213621329803
Epoch: 3995, Batch Gradient Norm: 4.46106875758405
Epoch: 3995, Batch Gradient Norm after: 4.46106875758405
Epoch 3996/10000, Prediction Accuracy = 63.71923076923077%, Loss = 0.008214706913209878
Epoch: 3996, Batch Gradient Norm: 3.651420525394911
Epoch: 3996, Batch Gradient Norm after: 3.651420525394911
Epoch 3997/10000, Prediction Accuracy = 64.88846153846154%, Loss = 0.007799900208528225
Epoch: 3997, Batch Gradient Norm: 3.2814351064496825
Epoch: 3997, Batch Gradient Norm after: 3.2814351064496825
Epoch 3998/10000, Prediction Accuracy = 64.99999999999999%, Loss = 0.007689920970453666
Epoch: 3998, Batch Gradient Norm: 3.752332585475188
Epoch: 3998, Batch Gradient Norm after: 3.752332585475188
Epoch 3999/10000, Prediction Accuracy = 64.3576923076923%, Loss = 0.007878019080425683
Epoch: 3999, Batch Gradient Norm: 4.184190195771708
Epoch: 3999, Batch Gradient Norm after: 4.184190195771708
Epoch 4000/10000, Prediction Accuracy = 64.24999999999999%, Loss = 0.007957908253257092
Epoch: 4000, Batch Gradient Norm: 4.065604050382929
Epoch: 4000, Batch Gradient Norm after: 4.065604050382929
Epoch 4001/10000, Prediction Accuracy = 64.22307692307692%, Loss = 0.00797172893698399
Epoch: 4001, Batch Gradient Norm: 3.835106757138979
Epoch: 4001, Batch Gradient Norm after: 3.835106757138979
Epoch 4002/10000, Prediction Accuracy = 64.46923076923078%, Loss = 0.007864802932510009
Epoch: 4002, Batch Gradient Norm: 4.226774156870334
Epoch: 4002, Batch Gradient Norm after: 4.226774156870334
Epoch 4003/10000, Prediction Accuracy = 63.91153846153846%, Loss = 0.008059047592373995
Epoch: 4003, Batch Gradient Norm: 4.168767921297716
Epoch: 4003, Batch Gradient Norm after: 4.168767921297716
Epoch 4004/10000, Prediction Accuracy = 64.24999999999999%, Loss = 0.008012893394781994
Epoch: 4004, Batch Gradient Norm: 4.071730289369647
Epoch: 4004, Batch Gradient Norm after: 4.071730289369647
Epoch 4005/10000, Prediction Accuracy = 64.12307692307692%, Loss = 0.00806032121181488
Epoch: 4005, Batch Gradient Norm: 3.849322382376736
Epoch: 4005, Batch Gradient Norm after: 3.849322382376736
Epoch 4006/10000, Prediction Accuracy = 64.50384615384615%, Loss = 0.007838647132023023
Epoch: 4006, Batch Gradient Norm: 3.948987413257171
Epoch: 4006, Batch Gradient Norm after: 3.948987413257171
Epoch 4007/10000, Prediction Accuracy = 64.38076923076923%, Loss = 0.007867459959995288
Epoch: 4007, Batch Gradient Norm: 4.057637739899968
Epoch: 4007, Batch Gradient Norm after: 4.057637739899968
Epoch 4008/10000, Prediction Accuracy = 64.18846153846154%, Loss = 0.007968590702288426
Epoch: 4008, Batch Gradient Norm: 3.9676673571347454
Epoch: 4008, Batch Gradient Norm after: 3.9676673571347454
Epoch 4009/10000, Prediction Accuracy = 63.723076923076924%, Loss = 0.008007705211639404
Epoch: 4009, Batch Gradient Norm: 4.346433436591545
Epoch: 4009, Batch Gradient Norm after: 4.346433436591545
Epoch 4010/10000, Prediction Accuracy = 63.93846153846153%, Loss = 0.00809459825261281
Epoch: 4010, Batch Gradient Norm: 4.340664835665098
Epoch: 4010, Batch Gradient Norm after: 4.340664835665098
Epoch 4011/10000, Prediction Accuracy = 63.596153846153854%, Loss = 0.008216090213793974
Epoch: 4011, Batch Gradient Norm: 4.1714019527802835
Epoch: 4011, Batch Gradient Norm after: 4.1714019527802835
Epoch 4012/10000, Prediction Accuracy = 63.50000000000001%, Loss = 0.0081812020821067
Epoch: 4012, Batch Gradient Norm: 4.0733597913437585
Epoch: 4012, Batch Gradient Norm after: 4.0733597913437585
Epoch 4013/10000, Prediction Accuracy = 63.42692307692308%, Loss = 0.008068574986492213
Epoch: 4013, Batch Gradient Norm: 4.0941663211170445
Epoch: 4013, Batch Gradient Norm after: 4.0941663211170445
Epoch 4014/10000, Prediction Accuracy = 63.873076923076916%, Loss = 0.008063806005968498
Epoch: 4014, Batch Gradient Norm: 3.869694334260446
Epoch: 4014, Batch Gradient Norm after: 3.869694334260446
Epoch 4015/10000, Prediction Accuracy = 64.44615384615385%, Loss = 0.00795714625229056
Epoch: 4015, Batch Gradient Norm: 4.082285381720807
Epoch: 4015, Batch Gradient Norm after: 4.082285381720807
Epoch 4016/10000, Prediction Accuracy = 63.88076923076923%, Loss = 0.008016974880145146
Epoch: 4016, Batch Gradient Norm: 4.1712189973558
Epoch: 4016, Batch Gradient Norm after: 4.1712189973558
Epoch 4017/10000, Prediction Accuracy = 63.94615384615385%, Loss = 0.00810018009864367
Epoch: 4017, Batch Gradient Norm: 4.418231039222932
Epoch: 4017, Batch Gradient Norm after: 4.418231039222932
Epoch 4018/10000, Prediction Accuracy = 63.4653846153846%, Loss = 0.00829030372775518
Epoch: 4018, Batch Gradient Norm: 4.38590241263504
Epoch: 4018, Batch Gradient Norm after: 4.38590241263504
Epoch 4019/10000, Prediction Accuracy = 62.93846153846153%, Loss = 0.008332810364663601
Epoch: 4019, Batch Gradient Norm: 3.986270934183659
Epoch: 4019, Batch Gradient Norm after: 3.986270934183659
Epoch 4020/10000, Prediction Accuracy = 64.11538461538461%, Loss = 0.008054113122992791
Epoch: 4020, Batch Gradient Norm: 3.9844136309337896
Epoch: 4020, Batch Gradient Norm after: 3.9844136309337896
Epoch 4021/10000, Prediction Accuracy = 63.68846153846153%, Loss = 0.008069006726145744
Epoch: 4021, Batch Gradient Norm: 3.9751670321774464
Epoch: 4021, Batch Gradient Norm after: 3.9751670321774464
Epoch 4022/10000, Prediction Accuracy = 63.95384615384616%, Loss = 0.007989672478288412
Epoch: 4022, Batch Gradient Norm: 3.8746129826461706
Epoch: 4022, Batch Gradient Norm after: 3.8746129826461706
Epoch 4023/10000, Prediction Accuracy = 64.0923076923077%, Loss = 0.007943209583083024
Epoch: 4023, Batch Gradient Norm: 3.9060924752120068
Epoch: 4023, Batch Gradient Norm after: 3.9060924752120068
Epoch 4024/10000, Prediction Accuracy = 64.47692307692309%, Loss = 0.007934090179892687
Epoch: 4024, Batch Gradient Norm: 4.265569539199133
Epoch: 4024, Batch Gradient Norm after: 4.265569539199133
Epoch 4025/10000, Prediction Accuracy = 63.63461538461537%, Loss = 0.008129266914553367
Epoch: 4025, Batch Gradient Norm: 3.8963974621124473
Epoch: 4025, Batch Gradient Norm after: 3.8963974621124473
Epoch 4026/10000, Prediction Accuracy = 64.16153846153846%, Loss = 0.007964329220927678
Epoch: 4026, Batch Gradient Norm: 3.780964688551543
Epoch: 4026, Batch Gradient Norm after: 3.780964688551543
Epoch 4027/10000, Prediction Accuracy = 64.81153846153846%, Loss = 0.007915614136996178
Epoch: 4027, Batch Gradient Norm: 4.30142631256111
Epoch: 4027, Batch Gradient Norm after: 4.30142631256111
Epoch 4028/10000, Prediction Accuracy = 63.292307692307695%, Loss = 0.0083227137175317
Epoch: 4028, Batch Gradient Norm: 4.551458799552467
Epoch: 4028, Batch Gradient Norm after: 4.551458799552467
Epoch 4029/10000, Prediction Accuracy = 63.05384615384616%, Loss = 0.00840722475774013
Epoch: 4029, Batch Gradient Norm: 4.406826467078204
Epoch: 4029, Batch Gradient Norm after: 4.406826467078204
Epoch 4030/10000, Prediction Accuracy = 63.48846153846154%, Loss = 0.008320263837679075
Epoch: 4030, Batch Gradient Norm: 4.031497771887338
Epoch: 4030, Batch Gradient Norm after: 4.031497771887338
Epoch 4031/10000, Prediction Accuracy = 63.37692307692308%, Loss = 0.008201994431706576
Epoch: 4031, Batch Gradient Norm: 3.9310469177453298
Epoch: 4031, Batch Gradient Norm after: 3.9310469177453298
Epoch 4032/10000, Prediction Accuracy = 63.58846153846153%, Loss = 0.008037100510241894
Epoch: 4032, Batch Gradient Norm: 3.9442712182920743
Epoch: 4032, Batch Gradient Norm after: 3.9442712182920743
Epoch 4033/10000, Prediction Accuracy = 64.23846153846155%, Loss = 0.007961285658753835
Epoch: 4033, Batch Gradient Norm: 3.964097477873559
Epoch: 4033, Batch Gradient Norm after: 3.964097477873559
Epoch 4034/10000, Prediction Accuracy = 63.88461538461539%, Loss = 0.007987555223875321
Epoch: 4034, Batch Gradient Norm: 3.9177931635166106
Epoch: 4034, Batch Gradient Norm after: 3.9177931635166106
Epoch 4035/10000, Prediction Accuracy = 64.12307692307692%, Loss = 0.008050069786035098
Epoch: 4035, Batch Gradient Norm: 3.986085981730842
Epoch: 4035, Batch Gradient Norm after: 3.986085981730842
Epoch 4036/10000, Prediction Accuracy = 64.13846153846154%, Loss = 0.007997253085844792
Epoch: 4036, Batch Gradient Norm: 3.823038078836027
Epoch: 4036, Batch Gradient Norm after: 3.823038078836027
Epoch 4037/10000, Prediction Accuracy = 64.0%, Loss = 0.008042015242748536
Epoch: 4037, Batch Gradient Norm: 3.58218167905358
Epoch: 4037, Batch Gradient Norm after: 3.58218167905358
Epoch 4038/10000, Prediction Accuracy = 64.58846153846153%, Loss = 0.007866876486402292
Epoch: 4038, Batch Gradient Norm: 4.047697758373517
Epoch: 4038, Batch Gradient Norm after: 4.047697758373517
Epoch 4039/10000, Prediction Accuracy = 63.792307692307695%, Loss = 0.008027399317003213
Epoch: 4039, Batch Gradient Norm: 4.251434787540403
Epoch: 4039, Batch Gradient Norm after: 4.251434787540403
Epoch 4040/10000, Prediction Accuracy = 63.75000000000001%, Loss = 0.008079773997171568
Epoch: 4040, Batch Gradient Norm: 4.0456838513673885
Epoch: 4040, Batch Gradient Norm after: 4.0456838513673885
Epoch 4041/10000, Prediction Accuracy = 64.22692307692307%, Loss = 0.00789847418379325
Epoch: 4041, Batch Gradient Norm: 4.248761062132696
Epoch: 4041, Batch Gradient Norm after: 4.248761062132696
Epoch 4042/10000, Prediction Accuracy = 63.719230769230776%, Loss = 0.008155073827275863
Epoch: 4042, Batch Gradient Norm: 4.511529340080197
Epoch: 4042, Batch Gradient Norm after: 4.511529340080197
Epoch 4043/10000, Prediction Accuracy = 63.7576923076923%, Loss = 0.008268530373103343
Epoch: 4043, Batch Gradient Norm: 4.557191982923424
Epoch: 4043, Batch Gradient Norm after: 4.557191982923424
Epoch 4044/10000, Prediction Accuracy = 63.44615384615384%, Loss = 0.008343493637557212
Epoch: 4044, Batch Gradient Norm: 4.005436792671208
Epoch: 4044, Batch Gradient Norm after: 4.005436792671208
Epoch 4045/10000, Prediction Accuracy = 63.98846153846153%, Loss = 0.008124673273414373
Epoch: 4045, Batch Gradient Norm: 4.461042706995427
Epoch: 4045, Batch Gradient Norm after: 4.461042706995427
Epoch 4046/10000, Prediction Accuracy = 63.52692307692307%, Loss = 0.008309936437469263
Epoch: 4046, Batch Gradient Norm: 4.273253772613827
Epoch: 4046, Batch Gradient Norm after: 4.273253772613827
Epoch 4047/10000, Prediction Accuracy = 63.33846153846154%, Loss = 0.008297026658860536
Epoch: 4047, Batch Gradient Norm: 3.9817645598963503
Epoch: 4047, Batch Gradient Norm after: 3.9817645598963503
Epoch 4048/10000, Prediction Accuracy = 64.06538461538462%, Loss = 0.00807232574488108
Epoch: 4048, Batch Gradient Norm: 3.775439340099026
Epoch: 4048, Batch Gradient Norm after: 3.775439340099026
Epoch 4049/10000, Prediction Accuracy = 64.23846153846154%, Loss = 0.007845749684537832
Epoch: 4049, Batch Gradient Norm: 4.5509117638095855
Epoch: 4049, Batch Gradient Norm after: 4.5509117638095855
Epoch 4050/10000, Prediction Accuracy = 63.957692307692305%, Loss = 0.008112328198666755
Epoch: 4050, Batch Gradient Norm: 4.233241007745148
Epoch: 4050, Batch Gradient Norm after: 4.233241007745148
Epoch 4051/10000, Prediction Accuracy = 63.8423076923077%, Loss = 0.008110726037277626
Epoch: 4051, Batch Gradient Norm: 4.360066320102893
Epoch: 4051, Batch Gradient Norm after: 4.360066320102893
Epoch 4052/10000, Prediction Accuracy = 63.5346153846154%, Loss = 0.008240189868956804
Epoch: 4052, Batch Gradient Norm: 3.942266437040204
Epoch: 4052, Batch Gradient Norm after: 3.942266437040204
Epoch 4053/10000, Prediction Accuracy = 63.880769230769246%, Loss = 0.008126557912104405
Epoch: 4053, Batch Gradient Norm: 3.9360393227633526
Epoch: 4053, Batch Gradient Norm after: 3.9360393227633526
Epoch 4054/10000, Prediction Accuracy = 63.8423076923077%, Loss = 0.008109023543791128
Epoch: 4054, Batch Gradient Norm: 4.0503845038459225
Epoch: 4054, Batch Gradient Norm after: 4.0503845038459225
Epoch 4055/10000, Prediction Accuracy = 63.64230769230768%, Loss = 0.008031563045313725
Epoch: 4055, Batch Gradient Norm: 4.175072259456569
Epoch: 4055, Batch Gradient Norm after: 4.175072259456569
Epoch 4056/10000, Prediction Accuracy = 63.68076923076923%, Loss = 0.008112973426110469
Epoch: 4056, Batch Gradient Norm: 4.080994832219365
Epoch: 4056, Batch Gradient Norm after: 4.080994832219365
Epoch 4057/10000, Prediction Accuracy = 64.49230769230769%, Loss = 0.007982624873805504
Epoch: 4057, Batch Gradient Norm: 3.948843615152683
Epoch: 4057, Batch Gradient Norm after: 3.948843615152683
Epoch 4058/10000, Prediction Accuracy = 64.18846153846154%, Loss = 0.007891658550271621
Epoch: 4058, Batch Gradient Norm: 4.015664105544756
Epoch: 4058, Batch Gradient Norm after: 4.015664105544756
Epoch 4059/10000, Prediction Accuracy = 63.926923076923075%, Loss = 0.008024194528563665
Epoch: 4059, Batch Gradient Norm: 3.806397942526237
Epoch: 4059, Batch Gradient Norm after: 3.806397942526237
Epoch 4060/10000, Prediction Accuracy = 64.4846153846154%, Loss = 0.007894308234636601
Epoch: 4060, Batch Gradient Norm: 4.447804670797172
Epoch: 4060, Batch Gradient Norm after: 4.447804670797172
Epoch 4061/10000, Prediction Accuracy = 63.28076923076924%, Loss = 0.008346986312132616
Epoch: 4061, Batch Gradient Norm: 4.616967780254154
Epoch: 4061, Batch Gradient Norm after: 4.616967780254154
Epoch 4062/10000, Prediction Accuracy = 62.81923076923077%, Loss = 0.008470903652218672
Epoch: 4062, Batch Gradient Norm: 4.296472821105374
Epoch: 4062, Batch Gradient Norm after: 4.296472821105374
Epoch 4063/10000, Prediction Accuracy = 63.76153846153846%, Loss = 0.008128351854303708
Epoch: 4063, Batch Gradient Norm: 4.27735682389498
Epoch: 4063, Batch Gradient Norm after: 4.27735682389498
Epoch 4064/10000, Prediction Accuracy = 63.926923076923075%, Loss = 0.008123944871700726
Epoch: 4064, Batch Gradient Norm: 3.981352320204215
Epoch: 4064, Batch Gradient Norm after: 3.981352320204215
Epoch 4065/10000, Prediction Accuracy = 64.1076923076923%, Loss = 0.008017473066082368
Epoch: 4065, Batch Gradient Norm: 3.79207699453913
Epoch: 4065, Batch Gradient Norm after: 3.79207699453913
Epoch 4066/10000, Prediction Accuracy = 63.97692307692307%, Loss = 0.008023623162164139
Epoch: 4066, Batch Gradient Norm: 3.710184259602768
Epoch: 4066, Batch Gradient Norm after: 3.710184259602768
Epoch 4067/10000, Prediction Accuracy = 64.66923076923077%, Loss = 0.007782934591747248
Epoch: 4067, Batch Gradient Norm: 4.11714839187619
Epoch: 4067, Batch Gradient Norm after: 4.11714839187619
Epoch 4068/10000, Prediction Accuracy = 64.23461538461537%, Loss = 0.008078478849851169
Epoch: 4068, Batch Gradient Norm: 4.161216524452102
Epoch: 4068, Batch Gradient Norm after: 4.161216524452102
Epoch 4069/10000, Prediction Accuracy = 63.684615384615384%, Loss = 0.008134743055472007
Epoch: 4069, Batch Gradient Norm: 4.047687459229302
Epoch: 4069, Batch Gradient Norm after: 4.047687459229302
Epoch 4070/10000, Prediction Accuracy = 64.26153846153846%, Loss = 0.007981716189533472
Epoch: 4070, Batch Gradient Norm: 3.8551290085121375
Epoch: 4070, Batch Gradient Norm after: 3.8551290085121375
Epoch 4071/10000, Prediction Accuracy = 64.51538461538463%, Loss = 0.007938917833738603
Epoch: 4071, Batch Gradient Norm: 3.7097614392093874
Epoch: 4071, Batch Gradient Norm after: 3.7097614392093874
Epoch 4072/10000, Prediction Accuracy = 64.57692307692308%, Loss = 0.007836726529953571
Epoch: 4072, Batch Gradient Norm: 3.7950645539114394
Epoch: 4072, Batch Gradient Norm after: 3.7950645539114394
Epoch 4073/10000, Prediction Accuracy = 64.51153846153846%, Loss = 0.007857398309100132
Epoch: 4073, Batch Gradient Norm: 3.977623413567216
Epoch: 4073, Batch Gradient Norm after: 3.977623413567216
Epoch 4074/10000, Prediction Accuracy = 64.45384615384616%, Loss = 0.008048699810527839
Epoch: 4074, Batch Gradient Norm: 4.599077501071973
Epoch: 4074, Batch Gradient Norm after: 4.599077501071973
Epoch 4075/10000, Prediction Accuracy = 63.20769230769231%, Loss = 0.008339628720512757
Epoch: 4075, Batch Gradient Norm: 4.072467619546671
Epoch: 4075, Batch Gradient Norm after: 4.072467619546671
Epoch 4076/10000, Prediction Accuracy = 63.676923076923075%, Loss = 0.00814283169949284
Epoch: 4076, Batch Gradient Norm: 4.349498060610525
Epoch: 4076, Batch Gradient Norm after: 4.349498060610525
Epoch 4077/10000, Prediction Accuracy = 63.30384615384616%, Loss = 0.008313643316236826
Epoch: 4077, Batch Gradient Norm: 4.294094875234864
Epoch: 4077, Batch Gradient Norm after: 4.294094875234864
Epoch 4078/10000, Prediction Accuracy = 63.50384615384615%, Loss = 0.008269501061966786
Epoch: 4078, Batch Gradient Norm: 3.911780149720246
Epoch: 4078, Batch Gradient Norm after: 3.911780149720246
Epoch 4079/10000, Prediction Accuracy = 64.49615384615385%, Loss = 0.007978539233310865
Epoch: 4079, Batch Gradient Norm: 4.143270021027231
Epoch: 4079, Batch Gradient Norm after: 4.143270021027231
Epoch 4080/10000, Prediction Accuracy = 63.97307692307693%, Loss = 0.008087233711893741
Epoch: 4080, Batch Gradient Norm: 3.993830235686128
Epoch: 4080, Batch Gradient Norm after: 3.993830235686128
Epoch 4081/10000, Prediction Accuracy = 64.07307692307693%, Loss = 0.008009414439304518
Epoch: 4081, Batch Gradient Norm: 4.234653967558842
Epoch: 4081, Batch Gradient Norm after: 4.234653967558842
Epoch 4082/10000, Prediction Accuracy = 63.98461538461538%, Loss = 0.0081035873422829
Epoch: 4082, Batch Gradient Norm: 3.8412039573076733
Epoch: 4082, Batch Gradient Norm after: 3.8412039573076733
Epoch 4083/10000, Prediction Accuracy = 63.95384615384615%, Loss = 0.007975271007475944
Epoch: 4083, Batch Gradient Norm: 3.8453152804037494
Epoch: 4083, Batch Gradient Norm after: 3.8453152804037494
Epoch 4084/10000, Prediction Accuracy = 64.71538461538461%, Loss = 0.007869188423053576
Epoch: 4084, Batch Gradient Norm: 3.9350784844377555
Epoch: 4084, Batch Gradient Norm after: 3.9350784844377555
Epoch 4085/10000, Prediction Accuracy = 63.630769230769225%, Loss = 0.008004495229285497
Epoch: 4085, Batch Gradient Norm: 3.9623417524741704
Epoch: 4085, Batch Gradient Norm after: 3.9623417524741704
Epoch 4086/10000, Prediction Accuracy = 64.48846153846154%, Loss = 0.00800745662015218
Epoch: 4086, Batch Gradient Norm: 3.9149517286458844
Epoch: 4086, Batch Gradient Norm after: 3.9149517286458844
Epoch 4087/10000, Prediction Accuracy = 64.55384615384615%, Loss = 0.007935645488592295
Epoch: 4087, Batch Gradient Norm: 4.042012519311939
Epoch: 4087, Batch Gradient Norm after: 4.042012519311939
Epoch 4088/10000, Prediction Accuracy = 64.63846153846156%, Loss = 0.007871579593763901
Epoch: 4088, Batch Gradient Norm: 4.3179039203307426
Epoch: 4088, Batch Gradient Norm after: 4.3179039203307426
Epoch 4089/10000, Prediction Accuracy = 64.26153846153845%, Loss = 0.00812414693287932
Epoch: 4089, Batch Gradient Norm: 3.8571427691088376
Epoch: 4089, Batch Gradient Norm after: 3.8571427691088376
Epoch 4090/10000, Prediction Accuracy = 64.52692307692308%, Loss = 0.007893673072640713
Epoch: 4090, Batch Gradient Norm: 3.9135853316292883
Epoch: 4090, Batch Gradient Norm after: 3.9135853316292883
Epoch 4091/10000, Prediction Accuracy = 64.7576923076923%, Loss = 0.0077993950376716945
Epoch: 4091, Batch Gradient Norm: 4.079924890425975
Epoch: 4091, Batch Gradient Norm after: 4.079924890425975
Epoch 4092/10000, Prediction Accuracy = 64.78846153846155%, Loss = 0.007975240094730487
Epoch: 4092, Batch Gradient Norm: 4.653638629691382
Epoch: 4092, Batch Gradient Norm after: 4.653638629691382
Epoch 4093/10000, Prediction Accuracy = 62.965384615384615%, Loss = 0.008335083078306455
Epoch: 4093, Batch Gradient Norm: 4.022221780006923
Epoch: 4093, Batch Gradient Norm after: 4.022221780006923
Epoch 4094/10000, Prediction Accuracy = 63.99230769230769%, Loss = 0.007960682340825979
Epoch: 4094, Batch Gradient Norm: 4.087201306466291
Epoch: 4094, Batch Gradient Norm after: 4.087201306466291
Epoch 4095/10000, Prediction Accuracy = 63.81923076923077%, Loss = 0.008022297281198777
Epoch: 4095, Batch Gradient Norm: 3.794138969837253
Epoch: 4095, Batch Gradient Norm after: 3.794138969837253
Epoch 4096/10000, Prediction Accuracy = 64.21153846153847%, Loss = 0.007940784454918824
Epoch: 4096, Batch Gradient Norm: 4.041825947779867
Epoch: 4096, Batch Gradient Norm after: 4.041825947779867
Epoch 4097/10000, Prediction Accuracy = 63.93461538461538%, Loss = 0.008042556197883991
Epoch: 4097, Batch Gradient Norm: 3.9328816324253344
Epoch: 4097, Batch Gradient Norm after: 3.9328816324253344
Epoch 4098/10000, Prediction Accuracy = 64.14230769230768%, Loss = 0.007985511794686317
Epoch: 4098, Batch Gradient Norm: 4.055716097944611
Epoch: 4098, Batch Gradient Norm after: 4.055716097944611
Epoch 4099/10000, Prediction Accuracy = 63.95%, Loss = 0.007993207922062049
Epoch: 4099, Batch Gradient Norm: 4.216162021128002
Epoch: 4099, Batch Gradient Norm after: 4.216162021128002
Epoch 4100/10000, Prediction Accuracy = 63.4423076923077%, Loss = 0.008200567358961472
Epoch: 4100, Batch Gradient Norm: 4.4407407871999665
Epoch: 4100, Batch Gradient Norm after: 4.4407407871999665
Epoch 4101/10000, Prediction Accuracy = 63.46153846153845%, Loss = 0.008261151396884369
Epoch: 4101, Batch Gradient Norm: 4.256408472040152
Epoch: 4101, Batch Gradient Norm after: 4.256408472040152
Epoch 4102/10000, Prediction Accuracy = 64.16153846153844%, Loss = 0.008075590746907087
Epoch: 4102, Batch Gradient Norm: 4.125842941993301
Epoch: 4102, Batch Gradient Norm after: 4.125842941993301
Epoch 4103/10000, Prediction Accuracy = 64.55%, Loss = 0.008051730656566529
Epoch: 4103, Batch Gradient Norm: 4.465020505111329
Epoch: 4103, Batch Gradient Norm after: 4.465020505111329
Epoch 4104/10000, Prediction Accuracy = 63.5076923076923%, Loss = 0.008249214635445522
Epoch: 4104, Batch Gradient Norm: 4.023654454876023
Epoch: 4104, Batch Gradient Norm after: 4.023654454876023
Epoch 4105/10000, Prediction Accuracy = 63.81153846153847%, Loss = 0.008055728788559254
Epoch: 4105, Batch Gradient Norm: 3.6445480298362836
Epoch: 4105, Batch Gradient Norm after: 3.6445480298362836
Epoch 4106/10000, Prediction Accuracy = 64.26923076923077%, Loss = 0.007892019509409483
Epoch: 4106, Batch Gradient Norm: 4.000650882518221
Epoch: 4106, Batch Gradient Norm after: 4.000650882518221
Epoch 4107/10000, Prediction Accuracy = 63.96538461538462%, Loss = 0.008006352501419874
Epoch: 4107, Batch Gradient Norm: 4.551799276906542
Epoch: 4107, Batch Gradient Norm after: 4.551799276906542
Epoch 4108/10000, Prediction Accuracy = 63.19230769230769%, Loss = 0.008176585086263143
Epoch: 4108, Batch Gradient Norm: 4.673130423305353
Epoch: 4108, Batch Gradient Norm after: 4.673130423305353
Epoch 4109/10000, Prediction Accuracy = 62.665384615384625%, Loss = 0.008425749515971312
Epoch: 4109, Batch Gradient Norm: 4.523488550819589
Epoch: 4109, Batch Gradient Norm after: 4.523488550819589
Epoch 4110/10000, Prediction Accuracy = 63.18846153846153%, Loss = 0.008369115826029044
Epoch: 4110, Batch Gradient Norm: 4.258024010243656
Epoch: 4110, Batch Gradient Norm after: 4.258024010243656
Epoch 4111/10000, Prediction Accuracy = 63.29230769230769%, Loss = 0.008225294403158702
Epoch: 4111, Batch Gradient Norm: 4.066531398875537
Epoch: 4111, Batch Gradient Norm after: 4.066531398875537
Epoch 4112/10000, Prediction Accuracy = 64.02307692307691%, Loss = 0.008025885881999364
Epoch: 4112, Batch Gradient Norm: 4.271944659621568
Epoch: 4112, Batch Gradient Norm after: 4.271944659621568
Epoch 4113/10000, Prediction Accuracy = 64.05384615384617%, Loss = 0.008154053097734084
Epoch: 4113, Batch Gradient Norm: 4.102098543039748
Epoch: 4113, Batch Gradient Norm after: 4.102098543039748
Epoch 4114/10000, Prediction Accuracy = 63.41153846153846%, Loss = 0.0081142710450177
Epoch: 4114, Batch Gradient Norm: 4.200045949947199
Epoch: 4114, Batch Gradient Norm after: 4.200045949947199
Epoch 4115/10000, Prediction Accuracy = 63.719230769230776%, Loss = 0.008149160322948145
Epoch: 4115, Batch Gradient Norm: 4.157491078123603
Epoch: 4115, Batch Gradient Norm after: 4.157491078123603
Epoch 4116/10000, Prediction Accuracy = 63.834615384615375%, Loss = 0.008159661593918618
Epoch: 4116, Batch Gradient Norm: 3.768007325701172
Epoch: 4116, Batch Gradient Norm after: 3.768007325701172
Epoch 4117/10000, Prediction Accuracy = 64.07692307692308%, Loss = 0.007944216235325886
Epoch: 4117, Batch Gradient Norm: 3.717251958022117
Epoch: 4117, Batch Gradient Norm after: 3.717251958022117
Epoch 4118/10000, Prediction Accuracy = 65.13846153846154%, Loss = 0.00784613535954402
Epoch: 4118, Batch Gradient Norm: 3.9000598230940002
Epoch: 4118, Batch Gradient Norm after: 3.9000598230940002
Epoch 4119/10000, Prediction Accuracy = 64.35384615384616%, Loss = 0.007839487149165226
Epoch: 4119, Batch Gradient Norm: 4.2604277767093075
Epoch: 4119, Batch Gradient Norm after: 4.2604277767093075
Epoch 4120/10000, Prediction Accuracy = 64.28076923076924%, Loss = 0.00801251345099165
Epoch: 4120, Batch Gradient Norm: 3.7579754788668187
Epoch: 4120, Batch Gradient Norm after: 3.7579754788668187
Epoch 4121/10000, Prediction Accuracy = 64.78846153846153%, Loss = 0.007870124509701362
Epoch: 4121, Batch Gradient Norm: 4.5785197568133835
Epoch: 4121, Batch Gradient Norm after: 4.5785197568133835
Epoch 4122/10000, Prediction Accuracy = 63.330769230769235%, Loss = 0.008317605449030032
Epoch: 4122, Batch Gradient Norm: 4.299462933233232
Epoch: 4122, Batch Gradient Norm after: 4.299462933233232
Epoch 4123/10000, Prediction Accuracy = 64.32692307692307%, Loss = 0.008083429760657825
Epoch: 4123, Batch Gradient Norm: 4.236577947898887
Epoch: 4123, Batch Gradient Norm after: 4.236577947898887
Epoch 4124/10000, Prediction Accuracy = 63.99230769230769%, Loss = 0.008119752523131095
Epoch: 4124, Batch Gradient Norm: 3.8296819779902744
Epoch: 4124, Batch Gradient Norm after: 3.8296819779902744
Epoch 4125/10000, Prediction Accuracy = 64.11923076923077%, Loss = 0.00791601288633851
Epoch: 4125, Batch Gradient Norm: 4.569466531348303
Epoch: 4125, Batch Gradient Norm after: 4.569466531348303
Epoch 4126/10000, Prediction Accuracy = 63.62307692307691%, Loss = 0.008295404868057141
Epoch: 4126, Batch Gradient Norm: 4.348199783628686
Epoch: 4126, Batch Gradient Norm after: 4.348199783628686
Epoch 4127/10000, Prediction Accuracy = 63.65384615384615%, Loss = 0.008258955338253425
Epoch: 4127, Batch Gradient Norm: 4.178686920241545
Epoch: 4127, Batch Gradient Norm after: 4.178686920241545
Epoch 4128/10000, Prediction Accuracy = 64.02692307692307%, Loss = 0.00812241119834093
Epoch: 4128, Batch Gradient Norm: 4.006955378695602
Epoch: 4128, Batch Gradient Norm after: 4.006955378695602
Epoch 4129/10000, Prediction Accuracy = 64.13846153846154%, Loss = 0.007966135413600849
Epoch: 4129, Batch Gradient Norm: 4.287409344885306
Epoch: 4129, Batch Gradient Norm after: 4.287409344885306
Epoch 4130/10000, Prediction Accuracy = 63.62307692307692%, Loss = 0.008158628255701982
Epoch: 4130, Batch Gradient Norm: 4.397990972868204
Epoch: 4130, Batch Gradient Norm after: 4.397990972868204
Epoch 4131/10000, Prediction Accuracy = 63.215384615384615%, Loss = 0.008226894666082583
Epoch: 4131, Batch Gradient Norm: 4.183342871542733
Epoch: 4131, Batch Gradient Norm after: 4.183342871542733
Epoch 4132/10000, Prediction Accuracy = 63.5576923076923%, Loss = 0.008126487704710318
Epoch: 4132, Batch Gradient Norm: 3.793785276947295
Epoch: 4132, Batch Gradient Norm after: 3.793785276947295
Epoch 4133/10000, Prediction Accuracy = 64.7769230769231%, Loss = 0.0078646638430655
Epoch: 4133, Batch Gradient Norm: 3.95913555013147
Epoch: 4133, Batch Gradient Norm after: 3.95913555013147
Epoch 4134/10000, Prediction Accuracy = 64.06538461538462%, Loss = 0.008013711490023594
Epoch: 4134, Batch Gradient Norm: 3.7727493640921472
Epoch: 4134, Batch Gradient Norm after: 3.7727493640921472
Epoch 4135/10000, Prediction Accuracy = 64.60769230769232%, Loss = 0.007763248904106708
Epoch: 4135, Batch Gradient Norm: 4.26304457254311
Epoch: 4135, Batch Gradient Norm after: 4.26304457254311
Epoch 4136/10000, Prediction Accuracy = 64.26153846153846%, Loss = 0.00803086981893732
Epoch: 4136, Batch Gradient Norm: 4.353313106653317
Epoch: 4136, Batch Gradient Norm after: 4.353313106653317
Epoch 4137/10000, Prediction Accuracy = 64.00769230769232%, Loss = 0.008220019642836772
Epoch: 4137, Batch Gradient Norm: 3.830626933522768
Epoch: 4137, Batch Gradient Norm after: 3.830626933522768
Epoch 4138/10000, Prediction Accuracy = 63.9923076923077%, Loss = 0.007964538875967264
Epoch: 4138, Batch Gradient Norm: 4.194661012766064
Epoch: 4138, Batch Gradient Norm after: 4.194661012766064
Epoch 4139/10000, Prediction Accuracy = 63.60000000000001%, Loss = 0.008200552135419387
Epoch: 4139, Batch Gradient Norm: 4.277343535885243
Epoch: 4139, Batch Gradient Norm after: 4.277343535885243
Epoch 4140/10000, Prediction Accuracy = 63.19615384615385%, Loss = 0.008259262209041761
Epoch: 4140, Batch Gradient Norm: 4.093715705710027
Epoch: 4140, Batch Gradient Norm after: 4.093715705710027
Epoch 4141/10000, Prediction Accuracy = 63.57307692307693%, Loss = 0.008171353560800735
Epoch: 4141, Batch Gradient Norm: 3.740019945647494
Epoch: 4141, Batch Gradient Norm after: 3.740019945647494
Epoch 4142/10000, Prediction Accuracy = 64.23076923076924%, Loss = 0.007895330110421548
Epoch: 4142, Batch Gradient Norm: 3.704189973673914
Epoch: 4142, Batch Gradient Norm after: 3.704189973673914
Epoch 4143/10000, Prediction Accuracy = 64.96923076923076%, Loss = 0.007808748346108656
Epoch: 4143, Batch Gradient Norm: 4.31638323576329
Epoch: 4143, Batch Gradient Norm after: 4.31638323576329
Epoch 4144/10000, Prediction Accuracy = 63.75%, Loss = 0.008150775952694507
Epoch: 4144, Batch Gradient Norm: 4.150635636987708
Epoch: 4144, Batch Gradient Norm after: 4.150635636987708
Epoch 4145/10000, Prediction Accuracy = 63.284615384615385%, Loss = 0.008089442235919146
Epoch: 4145, Batch Gradient Norm: 3.986529431539675
Epoch: 4145, Batch Gradient Norm after: 3.986529431539675
Epoch 4146/10000, Prediction Accuracy = 64.1923076923077%, Loss = 0.00796757244433348
Epoch: 4146, Batch Gradient Norm: 3.8907607383891074
Epoch: 4146, Batch Gradient Norm after: 3.8907607383891074
Epoch 4147/10000, Prediction Accuracy = 64.48846153846154%, Loss = 0.00794477087373917
Epoch: 4147, Batch Gradient Norm: 3.6957788556188875
Epoch: 4147, Batch Gradient Norm after: 3.6957788556188875
Epoch 4148/10000, Prediction Accuracy = 64.61538461538461%, Loss = 0.00786434500836409
Epoch: 4148, Batch Gradient Norm: 4.228966778009312
Epoch: 4148, Batch Gradient Norm after: 4.228966778009312
Epoch 4149/10000, Prediction Accuracy = 64.06153846153846%, Loss = 0.008093137544794725
Epoch: 4149, Batch Gradient Norm: 3.8236013661505988
Epoch: 4149, Batch Gradient Norm after: 3.8236013661505988
Epoch 4150/10000, Prediction Accuracy = 64.48846153846154%, Loss = 0.00786533013272744
Epoch: 4150, Batch Gradient Norm: 4.03503288651893
Epoch: 4150, Batch Gradient Norm after: 4.03503288651893
Epoch 4151/10000, Prediction Accuracy = 64.38076923076923%, Loss = 0.007951237297115417
Epoch: 4151, Batch Gradient Norm: 4.084596211100495
Epoch: 4151, Batch Gradient Norm after: 4.084596211100495
Epoch 4152/10000, Prediction Accuracy = 64.02307692307691%, Loss = 0.00799334428917903
Epoch: 4152, Batch Gradient Norm: 3.8290184542338666
Epoch: 4152, Batch Gradient Norm after: 3.8290184542338666
Epoch 4153/10000, Prediction Accuracy = 64.57692307692307%, Loss = 0.007860414361437926
Epoch: 4153, Batch Gradient Norm: 3.61931040184411
Epoch: 4153, Batch Gradient Norm after: 3.61931040184411
Epoch 4154/10000, Prediction Accuracy = 64.82307692307693%, Loss = 0.007697863396830284
Epoch: 4154, Batch Gradient Norm: 3.8428448111875664
Epoch: 4154, Batch Gradient Norm after: 3.8428448111875664
Epoch 4155/10000, Prediction Accuracy = 64.4346153846154%, Loss = 0.007853076005211243
Epoch: 4155, Batch Gradient Norm: 4.2307688875133325
Epoch: 4155, Batch Gradient Norm after: 4.2307688875133325
Epoch 4156/10000, Prediction Accuracy = 63.807692307692314%, Loss = 0.0080917002633214
Epoch: 4156, Batch Gradient Norm: 4.291490057211729
Epoch: 4156, Batch Gradient Norm after: 4.291490057211729
Epoch 4157/10000, Prediction Accuracy = 63.43461538461538%, Loss = 0.008142258542088361
Epoch: 4157, Batch Gradient Norm: 4.124710806242663
Epoch: 4157, Batch Gradient Norm after: 4.124710806242663
Epoch 4158/10000, Prediction Accuracy = 64.0576923076923%, Loss = 0.008036083183609523
Epoch: 4158, Batch Gradient Norm: 3.8756247516619924
Epoch: 4158, Batch Gradient Norm after: 3.8756247516619924
Epoch 4159/10000, Prediction Accuracy = 63.97692307692307%, Loss = 0.00798604329331563
Epoch: 4159, Batch Gradient Norm: 4.083169373283502
Epoch: 4159, Batch Gradient Norm after: 4.083169373283502
Epoch 4160/10000, Prediction Accuracy = 64.11153846153844%, Loss = 0.007992212194949389
Epoch: 4160, Batch Gradient Norm: 3.9169613086084496
Epoch: 4160, Batch Gradient Norm after: 3.9169613086084496
Epoch 4161/10000, Prediction Accuracy = 64.37692307692306%, Loss = 0.007840918771062907
Epoch: 4161, Batch Gradient Norm: 3.8535392165200912
Epoch: 4161, Batch Gradient Norm after: 3.8535392165200912
Epoch 4162/10000, Prediction Accuracy = 64.49230769230768%, Loss = 0.007881494883734446
Epoch: 4162, Batch Gradient Norm: 4.2157307605714935
Epoch: 4162, Batch Gradient Norm after: 4.2157307605714935
Epoch 4163/10000, Prediction Accuracy = 64.15384615384616%, Loss = 0.008060787123842882
Epoch: 4163, Batch Gradient Norm: 3.9695797772257677
Epoch: 4163, Batch Gradient Norm after: 3.9695797772257677
Epoch 4164/10000, Prediction Accuracy = 64.08076923076923%, Loss = 0.007970901779257335
Epoch: 4164, Batch Gradient Norm: 4.1050303544502205
Epoch: 4164, Batch Gradient Norm after: 4.1050303544502205
Epoch 4165/10000, Prediction Accuracy = 64.2346153846154%, Loss = 0.00798423054556434
Epoch: 4165, Batch Gradient Norm: 4.394813511105561
Epoch: 4165, Batch Gradient Norm after: 4.394813511105561
Epoch 4166/10000, Prediction Accuracy = 63.81153846153847%, Loss = 0.008083688847434062
Epoch: 4166, Batch Gradient Norm: 4.030022927111516
Epoch: 4166, Batch Gradient Norm after: 4.030022927111516
Epoch 4167/10000, Prediction Accuracy = 64.05%, Loss = 0.008015834224911837
Epoch: 4167, Batch Gradient Norm: 4.380250710860514
Epoch: 4167, Batch Gradient Norm after: 4.380250710860514
Epoch 4168/10000, Prediction Accuracy = 63.9923076923077%, Loss = 0.008109149129058305
Epoch: 4168, Batch Gradient Norm: 4.18427667213483
Epoch: 4168, Batch Gradient Norm after: 4.18427667213483
Epoch 4169/10000, Prediction Accuracy = 63.73461538461538%, Loss = 0.008108187717600511
Epoch: 4169, Batch Gradient Norm: 4.020673885500494
Epoch: 4169, Batch Gradient Norm after: 4.020673885500494
Epoch 4170/10000, Prediction Accuracy = 64.71153846153847%, Loss = 0.007844663726595731
Epoch: 4170, Batch Gradient Norm: 4.326406793527977
Epoch: 4170, Batch Gradient Norm after: 4.326406793527977
Epoch 4171/10000, Prediction Accuracy = 64.15769230769232%, Loss = 0.008060036907688929
Epoch: 4171, Batch Gradient Norm: 4.172207801312898
Epoch: 4171, Batch Gradient Norm after: 4.172207801312898
Epoch 4172/10000, Prediction Accuracy = 63.68076923076924%, Loss = 0.008079081164816251
Epoch: 4172, Batch Gradient Norm: 4.038594516268892
Epoch: 4172, Batch Gradient Norm after: 4.038594516268892
Epoch 4173/10000, Prediction Accuracy = 63.94230769230769%, Loss = 0.00804752677392501
Epoch: 4173, Batch Gradient Norm: 4.01262806901106
Epoch: 4173, Batch Gradient Norm after: 4.01262806901106
Epoch 4174/10000, Prediction Accuracy = 64.37307692307692%, Loss = 0.007916289739883862
Epoch: 4174, Batch Gradient Norm: 4.146084510343446
Epoch: 4174, Batch Gradient Norm after: 4.146084510343446
Epoch 4175/10000, Prediction Accuracy = 64.11153846153846%, Loss = 0.007949723002429191
Epoch: 4175, Batch Gradient Norm: 4.393803812877623
Epoch: 4175, Batch Gradient Norm after: 4.393803812877623
Epoch 4176/10000, Prediction Accuracy = 63.934615384615384%, Loss = 0.008022278009985503
Epoch: 4176, Batch Gradient Norm: 4.571979599504598
Epoch: 4176, Batch Gradient Norm after: 4.571979599504598
Epoch 4177/10000, Prediction Accuracy = 63.55%, Loss = 0.008206537638146143
Epoch: 4177, Batch Gradient Norm: 4.2823779555246775
Epoch: 4177, Batch Gradient Norm after: 4.2823779555246775
Epoch 4178/10000, Prediction Accuracy = 64.4%, Loss = 0.008023058744863821
Epoch: 4178, Batch Gradient Norm: 4.09554837815007
Epoch: 4178, Batch Gradient Norm after: 4.09554837815007
Epoch 4179/10000, Prediction Accuracy = 64.00384615384617%, Loss = 0.007980054387679467
Epoch: 4179, Batch Gradient Norm: 4.087083546105787
Epoch: 4179, Batch Gradient Norm after: 4.087083546105787
Epoch 4180/10000, Prediction Accuracy = 63.876923076923084%, Loss = 0.00805485538708476
Epoch: 4180, Batch Gradient Norm: 3.8804135685763144
Epoch: 4180, Batch Gradient Norm after: 3.8804135685763144
Epoch 4181/10000, Prediction Accuracy = 64.37692307692308%, Loss = 0.007829656788649468
Epoch: 4181, Batch Gradient Norm: 4.346321190339648
Epoch: 4181, Batch Gradient Norm after: 4.346321190339648
Epoch 4182/10000, Prediction Accuracy = 64.02692307692308%, Loss = 0.008056404570547434
Epoch: 4182, Batch Gradient Norm: 4.2643494813421725
Epoch: 4182, Batch Gradient Norm after: 4.2643494813421725
Epoch 4183/10000, Prediction Accuracy = 64.21153846153847%, Loss = 0.00804849026294855
Epoch: 4183, Batch Gradient Norm: 3.934459965152097
Epoch: 4183, Batch Gradient Norm after: 3.934459965152097
Epoch 4184/10000, Prediction Accuracy = 64.62692307692306%, Loss = 0.007894948733827243
Epoch: 4184, Batch Gradient Norm: 4.528180782599981
Epoch: 4184, Batch Gradient Norm after: 4.528180782599981
Epoch 4185/10000, Prediction Accuracy = 63.52307692307693%, Loss = 0.008163923791681345
Epoch: 4185, Batch Gradient Norm: 4.114186516955096
Epoch: 4185, Batch Gradient Norm after: 4.114186516955096
Epoch 4186/10000, Prediction Accuracy = 64.45384615384616%, Loss = 0.00795336988253089
Epoch: 4186, Batch Gradient Norm: 3.9599213658450103
Epoch: 4186, Batch Gradient Norm after: 3.9599213658450103
Epoch 4187/10000, Prediction Accuracy = 64.13461538461539%, Loss = 0.007941619457247166
Epoch: 4187, Batch Gradient Norm: 3.7005626304486254
Epoch: 4187, Batch Gradient Norm after: 3.7005626304486254
Epoch 4188/10000, Prediction Accuracy = 64.68846153846154%, Loss = 0.007813598423336562
Epoch: 4188, Batch Gradient Norm: 4.220054743751655
Epoch: 4188, Batch Gradient Norm after: 4.220054743751655
Epoch 4189/10000, Prediction Accuracy = 64.24615384615385%, Loss = 0.008082052370390067
Epoch: 4189, Batch Gradient Norm: 3.9541109288568634
Epoch: 4189, Batch Gradient Norm after: 3.9541109288568634
Epoch 4190/10000, Prediction Accuracy = 64.5%, Loss = 0.007803419998918588
Epoch: 4190, Batch Gradient Norm: 4.255557873643998
Epoch: 4190, Batch Gradient Norm after: 4.255557873643998
Epoch 4191/10000, Prediction Accuracy = 64.56538461538462%, Loss = 0.007849695375905586
Epoch: 4191, Batch Gradient Norm: 4.479355378744553
Epoch: 4191, Batch Gradient Norm after: 4.479355378744553
Epoch 4192/10000, Prediction Accuracy = 63.54615384615384%, Loss = 0.008126589720352339
Epoch: 4192, Batch Gradient Norm: 4.201105880199818
Epoch: 4192, Batch Gradient Norm after: 4.201105880199818
Epoch 4193/10000, Prediction Accuracy = 64.13076923076923%, Loss = 0.008040310349315405
Epoch: 4193, Batch Gradient Norm: 3.773083130902165
Epoch: 4193, Batch Gradient Norm after: 3.773083130902165
Epoch 4194/10000, Prediction Accuracy = 64.61538461538463%, Loss = 0.007817050406279473
Epoch: 4194, Batch Gradient Norm: 3.9454127413015607
Epoch: 4194, Batch Gradient Norm after: 3.9454127413015607
Epoch 4195/10000, Prediction Accuracy = 64.62307692307692%, Loss = 0.00782643251407605
Epoch: 4195, Batch Gradient Norm: 4.154986117289141
Epoch: 4195, Batch Gradient Norm after: 4.154986117289141
Epoch 4196/10000, Prediction Accuracy = 63.98846153846153%, Loss = 0.008015265330099143
Epoch: 4196, Batch Gradient Norm: 4.298414572271739
Epoch: 4196, Batch Gradient Norm after: 4.298414572271739
Epoch 4197/10000, Prediction Accuracy = 63.523076923076935%, Loss = 0.008120225205157813
Epoch: 4197, Batch Gradient Norm: 4.072945289108155
Epoch: 4197, Batch Gradient Norm after: 4.072945289108155
Epoch 4198/10000, Prediction Accuracy = 64.03076923076922%, Loss = 0.008028891080847153
Epoch: 4198, Batch Gradient Norm: 3.925458307299526
Epoch: 4198, Batch Gradient Norm after: 3.925458307299526
Epoch 4199/10000, Prediction Accuracy = 64.48076923076923%, Loss = 0.007901533184429774
Epoch: 4199, Batch Gradient Norm: 3.8708610631540634
Epoch: 4199, Batch Gradient Norm after: 3.8708610631540634
Epoch 4200/10000, Prediction Accuracy = 64.48076923076923%, Loss = 0.007806669025180431
Epoch: 4200, Batch Gradient Norm: 4.144106858552944
Epoch: 4200, Batch Gradient Norm after: 4.144106858552944
Epoch 4201/10000, Prediction Accuracy = 63.900000000000006%, Loss = 0.007957015616389422
Epoch: 4201, Batch Gradient Norm: 4.579192932545568
Epoch: 4201, Batch Gradient Norm after: 4.579192932545568
Epoch 4202/10000, Prediction Accuracy = 63.69230769230769%, Loss = 0.008218738107154002
Epoch: 4202, Batch Gradient Norm: 4.20555075071959
Epoch: 4202, Batch Gradient Norm after: 4.20555075071959
Epoch 4203/10000, Prediction Accuracy = 63.9076923076923%, Loss = 0.008061162805041442
Epoch: 4203, Batch Gradient Norm: 4.4238683069278855
Epoch: 4203, Batch Gradient Norm after: 4.4238683069278855
Epoch 4204/10000, Prediction Accuracy = 63.576923076923066%, Loss = 0.008112438452931551
Epoch: 4204, Batch Gradient Norm: 4.45302321082396
Epoch: 4204, Batch Gradient Norm after: 4.45302321082396
Epoch 4205/10000, Prediction Accuracy = 63.19615384615384%, Loss = 0.008245624816761566
Epoch: 4205, Batch Gradient Norm: 3.9449974924862614
Epoch: 4205, Batch Gradient Norm after: 3.9449974924862614
Epoch 4206/10000, Prediction Accuracy = 63.74615384615385%, Loss = 0.007980932839787923
Epoch: 4206, Batch Gradient Norm: 4.301728432982148
Epoch: 4206, Batch Gradient Norm after: 4.301728432982148
Epoch 4207/10000, Prediction Accuracy = 64.01923076923076%, Loss = 0.008110387071680564
Epoch: 4207, Batch Gradient Norm: 3.7336108986994336
Epoch: 4207, Batch Gradient Norm after: 3.7336108986994336
Epoch 4208/10000, Prediction Accuracy = 64.57307692307691%, Loss = 0.007780264489925825
Epoch: 4208, Batch Gradient Norm: 4.347167671763701
Epoch: 4208, Batch Gradient Norm after: 4.347167671763701
Epoch 4209/10000, Prediction Accuracy = 64.04230769230769%, Loss = 0.00811545206950261
Epoch: 4209, Batch Gradient Norm: 4.451612233921384
Epoch: 4209, Batch Gradient Norm after: 4.451612233921384
Epoch 4210/10000, Prediction Accuracy = 63.50769230769231%, Loss = 0.008145867058864007
Epoch: 4210, Batch Gradient Norm: 3.7727862055884387
Epoch: 4210, Batch Gradient Norm after: 3.7727862055884387
Epoch 4211/10000, Prediction Accuracy = 64.63461538461539%, Loss = 0.007808202268699041
Epoch: 4211, Batch Gradient Norm: 4.312249523400308
Epoch: 4211, Batch Gradient Norm after: 4.312249523400308
Epoch 4212/10000, Prediction Accuracy = 63.800000000000004%, Loss = 0.008165507720640073
Epoch: 4212, Batch Gradient Norm: 4.553182597768633
Epoch: 4212, Batch Gradient Norm after: 4.553182597768633
Epoch 4213/10000, Prediction Accuracy = 63.79615384615384%, Loss = 0.00812579931404728
Epoch: 4213, Batch Gradient Norm: 4.561553844089478
Epoch: 4213, Batch Gradient Norm after: 4.561553844089478
Epoch 4214/10000, Prediction Accuracy = 63.43846153846153%, Loss = 0.008212121597562846
Epoch: 4214, Batch Gradient Norm: 3.9926501989806327
Epoch: 4214, Batch Gradient Norm after: 3.9926501989806327
Epoch 4215/10000, Prediction Accuracy = 64.46923076923078%, Loss = 0.007965636081420459
Epoch: 4215, Batch Gradient Norm: 3.9056297109373848
Epoch: 4215, Batch Gradient Norm after: 3.9056297109373848
Epoch 4216/10000, Prediction Accuracy = 65.05384615384617%, Loss = 0.00784116517752409
Epoch: 4216, Batch Gradient Norm: 3.99779108906443
Epoch: 4216, Batch Gradient Norm after: 3.99779108906443
Epoch 4217/10000, Prediction Accuracy = 63.7423076923077%, Loss = 0.007984873910362903
Epoch: 4217, Batch Gradient Norm: 4.070046400777736
Epoch: 4217, Batch Gradient Norm after: 4.070046400777736
Epoch 4218/10000, Prediction Accuracy = 64.2423076923077%, Loss = 0.007973640655668883
Epoch: 4218, Batch Gradient Norm: 4.024633002389717
Epoch: 4218, Batch Gradient Norm after: 4.024633002389717
Epoch 4219/10000, Prediction Accuracy = 64.06538461538462%, Loss = 0.00795444749438992
Epoch: 4219, Batch Gradient Norm: 3.8530083765978747
Epoch: 4219, Batch Gradient Norm after: 3.8530083765978747
Epoch 4220/10000, Prediction Accuracy = 64.60384615384615%, Loss = 0.007831264287233353
Epoch: 4220, Batch Gradient Norm: 4.170486235397812
Epoch: 4220, Batch Gradient Norm after: 4.170486235397812
Epoch 4221/10000, Prediction Accuracy = 64.54230769230769%, Loss = 0.00783405528188898
Epoch: 4221, Batch Gradient Norm: 4.292880469629455
Epoch: 4221, Batch Gradient Norm after: 4.292880469629455
Epoch 4222/10000, Prediction Accuracy = 63.95384615384616%, Loss = 0.008001360361679243
Epoch: 4222, Batch Gradient Norm: 3.8953914086209274
Epoch: 4222, Batch Gradient Norm after: 3.8953914086209274
Epoch 4223/10000, Prediction Accuracy = 64.61538461538463%, Loss = 0.007827640869296514
Epoch: 4223, Batch Gradient Norm: 4.3335598034868745
Epoch: 4223, Batch Gradient Norm after: 4.3335598034868745
Epoch 4224/10000, Prediction Accuracy = 64.16923076923077%, Loss = 0.00802345097494813
Epoch: 4224, Batch Gradient Norm: 4.305745439907453
Epoch: 4224, Batch Gradient Norm after: 4.305745439907453
Epoch 4225/10000, Prediction Accuracy = 63.83076923076923%, Loss = 0.008056930158860408
Epoch: 4225, Batch Gradient Norm: 4.369883793513682
Epoch: 4225, Batch Gradient Norm after: 4.369883793513682
Epoch 4226/10000, Prediction Accuracy = 63.71153846153846%, Loss = 0.008132298835195027
Epoch: 4226, Batch Gradient Norm: 4.207241750427125
Epoch: 4226, Batch Gradient Norm after: 4.207241750427125
Epoch 4227/10000, Prediction Accuracy = 63.37307692307692%, Loss = 0.008013825720319381
Epoch: 4227, Batch Gradient Norm: 4.246946930162339
Epoch: 4227, Batch Gradient Norm after: 4.246946930162339
Epoch 4228/10000, Prediction Accuracy = 63.8076923076923%, Loss = 0.00806759620228639
Epoch: 4228, Batch Gradient Norm: 3.7309794590788643
Epoch: 4228, Batch Gradient Norm after: 3.7309794590788643
Epoch 4229/10000, Prediction Accuracy = 64.53846153846155%, Loss = 0.00789608286980253
Epoch: 4229, Batch Gradient Norm: 4.235617684839949
Epoch: 4229, Batch Gradient Norm after: 4.235617684839949
Epoch 4230/10000, Prediction Accuracy = 63.78461538461538%, Loss = 0.00807972252368927
Epoch: 4230, Batch Gradient Norm: 3.677449836886806
Epoch: 4230, Batch Gradient Norm after: 3.677449836886806
Epoch 4231/10000, Prediction Accuracy = 64.67307692307692%, Loss = 0.007822788105561184
Epoch: 4231, Batch Gradient Norm: 3.988207568580789
Epoch: 4231, Batch Gradient Norm after: 3.988207568580789
Epoch 4232/10000, Prediction Accuracy = 64.31923076923077%, Loss = 0.00783948994313295
Epoch: 4232, Batch Gradient Norm: 3.3622410478928666
Epoch: 4232, Batch Gradient Norm after: 3.3622410478928666
Epoch 4233/10000, Prediction Accuracy = 65.43461538461538%, Loss = 0.0075446214311971115
Epoch: 4233, Batch Gradient Norm: 3.8711619582474937
Epoch: 4233, Batch Gradient Norm after: 3.8711619582474937
Epoch 4234/10000, Prediction Accuracy = 64.94615384615385%, Loss = 0.0077149231130113965
Epoch: 4234, Batch Gradient Norm: 3.755405044369975
Epoch: 4234, Batch Gradient Norm after: 3.755405044369975
Epoch 4235/10000, Prediction Accuracy = 65.1076923076923%, Loss = 0.007670856188409603
Epoch: 4235, Batch Gradient Norm: 4.219196115714987
Epoch: 4235, Batch Gradient Norm after: 4.219196115714987
Epoch 4236/10000, Prediction Accuracy = 64.33846153846153%, Loss = 0.007878537110697765
Epoch: 4236, Batch Gradient Norm: 4.5727145328844365
Epoch: 4236, Batch Gradient Norm after: 4.5727145328844365
Epoch 4237/10000, Prediction Accuracy = 63.24999999999999%, Loss = 0.008170759162077537
Epoch: 4237, Batch Gradient Norm: 4.065612252837069
Epoch: 4237, Batch Gradient Norm after: 4.065612252837069
Epoch 4238/10000, Prediction Accuracy = 64.24615384615385%, Loss = 0.007891413791534992
Epoch: 4238, Batch Gradient Norm: 4.103434204001901
Epoch: 4238, Batch Gradient Norm after: 4.103434204001901
Epoch 4239/10000, Prediction Accuracy = 64.4846153846154%, Loss = 0.007932724968458597
Epoch: 4239, Batch Gradient Norm: 4.379265591949474
Epoch: 4239, Batch Gradient Norm after: 4.379265591949474
Epoch 4240/10000, Prediction Accuracy = 63.81153846153846%, Loss = 0.008151374828930084
Epoch: 4240, Batch Gradient Norm: 4.03235256067699
Epoch: 4240, Batch Gradient Norm after: 4.03235256067699
Epoch 4241/10000, Prediction Accuracy = 64.30000000000001%, Loss = 0.007863849329833802
Epoch: 4241, Batch Gradient Norm: 3.9217557645023184
Epoch: 4241, Batch Gradient Norm after: 3.9217557645023184
Epoch 4242/10000, Prediction Accuracy = 64.3423076923077%, Loss = 0.007913853113467876
Epoch: 4242, Batch Gradient Norm: 4.25255992025844
Epoch: 4242, Batch Gradient Norm after: 4.25255992025844
Epoch 4243/10000, Prediction Accuracy = 63.74615384615384%, Loss = 0.008069294289900707
Epoch: 4243, Batch Gradient Norm: 4.26098422402714
Epoch: 4243, Batch Gradient Norm after: 4.26098422402714
Epoch 4244/10000, Prediction Accuracy = 64.00769230769231%, Loss = 0.008118526723522406
Epoch: 4244, Batch Gradient Norm: 4.017606624578337
Epoch: 4244, Batch Gradient Norm after: 4.017606624578337
Epoch 4245/10000, Prediction Accuracy = 64.2923076923077%, Loss = 0.007958661729040055
Epoch: 4245, Batch Gradient Norm: 3.861746509147872
Epoch: 4245, Batch Gradient Norm after: 3.861746509147872
Epoch 4246/10000, Prediction Accuracy = 64.52692307692308%, Loss = 0.007782153283747343
Epoch: 4246, Batch Gradient Norm: 4.568423542961181
Epoch: 4246, Batch Gradient Norm after: 4.568423542961181
Epoch 4247/10000, Prediction Accuracy = 63.176923076923075%, Loss = 0.008113370599368444
Epoch: 4247, Batch Gradient Norm: 4.339050597107268
Epoch: 4247, Batch Gradient Norm after: 4.339050597107268
Epoch 4248/10000, Prediction Accuracy = 63.776923076923076%, Loss = 0.008060272568120407
Epoch: 4248, Batch Gradient Norm: 4.17733787897912
Epoch: 4248, Batch Gradient Norm after: 4.17733787897912
Epoch 4249/10000, Prediction Accuracy = 64.49999999999999%, Loss = 0.007863684772298886
Epoch: 4249, Batch Gradient Norm: 4.068454823789644
Epoch: 4249, Batch Gradient Norm after: 4.068454823789644
Epoch 4250/10000, Prediction Accuracy = 64.25769230769231%, Loss = 0.00783522971547567
Epoch: 4250, Batch Gradient Norm: 4.144773687986797
Epoch: 4250, Batch Gradient Norm after: 4.144773687986797
Epoch 4251/10000, Prediction Accuracy = 64.50769230769231%, Loss = 0.00799433783126565
Epoch: 4251, Batch Gradient Norm: 4.383255188665361
Epoch: 4251, Batch Gradient Norm after: 4.383255188665361
Epoch 4252/10000, Prediction Accuracy = 63.75%, Loss = 0.008068187842861963
Epoch: 4252, Batch Gradient Norm: 4.201850278496151
Epoch: 4252, Batch Gradient Norm after: 4.201850278496151
Epoch 4253/10000, Prediction Accuracy = 63.25%, Loss = 0.00810513638246518
Epoch: 4253, Batch Gradient Norm: 4.118137727254028
Epoch: 4253, Batch Gradient Norm after: 4.118137727254028
Epoch 4254/10000, Prediction Accuracy = 64.1923076923077%, Loss = 0.007909713527904106
Epoch: 4254, Batch Gradient Norm: 3.589740016023963
Epoch: 4254, Batch Gradient Norm after: 3.589740016023963
Epoch 4255/10000, Prediction Accuracy = 64.95384615384616%, Loss = 0.007634945392895203
Epoch: 4255, Batch Gradient Norm: 3.802087304850781
Epoch: 4255, Batch Gradient Norm after: 3.802087304850781
Epoch 4256/10000, Prediction Accuracy = 64.38076923076923%, Loss = 0.0077167561349387355
Epoch: 4256, Batch Gradient Norm: 3.7725195046268034
Epoch: 4256, Batch Gradient Norm after: 3.7725195046268034
Epoch 4257/10000, Prediction Accuracy = 64.34615384615384%, Loss = 0.007793214315405259
Epoch: 4257, Batch Gradient Norm: 4.594900906460083
Epoch: 4257, Batch Gradient Norm after: 4.594900906460083
Epoch 4258/10000, Prediction Accuracy = 63.31538461538462%, Loss = 0.008256365473453816
Epoch: 4258, Batch Gradient Norm: 4.2445257091019934
Epoch: 4258, Batch Gradient Norm after: 4.2445257091019934
Epoch 4259/10000, Prediction Accuracy = 64.07307692307691%, Loss = 0.008060946129262447
Epoch: 4259, Batch Gradient Norm: 3.9249655030458754
Epoch: 4259, Batch Gradient Norm after: 3.9249655030458754
Epoch 4260/10000, Prediction Accuracy = 64.38076923076923%, Loss = 0.007886521195849547
Epoch: 4260, Batch Gradient Norm: 3.845132218637207
Epoch: 4260, Batch Gradient Norm after: 3.845132218637207
Epoch 4261/10000, Prediction Accuracy = 64.73846153846154%, Loss = 0.007823606953024864
Epoch: 4261, Batch Gradient Norm: 4.287104229456688
Epoch: 4261, Batch Gradient Norm after: 4.287104229456688
Epoch 4262/10000, Prediction Accuracy = 64.03846153846153%, Loss = 0.008046343707694458
Epoch: 4262, Batch Gradient Norm: 4.119817006886693
Epoch: 4262, Batch Gradient Norm after: 4.119817006886693
Epoch 4263/10000, Prediction Accuracy = 64.56923076923077%, Loss = 0.007875272789253639
Epoch: 4263, Batch Gradient Norm: 4.181766409182121
Epoch: 4263, Batch Gradient Norm after: 4.181766409182121
Epoch 4264/10000, Prediction Accuracy = 64.55384615384615%, Loss = 0.007796663576020644
Epoch: 4264, Batch Gradient Norm: 3.8748344141750484
Epoch: 4264, Batch Gradient Norm after: 3.8748344141750484
Epoch 4265/10000, Prediction Accuracy = 64.44230769230768%, Loss = 0.007834534196612926
Epoch: 4265, Batch Gradient Norm: 3.6802709387199095
Epoch: 4265, Batch Gradient Norm after: 3.6802709387199095
Epoch 4266/10000, Prediction Accuracy = 64.82692307692307%, Loss = 0.007682890523798191
Epoch: 4266, Batch Gradient Norm: 4.419295987427744
Epoch: 4266, Batch Gradient Norm after: 4.419295987427744
Epoch 4267/10000, Prediction Accuracy = 63.20384615384615%, Loss = 0.008078285242215945
Epoch: 4267, Batch Gradient Norm: 4.318551590903933
Epoch: 4267, Batch Gradient Norm after: 4.318551590903933
Epoch 4268/10000, Prediction Accuracy = 63.892307692307696%, Loss = 0.008035746009017412
Epoch: 4268, Batch Gradient Norm: 4.334828666781651
Epoch: 4268, Batch Gradient Norm after: 4.334828666781651
Epoch 4269/10000, Prediction Accuracy = 64.03461538461539%, Loss = 0.00805923192260357
Epoch: 4269, Batch Gradient Norm: 3.9701664381426074
Epoch: 4269, Batch Gradient Norm after: 3.9701664381426074
Epoch 4270/10000, Prediction Accuracy = 64.67692307692307%, Loss = 0.007858768929369174
Epoch: 4270, Batch Gradient Norm: 4.122714560998623
Epoch: 4270, Batch Gradient Norm after: 4.122714560998623
Epoch 4271/10000, Prediction Accuracy = 64.06923076923077%, Loss = 0.007988849332412848
Epoch: 4271, Batch Gradient Norm: 4.359619477990452
Epoch: 4271, Batch Gradient Norm after: 4.359619477990452
Epoch 4272/10000, Prediction Accuracy = 64.06153846153846%, Loss = 0.008098787449013729
Epoch: 4272, Batch Gradient Norm: 4.19776266485968
Epoch: 4272, Batch Gradient Norm after: 4.19776266485968
Epoch 4273/10000, Prediction Accuracy = 63.98846153846154%, Loss = 0.008001265151856037
Epoch: 4273, Batch Gradient Norm: 4.053492250901275
Epoch: 4273, Batch Gradient Norm after: 4.053492250901275
Epoch 4274/10000, Prediction Accuracy = 64.45384615384616%, Loss = 0.007892188974297963
Epoch: 4274, Batch Gradient Norm: 3.9072920606195596
Epoch: 4274, Batch Gradient Norm after: 3.9072920606195596
Epoch 4275/10000, Prediction Accuracy = 64.57307692307693%, Loss = 0.007770675306136792
Epoch: 4275, Batch Gradient Norm: 4.047452756194375
Epoch: 4275, Batch Gradient Norm after: 4.047452756194375
Epoch 4276/10000, Prediction Accuracy = 64.30384615384615%, Loss = 0.007969204909526385
Epoch: 4276, Batch Gradient Norm: 4.514899190351601
Epoch: 4276, Batch Gradient Norm after: 4.514899190351601
Epoch 4277/10000, Prediction Accuracy = 63.58846153846154%, Loss = 0.00808270827222329
Epoch: 4277, Batch Gradient Norm: 4.163160838484115
Epoch: 4277, Batch Gradient Norm after: 4.163160838484115
Epoch 4278/10000, Prediction Accuracy = 64.58076923076922%, Loss = 0.00790619427481523
Epoch: 4278, Batch Gradient Norm: 4.084435061087469
Epoch: 4278, Batch Gradient Norm after: 4.084435061087469
Epoch 4279/10000, Prediction Accuracy = 64.5576923076923%, Loss = 0.007887394955525031
Epoch: 4279, Batch Gradient Norm: 4.084365491615124
Epoch: 4279, Batch Gradient Norm after: 4.084365491615124
Epoch 4280/10000, Prediction Accuracy = 64.18076923076923%, Loss = 0.00794190472851579
Epoch: 4280, Batch Gradient Norm: 4.104730541334397
Epoch: 4280, Batch Gradient Norm after: 4.104730541334397
Epoch 4281/10000, Prediction Accuracy = 64.4576923076923%, Loss = 0.007883742559128083
Epoch: 4281, Batch Gradient Norm: 4.019831237196063
Epoch: 4281, Batch Gradient Norm after: 4.019831237196063
Epoch 4282/10000, Prediction Accuracy = 64.29615384615384%, Loss = 0.007885121525480198
Epoch: 4282, Batch Gradient Norm: 3.8977492467820523
Epoch: 4282, Batch Gradient Norm after: 3.8977492467820523
Epoch 4283/10000, Prediction Accuracy = 64.13461538461539%, Loss = 0.007938518045613399
Epoch: 4283, Batch Gradient Norm: 3.998252281176887
Epoch: 4283, Batch Gradient Norm after: 3.998252281176887
Epoch 4284/10000, Prediction Accuracy = 64.26538461538462%, Loss = 0.007880656621777095
Epoch: 4284, Batch Gradient Norm: 4.101259318628231
Epoch: 4284, Batch Gradient Norm after: 4.101259318628231
Epoch 4285/10000, Prediction Accuracy = 64.41538461538462%, Loss = 0.007858599285380198
Epoch: 4285, Batch Gradient Norm: 4.282042046239421
Epoch: 4285, Batch Gradient Norm after: 4.282042046239421
Epoch 4286/10000, Prediction Accuracy = 64.36538461538461%, Loss = 0.007931291663016263
Epoch: 4286, Batch Gradient Norm: 4.200922049595066
Epoch: 4286, Batch Gradient Norm after: 4.200922049595066
Epoch 4287/10000, Prediction Accuracy = 64.42692307692307%, Loss = 0.007906909602192732
Epoch: 4287, Batch Gradient Norm: 4.482381940796033
Epoch: 4287, Batch Gradient Norm after: 4.482381940796033
Epoch 4288/10000, Prediction Accuracy = 63.88076923076923%, Loss = 0.008153856875231633
Epoch: 4288, Batch Gradient Norm: 4.139415318316846
Epoch: 4288, Batch Gradient Norm after: 4.139415318316846
Epoch 4289/10000, Prediction Accuracy = 64.1423076923077%, Loss = 0.007960125409926359
Epoch: 4289, Batch Gradient Norm: 4.452238295415502
Epoch: 4289, Batch Gradient Norm after: 4.452238295415502
Epoch 4290/10000, Prediction Accuracy = 63.500000000000014%, Loss = 0.008196782356557937
Epoch: 4290, Batch Gradient Norm: 4.091190116386518
Epoch: 4290, Batch Gradient Norm after: 4.091190116386518
Epoch 4291/10000, Prediction Accuracy = 64.28846153846153%, Loss = 0.00788279866369871
Epoch: 4291, Batch Gradient Norm: 3.916455863103579
Epoch: 4291, Batch Gradient Norm after: 3.916455863103579
Epoch 4292/10000, Prediction Accuracy = 64.5576923076923%, Loss = 0.007849345664278818
Epoch: 4292, Batch Gradient Norm: 4.337124661848565
Epoch: 4292, Batch Gradient Norm after: 4.337124661848565
Epoch 4293/10000, Prediction Accuracy = 64.57307692307691%, Loss = 0.007936890416133862
Epoch: 4293, Batch Gradient Norm: 4.2397552612125695
Epoch: 4293, Batch Gradient Norm after: 4.2397552612125695
Epoch 4294/10000, Prediction Accuracy = 63.85384615384616%, Loss = 0.008032242122751016
Epoch: 4294, Batch Gradient Norm: 4.104642009838374
Epoch: 4294, Batch Gradient Norm after: 4.104642009838374
Epoch 4295/10000, Prediction Accuracy = 64.23076923076924%, Loss = 0.007923223472271975
Epoch: 4295, Batch Gradient Norm: 4.00054133964696
Epoch: 4295, Batch Gradient Norm after: 4.00054133964696
Epoch 4296/10000, Prediction Accuracy = 64.48076923076923%, Loss = 0.007908346597105265
Epoch: 4296, Batch Gradient Norm: 3.960237816015148
Epoch: 4296, Batch Gradient Norm after: 3.960237816015148
Epoch 4297/10000, Prediction Accuracy = 64.21923076923076%, Loss = 0.007800654078332277
Epoch: 4297, Batch Gradient Norm: 3.9152430642888816
Epoch: 4297, Batch Gradient Norm after: 3.9152430642888816
Epoch 4298/10000, Prediction Accuracy = 64.88461538461539%, Loss = 0.007693492413426821
Epoch: 4298, Batch Gradient Norm: 3.7675932062139936
Epoch: 4298, Batch Gradient Norm after: 3.7675932062139936
Epoch 4299/10000, Prediction Accuracy = 64.92692307692306%, Loss = 0.007687664805696561
Epoch: 4299, Batch Gradient Norm: 4.2240775716443615
Epoch: 4299, Batch Gradient Norm after: 4.2240775716443615
Epoch 4300/10000, Prediction Accuracy = 64.01153846153845%, Loss = 0.00795425191664925
Epoch: 4300, Batch Gradient Norm: 4.1328857520574465
Epoch: 4300, Batch Gradient Norm after: 4.1328857520574465
Epoch 4301/10000, Prediction Accuracy = 64.03846153846155%, Loss = 0.007904378733096214
Epoch: 4301, Batch Gradient Norm: 4.111252579890719
Epoch: 4301, Batch Gradient Norm after: 4.111252579890719
Epoch 4302/10000, Prediction Accuracy = 64.21153846153847%, Loss = 0.007886021469648067
Epoch: 4302, Batch Gradient Norm: 3.993076126890575
Epoch: 4302, Batch Gradient Norm after: 3.993076126890575
Epoch 4303/10000, Prediction Accuracy = 64.64615384615384%, Loss = 0.00782602484552906
Epoch: 4303, Batch Gradient Norm: 4.1298604855657635
Epoch: 4303, Batch Gradient Norm after: 4.1298604855657635
Epoch 4304/10000, Prediction Accuracy = 64.41538461538461%, Loss = 0.007867796489825616
Epoch: 4304, Batch Gradient Norm: 4.139751399058273
Epoch: 4304, Batch Gradient Norm after: 4.139751399058273
Epoch 4305/10000, Prediction Accuracy = 63.72692307692308%, Loss = 0.007936780949911246
Epoch: 4305, Batch Gradient Norm: 4.0829038546636065
Epoch: 4305, Batch Gradient Norm after: 4.0829038546636065
Epoch 4306/10000, Prediction Accuracy = 64.26538461538463%, Loss = 0.007792823267384217
Epoch: 4306, Batch Gradient Norm: 3.8362994180277847
Epoch: 4306, Batch Gradient Norm after: 3.8362994180277847
Epoch 4307/10000, Prediction Accuracy = 64.56923076923077%, Loss = 0.007719071796880319
Epoch: 4307, Batch Gradient Norm: 4.1576068102713055
Epoch: 4307, Batch Gradient Norm after: 4.1576068102713055
Epoch 4308/10000, Prediction Accuracy = 64.26538461538462%, Loss = 0.007936839981434437
Epoch: 4308, Batch Gradient Norm: 3.917972728417114
Epoch: 4308, Batch Gradient Norm after: 3.917972728417114
Epoch 4309/10000, Prediction Accuracy = 65.01923076923077%, Loss = 0.007721902766766457
Epoch: 4309, Batch Gradient Norm: 4.503203340179975
Epoch: 4309, Batch Gradient Norm after: 4.503203340179975
Epoch 4310/10000, Prediction Accuracy = 63.56923076923078%, Loss = 0.00811647899592152
Epoch: 4310, Batch Gradient Norm: 3.8581614794015615
Epoch: 4310, Batch Gradient Norm after: 3.8581614794015615
Epoch 4311/10000, Prediction Accuracy = 64.54615384615384%, Loss = 0.00786126025307637
Epoch: 4311, Batch Gradient Norm: 4.25385349744341
Epoch: 4311, Batch Gradient Norm after: 4.25385349744341
Epoch 4312/10000, Prediction Accuracy = 64.60769230769232%, Loss = 0.007888535001816658
Epoch: 4312, Batch Gradient Norm: 4.336037887792713
Epoch: 4312, Batch Gradient Norm after: 4.336037887792713
Epoch 4313/10000, Prediction Accuracy = 63.98846153846154%, Loss = 0.008145321053094588
Epoch: 4313, Batch Gradient Norm: 4.424560599654688
Epoch: 4313, Batch Gradient Norm after: 4.424560599654688
Epoch 4314/10000, Prediction Accuracy = 63.807692307692314%, Loss = 0.008244196848513989
Epoch: 4314, Batch Gradient Norm: 4.195229323948584
Epoch: 4314, Batch Gradient Norm after: 4.195229323948584
Epoch 4315/10000, Prediction Accuracy = 64.28846153846153%, Loss = 0.00794521590264944
Epoch: 4315, Batch Gradient Norm: 3.704167630516545
Epoch: 4315, Batch Gradient Norm after: 3.704167630516545
Epoch 4316/10000, Prediction Accuracy = 64.6846153846154%, Loss = 0.007688757318716783
Epoch: 4316, Batch Gradient Norm: 3.617589848061772
Epoch: 4316, Batch Gradient Norm after: 3.617589848061772
Epoch 4317/10000, Prediction Accuracy = 64.96153846153847%, Loss = 0.007627445416381726
Epoch: 4317, Batch Gradient Norm: 3.561484311724281
Epoch: 4317, Batch Gradient Norm after: 3.561484311724281
Epoch 4318/10000, Prediction Accuracy = 65.48076923076925%, Loss = 0.007476896369973054
Epoch: 4318, Batch Gradient Norm: 3.8252448083407127
Epoch: 4318, Batch Gradient Norm after: 3.8252448083407127
Epoch 4319/10000, Prediction Accuracy = 64.98076923076924%, Loss = 0.007643942327166979
Epoch: 4319, Batch Gradient Norm: 4.046186934752656
Epoch: 4319, Batch Gradient Norm after: 4.046186934752656
Epoch 4320/10000, Prediction Accuracy = 64.45384615384617%, Loss = 0.007735300486764083
Epoch: 4320, Batch Gradient Norm: 4.107650709883792
Epoch: 4320, Batch Gradient Norm after: 4.107650709883792
Epoch 4321/10000, Prediction Accuracy = 64.62307692307692%, Loss = 0.007833516440139366
Epoch: 4321, Batch Gradient Norm: 4.237978077686235
Epoch: 4321, Batch Gradient Norm after: 4.237978077686235
Epoch 4322/10000, Prediction Accuracy = 63.51153846153846%, Loss = 0.00796000949608592
Epoch: 4322, Batch Gradient Norm: 4.0171885025579375
Epoch: 4322, Batch Gradient Norm after: 4.0171885025579375
Epoch 4323/10000, Prediction Accuracy = 64.53461538461538%, Loss = 0.00777165677685004
Epoch: 4323, Batch Gradient Norm: 3.9385130226215805
Epoch: 4323, Batch Gradient Norm after: 3.9385130226215805
Epoch 4324/10000, Prediction Accuracy = 64.51153846153846%, Loss = 0.007749026354688864
Epoch: 4324, Batch Gradient Norm: 4.245128731942015
Epoch: 4324, Batch Gradient Norm after: 4.245128731942015
Epoch 4325/10000, Prediction Accuracy = 64.94615384615385%, Loss = 0.007851608312473847
Epoch: 4325, Batch Gradient Norm: 4.352560122564074
Epoch: 4325, Batch Gradient Norm after: 4.352560122564074
Epoch 4326/10000, Prediction Accuracy = 64.27307692307693%, Loss = 0.00789853292875565
Epoch: 4326, Batch Gradient Norm: 3.7536066066729106
Epoch: 4326, Batch Gradient Norm after: 3.7536066066729106
Epoch 4327/10000, Prediction Accuracy = 64.45384615384616%, Loss = 0.0076546752467178385
Epoch: 4327, Batch Gradient Norm: 4.256356075019761
Epoch: 4327, Batch Gradient Norm after: 4.256356075019761
Epoch 4328/10000, Prediction Accuracy = 64.14615384615385%, Loss = 0.00788921769708395
Epoch: 4328, Batch Gradient Norm: 5.104848484605055
Epoch: 4328, Batch Gradient Norm after: 5.104848484605055
Epoch 4329/10000, Prediction Accuracy = 63.08461538461539%, Loss = 0.008404463744507385
Epoch: 4329, Batch Gradient Norm: 4.498844240908053
Epoch: 4329, Batch Gradient Norm after: 4.498844240908053
Epoch 4330/10000, Prediction Accuracy = 63.55384615384616%, Loss = 0.008160973684145855
Epoch: 4330, Batch Gradient Norm: 4.15916356137617
Epoch: 4330, Batch Gradient Norm after: 4.15916356137617
Epoch 4331/10000, Prediction Accuracy = 64.11538461538461%, Loss = 0.007912859392280761
Epoch: 4331, Batch Gradient Norm: 4.271692056438782
Epoch: 4331, Batch Gradient Norm after: 4.271692056438782
Epoch 4332/10000, Prediction Accuracy = 64.27307692307691%, Loss = 0.007871662445652943
Epoch: 4332, Batch Gradient Norm: 4.15742117202529
Epoch: 4332, Batch Gradient Norm after: 4.15742117202529
Epoch 4333/10000, Prediction Accuracy = 64.05769230769232%, Loss = 0.007964125726945125
Epoch: 4333, Batch Gradient Norm: 4.616732194763761
Epoch: 4333, Batch Gradient Norm after: 4.616732194763761
Epoch 4334/10000, Prediction Accuracy = 63.71538461538462%, Loss = 0.00813804968045308
Epoch: 4334, Batch Gradient Norm: 4.5914026743739935
Epoch: 4334, Batch Gradient Norm after: 4.5914026743739935
Epoch 4335/10000, Prediction Accuracy = 63.77692307692309%, Loss = 0.008183287671552254
Epoch: 4335, Batch Gradient Norm: 4.767265383015337
Epoch: 4335, Batch Gradient Norm after: 4.767265383015337
Epoch 4336/10000, Prediction Accuracy = 63.21153846153845%, Loss = 0.008308407778923329
Epoch: 4336, Batch Gradient Norm: 4.545002923677327
Epoch: 4336, Batch Gradient Norm after: 4.545002923677327
Epoch 4337/10000, Prediction Accuracy = 63.79615384615384%, Loss = 0.00819014199078083
Epoch: 4337, Batch Gradient Norm: 3.786412158628047
Epoch: 4337, Batch Gradient Norm after: 3.786412158628047
Epoch 4338/10000, Prediction Accuracy = 64.5423076923077%, Loss = 0.00781081563148361
Epoch: 4338, Batch Gradient Norm: 4.516728229698731
Epoch: 4338, Batch Gradient Norm after: 4.516728229698731
Epoch 4339/10000, Prediction Accuracy = 63.223076923076924%, Loss = 0.00815199172267547
Epoch: 4339, Batch Gradient Norm: 4.057283876894079
Epoch: 4339, Batch Gradient Norm after: 4.057283876894079
Epoch 4340/10000, Prediction Accuracy = 64.23846153846154%, Loss = 0.007928166144455854
Epoch: 4340, Batch Gradient Norm: 4.552325119764717
Epoch: 4340, Batch Gradient Norm after: 4.552325119764717
Epoch 4341/10000, Prediction Accuracy = 64.00384615384615%, Loss = 0.008163287196881495
Epoch: 4341, Batch Gradient Norm: 4.369107037593691
Epoch: 4341, Batch Gradient Norm after: 4.369107037593691
Epoch 4342/10000, Prediction Accuracy = 63.75384615384615%, Loss = 0.008151704660401894
Epoch: 4342, Batch Gradient Norm: 4.2496043258229586
Epoch: 4342, Batch Gradient Norm after: 4.2496043258229586
Epoch 4343/10000, Prediction Accuracy = 63.36153846153846%, Loss = 0.008186702186671587
Epoch: 4343, Batch Gradient Norm: 3.9808018941019543
Epoch: 4343, Batch Gradient Norm after: 3.9808018941019543
Epoch 4344/10000, Prediction Accuracy = 64.67692307692307%, Loss = 0.007908133180955281
Epoch: 4344, Batch Gradient Norm: 4.202325939963464
Epoch: 4344, Batch Gradient Norm after: 4.202325939963464
Epoch 4345/10000, Prediction Accuracy = 64.13076923076923%, Loss = 0.007968095561059622
Epoch: 4345, Batch Gradient Norm: 3.9601011129141597
Epoch: 4345, Batch Gradient Norm after: 3.9601011129141597
Epoch 4346/10000, Prediction Accuracy = 64.13461538461537%, Loss = 0.007785853392516191
Epoch: 4346, Batch Gradient Norm: 3.6624068589460066
Epoch: 4346, Batch Gradient Norm after: 3.6624068589460066
Epoch 4347/10000, Prediction Accuracy = 64.66923076923077%, Loss = 0.007733498879063588
Epoch: 4347, Batch Gradient Norm: 4.709505269272457
Epoch: 4347, Batch Gradient Norm after: 4.709505269272457
Epoch 4348/10000, Prediction Accuracy = 63.99615384615385%, Loss = 0.008135612660016004
Epoch: 4348, Batch Gradient Norm: 4.53446928594746
Epoch: 4348, Batch Gradient Norm after: 4.53446928594746
Epoch 4349/10000, Prediction Accuracy = 63.85000000000001%, Loss = 0.008116071613935323
Epoch: 4349, Batch Gradient Norm: 4.513736637585562
Epoch: 4349, Batch Gradient Norm after: 4.513736637585562
Epoch 4350/10000, Prediction Accuracy = 63.50769230769231%, Loss = 0.008172545940257035
Epoch: 4350, Batch Gradient Norm: 3.9786948413364795
Epoch: 4350, Batch Gradient Norm after: 3.9786948413364795
Epoch 4351/10000, Prediction Accuracy = 64.61923076923077%, Loss = 0.00783378741918848
Epoch: 4351, Batch Gradient Norm: 4.021958939375921
Epoch: 4351, Batch Gradient Norm after: 4.021958939375921
Epoch 4352/10000, Prediction Accuracy = 64.68846153846152%, Loss = 0.00789643032476306
Epoch: 4352, Batch Gradient Norm: 4.181138042129661
Epoch: 4352, Batch Gradient Norm after: 4.181138042129661
Epoch 4353/10000, Prediction Accuracy = 64.42307692307692%, Loss = 0.007911473046988249
Epoch: 4353, Batch Gradient Norm: 4.247441305908019
Epoch: 4353, Batch Gradient Norm after: 4.247441305908019
Epoch 4354/10000, Prediction Accuracy = 64.32692307692307%, Loss = 0.007885087209825333
Epoch: 4354, Batch Gradient Norm: 4.228724163144603
Epoch: 4354, Batch Gradient Norm after: 4.228724163144603
Epoch 4355/10000, Prediction Accuracy = 64.3076923076923%, Loss = 0.007957928885634128
Epoch: 4355, Batch Gradient Norm: 3.968672082918016
Epoch: 4355, Batch Gradient Norm after: 3.968672082918016
Epoch 4356/10000, Prediction Accuracy = 64.53846153846153%, Loss = 0.007817833970945615
Epoch: 4356, Batch Gradient Norm: 4.187992192696007
Epoch: 4356, Batch Gradient Norm after: 4.187992192696007
Epoch 4357/10000, Prediction Accuracy = 64.52307692307693%, Loss = 0.007891451832480155
Epoch: 4357, Batch Gradient Norm: 4.512395955084596
Epoch: 4357, Batch Gradient Norm after: 4.512395955084596
Epoch 4358/10000, Prediction Accuracy = 63.542307692307695%, Loss = 0.008138073429178733
Epoch: 4358, Batch Gradient Norm: 4.039689194984625
Epoch: 4358, Batch Gradient Norm after: 4.039689194984625
Epoch 4359/10000, Prediction Accuracy = 64.52307692307691%, Loss = 0.007811328933502619
Epoch: 4359, Batch Gradient Norm: 3.831152172671688
Epoch: 4359, Batch Gradient Norm after: 3.831152172671688
Epoch 4360/10000, Prediction Accuracy = 64.76923076923076%, Loss = 0.007814983049264321
Epoch: 4360, Batch Gradient Norm: 3.8326596794556664
Epoch: 4360, Batch Gradient Norm after: 3.8326596794556664
Epoch 4361/10000, Prediction Accuracy = 64.46153846153847%, Loss = 0.007749972148583486
Epoch: 4361, Batch Gradient Norm: 4.436518435823408
Epoch: 4361, Batch Gradient Norm after: 4.436518435823408
Epoch 4362/10000, Prediction Accuracy = 63.96153846153846%, Loss = 0.008063385943667246
Epoch: 4362, Batch Gradient Norm: 4.471564652399144
Epoch: 4362, Batch Gradient Norm after: 4.471564652399144
Epoch 4363/10000, Prediction Accuracy = 63.56153846153847%, Loss = 0.008214852772653103
Epoch: 4363, Batch Gradient Norm: 4.027128663257551
Epoch: 4363, Batch Gradient Norm after: 4.027128663257551
Epoch 4364/10000, Prediction Accuracy = 64.37692307692306%, Loss = 0.0078515476332261
Epoch: 4364, Batch Gradient Norm: 3.992254625017815
Epoch: 4364, Batch Gradient Norm after: 3.992254625017815
Epoch 4365/10000, Prediction Accuracy = 64.51538461538463%, Loss = 0.007766288024588273
Epoch: 4365, Batch Gradient Norm: 4.107729859394039
Epoch: 4365, Batch Gradient Norm after: 4.107729859394039
Epoch 4366/10000, Prediction Accuracy = 64.05%, Loss = 0.007932680444075512
Epoch: 4366, Batch Gradient Norm: 4.520419936206971
Epoch: 4366, Batch Gradient Norm after: 4.520419936206971
Epoch 4367/10000, Prediction Accuracy = 63.23846153846152%, Loss = 0.008169032991505586
Epoch: 4367, Batch Gradient Norm: 4.4280772878566355
Epoch: 4367, Batch Gradient Norm after: 4.4280772878566355
Epoch 4368/10000, Prediction Accuracy = 63.95384615384615%, Loss = 0.008040074366503037
Epoch: 4368, Batch Gradient Norm: 4.529771733725594
Epoch: 4368, Batch Gradient Norm after: 4.529771733725594
Epoch 4369/10000, Prediction Accuracy = 63.857692307692304%, Loss = 0.008114964271394106
Epoch: 4369, Batch Gradient Norm: 4.2870747770447135
Epoch: 4369, Batch Gradient Norm after: 4.2870747770447135
Epoch 4370/10000, Prediction Accuracy = 63.68461538461539%, Loss = 0.008141068526758598
Epoch: 4370, Batch Gradient Norm: 4.007012190324296
Epoch: 4370, Batch Gradient Norm after: 4.007012190324296
Epoch 4371/10000, Prediction Accuracy = 64.89230769230768%, Loss = 0.007886886274298796
Epoch: 4371, Batch Gradient Norm: 4.168337241136806
Epoch: 4371, Batch Gradient Norm after: 4.168337241136806
Epoch 4372/10000, Prediction Accuracy = 64.50384615384615%, Loss = 0.007903886385835134
Epoch: 4372, Batch Gradient Norm: 3.845618108459701
Epoch: 4372, Batch Gradient Norm after: 3.845618108459701
Epoch 4373/10000, Prediction Accuracy = 64.35000000000001%, Loss = 0.007815600050470004
Epoch: 4373, Batch Gradient Norm: 4.015052909432536
Epoch: 4373, Batch Gradient Norm after: 4.015052909432536
Epoch 4374/10000, Prediction Accuracy = 64.28076923076924%, Loss = 0.0078625982770553
Epoch: 4374, Batch Gradient Norm: 4.425785368265945
Epoch: 4374, Batch Gradient Norm after: 4.425785368265945
Epoch 4375/10000, Prediction Accuracy = 64.21538461538462%, Loss = 0.007949275000450702
Epoch: 4375, Batch Gradient Norm: 4.496874461931247
Epoch: 4375, Batch Gradient Norm after: 4.496874461931247
Epoch 4376/10000, Prediction Accuracy = 64.0653846153846%, Loss = 0.008045309617255744
Epoch: 4376, Batch Gradient Norm: 4.890836708169283
Epoch: 4376, Batch Gradient Norm after: 4.890836708169283
Epoch 4377/10000, Prediction Accuracy = 63.17307692307692%, Loss = 0.008302656933665276
Epoch: 4377, Batch Gradient Norm: 4.594964380462365
Epoch: 4377, Batch Gradient Norm after: 4.594964380462365
Epoch 4378/10000, Prediction Accuracy = 63.26538461538461%, Loss = 0.008348735980689526
Epoch: 4378, Batch Gradient Norm: 4.294565841178774
Epoch: 4378, Batch Gradient Norm after: 4.294565841178774
Epoch 4379/10000, Prediction Accuracy = 63.74230769230769%, Loss = 0.008120461367070675
Epoch: 4379, Batch Gradient Norm: 4.318864060369431
Epoch: 4379, Batch Gradient Norm after: 4.318864060369431
Epoch 4380/10000, Prediction Accuracy = 63.80384615384615%, Loss = 0.008111664631332342
Epoch: 4380, Batch Gradient Norm: 3.8394071231028013
Epoch: 4380, Batch Gradient Norm after: 3.8394071231028013
Epoch 4381/10000, Prediction Accuracy = 64.60384615384615%, Loss = 0.007812246035497922
Epoch: 4381, Batch Gradient Norm: 3.5892852090800944
Epoch: 4381, Batch Gradient Norm after: 3.5892852090800944
Epoch 4382/10000, Prediction Accuracy = 65.07307692307693%, Loss = 0.007612247843868458
Epoch: 4382, Batch Gradient Norm: 3.5335134860548623
Epoch: 4382, Batch Gradient Norm after: 3.5335134860548623
Epoch 4383/10000, Prediction Accuracy = 65.06153846153846%, Loss = 0.007564333374970234
Epoch: 4383, Batch Gradient Norm: 4.240348429991096
Epoch: 4383, Batch Gradient Norm after: 4.240348429991096
Epoch 4384/10000, Prediction Accuracy = 64.26153846153846%, Loss = 0.007861176541504951
Epoch: 4384, Batch Gradient Norm: 3.7200830681085777
Epoch: 4384, Batch Gradient Norm after: 3.7200830681085777
Epoch 4385/10000, Prediction Accuracy = 64.73461538461538%, Loss = 0.007672067982359574
Epoch: 4385, Batch Gradient Norm: 4.034482691200749
Epoch: 4385, Batch Gradient Norm after: 4.034482691200749
Epoch 4386/10000, Prediction Accuracy = 64.51923076923076%, Loss = 0.007847909385768266
Epoch: 4386, Batch Gradient Norm: 4.021643446223945
Epoch: 4386, Batch Gradient Norm after: 4.021643446223945
Epoch 4387/10000, Prediction Accuracy = 63.9923076923077%, Loss = 0.007748956039834481
Epoch: 4387, Batch Gradient Norm: 4.133156617287269
Epoch: 4387, Batch Gradient Norm after: 4.133156617287269
Epoch 4388/10000, Prediction Accuracy = 64.77307692307693%, Loss = 0.00771325439787828
Epoch: 4388, Batch Gradient Norm: 3.997445121857252
Epoch: 4388, Batch Gradient Norm after: 3.997445121857252
Epoch 4389/10000, Prediction Accuracy = 64.28846153846153%, Loss = 0.0077807031786785675
Epoch: 4389, Batch Gradient Norm: 3.9772725598672096
Epoch: 4389, Batch Gradient Norm after: 3.9772725598672096
Epoch 4390/10000, Prediction Accuracy = 64.95%, Loss = 0.0076990763012033244
Epoch: 4390, Batch Gradient Norm: 4.047377215285848
Epoch: 4390, Batch Gradient Norm after: 4.047377215285848
Epoch 4391/10000, Prediction Accuracy = 64.72307692307692%, Loss = 0.007827557193545194
Epoch: 4391, Batch Gradient Norm: 3.9881731196993266
Epoch: 4391, Batch Gradient Norm after: 3.9881731196993266
Epoch 4392/10000, Prediction Accuracy = 64.51153846153846%, Loss = 0.007793868103852639
Epoch: 4392, Batch Gradient Norm: 4.272139921566896
Epoch: 4392, Batch Gradient Norm after: 4.272139921566896
Epoch 4393/10000, Prediction Accuracy = 64.31538461538462%, Loss = 0.00795656618160697
Epoch: 4393, Batch Gradient Norm: 4.098395066808379
Epoch: 4393, Batch Gradient Norm after: 4.098395066808379
Epoch 4394/10000, Prediction Accuracy = 64.6923076923077%, Loss = 0.00776989278025352
Epoch: 4394, Batch Gradient Norm: 4.429070755569499
Epoch: 4394, Batch Gradient Norm after: 4.429070755569499
Epoch 4395/10000, Prediction Accuracy = 64.62692307692308%, Loss = 0.00785095735381429
Epoch: 4395, Batch Gradient Norm: 4.333229956548404
Epoch: 4395, Batch Gradient Norm after: 4.333229956548404
Epoch 4396/10000, Prediction Accuracy = 64.56923076923077%, Loss = 0.00786720603131331
Epoch: 4396, Batch Gradient Norm: 4.329958267023738
Epoch: 4396, Batch Gradient Norm after: 4.329958267023738
Epoch 4397/10000, Prediction Accuracy = 63.82692307692308%, Loss = 0.007945071547650374
Epoch: 4397, Batch Gradient Norm: 3.9199096048057154
Epoch: 4397, Batch Gradient Norm after: 3.9199096048057154
Epoch 4398/10000, Prediction Accuracy = 64.63076923076923%, Loss = 0.00772012472869112
Epoch: 4398, Batch Gradient Norm: 3.9960482950569456
Epoch: 4398, Batch Gradient Norm after: 3.9960482950569456
Epoch 4399/10000, Prediction Accuracy = 64.77307692307691%, Loss = 0.007703335382617437
Epoch: 4399, Batch Gradient Norm: 3.9857131176648557
Epoch: 4399, Batch Gradient Norm after: 3.9857131176648557
Epoch 4400/10000, Prediction Accuracy = 64.42692307692309%, Loss = 0.007842148654162884
Epoch: 4400, Batch Gradient Norm: 4.031626648468509
Epoch: 4400, Batch Gradient Norm after: 4.031626648468509
Epoch 4401/10000, Prediction Accuracy = 64.8576923076923%, Loss = 0.007783024034534509
Epoch: 4401, Batch Gradient Norm: 3.9182440960521436
Epoch: 4401, Batch Gradient Norm after: 3.9182440960521436
Epoch 4402/10000, Prediction Accuracy = 65.01923076923077%, Loss = 0.007656705100089312
Epoch: 4402, Batch Gradient Norm: 4.172217101620443
Epoch: 4402, Batch Gradient Norm after: 4.172217101620443
Epoch 4403/10000, Prediction Accuracy = 64.37692307692308%, Loss = 0.007898064473500619
Epoch: 4403, Batch Gradient Norm: 4.367561153115899
Epoch: 4403, Batch Gradient Norm after: 4.367561153115899
Epoch 4404/10000, Prediction Accuracy = 63.61538461538461%, Loss = 0.008066224650694774
Epoch: 4404, Batch Gradient Norm: 4.461220677918117
Epoch: 4404, Batch Gradient Norm after: 4.461220677918117
Epoch 4405/10000, Prediction Accuracy = 63.73461538461539%, Loss = 0.008120490990292568
Epoch: 4405, Batch Gradient Norm: 4.024855198463879
Epoch: 4405, Batch Gradient Norm after: 4.024855198463879
Epoch 4406/10000, Prediction Accuracy = 64.55769230769229%, Loss = 0.007889414528528085
Epoch: 4406, Batch Gradient Norm: 4.173080660934535
Epoch: 4406, Batch Gradient Norm after: 4.173080660934535
Epoch 4407/10000, Prediction Accuracy = 64.00384615384615%, Loss = 0.007894146506889509
Epoch: 4407, Batch Gradient Norm: 4.052593687719503
Epoch: 4407, Batch Gradient Norm after: 4.052593687719503
Epoch 4408/10000, Prediction Accuracy = 64.35000000000001%, Loss = 0.007841354880768519
Epoch: 4408, Batch Gradient Norm: 3.8243313060280006
Epoch: 4408, Batch Gradient Norm after: 3.8243313060280006
Epoch 4409/10000, Prediction Accuracy = 64.6076923076923%, Loss = 0.007698961891807043
Epoch: 4409, Batch Gradient Norm: 4.133237989652539
Epoch: 4409, Batch Gradient Norm after: 4.133237989652539
Epoch 4410/10000, Prediction Accuracy = 64.28846153846152%, Loss = 0.007888509175525261
Epoch: 4410, Batch Gradient Norm: 4.077372601243999
Epoch: 4410, Batch Gradient Norm after: 4.077372601243999
Epoch 4411/10000, Prediction Accuracy = 64.18076923076924%, Loss = 0.007799165466657052
Epoch: 4411, Batch Gradient Norm: 4.436518937251555
Epoch: 4411, Batch Gradient Norm after: 4.436518937251555
Epoch 4412/10000, Prediction Accuracy = 64.23846153846155%, Loss = 0.008030893066181587
Epoch: 4412, Batch Gradient Norm: 4.055760920949425
Epoch: 4412, Batch Gradient Norm after: 4.055760920949425
Epoch 4413/10000, Prediction Accuracy = 64.18846153846154%, Loss = 0.007882221279522547
Epoch: 4413, Batch Gradient Norm: 4.484597325917247
Epoch: 4413, Batch Gradient Norm after: 4.484597325917247
Epoch 4414/10000, Prediction Accuracy = 63.849999999999994%, Loss = 0.008062009556362262
Epoch: 4414, Batch Gradient Norm: 4.212395567147568
Epoch: 4414, Batch Gradient Norm after: 4.212395567147568
Epoch 4415/10000, Prediction Accuracy = 64.82692307692308%, Loss = 0.00788368252464212
Epoch: 4415, Batch Gradient Norm: 4.173707284180182
Epoch: 4415, Batch Gradient Norm after: 4.173707284180182
Epoch 4416/10000, Prediction Accuracy = 63.77307692307693%, Loss = 0.007937807804689957
Epoch: 4416, Batch Gradient Norm: 4.458831533717627
Epoch: 4416, Batch Gradient Norm after: 4.458831533717627
Epoch 4417/10000, Prediction Accuracy = 63.830769230769235%, Loss = 0.008000499246498713
Epoch: 4417, Batch Gradient Norm: 4.006955688268272
Epoch: 4417, Batch Gradient Norm after: 4.006955688268272
Epoch 4418/10000, Prediction Accuracy = 64.46153846153847%, Loss = 0.007833183098297853
Epoch: 4418, Batch Gradient Norm: 4.337028712446226
Epoch: 4418, Batch Gradient Norm after: 4.337028712446226
Epoch 4419/10000, Prediction Accuracy = 64.12307692307691%, Loss = 0.007942731026560068
Epoch: 4419, Batch Gradient Norm: 4.326389105457711
Epoch: 4419, Batch Gradient Norm after: 4.326389105457711
Epoch 4420/10000, Prediction Accuracy = 64.08076923076922%, Loss = 0.008027355688122602
Epoch: 4420, Batch Gradient Norm: 4.3084592507386885
Epoch: 4420, Batch Gradient Norm after: 4.3084592507386885
Epoch 4421/10000, Prediction Accuracy = 63.76153846153846%, Loss = 0.008014604950753542
Epoch: 4421, Batch Gradient Norm: 3.962609168842455
Epoch: 4421, Batch Gradient Norm after: 3.962609168842455
Epoch 4422/10000, Prediction Accuracy = 64.09615384615384%, Loss = 0.007858250146875015
Epoch: 4422, Batch Gradient Norm: 3.9808877007563814
Epoch: 4422, Batch Gradient Norm after: 3.9808877007563814
Epoch 4423/10000, Prediction Accuracy = 64.54999999999998%, Loss = 0.007778713802018991
Epoch: 4423, Batch Gradient Norm: 4.279444503187943
Epoch: 4423, Batch Gradient Norm after: 4.279444503187943
Epoch 4424/10000, Prediction Accuracy = 64.00384615384617%, Loss = 0.007952997747522134
Epoch: 4424, Batch Gradient Norm: 3.997179730836221
Epoch: 4424, Batch Gradient Norm after: 3.997179730836221
Epoch 4425/10000, Prediction Accuracy = 64.25769230769231%, Loss = 0.007825404763794862
Epoch: 4425, Batch Gradient Norm: 4.289634390277468
Epoch: 4425, Batch Gradient Norm after: 4.289634390277468
Epoch 4426/10000, Prediction Accuracy = 64.60384615384616%, Loss = 0.007853408236629687
Epoch: 4426, Batch Gradient Norm: 4.364912262483246
Epoch: 4426, Batch Gradient Norm after: 4.364912262483246
Epoch 4427/10000, Prediction Accuracy = 64.34615384615384%, Loss = 0.007943990568702038
Epoch: 4427, Batch Gradient Norm: 4.183575366094718
Epoch: 4427, Batch Gradient Norm after: 4.183575366094718
Epoch 4428/10000, Prediction Accuracy = 64.14615384615384%, Loss = 0.007927174500834484
Epoch: 4428, Batch Gradient Norm: 4.435736547770795
Epoch: 4428, Batch Gradient Norm after: 4.435736547770795
Epoch 4429/10000, Prediction Accuracy = 63.96153846153845%, Loss = 0.008019426515182624
Epoch: 4429, Batch Gradient Norm: 4.0648960381477455
Epoch: 4429, Batch Gradient Norm after: 4.0648960381477455
Epoch 4430/10000, Prediction Accuracy = 64.38846153846154%, Loss = 0.007844191187849412
Epoch: 4430, Batch Gradient Norm: 4.410486953129255
Epoch: 4430, Batch Gradient Norm after: 4.410486953129255
Epoch 4431/10000, Prediction Accuracy = 63.81153846153846%, Loss = 0.007984988749600373
Epoch: 4431, Batch Gradient Norm: 4.401252179501227
Epoch: 4431, Batch Gradient Norm after: 4.401252179501227
Epoch 4432/10000, Prediction Accuracy = 64.17692307692307%, Loss = 0.007940940809651064
Epoch: 4432, Batch Gradient Norm: 4.416409936779895
Epoch: 4432, Batch Gradient Norm after: 4.416409936779895
Epoch 4433/10000, Prediction Accuracy = 64.46923076923078%, Loss = 0.0079068007449118
Epoch: 4433, Batch Gradient Norm: 4.391783009944107
Epoch: 4433, Batch Gradient Norm after: 4.391783009944107
Epoch 4434/10000, Prediction Accuracy = 63.74615384615385%, Loss = 0.008009716725120178
Epoch: 4434, Batch Gradient Norm: 3.9297605659355996
Epoch: 4434, Batch Gradient Norm after: 3.9297605659355996
Epoch 4435/10000, Prediction Accuracy = 64.47307692307692%, Loss = 0.00785349148253982
Epoch: 4435, Batch Gradient Norm: 3.633260915954694
Epoch: 4435, Batch Gradient Norm after: 3.633260915954694
Epoch 4436/10000, Prediction Accuracy = 65.27692307692307%, Loss = 0.007568380902879513
Epoch: 4436, Batch Gradient Norm: 4.108429305644898
Epoch: 4436, Batch Gradient Norm after: 4.108429305644898
Epoch 4437/10000, Prediction Accuracy = 64.65769230769232%, Loss = 0.00775808640397512
Epoch: 4437, Batch Gradient Norm: 3.9993517698588072
Epoch: 4437, Batch Gradient Norm after: 3.9993517698588072
Epoch 4438/10000, Prediction Accuracy = 65.01538461538462%, Loss = 0.007771379959124785
Epoch: 4438, Batch Gradient Norm: 4.111582658918116
Epoch: 4438, Batch Gradient Norm after: 4.111582658918116
Epoch 4439/10000, Prediction Accuracy = 64.26538461538462%, Loss = 0.007826396801437322
Epoch: 4439, Batch Gradient Norm: 3.8824823958214507
Epoch: 4439, Batch Gradient Norm after: 3.8824823958214507
Epoch 4440/10000, Prediction Accuracy = 64.46923076923078%, Loss = 0.007721856845399508
Epoch: 4440, Batch Gradient Norm: 4.0624555359321075
Epoch: 4440, Batch Gradient Norm after: 4.0624555359321075
Epoch 4441/10000, Prediction Accuracy = 65.26538461538462%, Loss = 0.007698158411165843
Epoch: 4441, Batch Gradient Norm: 4.315914528495734
Epoch: 4441, Batch Gradient Norm after: 4.315914528495734
Epoch 4442/10000, Prediction Accuracy = 64.11538461538463%, Loss = 0.00782972638710187
Epoch: 4442, Batch Gradient Norm: 3.992451728252657
Epoch: 4442, Batch Gradient Norm after: 3.992451728252657
Epoch 4443/10000, Prediction Accuracy = 64.61538461538463%, Loss = 0.0077654985496057915
Epoch: 4443, Batch Gradient Norm: 4.286707583263561
Epoch: 4443, Batch Gradient Norm after: 4.286707583263561
Epoch 4444/10000, Prediction Accuracy = 64.27307692307691%, Loss = 0.007876931725499721
Epoch: 4444, Batch Gradient Norm: 4.102524642349778
Epoch: 4444, Batch Gradient Norm after: 4.102524642349778
Epoch 4445/10000, Prediction Accuracy = 64.9%, Loss = 0.0077713878395465705
Epoch: 4445, Batch Gradient Norm: 4.4152180653524296
Epoch: 4445, Batch Gradient Norm after: 4.4152180653524296
Epoch 4446/10000, Prediction Accuracy = 64.3423076923077%, Loss = 0.007938234314609032
Epoch: 4446, Batch Gradient Norm: 3.96927358723372
Epoch: 4446, Batch Gradient Norm after: 3.96927358723372
Epoch 4447/10000, Prediction Accuracy = 65.33076923076922%, Loss = 0.007677717170176597
Epoch: 4447, Batch Gradient Norm: 3.842808698159339
Epoch: 4447, Batch Gradient Norm after: 3.842808698159339
Epoch 4448/10000, Prediction Accuracy = 64.88461538461539%, Loss = 0.0076579393890614696
Epoch: 4448, Batch Gradient Norm: 4.120487189098208
Epoch: 4448, Batch Gradient Norm after: 4.120487189098208
Epoch 4449/10000, Prediction Accuracy = 64.68076923076923%, Loss = 0.007744537451519416
Epoch: 4449, Batch Gradient Norm: 4.335931380348409
Epoch: 4449, Batch Gradient Norm after: 4.335931380348409
Epoch 4450/10000, Prediction Accuracy = 63.93076923076922%, Loss = 0.007922297665992608
Epoch: 4450, Batch Gradient Norm: 4.297993295729962
Epoch: 4450, Batch Gradient Norm after: 4.297993295729962
Epoch 4451/10000, Prediction Accuracy = 64.23846153846154%, Loss = 0.00792487796682578
Epoch: 4451, Batch Gradient Norm: 4.134486960920395
Epoch: 4451, Batch Gradient Norm after: 4.134486960920395
Epoch 4452/10000, Prediction Accuracy = 64.58461538461539%, Loss = 0.007900608022912191
Epoch: 4452, Batch Gradient Norm: 4.654330665373362
Epoch: 4452, Batch Gradient Norm after: 4.654330665373362
Epoch 4453/10000, Prediction Accuracy = 64.25000000000001%, Loss = 0.008024039033513803
Epoch: 4453, Batch Gradient Norm: 4.363875377308542
Epoch: 4453, Batch Gradient Norm after: 4.363875377308542
Epoch 4454/10000, Prediction Accuracy = 64.34230769230768%, Loss = 0.007961816870822357
Epoch: 4454, Batch Gradient Norm: 4.139396548728285
Epoch: 4454, Batch Gradient Norm after: 4.139396548728285
Epoch 4455/10000, Prediction Accuracy = 64.38076923076923%, Loss = 0.00792639129436933
Epoch: 4455, Batch Gradient Norm: 3.9576774078443613
Epoch: 4455, Batch Gradient Norm after: 3.9576774078443613
Epoch 4456/10000, Prediction Accuracy = 64.63461538461537%, Loss = 0.007740128391350691
Epoch: 4456, Batch Gradient Norm: 3.7404648564034755
Epoch: 4456, Batch Gradient Norm after: 3.7404648564034755
Epoch 4457/10000, Prediction Accuracy = 64.93846153846155%, Loss = 0.007610190552301132
Epoch: 4457, Batch Gradient Norm: 4.460167443171277
Epoch: 4457, Batch Gradient Norm after: 4.460167443171277
Epoch 4458/10000, Prediction Accuracy = 64.3846153846154%, Loss = 0.007986712699326185
Epoch: 4458, Batch Gradient Norm: 4.79625797617646
Epoch: 4458, Batch Gradient Norm after: 4.79625797617646
Epoch 4459/10000, Prediction Accuracy = 63.23846153846154%, Loss = 0.008212571354726186
Epoch: 4459, Batch Gradient Norm: 4.446646583446342
Epoch: 4459, Batch Gradient Norm after: 4.446646583446342
Epoch 4460/10000, Prediction Accuracy = 64.32307692307693%, Loss = 0.007972867550471654
Epoch: 4460, Batch Gradient Norm: 4.538620116510016
Epoch: 4460, Batch Gradient Norm after: 4.538620116510016
Epoch 4461/10000, Prediction Accuracy = 63.57307692307692%, Loss = 0.008118494521253385
Epoch: 4461, Batch Gradient Norm: 3.984591788206469
Epoch: 4461, Batch Gradient Norm after: 3.984591788206469
Epoch 4462/10000, Prediction Accuracy = 64.07307692307694%, Loss = 0.0078827439664075
Epoch: 4462, Batch Gradient Norm: 3.7063200421175564
Epoch: 4462, Batch Gradient Norm after: 3.7063200421175564
Epoch 4463/10000, Prediction Accuracy = 64.64999999999999%, Loss = 0.007753859274089336
Epoch: 4463, Batch Gradient Norm: 3.776328104909162
Epoch: 4463, Batch Gradient Norm after: 3.776328104909162
Epoch 4464/10000, Prediction Accuracy = 64.45769230769231%, Loss = 0.007757689660558334
Epoch: 4464, Batch Gradient Norm: 3.9615436875017487
Epoch: 4464, Batch Gradient Norm after: 3.9615436875017487
Epoch 4465/10000, Prediction Accuracy = 64.8576923076923%, Loss = 0.0077997224333767705
Epoch: 4465, Batch Gradient Norm: 3.906840034832224
Epoch: 4465, Batch Gradient Norm after: 3.906840034832224
Epoch 4466/10000, Prediction Accuracy = 64.8076923076923%, Loss = 0.007723053953108879
Epoch: 4466, Batch Gradient Norm: 4.230306763386629
Epoch: 4466, Batch Gradient Norm after: 4.230306763386629
Epoch 4467/10000, Prediction Accuracy = 64.67307692307693%, Loss = 0.007742411528642361
Epoch: 4467, Batch Gradient Norm: 3.995035213456701
Epoch: 4467, Batch Gradient Norm after: 3.995035213456701
Epoch 4468/10000, Prediction Accuracy = 64.76923076923076%, Loss = 0.007825144423315158
Epoch: 4468, Batch Gradient Norm: 3.8502518989251495
Epoch: 4468, Batch Gradient Norm after: 3.8502518989251495
Epoch 4469/10000, Prediction Accuracy = 64.91923076923078%, Loss = 0.007704064285812469
Epoch: 4469, Batch Gradient Norm: 4.386987432765351
Epoch: 4469, Batch Gradient Norm after: 4.386987432765351
Epoch 4470/10000, Prediction Accuracy = 64.3%, Loss = 0.00787919655872079
Epoch: 4470, Batch Gradient Norm: 3.900849796744736
Epoch: 4470, Batch Gradient Norm after: 3.900849796744736
Epoch 4471/10000, Prediction Accuracy = 64.5923076923077%, Loss = 0.007757074951838989
Epoch: 4471, Batch Gradient Norm: 4.4298875786587235
Epoch: 4471, Batch Gradient Norm after: 4.4298875786587235
Epoch 4472/10000, Prediction Accuracy = 64.02692307692308%, Loss = 0.007957707445781965
Epoch: 4472, Batch Gradient Norm: 4.234501381637572
Epoch: 4472, Batch Gradient Norm after: 4.234501381637572
Epoch 4473/10000, Prediction Accuracy = 64.15%, Loss = 0.007888489546110997
Epoch: 4473, Batch Gradient Norm: 4.344617690322055
Epoch: 4473, Batch Gradient Norm after: 4.344617690322055
Epoch 4474/10000, Prediction Accuracy = 64.47307692307692%, Loss = 0.007919532246887684
Epoch: 4474, Batch Gradient Norm: 4.446385018300276
Epoch: 4474, Batch Gradient Norm after: 4.446385018300276
Epoch 4475/10000, Prediction Accuracy = 63.942307692307686%, Loss = 0.007973554293410135
Epoch: 4475, Batch Gradient Norm: 4.044566036104482
Epoch: 4475, Batch Gradient Norm after: 4.044566036104482
Epoch 4476/10000, Prediction Accuracy = 64.69615384615385%, Loss = 0.007831331700659715
Epoch: 4476, Batch Gradient Norm: 3.984778925059729
Epoch: 4476, Batch Gradient Norm after: 3.984778925059729
Epoch 4477/10000, Prediction Accuracy = 64.46153846153845%, Loss = 0.00771318469196558
Epoch: 4477, Batch Gradient Norm: 4.091702585188418
Epoch: 4477, Batch Gradient Norm after: 4.091702585188418
Epoch 4478/10000, Prediction Accuracy = 64.61153846153846%, Loss = 0.007746905339165376
Epoch: 4478, Batch Gradient Norm: 3.9558660752584647
Epoch: 4478, Batch Gradient Norm after: 3.9558660752584647
Epoch 4479/10000, Prediction Accuracy = 64.96153846153847%, Loss = 0.007693832417806754
Epoch: 4479, Batch Gradient Norm: 3.755242215849675
Epoch: 4479, Batch Gradient Norm after: 3.755242215849675
Epoch 4480/10000, Prediction Accuracy = 65.1923076923077%, Loss = 0.007579007365096074
Epoch: 4480, Batch Gradient Norm: 3.8734483109146796
Epoch: 4480, Batch Gradient Norm after: 3.8734483109146796
Epoch 4481/10000, Prediction Accuracy = 64.9346153846154%, Loss = 0.00769496551499917
Epoch: 4481, Batch Gradient Norm: 4.184828644575175
Epoch: 4481, Batch Gradient Norm after: 4.184828644575175
Epoch 4482/10000, Prediction Accuracy = 64.52692307692307%, Loss = 0.007824575421042167
Epoch: 4482, Batch Gradient Norm: 4.379450591098746
Epoch: 4482, Batch Gradient Norm after: 4.379450591098746
Epoch 4483/10000, Prediction Accuracy = 64.45384615384616%, Loss = 0.007830735439291367
Epoch: 4483, Batch Gradient Norm: 4.321253642588
Epoch: 4483, Batch Gradient Norm after: 4.321253642588
Epoch 4484/10000, Prediction Accuracy = 64.01923076923076%, Loss = 0.007974732416467024
Epoch: 4484, Batch Gradient Norm: 4.003679144555426
Epoch: 4484, Batch Gradient Norm after: 4.003679144555426
Epoch 4485/10000, Prediction Accuracy = 64.78076923076922%, Loss = 0.007732217594121511
Epoch: 4485, Batch Gradient Norm: 4.089513166952104
Epoch: 4485, Batch Gradient Norm after: 4.089513166952104
Epoch 4486/10000, Prediction Accuracy = 64.18076923076923%, Loss = 0.007802765135868237
Epoch: 4486, Batch Gradient Norm: 4.248114476435981
Epoch: 4486, Batch Gradient Norm after: 4.248114476435981
Epoch 4487/10000, Prediction Accuracy = 64.35384615384615%, Loss = 0.007853975268797232
Epoch: 4487, Batch Gradient Norm: 4.348219650581417
Epoch: 4487, Batch Gradient Norm after: 4.348219650581417
Epoch 4488/10000, Prediction Accuracy = 64.73461538461538%, Loss = 0.007834504322650341
Epoch: 4488, Batch Gradient Norm: 4.534100327782336
Epoch: 4488, Batch Gradient Norm after: 4.534100327782336
Epoch 4489/10000, Prediction Accuracy = 63.69615384615384%, Loss = 0.008028966661256094
Epoch: 4489, Batch Gradient Norm: 3.8450859773948136
Epoch: 4489, Batch Gradient Norm after: 3.8450859773948136
Epoch 4490/10000, Prediction Accuracy = 64.45769230769231%, Loss = 0.007652087746044764
Epoch: 4490, Batch Gradient Norm: 4.473622931326712
Epoch: 4490, Batch Gradient Norm after: 4.473622931326712
Epoch 4491/10000, Prediction Accuracy = 64.55384615384615%, Loss = 0.007871625479310751
Epoch: 4491, Batch Gradient Norm: 4.532795421040031
Epoch: 4491, Batch Gradient Norm after: 4.532795421040031
Epoch 4492/10000, Prediction Accuracy = 63.57692307692308%, Loss = 0.008048758018188752
Epoch: 4492, Batch Gradient Norm: 4.216361651460219
Epoch: 4492, Batch Gradient Norm after: 4.216361651460219
Epoch 4493/10000, Prediction Accuracy = 64.30384615384615%, Loss = 0.007891790511516424
Epoch: 4493, Batch Gradient Norm: 4.1528898152078915
Epoch: 4493, Batch Gradient Norm after: 4.1528898152078915
Epoch 4494/10000, Prediction Accuracy = 64.21538461538461%, Loss = 0.00785261088122542
Epoch: 4494, Batch Gradient Norm: 4.071378496905218
Epoch: 4494, Batch Gradient Norm after: 4.071378496905218
Epoch 4495/10000, Prediction Accuracy = 64.41923076923078%, Loss = 0.007867141125293879
Epoch: 4495, Batch Gradient Norm: 4.283076492469226
Epoch: 4495, Batch Gradient Norm after: 4.283076492469226
Epoch 4496/10000, Prediction Accuracy = 64.37307692307692%, Loss = 0.007821240139981875
Epoch: 4496, Batch Gradient Norm: 4.123055011937093
Epoch: 4496, Batch Gradient Norm after: 4.123055011937093
Epoch 4497/10000, Prediction Accuracy = 64.21923076923078%, Loss = 0.00785163503426772
Epoch: 4497, Batch Gradient Norm: 4.29879499536952
Epoch: 4497, Batch Gradient Norm after: 4.29879499536952
Epoch 4498/10000, Prediction Accuracy = 64.13076923076923%, Loss = 0.007977570908573957
Epoch: 4498, Batch Gradient Norm: 3.921089209397799
Epoch: 4498, Batch Gradient Norm after: 3.921089209397799
Epoch 4499/10000, Prediction Accuracy = 64.62307692307692%, Loss = 0.007750834589107678
Epoch: 4499, Batch Gradient Norm: 3.920309366896601
Epoch: 4499, Batch Gradient Norm after: 3.920309366896601
Epoch 4500/10000, Prediction Accuracy = 64.92692307692306%, Loss = 0.0076623071844761186
Epoch: 4500, Batch Gradient Norm: 4.138597873166845
Epoch: 4500, Batch Gradient Norm after: 4.138597873166845
Epoch 4501/10000, Prediction Accuracy = 64.77307692307691%, Loss = 0.007794377286560261
Epoch: 4501, Batch Gradient Norm: 4.8139877467235515
Epoch: 4501, Batch Gradient Norm after: 4.8139877467235515
Epoch 4502/10000, Prediction Accuracy = 63.9076923076923%, Loss = 0.008098409690249424
Epoch: 4502, Batch Gradient Norm: 4.0471025910829095
Epoch: 4502, Batch Gradient Norm after: 4.0471025910829095
Epoch 4503/10000, Prediction Accuracy = 64.30000000000001%, Loss = 0.00781236753727381
Epoch: 4503, Batch Gradient Norm: 3.763438999265772
Epoch: 4503, Batch Gradient Norm after: 3.763438999265772
Epoch 4504/10000, Prediction Accuracy = 65.00384615384614%, Loss = 0.007632599391329747
Epoch: 4504, Batch Gradient Norm: 4.160679543270404
Epoch: 4504, Batch Gradient Norm after: 4.160679543270404
Epoch 4505/10000, Prediction Accuracy = 64.71923076923078%, Loss = 0.007749855804901857
Epoch: 4505, Batch Gradient Norm: 4.174974604976112
Epoch: 4505, Batch Gradient Norm after: 4.174974604976112
Epoch 4506/10000, Prediction Accuracy = 64.61923076923077%, Loss = 0.007855544941356549
Epoch: 4506, Batch Gradient Norm: 4.050696648109495
Epoch: 4506, Batch Gradient Norm after: 4.050696648109495
Epoch 4507/10000, Prediction Accuracy = 64.56153846153846%, Loss = 0.007709371893165203
Epoch: 4507, Batch Gradient Norm: 4.382198945888764
Epoch: 4507, Batch Gradient Norm after: 4.382198945888764
Epoch 4508/10000, Prediction Accuracy = 64.56923076923077%, Loss = 0.007742493485028927
Epoch: 4508, Batch Gradient Norm: 4.3052976516615935
Epoch: 4508, Batch Gradient Norm after: 4.3052976516615935
Epoch 4509/10000, Prediction Accuracy = 64.46153846153847%, Loss = 0.007829117696159162
Epoch: 4509, Batch Gradient Norm: 4.424901206912361
Epoch: 4509, Batch Gradient Norm after: 4.424901206912361
Epoch 4510/10000, Prediction Accuracy = 63.834615384615375%, Loss = 0.00802350646028152
Epoch: 4510, Batch Gradient Norm: 4.501395447402082
Epoch: 4510, Batch Gradient Norm after: 4.501395447402082
Epoch 4511/10000, Prediction Accuracy = 63.55384615384615%, Loss = 0.008117597836714525
Epoch: 4511, Batch Gradient Norm: 4.30077865059348
Epoch: 4511, Batch Gradient Norm after: 4.30077865059348
Epoch 4512/10000, Prediction Accuracy = 63.82692307692309%, Loss = 0.007869764374425778
Epoch: 4512, Batch Gradient Norm: 4.641169059041018
Epoch: 4512, Batch Gradient Norm after: 4.641169059041018
Epoch 4513/10000, Prediction Accuracy = 64.01923076923077%, Loss = 0.008047928675436057
Epoch: 4513, Batch Gradient Norm: 4.431339238202798
Epoch: 4513, Batch Gradient Norm after: 4.431339238202798
Epoch 4514/10000, Prediction Accuracy = 64.17307692307692%, Loss = 0.007898739825647611
Epoch: 4514, Batch Gradient Norm: 4.451101572664712
Epoch: 4514, Batch Gradient Norm after: 4.451101572664712
Epoch 4515/10000, Prediction Accuracy = 64.42307692307692%, Loss = 0.007926686165424494
Epoch: 4515, Batch Gradient Norm: 4.685628413127034
Epoch: 4515, Batch Gradient Norm after: 4.685628413127034
Epoch 4516/10000, Prediction Accuracy = 64.22692307692309%, Loss = 0.008088971380717479
Epoch: 4516, Batch Gradient Norm: 4.5132075727746015
Epoch: 4516, Batch Gradient Norm after: 4.5132075727746015
Epoch 4517/10000, Prediction Accuracy = 64.2923076923077%, Loss = 0.0079900471565242
Epoch: 4517, Batch Gradient Norm: 3.9543885466397564
Epoch: 4517, Batch Gradient Norm after: 3.9543885466397564
Epoch 4518/10000, Prediction Accuracy = 64.88461538461539%, Loss = 0.007682385639502452
Epoch: 4518, Batch Gradient Norm: 3.9786960015032276
Epoch: 4518, Batch Gradient Norm after: 3.9786960015032276
Epoch 4519/10000, Prediction Accuracy = 64.80384615384615%, Loss = 0.007697059772908688
Epoch: 4519, Batch Gradient Norm: 4.142290527392289
Epoch: 4519, Batch Gradient Norm after: 4.142290527392289
Epoch 4520/10000, Prediction Accuracy = 64.25769230769231%, Loss = 0.007765378014972577
Epoch: 4520, Batch Gradient Norm: 4.326452917041027
Epoch: 4520, Batch Gradient Norm after: 4.326452917041027
Epoch 4521/10000, Prediction Accuracy = 64.4423076923077%, Loss = 0.007855508118294753
Epoch: 4521, Batch Gradient Norm: 4.5309113151118305
Epoch: 4521, Batch Gradient Norm after: 4.5309113151118305
Epoch 4522/10000, Prediction Accuracy = 63.94230769230769%, Loss = 0.008076989879974952
Epoch: 4522, Batch Gradient Norm: 4.24242013767822
Epoch: 4522, Batch Gradient Norm after: 4.24242013767822
Epoch 4523/10000, Prediction Accuracy = 63.707692307692305%, Loss = 0.007996421558066057
Epoch: 4523, Batch Gradient Norm: 4.280067243796127
Epoch: 4523, Batch Gradient Norm after: 4.280067243796127
Epoch 4524/10000, Prediction Accuracy = 64.40384615384616%, Loss = 0.007962955448489923
Epoch: 4524, Batch Gradient Norm: 4.282658026516276
Epoch: 4524, Batch Gradient Norm after: 4.282658026516276
Epoch 4525/10000, Prediction Accuracy = 64.00384615384617%, Loss = 0.007900065670792874
Epoch: 4525, Batch Gradient Norm: 3.9924317421516706
Epoch: 4525, Batch Gradient Norm after: 3.9924317421516706
Epoch 4526/10000, Prediction Accuracy = 64.56538461538463%, Loss = 0.007661686243059544
Epoch: 4526, Batch Gradient Norm: 3.970925651095045
Epoch: 4526, Batch Gradient Norm after: 3.970925651095045
Epoch 4527/10000, Prediction Accuracy = 64.58076923076922%, Loss = 0.007721814792603254
Epoch: 4527, Batch Gradient Norm: 3.904320117585844
Epoch: 4527, Batch Gradient Norm after: 3.904320117585844
Epoch 4528/10000, Prediction Accuracy = 64.7076923076923%, Loss = 0.007674220018088818
Epoch: 4528, Batch Gradient Norm: 4.358372408267133
Epoch: 4528, Batch Gradient Norm after: 4.358372408267133
Epoch 4529/10000, Prediction Accuracy = 63.707692307692305%, Loss = 0.007959882728755474
Epoch: 4529, Batch Gradient Norm: 4.125985813464027
Epoch: 4529, Batch Gradient Norm after: 4.125985813464027
Epoch 4530/10000, Prediction Accuracy = 64.91538461538461%, Loss = 0.0077238144496312505
Epoch: 4530, Batch Gradient Norm: 4.1010627364191885
Epoch: 4530, Batch Gradient Norm after: 4.1010627364191885
Epoch 4531/10000, Prediction Accuracy = 64.80384615384615%, Loss = 0.00768950037085093
Epoch: 4531, Batch Gradient Norm: 4.577489069508391
Epoch: 4531, Batch Gradient Norm after: 4.577489069508391
Epoch 4532/10000, Prediction Accuracy = 63.919230769230765%, Loss = 0.008072980178090243
Epoch: 4532, Batch Gradient Norm: 4.368260781607862
Epoch: 4532, Batch Gradient Norm after: 4.368260781607862
Epoch 4533/10000, Prediction Accuracy = 63.823076923076925%, Loss = 0.008041845240558568
Epoch: 4533, Batch Gradient Norm: 4.187794606365581
Epoch: 4533, Batch Gradient Norm after: 4.187794606365581
Epoch 4534/10000, Prediction Accuracy = 64.63461538461539%, Loss = 0.007808485140021031
Epoch: 4534, Batch Gradient Norm: 3.7812513530616703
Epoch: 4534, Batch Gradient Norm after: 3.7812513530616703
Epoch 4535/10000, Prediction Accuracy = 64.70769230769233%, Loss = 0.007595138982511484
Epoch: 4535, Batch Gradient Norm: 3.985352866487684
Epoch: 4535, Batch Gradient Norm after: 3.985352866487684
Epoch 4536/10000, Prediction Accuracy = 64.88846153846154%, Loss = 0.007726970916757217
Epoch: 4536, Batch Gradient Norm: 4.112475514944879
Epoch: 4536, Batch Gradient Norm after: 4.112475514944879
Epoch 4537/10000, Prediction Accuracy = 64.47692307692309%, Loss = 0.007740052524380959
Epoch: 4537, Batch Gradient Norm: 4.044393805907207
Epoch: 4537, Batch Gradient Norm after: 4.044393805907207
Epoch 4538/10000, Prediction Accuracy = 64.9%, Loss = 0.007671966575659239
Epoch: 4538, Batch Gradient Norm: 4.160106307837325
Epoch: 4538, Batch Gradient Norm after: 4.160106307837325
Epoch 4539/10000, Prediction Accuracy = 64.62692307692308%, Loss = 0.007773773243220953
Epoch: 4539, Batch Gradient Norm: 4.4453563388508615
Epoch: 4539, Batch Gradient Norm after: 4.4453563388508615
Epoch 4540/10000, Prediction Accuracy = 64.27692307692305%, Loss = 0.007888971720463954
Epoch: 4540, Batch Gradient Norm: 4.059525196108486
Epoch: 4540, Batch Gradient Norm after: 4.059525196108486
Epoch 4541/10000, Prediction Accuracy = 64.85000000000001%, Loss = 0.007780273982252066
Epoch: 4541, Batch Gradient Norm: 3.967434305358408
Epoch: 4541, Batch Gradient Norm after: 3.967434305358408
Epoch 4542/10000, Prediction Accuracy = 64.62307692307692%, Loss = 0.007695148985546369
Epoch: 4542, Batch Gradient Norm: 4.474987356195041
Epoch: 4542, Batch Gradient Norm after: 4.474987356195041
Epoch 4543/10000, Prediction Accuracy = 64.12307692307692%, Loss = 0.007888626235608872
Epoch: 4543, Batch Gradient Norm: 3.9284942916244936
Epoch: 4543, Batch Gradient Norm after: 3.9284942916244936
Epoch 4544/10000, Prediction Accuracy = 64.81538461538462%, Loss = 0.007624789642599912
Epoch: 4544, Batch Gradient Norm: 3.8175183918048416
Epoch: 4544, Batch Gradient Norm after: 3.8175183918048416
Epoch 4545/10000, Prediction Accuracy = 64.71923076923078%, Loss = 0.00760831436715447
Epoch: 4545, Batch Gradient Norm: 4.151300593139832
Epoch: 4545, Batch Gradient Norm after: 4.151300593139832
Epoch 4546/10000, Prediction Accuracy = 64.40384615384616%, Loss = 0.0077149017642323785
Epoch: 4546, Batch Gradient Norm: 4.589293628687073
Epoch: 4546, Batch Gradient Norm after: 4.589293628687073
Epoch 4547/10000, Prediction Accuracy = 63.99230769230768%, Loss = 0.007955695753200697
Epoch: 4547, Batch Gradient Norm: 4.356063541631835
Epoch: 4547, Batch Gradient Norm after: 4.356063541631835
Epoch 4548/10000, Prediction Accuracy = 64.3923076923077%, Loss = 0.007922490879606742
Epoch: 4548, Batch Gradient Norm: 4.066908485662218
Epoch: 4548, Batch Gradient Norm after: 4.066908485662218
Epoch 4549/10000, Prediction Accuracy = 64.55384615384615%, Loss = 0.007727885117324499
Epoch: 4549, Batch Gradient Norm: 4.00167511301455
Epoch: 4549, Batch Gradient Norm after: 4.00167511301455
Epoch 4550/10000, Prediction Accuracy = 65.05384615384617%, Loss = 0.007635819904792767
Epoch: 4550, Batch Gradient Norm: 4.187281590954723
Epoch: 4550, Batch Gradient Norm after: 4.187281590954723
Epoch 4551/10000, Prediction Accuracy = 64.71923076923078%, Loss = 0.007686044411877027
Epoch: 4551, Batch Gradient Norm: 4.555243912061764
Epoch: 4551, Batch Gradient Norm after: 4.555243912061764
Epoch 4552/10000, Prediction Accuracy = 64.13846153846154%, Loss = 0.007892245677514719
Epoch: 4552, Batch Gradient Norm: 3.8731493089631823
Epoch: 4552, Batch Gradient Norm after: 3.8731493089631823
Epoch 4553/10000, Prediction Accuracy = 65.04615384615384%, Loss = 0.007578575876183235
Epoch: 4553, Batch Gradient Norm: 3.669156830992736
Epoch: 4553, Batch Gradient Norm after: 3.669156830992736
Epoch 4554/10000, Prediction Accuracy = 65.41538461538461%, Loss = 0.007495457772165537
Epoch: 4554, Batch Gradient Norm: 4.2103656317470355
Epoch: 4554, Batch Gradient Norm after: 4.2103656317470355
Epoch 4555/10000, Prediction Accuracy = 64.65384615384616%, Loss = 0.007745026646611782
Epoch: 4555, Batch Gradient Norm: 3.881605853297944
Epoch: 4555, Batch Gradient Norm after: 3.881605853297944
Epoch 4556/10000, Prediction Accuracy = 65.3076923076923%, Loss = 0.007495856628968165
Epoch: 4556, Batch Gradient Norm: 4.148325370153814
Epoch: 4556, Batch Gradient Norm after: 4.148325370153814
Epoch 4557/10000, Prediction Accuracy = 64.66153846153847%, Loss = 0.007697395192315945
Epoch: 4557, Batch Gradient Norm: 4.225493952902888
Epoch: 4557, Batch Gradient Norm after: 4.225493952902888
Epoch 4558/10000, Prediction Accuracy = 64.46153846153847%, Loss = 0.0077294039969834
Epoch: 4558, Batch Gradient Norm: 4.373426681567301
Epoch: 4558, Batch Gradient Norm after: 4.373426681567301
Epoch 4559/10000, Prediction Accuracy = 64.27692307692308%, Loss = 0.0078869117782093
Epoch: 4559, Batch Gradient Norm: 4.355921223582225
Epoch: 4559, Batch Gradient Norm after: 4.355921223582225
Epoch 4560/10000, Prediction Accuracy = 64.51153846153846%, Loss = 0.00789281392756563
Epoch: 4560, Batch Gradient Norm: 4.822306696318564
Epoch: 4560, Batch Gradient Norm after: 4.822306696318564
Epoch 4561/10000, Prediction Accuracy = 63.76923076923077%, Loss = 0.008078905037389351
Epoch: 4561, Batch Gradient Norm: 3.9203623838923085
Epoch: 4561, Batch Gradient Norm after: 3.9203623838923085
Epoch 4562/10000, Prediction Accuracy = 64.39615384615385%, Loss = 0.007696289175118391
Epoch: 4562, Batch Gradient Norm: 4.3337209059803525
Epoch: 4562, Batch Gradient Norm after: 4.3337209059803525
Epoch 4563/10000, Prediction Accuracy = 64.21538461538462%, Loss = 0.007891857638381995
Epoch: 4563, Batch Gradient Norm: 4.156726071613195
Epoch: 4563, Batch Gradient Norm after: 4.156726071613195
Epoch 4564/10000, Prediction Accuracy = 64.50384615384615%, Loss = 0.007820606267509552
Epoch: 4564, Batch Gradient Norm: 4.438662037775073
Epoch: 4564, Batch Gradient Norm after: 4.438662037775073
Epoch 4565/10000, Prediction Accuracy = 64.35384615384615%, Loss = 0.00791161385579751
Epoch: 4565, Batch Gradient Norm: 4.261568823212812
Epoch: 4565, Batch Gradient Norm after: 4.261568823212812
Epoch 4566/10000, Prediction Accuracy = 64.01923076923077%, Loss = 0.007963207944367941
Epoch: 4566, Batch Gradient Norm: 4.363715888122698
Epoch: 4566, Batch Gradient Norm after: 4.363715888122698
Epoch 4567/10000, Prediction Accuracy = 64.0576923076923%, Loss = 0.007939693267242266
Epoch: 4567, Batch Gradient Norm: 4.430636457486883
Epoch: 4567, Batch Gradient Norm after: 4.430636457486883
Epoch 4568/10000, Prediction Accuracy = 64.02307692307693%, Loss = 0.007929792914253015
Epoch: 4568, Batch Gradient Norm: 4.519665692516754
Epoch: 4568, Batch Gradient Norm after: 4.519665692516754
Epoch 4569/10000, Prediction Accuracy = 64.22307692307692%, Loss = 0.008000687660219578
Epoch: 4569, Batch Gradient Norm: 4.641042315464229
Epoch: 4569, Batch Gradient Norm after: 4.641042315464229
Epoch 4570/10000, Prediction Accuracy = 63.857692307692304%, Loss = 0.008054072968661785
Epoch: 4570, Batch Gradient Norm: 4.417768931117176
Epoch: 4570, Batch Gradient Norm after: 4.417768931117176
Epoch 4571/10000, Prediction Accuracy = 63.82692307692309%, Loss = 0.007973228867810506
Epoch: 4571, Batch Gradient Norm: 4.451048472299497
Epoch: 4571, Batch Gradient Norm after: 4.451048472299497
Epoch 4572/10000, Prediction Accuracy = 64.06153846153846%, Loss = 0.0079254494765057
Epoch: 4572, Batch Gradient Norm: 4.396169836506476
Epoch: 4572, Batch Gradient Norm after: 4.396169836506476
Epoch 4573/10000, Prediction Accuracy = 64.05000000000001%, Loss = 0.008000280457333876
Epoch: 4573, Batch Gradient Norm: 4.409237442809429
Epoch: 4573, Batch Gradient Norm after: 4.409237442809429
Epoch 4574/10000, Prediction Accuracy = 64.16538461538462%, Loss = 0.007977456427537478
Epoch: 4574, Batch Gradient Norm: 3.560512039818478
Epoch: 4574, Batch Gradient Norm after: 3.560512039818478
Epoch 4575/10000, Prediction Accuracy = 65.33076923076923%, Loss = 0.007550787467222948
Epoch: 4575, Batch Gradient Norm: 3.7640206094202022
Epoch: 4575, Batch Gradient Norm after: 3.7640206094202022
Epoch 4576/10000, Prediction Accuracy = 64.93076923076923%, Loss = 0.007510855364111753
Epoch: 4576, Batch Gradient Norm: 3.834114471444766
Epoch: 4576, Batch Gradient Norm after: 3.834114471444766
Epoch 4577/10000, Prediction Accuracy = 65.03461538461539%, Loss = 0.007638403142874057
Epoch: 4577, Batch Gradient Norm: 4.315673040063106
Epoch: 4577, Batch Gradient Norm after: 4.315673040063106
Epoch 4578/10000, Prediction Accuracy = 64.13076923076925%, Loss = 0.007899144986787668
Epoch: 4578, Batch Gradient Norm: 4.089275902469695
Epoch: 4578, Batch Gradient Norm after: 4.089275902469695
Epoch 4579/10000, Prediction Accuracy = 64.27307692307693%, Loss = 0.007809729422800816
Epoch: 4579, Batch Gradient Norm: 4.042662024857899
Epoch: 4579, Batch Gradient Norm after: 4.042662024857899
Epoch 4580/10000, Prediction Accuracy = 64.18846153846155%, Loss = 0.007860674092975946
Epoch: 4580, Batch Gradient Norm: 4.124269596905386
Epoch: 4580, Batch Gradient Norm after: 4.124269596905386
Epoch 4581/10000, Prediction Accuracy = 64.3576923076923%, Loss = 0.007776347956118675
Epoch: 4581, Batch Gradient Norm: 4.119512322662996
Epoch: 4581, Batch Gradient Norm after: 4.119512322662996
Epoch 4582/10000, Prediction Accuracy = 64.60769230769232%, Loss = 0.007774419616907835
Epoch: 4582, Batch Gradient Norm: 4.237064158943304
Epoch: 4582, Batch Gradient Norm after: 4.237064158943304
Epoch 4583/10000, Prediction Accuracy = 64.47307692307693%, Loss = 0.007835216748599824
Epoch: 4583, Batch Gradient Norm: 4.024198582752032
Epoch: 4583, Batch Gradient Norm after: 4.024198582752032
Epoch 4584/10000, Prediction Accuracy = 64.57692307692308%, Loss = 0.007740965865265865
Epoch: 4584, Batch Gradient Norm: 4.155924383756485
Epoch: 4584, Batch Gradient Norm after: 4.155924383756485
Epoch 4585/10000, Prediction Accuracy = 65.06153846153848%, Loss = 0.007752582645760133
Epoch: 4585, Batch Gradient Norm: 3.9307382806127684
Epoch: 4585, Batch Gradient Norm after: 3.9307382806127684
Epoch 4586/10000, Prediction Accuracy = 65.01923076923077%, Loss = 0.007602136976157243
Epoch: 4586, Batch Gradient Norm: 4.128382674089784
Epoch: 4586, Batch Gradient Norm after: 4.128382674089784
Epoch 4587/10000, Prediction Accuracy = 65.11538461538463%, Loss = 0.007604571954848675
Epoch: 4587, Batch Gradient Norm: 4.116679566640184
Epoch: 4587, Batch Gradient Norm after: 4.116679566640184
Epoch 4588/10000, Prediction Accuracy = 65.2346153846154%, Loss = 0.0076344809494912624
Epoch: 4588, Batch Gradient Norm: 3.993497124094185
Epoch: 4588, Batch Gradient Norm after: 3.993497124094185
Epoch 4589/10000, Prediction Accuracy = 64.72307692307693%, Loss = 0.007702029775828123
Epoch: 4589, Batch Gradient Norm: 4.15503256335867
Epoch: 4589, Batch Gradient Norm after: 4.15503256335867
Epoch 4590/10000, Prediction Accuracy = 64.9346153846154%, Loss = 0.00775323396262068
Epoch: 4590, Batch Gradient Norm: 4.250201295213171
Epoch: 4590, Batch Gradient Norm after: 4.250201295213171
Epoch 4591/10000, Prediction Accuracy = 64.56538461538462%, Loss = 0.00787135736586956
Epoch: 4591, Batch Gradient Norm: 4.3932048145109945
Epoch: 4591, Batch Gradient Norm after: 4.3932048145109945
Epoch 4592/10000, Prediction Accuracy = 64.79615384615384%, Loss = 0.007832985299711045
Epoch: 4592, Batch Gradient Norm: 4.6121599571867735
Epoch: 4592, Batch Gradient Norm after: 4.6121599571867735
Epoch 4593/10000, Prediction Accuracy = 64.08076923076922%, Loss = 0.007957314785856467
Epoch: 4593, Batch Gradient Norm: 4.222682770239532
Epoch: 4593, Batch Gradient Norm after: 4.222682770239532
Epoch 4594/10000, Prediction Accuracy = 63.923076923076934%, Loss = 0.007989597936662344
Epoch: 4594, Batch Gradient Norm: 4.213298306014326
Epoch: 4594, Batch Gradient Norm after: 4.213298306014326
Epoch 4595/10000, Prediction Accuracy = 64.28846153846153%, Loss = 0.007839227345987009
Epoch: 4595, Batch Gradient Norm: 4.294138674449987
Epoch: 4595, Batch Gradient Norm after: 4.294138674449987
Epoch 4596/10000, Prediction Accuracy = 64.28461538461539%, Loss = 0.007883428882520933
Epoch: 4596, Batch Gradient Norm: 4.334437230255525
Epoch: 4596, Batch Gradient Norm after: 4.334437230255525
Epoch 4597/10000, Prediction Accuracy = 63.81538461538462%, Loss = 0.00793787446589424
Epoch: 4597, Batch Gradient Norm: 4.2582433886635265
Epoch: 4597, Batch Gradient Norm after: 4.2582433886635265
Epoch 4598/10000, Prediction Accuracy = 64.36538461538461%, Loss = 0.007845190819352865
Epoch: 4598, Batch Gradient Norm: 4.126548068308195
Epoch: 4598, Batch Gradient Norm after: 4.126548068308195
Epoch 4599/10000, Prediction Accuracy = 64.7923076923077%, Loss = 0.007753331035089035
Epoch: 4599, Batch Gradient Norm: 4.095361100614121
Epoch: 4599, Batch Gradient Norm after: 4.095361100614121
Epoch 4600/10000, Prediction Accuracy = 64.86538461538461%, Loss = 0.0077014175028755115
Epoch: 4600, Batch Gradient Norm: 4.12777718171132
Epoch: 4600, Batch Gradient Norm after: 4.12777718171132
Epoch 4601/10000, Prediction Accuracy = 64.71923076923078%, Loss = 0.0077444050246133255
Epoch: 4601, Batch Gradient Norm: 4.321450172999882
Epoch: 4601, Batch Gradient Norm after: 4.321450172999882
Epoch 4602/10000, Prediction Accuracy = 64.6%, Loss = 0.007789434220355291
Epoch: 4602, Batch Gradient Norm: 3.9983413272345896
Epoch: 4602, Batch Gradient Norm after: 3.9983413272345896
Epoch 4603/10000, Prediction Accuracy = 64.92692307692307%, Loss = 0.007705993484705687
Epoch: 4603, Batch Gradient Norm: 3.959085411093284
Epoch: 4603, Batch Gradient Norm after: 3.959085411093284
Epoch 4604/10000, Prediction Accuracy = 64.83076923076923%, Loss = 0.007609014291889393
Epoch: 4604, Batch Gradient Norm: 4.630775799052443
Epoch: 4604, Batch Gradient Norm after: 4.630775799052443
Epoch 4605/10000, Prediction Accuracy = 64.58461538461539%, Loss = 0.007924724119500471
Epoch: 4605, Batch Gradient Norm: 4.134223313238237
Epoch: 4605, Batch Gradient Norm after: 4.134223313238237
Epoch 4606/10000, Prediction Accuracy = 64.38076923076923%, Loss = 0.007702371965234096
Epoch: 4606, Batch Gradient Norm: 4.123641714866666
Epoch: 4606, Batch Gradient Norm after: 4.123641714866666
Epoch 4607/10000, Prediction Accuracy = 64.85769230769232%, Loss = 0.007623402760005915
Epoch: 4607, Batch Gradient Norm: 4.457265894977861
Epoch: 4607, Batch Gradient Norm after: 4.457265894977861
Epoch 4608/10000, Prediction Accuracy = 64.22692307692307%, Loss = 0.007959943551283617
Epoch: 4608, Batch Gradient Norm: 4.67910452827828
Epoch: 4608, Batch Gradient Norm after: 4.67910452827828
Epoch 4609/10000, Prediction Accuracy = 63.98076923076922%, Loss = 0.008084572278536283
Epoch: 4609, Batch Gradient Norm: 3.99451951052852
Epoch: 4609, Batch Gradient Norm after: 3.99451951052852
Epoch 4610/10000, Prediction Accuracy = 64.44615384615383%, Loss = 0.007788508915557311
Epoch: 4610, Batch Gradient Norm: 4.22525644804021
Epoch: 4610, Batch Gradient Norm after: 4.22525644804021
Epoch 4611/10000, Prediction Accuracy = 64.55384615384615%, Loss = 0.007784304495614309
Epoch: 4611, Batch Gradient Norm: 4.298508623843659
Epoch: 4611, Batch Gradient Norm after: 4.298508623843659
Epoch 4612/10000, Prediction Accuracy = 64.50384615384615%, Loss = 0.0078075856256943485
Epoch: 4612, Batch Gradient Norm: 3.9727465020592265
Epoch: 4612, Batch Gradient Norm after: 3.9727465020592265
Epoch 4613/10000, Prediction Accuracy = 64.76153846153846%, Loss = 0.007643253148461764
Epoch: 4613, Batch Gradient Norm: 4.120142991885941
Epoch: 4613, Batch Gradient Norm after: 4.120142991885941
Epoch 4614/10000, Prediction Accuracy = 64.64615384615384%, Loss = 0.0077396685329194255
Epoch: 4614, Batch Gradient Norm: 4.224523016809885
Epoch: 4614, Batch Gradient Norm after: 4.224523016809885
Epoch 4615/10000, Prediction Accuracy = 64.04230769230767%, Loss = 0.007917408294116076
Epoch: 4615, Batch Gradient Norm: 4.153783499925948
Epoch: 4615, Batch Gradient Norm after: 4.153783499925948
Epoch 4616/10000, Prediction Accuracy = 64.63846153846154%, Loss = 0.007798416504206566
Epoch: 4616, Batch Gradient Norm: 3.9794101652318012
Epoch: 4616, Batch Gradient Norm after: 3.9794101652318012
Epoch 4617/10000, Prediction Accuracy = 64.81538461538462%, Loss = 0.007675487010811384
Epoch: 4617, Batch Gradient Norm: 4.2107923817871775
Epoch: 4617, Batch Gradient Norm after: 4.2107923817871775
Epoch 4618/10000, Prediction Accuracy = 64.58461538461539%, Loss = 0.007831060900711097
Epoch: 4618, Batch Gradient Norm: 4.435935247308016
Epoch: 4618, Batch Gradient Norm after: 4.435935247308016
Epoch 4619/10000, Prediction Accuracy = 64.62692307692308%, Loss = 0.007864482163523253
Epoch: 4619, Batch Gradient Norm: 4.432246089724508
Epoch: 4619, Batch Gradient Norm after: 4.432246089724508
Epoch 4620/10000, Prediction Accuracy = 64.0576923076923%, Loss = 0.007929084822535515
Epoch: 4620, Batch Gradient Norm: 4.160093625662528
Epoch: 4620, Batch Gradient Norm after: 4.160093625662528
Epoch 4621/10000, Prediction Accuracy = 64.23461538461538%, Loss = 0.00780976742792588
Epoch: 4621, Batch Gradient Norm: 4.281048839931969
Epoch: 4621, Batch Gradient Norm after: 4.281048839931969
Epoch 4622/10000, Prediction Accuracy = 64.65769230769232%, Loss = 0.007728177695893324
Epoch: 4622, Batch Gradient Norm: 4.0828001357897135
Epoch: 4622, Batch Gradient Norm after: 4.0828001357897135
Epoch 4623/10000, Prediction Accuracy = 64.7076923076923%, Loss = 0.007686451650582827
Epoch: 4623, Batch Gradient Norm: 4.283175457867874
Epoch: 4623, Batch Gradient Norm after: 4.283175457867874
Epoch 4624/10000, Prediction Accuracy = 64.37307692307692%, Loss = 0.00781730548120462
Epoch: 4624, Batch Gradient Norm: 3.9947708281645893
Epoch: 4624, Batch Gradient Norm after: 3.9947708281645893
Epoch 4625/10000, Prediction Accuracy = 64.86153846153846%, Loss = 0.007692744847960197
Epoch: 4625, Batch Gradient Norm: 4.127382243403957
Epoch: 4625, Batch Gradient Norm after: 4.127382243403957
Epoch 4626/10000, Prediction Accuracy = 64.53076923076924%, Loss = 0.007717481885965054
Epoch: 4626, Batch Gradient Norm: 4.373308756190473
Epoch: 4626, Batch Gradient Norm after: 4.373308756190473
Epoch 4627/10000, Prediction Accuracy = 64.13846153846154%, Loss = 0.007823260107006017
Epoch: 4627, Batch Gradient Norm: 4.224335641621518
Epoch: 4627, Batch Gradient Norm after: 4.224335641621518
Epoch 4628/10000, Prediction Accuracy = 64.32307692307693%, Loss = 0.007817489345772909
Epoch: 4628, Batch Gradient Norm: 4.206432028053722
Epoch: 4628, Batch Gradient Norm after: 4.206432028053722
Epoch 4629/10000, Prediction Accuracy = 64.36153846153846%, Loss = 0.007830190973786207
Epoch: 4629, Batch Gradient Norm: 4.121945299906084
Epoch: 4629, Batch Gradient Norm after: 4.121945299906084
Epoch 4630/10000, Prediction Accuracy = 64.3153846153846%, Loss = 0.00785760205382338
Epoch: 4630, Batch Gradient Norm: 4.155023039138497
Epoch: 4630, Batch Gradient Norm after: 4.155023039138497
Epoch 4631/10000, Prediction Accuracy = 64.60384615384615%, Loss = 0.0077035591149559384
Epoch: 4631, Batch Gradient Norm: 3.9347996557772555
Epoch: 4631, Batch Gradient Norm after: 3.9347996557772555
Epoch 4632/10000, Prediction Accuracy = 64.99615384615385%, Loss = 0.007515020704326721
Epoch: 4632, Batch Gradient Norm: 4.30980553016268
Epoch: 4632, Batch Gradient Norm after: 4.30980553016268
Epoch 4633/10000, Prediction Accuracy = 64.40384615384616%, Loss = 0.007882648470023504
Epoch: 4633, Batch Gradient Norm: 4.482697683067972
Epoch: 4633, Batch Gradient Norm after: 4.482697683067972
Epoch 4634/10000, Prediction Accuracy = 64.03461538461538%, Loss = 0.007957584475382017
Epoch: 4634, Batch Gradient Norm: 4.032007983076406
Epoch: 4634, Batch Gradient Norm after: 4.032007983076406
Epoch 4635/10000, Prediction Accuracy = 64.87692307692306%, Loss = 0.007732397303558313
Epoch: 4635, Batch Gradient Norm: 3.8646448738628814
Epoch: 4635, Batch Gradient Norm after: 3.8646448738628814
Epoch 4636/10000, Prediction Accuracy = 64.8076923076923%, Loss = 0.00757764673863466
Epoch: 4636, Batch Gradient Norm: 4.05963398735575
Epoch: 4636, Batch Gradient Norm after: 4.05963398735575
Epoch 4637/10000, Prediction Accuracy = 65.12307692307692%, Loss = 0.007598781385100805
Epoch: 4637, Batch Gradient Norm: 4.371564309207711
Epoch: 4637, Batch Gradient Norm after: 4.371564309207711
Epoch 4638/10000, Prediction Accuracy = 64.69615384615386%, Loss = 0.007755665896603694
Epoch: 4638, Batch Gradient Norm: 4.304938921663314
Epoch: 4638, Batch Gradient Norm after: 4.304938921663314
Epoch 4639/10000, Prediction Accuracy = 64.53846153846153%, Loss = 0.007891923869745089
Epoch: 4639, Batch Gradient Norm: 4.6034372312242615
Epoch: 4639, Batch Gradient Norm after: 4.6034372312242615
Epoch 4640/10000, Prediction Accuracy = 63.5846153846154%, Loss = 0.008184299016228089
Epoch: 4640, Batch Gradient Norm: 4.216282681213979
Epoch: 4640, Batch Gradient Norm after: 4.216282681213979
Epoch 4641/10000, Prediction Accuracy = 64.54230769230769%, Loss = 0.007859497940024504
Epoch: 4641, Batch Gradient Norm: 4.182276375354467
Epoch: 4641, Batch Gradient Norm after: 4.182276375354467
Epoch 4642/10000, Prediction Accuracy = 64.28461538461539%, Loss = 0.00794973156343286
Epoch: 4642, Batch Gradient Norm: 4.264636130603491
Epoch: 4642, Batch Gradient Norm after: 4.264636130603491
Epoch 4643/10000, Prediction Accuracy = 63.98461538461538%, Loss = 0.007905318580854397
Epoch: 4643, Batch Gradient Norm: 4.324069969658431
Epoch: 4643, Batch Gradient Norm after: 4.324069969658431
Epoch 4644/10000, Prediction Accuracy = 64.4%, Loss = 0.00785475353208872
Epoch: 4644, Batch Gradient Norm: 4.409897172561337
Epoch: 4644, Batch Gradient Norm after: 4.409897172561337
Epoch 4645/10000, Prediction Accuracy = 64.31538461538462%, Loss = 0.007880954430080377
Epoch: 4645, Batch Gradient Norm: 4.111875692834786
Epoch: 4645, Batch Gradient Norm after: 4.111875692834786
Epoch 4646/10000, Prediction Accuracy = 64.79615384615384%, Loss = 0.007690010556521324
Epoch: 4646, Batch Gradient Norm: 4.4032651772020674
Epoch: 4646, Batch Gradient Norm after: 4.4032651772020674
Epoch 4647/10000, Prediction Accuracy = 64.1923076923077%, Loss = 0.007928251217191037
Epoch: 4647, Batch Gradient Norm: 4.324036227335622
Epoch: 4647, Batch Gradient Norm after: 4.324036227335622
Epoch 4648/10000, Prediction Accuracy = 64.41538461538462%, Loss = 0.007855709427251266
Epoch: 4648, Batch Gradient Norm: 4.407180006494811
Epoch: 4648, Batch Gradient Norm after: 4.407180006494811
Epoch 4649/10000, Prediction Accuracy = 64.0576923076923%, Loss = 0.007919291177621255
Epoch: 4649, Batch Gradient Norm: 4.2186841103741415
Epoch: 4649, Batch Gradient Norm after: 4.2186841103741415
Epoch 4650/10000, Prediction Accuracy = 64.45%, Loss = 0.007808466477749439
Epoch: 4650, Batch Gradient Norm: 4.06134771746642
Epoch: 4650, Batch Gradient Norm after: 4.06134771746642
Epoch 4651/10000, Prediction Accuracy = 65.18846153846154%, Loss = 0.0076960479267514665
Epoch: 4651, Batch Gradient Norm: 4.382427100525854
Epoch: 4651, Batch Gradient Norm after: 4.382427100525854
Epoch 4652/10000, Prediction Accuracy = 64.94999999999999%, Loss = 0.0078004986907427125
Epoch: 4652, Batch Gradient Norm: 4.385962962527075
Epoch: 4652, Batch Gradient Norm after: 4.385962962527075
Epoch 4653/10000, Prediction Accuracy = 63.861538461538466%, Loss = 0.007976177184341045
Epoch: 4653, Batch Gradient Norm: 4.775840000716405
Epoch: 4653, Batch Gradient Norm after: 4.775840000716405
Epoch 4654/10000, Prediction Accuracy = 63.37692307692306%, Loss = 0.00816350974715673
Epoch: 4654, Batch Gradient Norm: 4.383030551940858
Epoch: 4654, Batch Gradient Norm after: 4.383030551940858
Epoch 4655/10000, Prediction Accuracy = 63.934615384615384%, Loss = 0.007952357355791789
Epoch: 4655, Batch Gradient Norm: 4.145447147439108
Epoch: 4655, Batch Gradient Norm after: 4.145447147439108
Epoch 4656/10000, Prediction Accuracy = 64.6%, Loss = 0.007669010951828498
Epoch: 4656, Batch Gradient Norm: 3.8374356986528815
Epoch: 4656, Batch Gradient Norm after: 3.8374356986528815
Epoch 4657/10000, Prediction Accuracy = 64.5576923076923%, Loss = 0.007634904343061722
Epoch: 4657, Batch Gradient Norm: 3.787677309778951
Epoch: 4657, Batch Gradient Norm after: 3.787677309778951
Epoch 4658/10000, Prediction Accuracy = 65.18076923076923%, Loss = 0.007642120194549744
Epoch: 4658, Batch Gradient Norm: 4.163284366708583
Epoch: 4658, Batch Gradient Norm after: 4.163284366708583
Epoch 4659/10000, Prediction Accuracy = 64.49999999999999%, Loss = 0.00773551447603565
Epoch: 4659, Batch Gradient Norm: 3.9154153576078925
Epoch: 4659, Batch Gradient Norm after: 3.9154153576078925
Epoch 4660/10000, Prediction Accuracy = 65.26923076923076%, Loss = 0.007558182849047275
Epoch: 4660, Batch Gradient Norm: 3.795402327070324
Epoch: 4660, Batch Gradient Norm after: 3.795402327070324
Epoch 4661/10000, Prediction Accuracy = 65.23461538461538%, Loss = 0.0075242479618352195
Epoch: 4661, Batch Gradient Norm: 4.2405584915845616
Epoch: 4661, Batch Gradient Norm after: 4.2405584915845616
Epoch 4662/10000, Prediction Accuracy = 64.64615384615385%, Loss = 0.007664117496460676
Epoch: 4662, Batch Gradient Norm: 4.172593702737054
Epoch: 4662, Batch Gradient Norm after: 4.172593702737054
Epoch 4663/10000, Prediction Accuracy = 65.1923076923077%, Loss = 0.007745861147458737
Epoch: 4663, Batch Gradient Norm: 3.814479883141591
Epoch: 4663, Batch Gradient Norm after: 3.814479883141591
Epoch 4664/10000, Prediction Accuracy = 65.43461538461537%, Loss = 0.007527325445642838
Epoch: 4664, Batch Gradient Norm: 3.9236341805688024
Epoch: 4664, Batch Gradient Norm after: 3.9236341805688024
Epoch 4665/10000, Prediction Accuracy = 65.61538461538463%, Loss = 0.007563715263341482
Epoch: 4665, Batch Gradient Norm: 3.9774871071712687
Epoch: 4665, Batch Gradient Norm after: 3.9774871071712687
Epoch 4666/10000, Prediction Accuracy = 65.04230769230767%, Loss = 0.007543001395578568
Epoch: 4666, Batch Gradient Norm: 3.9621335697370283
Epoch: 4666, Batch Gradient Norm after: 3.9621335697370283
Epoch 4667/10000, Prediction Accuracy = 65.65769230769232%, Loss = 0.007535501239964595
Epoch: 4667, Batch Gradient Norm: 4.3752777928397935
Epoch: 4667, Batch Gradient Norm after: 4.3752777928397935
Epoch 4668/10000, Prediction Accuracy = 64.43076923076924%, Loss = 0.007751174808408205
Epoch: 4668, Batch Gradient Norm: 4.091497945998258
Epoch: 4668, Batch Gradient Norm after: 4.091497945998258
Epoch 4669/10000, Prediction Accuracy = 64.87692307692308%, Loss = 0.007567212200508668
Epoch: 4669, Batch Gradient Norm: 4.531613704042599
Epoch: 4669, Batch Gradient Norm after: 4.531613704042599
Epoch 4670/10000, Prediction Accuracy = 63.92307692307692%, Loss = 0.00792034794218265
Epoch: 4670, Batch Gradient Norm: 4.20434468355252
Epoch: 4670, Batch Gradient Norm after: 4.20434468355252
Epoch 4671/10000, Prediction Accuracy = 64.64615384615385%, Loss = 0.007722425561111707
Epoch: 4671, Batch Gradient Norm: 4.30505661382321
Epoch: 4671, Batch Gradient Norm after: 4.30505661382321
Epoch 4672/10000, Prediction Accuracy = 64.18076923076923%, Loss = 0.007788600829931406
Epoch: 4672, Batch Gradient Norm: 3.920329232368684
Epoch: 4672, Batch Gradient Norm after: 3.920329232368684
Epoch 4673/10000, Prediction Accuracy = 64.85384615384615%, Loss = 0.0075660545307283215
Epoch: 4673, Batch Gradient Norm: 3.8720531958610014
Epoch: 4673, Batch Gradient Norm after: 3.8720531958610014
Epoch 4674/10000, Prediction Accuracy = 65.6423076923077%, Loss = 0.00749681771804507
Epoch: 4674, Batch Gradient Norm: 4.318642703813197
Epoch: 4674, Batch Gradient Norm after: 4.318642703813197
Epoch 4675/10000, Prediction Accuracy = 65.06153846153846%, Loss = 0.007751459434915047
Epoch: 4675, Batch Gradient Norm: 4.284044848521606
Epoch: 4675, Batch Gradient Norm after: 4.284044848521606
Epoch 4676/10000, Prediction Accuracy = 64.67307692307692%, Loss = 0.007801780405525978
Epoch: 4676, Batch Gradient Norm: 4.052572483176094
Epoch: 4676, Batch Gradient Norm after: 4.052572483176094
Epoch 4677/10000, Prediction Accuracy = 64.92307692307692%, Loss = 0.00760401591945153
Epoch: 4677, Batch Gradient Norm: 4.311309074599486
Epoch: 4677, Batch Gradient Norm after: 4.311309074599486
Epoch 4678/10000, Prediction Accuracy = 64.43846153846154%, Loss = 0.0077626615977631165
Epoch: 4678, Batch Gradient Norm: 4.187970712364814
Epoch: 4678, Batch Gradient Norm after: 4.187970712364814
Epoch 4679/10000, Prediction Accuracy = 64.69999999999999%, Loss = 0.007718533707352785
Epoch: 4679, Batch Gradient Norm: 4.274512766465102
Epoch: 4679, Batch Gradient Norm after: 4.274512766465102
Epoch 4680/10000, Prediction Accuracy = 64.7423076923077%, Loss = 0.007801480018175566
Epoch: 4680, Batch Gradient Norm: 4.1305688065448045
Epoch: 4680, Batch Gradient Norm after: 4.1305688065448045
Epoch 4681/10000, Prediction Accuracy = 64.7346153846154%, Loss = 0.007732224077559435
Epoch: 4681, Batch Gradient Norm: 4.16735772110228
Epoch: 4681, Batch Gradient Norm after: 4.16735772110228
Epoch 4682/10000, Prediction Accuracy = 64.48076923076924%, Loss = 0.0076822460127564576
Epoch: 4682, Batch Gradient Norm: 4.248647269727796
Epoch: 4682, Batch Gradient Norm after: 4.248647269727796
Epoch 4683/10000, Prediction Accuracy = 64.35000000000001%, Loss = 0.007790844636754348
Epoch: 4683, Batch Gradient Norm: 4.528577825921312
Epoch: 4683, Batch Gradient Norm after: 4.528577825921312
Epoch 4684/10000, Prediction Accuracy = 64.67692307692306%, Loss = 0.007856804590958815
Epoch: 4684, Batch Gradient Norm: 4.303314667804537
Epoch: 4684, Batch Gradient Norm after: 4.303314667804537
Epoch 4685/10000, Prediction Accuracy = 64.94999999999999%, Loss = 0.007701363844367174
Epoch: 4685, Batch Gradient Norm: 4.482671721552202
Epoch: 4685, Batch Gradient Norm after: 4.482671721552202
Epoch 4686/10000, Prediction Accuracy = 64.50769230769232%, Loss = 0.0077931484064230555
Epoch: 4686, Batch Gradient Norm: 4.435232388465597
Epoch: 4686, Batch Gradient Norm after: 4.435232388465597
Epoch 4687/10000, Prediction Accuracy = 64.3076923076923%, Loss = 0.00789278788635364
Epoch: 4687, Batch Gradient Norm: 3.8986977160333893
Epoch: 4687, Batch Gradient Norm after: 3.8986977160333893
Epoch 4688/10000, Prediction Accuracy = 64.82307692307691%, Loss = 0.007633481103067215
Epoch: 4688, Batch Gradient Norm: 4.198404861742418
Epoch: 4688, Batch Gradient Norm after: 4.198404861742418
Epoch 4689/10000, Prediction Accuracy = 64.49230769230769%, Loss = 0.007819636115947595
Epoch: 4689, Batch Gradient Norm: 3.935070426131456
Epoch: 4689, Batch Gradient Norm after: 3.935070426131456
Epoch 4690/10000, Prediction Accuracy = 64.88461538461539%, Loss = 0.007660584488453774
Epoch: 4690, Batch Gradient Norm: 3.7726292199533824
Epoch: 4690, Batch Gradient Norm after: 3.7726292199533824
Epoch 4691/10000, Prediction Accuracy = 65.19615384615383%, Loss = 0.0074915384802107625
Epoch: 4691, Batch Gradient Norm: 4.064868843289707
Epoch: 4691, Batch Gradient Norm after: 4.064868843289707
Epoch 4692/10000, Prediction Accuracy = 64.91538461538461%, Loss = 0.0075884227497646445
Epoch: 4692, Batch Gradient Norm: 3.9881840324056506
Epoch: 4692, Batch Gradient Norm after: 3.9881840324056506
Epoch 4693/10000, Prediction Accuracy = 65.21538461538462%, Loss = 0.007585090191031878
Epoch: 4693, Batch Gradient Norm: 4.615765851442079
Epoch: 4693, Batch Gradient Norm after: 4.615765851442079
Epoch 4694/10000, Prediction Accuracy = 64.18846153846154%, Loss = 0.007938324402158078
Epoch: 4694, Batch Gradient Norm: 4.414963082466279
Epoch: 4694, Batch Gradient Norm after: 4.414963082466279
Epoch 4695/10000, Prediction Accuracy = 64.0653846153846%, Loss = 0.00787671791532865
Epoch: 4695, Batch Gradient Norm: 4.036970063397892
Epoch: 4695, Batch Gradient Norm after: 4.036970063397892
Epoch 4696/10000, Prediction Accuracy = 64.4576923076923%, Loss = 0.007791957997072201
Epoch: 4696, Batch Gradient Norm: 4.0946284339809065
Epoch: 4696, Batch Gradient Norm after: 4.0946284339809065
Epoch 4697/10000, Prediction Accuracy = 64.53076923076922%, Loss = 0.007786175164465721
Epoch: 4697, Batch Gradient Norm: 4.191944129386764
Epoch: 4697, Batch Gradient Norm after: 4.191944129386764
Epoch 4698/10000, Prediction Accuracy = 64.83461538461539%, Loss = 0.007728943959451639
Epoch: 4698, Batch Gradient Norm: 4.15459070471038
Epoch: 4698, Batch Gradient Norm after: 4.15459070471038
Epoch 4699/10000, Prediction Accuracy = 64.96923076923078%, Loss = 0.007715094619645522
Epoch: 4699, Batch Gradient Norm: 4.144086957964928
Epoch: 4699, Batch Gradient Norm after: 4.144086957964928
Epoch 4700/10000, Prediction Accuracy = 64.85384615384616%, Loss = 0.007585926733624477
Epoch: 4700, Batch Gradient Norm: 4.199952919758818
Epoch: 4700, Batch Gradient Norm after: 4.199952919758818
Epoch 4701/10000, Prediction Accuracy = 65.08461538461538%, Loss = 0.007620341072861965
Epoch: 4701, Batch Gradient Norm: 4.050579232097685
Epoch: 4701, Batch Gradient Norm after: 4.050579232097685
Epoch 4702/10000, Prediction Accuracy = 65.12307692307692%, Loss = 0.007538675330579281
Epoch: 4702, Batch Gradient Norm: 4.317359749395451
Epoch: 4702, Batch Gradient Norm after: 4.317359749395451
Epoch 4703/10000, Prediction Accuracy = 65.12692307692308%, Loss = 0.007690299159059158
Epoch: 4703, Batch Gradient Norm: 3.7346954977762197
Epoch: 4703, Batch Gradient Norm after: 3.7346954977762197
Epoch 4704/10000, Prediction Accuracy = 64.83846153846153%, Loss = 0.007503734829907234
Epoch: 4704, Batch Gradient Norm: 4.621094205523178
Epoch: 4704, Batch Gradient Norm after: 4.621094205523178
Epoch 4705/10000, Prediction Accuracy = 64.04615384615384%, Loss = 0.007946661601846036
Epoch: 4705, Batch Gradient Norm: 4.450075509707803
Epoch: 4705, Batch Gradient Norm after: 4.450075509707803
Epoch 4706/10000, Prediction Accuracy = 64.36538461538463%, Loss = 0.007916183318369664
Epoch: 4706, Batch Gradient Norm: 4.434496344489174
Epoch: 4706, Batch Gradient Norm after: 4.434496344489174
Epoch 4707/10000, Prediction Accuracy = 64.48846153846155%, Loss = 0.007817143932558022
Epoch: 4707, Batch Gradient Norm: 4.621808915858628
Epoch: 4707, Batch Gradient Norm after: 4.621808915858628
Epoch 4708/10000, Prediction Accuracy = 64.32307692307694%, Loss = 0.00779847539244936
Epoch: 4708, Batch Gradient Norm: 4.548644890976928
Epoch: 4708, Batch Gradient Norm after: 4.548644890976928
Epoch 4709/10000, Prediction Accuracy = 63.95384615384616%, Loss = 0.007907991225902852
Epoch: 4709, Batch Gradient Norm: 4.257327712742072
Epoch: 4709, Batch Gradient Norm after: 4.257327712742072
Epoch 4710/10000, Prediction Accuracy = 64.6076923076923%, Loss = 0.007712969556450844
Epoch: 4710, Batch Gradient Norm: 4.102330741016102
Epoch: 4710, Batch Gradient Norm after: 4.102330741016102
Epoch 4711/10000, Prediction Accuracy = 64.91538461538462%, Loss = 0.007623705869683852
Epoch: 4711, Batch Gradient Norm: 4.0526488403572944
Epoch: 4711, Batch Gradient Norm after: 4.0526488403572944
Epoch 4712/10000, Prediction Accuracy = 65.06923076923076%, Loss = 0.007620951984650814
Epoch: 4712, Batch Gradient Norm: 4.62936851321922
Epoch: 4712, Batch Gradient Norm after: 4.62936851321922
Epoch 4713/10000, Prediction Accuracy = 64.17307692307692%, Loss = 0.007880503813234659
Epoch: 4713, Batch Gradient Norm: 4.830656210967502
Epoch: 4713, Batch Gradient Norm after: 4.830656210967502
Epoch 4714/10000, Prediction Accuracy = 63.684615384615384%, Loss = 0.008166552449648198
Epoch: 4714, Batch Gradient Norm: 4.8412384484708815
Epoch: 4714, Batch Gradient Norm after: 4.8412384484708815
Epoch 4715/10000, Prediction Accuracy = 63.36923076923077%, Loss = 0.008136994563616239
Epoch: 4715, Batch Gradient Norm: 4.142128718772629
Epoch: 4715, Batch Gradient Norm after: 4.142128718772629
Epoch 4716/10000, Prediction Accuracy = 64.48461538461538%, Loss = 0.007824575958343653
Epoch: 4716, Batch Gradient Norm: 3.7557578488121437
Epoch: 4716, Batch Gradient Norm after: 3.7557578488121437
Epoch 4717/10000, Prediction Accuracy = 65.26923076923077%, Loss = 0.00763166004505295
Epoch: 4717, Batch Gradient Norm: 4.340553077267762
Epoch: 4717, Batch Gradient Norm after: 4.340553077267762
Epoch 4718/10000, Prediction Accuracy = 64.51153846153846%, Loss = 0.007871913078885812
Epoch: 4718, Batch Gradient Norm: 3.919629841787012
Epoch: 4718, Batch Gradient Norm after: 3.919629841787012
Epoch 4719/10000, Prediction Accuracy = 65.06538461538462%, Loss = 0.007540779761396921
Epoch: 4719, Batch Gradient Norm: 3.895213805538233
Epoch: 4719, Batch Gradient Norm after: 3.895213805538233
Epoch 4720/10000, Prediction Accuracy = 65.23846153846154%, Loss = 0.0075151432807055805
Epoch: 4720, Batch Gradient Norm: 3.7099039063857147
Epoch: 4720, Batch Gradient Norm after: 3.7099039063857147
Epoch 4721/10000, Prediction Accuracy = 64.96923076923076%, Loss = 0.007456675494233003
Epoch: 4721, Batch Gradient Norm: 3.62773943790487
Epoch: 4721, Batch Gradient Norm after: 3.62773943790487
Epoch 4722/10000, Prediction Accuracy = 65.28846153846153%, Loss = 0.007484870532957407
Epoch: 4722, Batch Gradient Norm: 3.7255951622565537
Epoch: 4722, Batch Gradient Norm after: 3.7255951622565537
Epoch 4723/10000, Prediction Accuracy = 65.50769230769231%, Loss = 0.007513330712054784
Epoch: 4723, Batch Gradient Norm: 4.338651605974735
Epoch: 4723, Batch Gradient Norm after: 4.338651605974735
Epoch 4724/10000, Prediction Accuracy = 64.63846153846154%, Loss = 0.0077673200374612445
Epoch: 4724, Batch Gradient Norm: 4.56250207512908
Epoch: 4724, Batch Gradient Norm after: 4.56250207512908
Epoch 4725/10000, Prediction Accuracy = 63.82692307692309%, Loss = 0.007900928612798452
Epoch: 4725, Batch Gradient Norm: 5.06824753092942
Epoch: 4725, Batch Gradient Norm after: 5.06824753092942
Epoch 4726/10000, Prediction Accuracy = 63.51153846153845%, Loss = 0.008175389554638129
Epoch: 4726, Batch Gradient Norm: 5.1310075102147605
Epoch: 4726, Batch Gradient Norm after: 5.1310075102147605
Epoch 4727/10000, Prediction Accuracy = 63.84615384615385%, Loss = 0.008162663819698187
Epoch: 4727, Batch Gradient Norm: 4.356148004703208
Epoch: 4727, Batch Gradient Norm after: 4.356148004703208
Epoch 4728/10000, Prediction Accuracy = 63.85000000000001%, Loss = 0.008011719785057582
Epoch: 4728, Batch Gradient Norm: 4.018272707133812
Epoch: 4728, Batch Gradient Norm after: 4.018272707133812
Epoch 4729/10000, Prediction Accuracy = 64.49615384615385%, Loss = 0.007758992115178933
Epoch: 4729, Batch Gradient Norm: 4.086235296212808
Epoch: 4729, Batch Gradient Norm after: 4.086235296212808
Epoch 4730/10000, Prediction Accuracy = 64.68846153846154%, Loss = 0.007729434694808263
Epoch: 4730, Batch Gradient Norm: 4.26735558997057
Epoch: 4730, Batch Gradient Norm after: 4.26735558997057
Epoch 4731/10000, Prediction Accuracy = 64.50769230769231%, Loss = 0.007743987827919996
Epoch: 4731, Batch Gradient Norm: 4.408767562114628
Epoch: 4731, Batch Gradient Norm after: 4.408767562114628
Epoch 4732/10000, Prediction Accuracy = 64.24230769230769%, Loss = 0.007901837189610187
Epoch: 4732, Batch Gradient Norm: 4.024516670165284
Epoch: 4732, Batch Gradient Norm after: 4.024516670165284
Epoch 4733/10000, Prediction Accuracy = 65.02692307692307%, Loss = 0.007579104258463933
Epoch: 4733, Batch Gradient Norm: 4.157995488926261
Epoch: 4733, Batch Gradient Norm after: 4.157995488926261
Epoch 4734/10000, Prediction Accuracy = 64.43076923076923%, Loss = 0.00764901817847903
Epoch: 4734, Batch Gradient Norm: 4.357476441473317
Epoch: 4734, Batch Gradient Norm after: 4.357476441473317
Epoch 4735/10000, Prediction Accuracy = 64.32692307692308%, Loss = 0.007790874224156141
Epoch: 4735, Batch Gradient Norm: 4.431936284437369
Epoch: 4735, Batch Gradient Norm after: 4.431936284437369
Epoch 4736/10000, Prediction Accuracy = 64.49615384615385%, Loss = 0.007776196114718914
Epoch: 4736, Batch Gradient Norm: 4.580672193460488
Epoch: 4736, Batch Gradient Norm after: 4.580672193460488
Epoch 4737/10000, Prediction Accuracy = 64.6076923076923%, Loss = 0.007855636676630149
Epoch: 4737, Batch Gradient Norm: 3.901047493977553
Epoch: 4737, Batch Gradient Norm after: 3.901047493977553
Epoch 4738/10000, Prediction Accuracy = 65.00000000000001%, Loss = 0.007596664202327912
Epoch: 4738, Batch Gradient Norm: 3.929780961867564
Epoch: 4738, Batch Gradient Norm after: 3.929780961867564
Epoch 4739/10000, Prediction Accuracy = 64.97307692307693%, Loss = 0.007579035197313015
Epoch: 4739, Batch Gradient Norm: 3.87414567988292
Epoch: 4739, Batch Gradient Norm after: 3.87414567988292
Epoch 4740/10000, Prediction Accuracy = 65.38461538461539%, Loss = 0.007448222237424209
Epoch: 4740, Batch Gradient Norm: 4.227926868590724
Epoch: 4740, Batch Gradient Norm after: 4.227926868590724
Epoch 4741/10000, Prediction Accuracy = 64.61153846153846%, Loss = 0.0076455492168091815
Epoch: 4741, Batch Gradient Norm: 4.145447048663789
Epoch: 4741, Batch Gradient Norm after: 4.145447048663789
Epoch 4742/10000, Prediction Accuracy = 64.65%, Loss = 0.007691172059052265
Epoch: 4742, Batch Gradient Norm: 4.289118460101995
Epoch: 4742, Batch Gradient Norm after: 4.289118460101995
Epoch 4743/10000, Prediction Accuracy = 64.41923076923075%, Loss = 0.00764729598393807
Epoch: 4743, Batch Gradient Norm: 4.529339013241421
Epoch: 4743, Batch Gradient Norm after: 4.529339013241421
Epoch 4744/10000, Prediction Accuracy = 64.56923076923077%, Loss = 0.00778264061619456
Epoch: 4744, Batch Gradient Norm: 3.926857184908055
Epoch: 4744, Batch Gradient Norm after: 3.926857184908055
Epoch 4745/10000, Prediction Accuracy = 64.97692307692309%, Loss = 0.007507954831593311
Epoch: 4745, Batch Gradient Norm: 4.088997943030781
Epoch: 4745, Batch Gradient Norm after: 4.088997943030781
Epoch 4746/10000, Prediction Accuracy = 65.23846153846154%, Loss = 0.007578788217730247
Epoch: 4746, Batch Gradient Norm: 4.064428845490521
Epoch: 4746, Batch Gradient Norm after: 4.064428845490521
Epoch 4747/10000, Prediction Accuracy = 65.22307692307692%, Loss = 0.007498306222259998
Epoch: 4747, Batch Gradient Norm: 4.108363477080315
Epoch: 4747, Batch Gradient Norm after: 4.108363477080315
Epoch 4748/10000, Prediction Accuracy = 64.95769230769231%, Loss = 0.007566358965749924
Epoch: 4748, Batch Gradient Norm: 4.098212341290072
Epoch: 4748, Batch Gradient Norm after: 4.098212341290072
Epoch 4749/10000, Prediction Accuracy = 65.21538461538461%, Loss = 0.007587090170440765
Epoch: 4749, Batch Gradient Norm: 4.3425148206711945
Epoch: 4749, Batch Gradient Norm after: 4.3425148206711945
Epoch 4750/10000, Prediction Accuracy = 64.74615384615385%, Loss = 0.007690255852559438
Epoch: 4750, Batch Gradient Norm: 4.389111636133085
Epoch: 4750, Batch Gradient Norm after: 4.389111636133085
Epoch 4751/10000, Prediction Accuracy = 64.12692307692308%, Loss = 0.007737930219333906
Epoch: 4751, Batch Gradient Norm: 4.1448272826172845
Epoch: 4751, Batch Gradient Norm after: 4.1448272826172845
Epoch 4752/10000, Prediction Accuracy = 64.97307692307692%, Loss = 0.007590975290021071
Epoch: 4752, Batch Gradient Norm: 4.290926000243899
Epoch: 4752, Batch Gradient Norm after: 4.290926000243899
Epoch 4753/10000, Prediction Accuracy = 64.63076923076922%, Loss = 0.0077056584951396175
Epoch: 4753, Batch Gradient Norm: 3.7647615623019517
Epoch: 4753, Batch Gradient Norm after: 3.7647615623019517
Epoch 4754/10000, Prediction Accuracy = 65.17692307692307%, Loss = 0.007424633699254348
Epoch: 4754, Batch Gradient Norm: 4.4389280978974215
Epoch: 4754, Batch Gradient Norm after: 4.4389280978974215
Epoch 4755/10000, Prediction Accuracy = 64.49615384615385%, Loss = 0.007834511379209848
Epoch: 4755, Batch Gradient Norm: 4.676241162449718
Epoch: 4755, Batch Gradient Norm after: 4.676241162449718
Epoch 4756/10000, Prediction Accuracy = 64.37307692307692%, Loss = 0.007884892097745951
Epoch: 4756, Batch Gradient Norm: 4.832020103209501
Epoch: 4756, Batch Gradient Norm after: 4.832020103209501
Epoch 4757/10000, Prediction Accuracy = 63.7%, Loss = 0.008045947179198265
Epoch: 4757, Batch Gradient Norm: 4.367148175963077
Epoch: 4757, Batch Gradient Norm after: 4.367148175963077
Epoch 4758/10000, Prediction Accuracy = 64.29615384615384%, Loss = 0.0078248126933781
Epoch: 4758, Batch Gradient Norm: 4.038408779986386
Epoch: 4758, Batch Gradient Norm after: 4.038408779986386
Epoch 4759/10000, Prediction Accuracy = 64.9346153846154%, Loss = 0.007610787279330767
Epoch: 4759, Batch Gradient Norm: 4.829420753182058
Epoch: 4759, Batch Gradient Norm after: 4.829420753182058
Epoch 4760/10000, Prediction Accuracy = 63.86923076923079%, Loss = 0.008056033331041153
Epoch: 4760, Batch Gradient Norm: 4.360890560990476
Epoch: 4760, Batch Gradient Norm after: 4.360890560990476
Epoch 4761/10000, Prediction Accuracy = 64.68076923076923%, Loss = 0.007804052725147743
Epoch: 4761, Batch Gradient Norm: 4.004763340533276
Epoch: 4761, Batch Gradient Norm after: 4.004763340533276
Epoch 4762/10000, Prediction Accuracy = 65.44230769230768%, Loss = 0.0074713863790608365
Epoch: 4762, Batch Gradient Norm: 3.9427361475164484
Epoch: 4762, Batch Gradient Norm after: 3.9427361475164484
Epoch 4763/10000, Prediction Accuracy = 65.0653846153846%, Loss = 0.0075384286375573045
Epoch: 4763, Batch Gradient Norm: 4.77157217912125
Epoch: 4763, Batch Gradient Norm after: 4.77157217912125
Epoch 4764/10000, Prediction Accuracy = 64.23461538461538%, Loss = 0.007972861031213632
Epoch: 4764, Batch Gradient Norm: 4.167067737914638
Epoch: 4764, Batch Gradient Norm after: 4.167067737914638
Epoch 4765/10000, Prediction Accuracy = 64.47307692307693%, Loss = 0.007814081457371894
Epoch: 4765, Batch Gradient Norm: 4.075453833585514
Epoch: 4765, Batch Gradient Norm after: 4.075453833585514
Epoch 4766/10000, Prediction Accuracy = 64.61153846153846%, Loss = 0.007634381369615977
Epoch: 4766, Batch Gradient Norm: 4.29502884542369
Epoch: 4766, Batch Gradient Norm after: 4.29502884542369
Epoch 4767/10000, Prediction Accuracy = 64.35769230769232%, Loss = 0.007708774807934578
Epoch: 4767, Batch Gradient Norm: 4.2499969572983956
Epoch: 4767, Batch Gradient Norm after: 4.2499969572983956
Epoch 4768/10000, Prediction Accuracy = 64.75384615384617%, Loss = 0.007660806537247621
Epoch: 4768, Batch Gradient Norm: 4.100727472191119
Epoch: 4768, Batch Gradient Norm after: 4.100727472191119
Epoch 4769/10000, Prediction Accuracy = 64.52692307692307%, Loss = 0.007697869271326523
Epoch: 4769, Batch Gradient Norm: 4.046992489358154
Epoch: 4769, Batch Gradient Norm after: 4.046992489358154
Epoch 4770/10000, Prediction Accuracy = 65.0%, Loss = 0.007632428386177008
Epoch: 4770, Batch Gradient Norm: 4.77740688392045
Epoch: 4770, Batch Gradient Norm after: 4.77740688392045
Epoch 4771/10000, Prediction Accuracy = 64.09615384615385%, Loss = 0.007990209457392875
Epoch: 4771, Batch Gradient Norm: 4.411215075849829
Epoch: 4771, Batch Gradient Norm after: 4.411215075849829
Epoch 4772/10000, Prediction Accuracy = 64.02692307692308%, Loss = 0.0079027245609233
Epoch: 4772, Batch Gradient Norm: 4.431269894234046
Epoch: 4772, Batch Gradient Norm after: 4.431269894234046
Epoch 4773/10000, Prediction Accuracy = 64.55384615384615%, Loss = 0.007892751457312932
Epoch: 4773, Batch Gradient Norm: 4.652230541680382
Epoch: 4773, Batch Gradient Norm after: 4.652230541680382
Epoch 4774/10000, Prediction Accuracy = 64.45384615384616%, Loss = 0.007939583335358363
Epoch: 4774, Batch Gradient Norm: 4.528355081810119
Epoch: 4774, Batch Gradient Norm after: 4.528355081810119
Epoch 4775/10000, Prediction Accuracy = 63.99230769230768%, Loss = 0.0079651979299692
Epoch: 4775, Batch Gradient Norm: 4.56472150445362
Epoch: 4775, Batch Gradient Norm after: 4.56472150445362
Epoch 4776/10000, Prediction Accuracy = 64.2653846153846%, Loss = 0.00795971849360145
Epoch: 4776, Batch Gradient Norm: 4.6457116873799045
Epoch: 4776, Batch Gradient Norm after: 4.6457116873799045
Epoch 4777/10000, Prediction Accuracy = 64.69615384615383%, Loss = 0.007861805649904104
Epoch: 4777, Batch Gradient Norm: 4.45012155775137
Epoch: 4777, Batch Gradient Norm after: 4.45012155775137
Epoch 4778/10000, Prediction Accuracy = 64.41153846153847%, Loss = 0.00781706666860443
Epoch: 4778, Batch Gradient Norm: 4.581250805087635
Epoch: 4778, Batch Gradient Norm after: 4.581250805087635
Epoch 4779/10000, Prediction Accuracy = 63.74230769230769%, Loss = 0.00796365848957346
Epoch: 4779, Batch Gradient Norm: 4.168026093498536
Epoch: 4779, Batch Gradient Norm after: 4.168026093498536
Epoch 4780/10000, Prediction Accuracy = 64.92307692307693%, Loss = 0.007734605218642033
Epoch: 4780, Batch Gradient Norm: 4.068518257120939
Epoch: 4780, Batch Gradient Norm after: 4.068518257120939
Epoch 4781/10000, Prediction Accuracy = 64.81153846153846%, Loss = 0.007613090010216603
Epoch: 4781, Batch Gradient Norm: 4.267279552535512
Epoch: 4781, Batch Gradient Norm after: 4.267279552535512
Epoch 4782/10000, Prediction Accuracy = 64.77307692307691%, Loss = 0.0077291635008385545
Epoch: 4782, Batch Gradient Norm: 4.0417593764533795
Epoch: 4782, Batch Gradient Norm after: 4.0417593764533795
Epoch 4783/10000, Prediction Accuracy = 64.86923076923077%, Loss = 0.0076687507188090915
Epoch: 4783, Batch Gradient Norm: 4.00278582631475
Epoch: 4783, Batch Gradient Norm after: 4.00278582631475
Epoch 4784/10000, Prediction Accuracy = 64.37307692307692%, Loss = 0.007581791733033382
Epoch: 4784, Batch Gradient Norm: 3.5488008781384885
Epoch: 4784, Batch Gradient Norm after: 3.5488008781384885
Epoch 4785/10000, Prediction Accuracy = 65.39615384615382%, Loss = 0.007403919652390938
Epoch: 4785, Batch Gradient Norm: 3.8905428828327615
Epoch: 4785, Batch Gradient Norm after: 3.8905428828327615
Epoch 4786/10000, Prediction Accuracy = 65.71153846153847%, Loss = 0.007418800002107253
Epoch: 4786, Batch Gradient Norm: 4.145572921085021
Epoch: 4786, Batch Gradient Norm after: 4.145572921085021
Epoch 4787/10000, Prediction Accuracy = 64.88076923076923%, Loss = 0.007582966811381853
Epoch: 4787, Batch Gradient Norm: 4.202380593502272
Epoch: 4787, Batch Gradient Norm after: 4.202380593502272
Epoch 4788/10000, Prediction Accuracy = 64.8076923076923%, Loss = 0.007601132831321313
Epoch: 4788, Batch Gradient Norm: 4.336695390908292
Epoch: 4788, Batch Gradient Norm after: 4.336695390908292
Epoch 4789/10000, Prediction Accuracy = 64.40384615384616%, Loss = 0.007704002818522545
Epoch: 4789, Batch Gradient Norm: 4.111397010289794
Epoch: 4789, Batch Gradient Norm after: 4.111397010289794
Epoch 4790/10000, Prediction Accuracy = 65.08076923076922%, Loss = 0.0076140476963841
Epoch: 4790, Batch Gradient Norm: 4.180448611325398
Epoch: 4790, Batch Gradient Norm after: 4.180448611325398
Epoch 4791/10000, Prediction Accuracy = 64.65384615384616%, Loss = 0.0076746269344137264
Epoch: 4791, Batch Gradient Norm: 3.7366231947598547
Epoch: 4791, Batch Gradient Norm after: 3.7366231947598547
Epoch 4792/10000, Prediction Accuracy = 65.37307692307692%, Loss = 0.007477104592208679
Epoch: 4792, Batch Gradient Norm: 4.203139087737352
Epoch: 4792, Batch Gradient Norm after: 4.203139087737352
Epoch 4793/10000, Prediction Accuracy = 65.26923076923077%, Loss = 0.007542916287023287
Epoch: 4793, Batch Gradient Norm: 4.214722365673579
Epoch: 4793, Batch Gradient Norm after: 4.214722365673579
Epoch 4794/10000, Prediction Accuracy = 64.92307692307692%, Loss = 0.007597329668127573
Epoch: 4794, Batch Gradient Norm: 4.06759618051134
Epoch: 4794, Batch Gradient Norm after: 4.06759618051134
Epoch 4795/10000, Prediction Accuracy = 65.25769230769231%, Loss = 0.007552175496060114
Epoch: 4795, Batch Gradient Norm: 4.207600715721949
Epoch: 4795, Batch Gradient Norm after: 4.207600715721949
Epoch 4796/10000, Prediction Accuracy = 65.2923076923077%, Loss = 0.007606056268112018
Epoch: 4796, Batch Gradient Norm: 4.422741752151796
Epoch: 4796, Batch Gradient Norm after: 4.422741752151796
Epoch 4797/10000, Prediction Accuracy = 64.35000000000001%, Loss = 0.007656983959560211
Epoch: 4797, Batch Gradient Norm: 4.441308230390686
Epoch: 4797, Batch Gradient Norm after: 4.441308230390686
Epoch 4798/10000, Prediction Accuracy = 63.95384615384617%, Loss = 0.007865268737077713
Epoch: 4798, Batch Gradient Norm: 4.2286423201981185
Epoch: 4798, Batch Gradient Norm after: 4.2286423201981185
Epoch 4799/10000, Prediction Accuracy = 64.14999999999999%, Loss = 0.007689004226659353
Epoch: 4799, Batch Gradient Norm: 4.224511967767746
Epoch: 4799, Batch Gradient Norm after: 4.224511967767746
Epoch 4800/10000, Prediction Accuracy = 64.8923076923077%, Loss = 0.0076774365555208465
Epoch: 4800, Batch Gradient Norm: 4.609867610456999
Epoch: 4800, Batch Gradient Norm after: 4.609867610456999
Epoch 4801/10000, Prediction Accuracy = 64.39615384615384%, Loss = 0.007788334722415759
Epoch: 4801, Batch Gradient Norm: 4.2858858537446345
Epoch: 4801, Batch Gradient Norm after: 4.2858858537446345
Epoch 4802/10000, Prediction Accuracy = 64.42307692307692%, Loss = 0.007743015634612395
Epoch: 4802, Batch Gradient Norm: 4.382241174568399
Epoch: 4802, Batch Gradient Norm after: 4.382241174568399
Epoch 4803/10000, Prediction Accuracy = 64.60384615384615%, Loss = 0.00767255721327204
Epoch: 4803, Batch Gradient Norm: 4.052352028372112
Epoch: 4803, Batch Gradient Norm after: 4.052352028372112
Epoch 4804/10000, Prediction Accuracy = 65.02307692307694%, Loss = 0.007617025206295343
Epoch: 4804, Batch Gradient Norm: 4.144384241877187
Epoch: 4804, Batch Gradient Norm after: 4.144384241877187
Epoch 4805/10000, Prediction Accuracy = 64.92307692307692%, Loss = 0.0076745107698325925
Epoch: 4805, Batch Gradient Norm: 4.21818162227007
Epoch: 4805, Batch Gradient Norm after: 4.21818162227007
Epoch 4806/10000, Prediction Accuracy = 64.92692307692309%, Loss = 0.007710868994203897
Epoch: 4806, Batch Gradient Norm: 4.215608289885646
Epoch: 4806, Batch Gradient Norm after: 4.215608289885646
Epoch 4807/10000, Prediction Accuracy = 64.58846153846154%, Loss = 0.007743765958226644
Epoch: 4807, Batch Gradient Norm: 4.588755493496735
Epoch: 4807, Batch Gradient Norm after: 4.588755493496735
Epoch 4808/10000, Prediction Accuracy = 64.53076923076922%, Loss = 0.007777410881737104
Epoch: 4808, Batch Gradient Norm: 4.066991099549489
Epoch: 4808, Batch Gradient Norm after: 4.066991099549489
Epoch 4809/10000, Prediction Accuracy = 64.74230769230769%, Loss = 0.007739627733826637
Epoch: 4809, Batch Gradient Norm: 4.099225013565981
Epoch: 4809, Batch Gradient Norm after: 4.099225013565981
Epoch 4810/10000, Prediction Accuracy = 64.4846153846154%, Loss = 0.007658087075329744
Epoch: 4810, Batch Gradient Norm: 4.472959110311451
Epoch: 4810, Batch Gradient Norm after: 4.472959110311451
Epoch 4811/10000, Prediction Accuracy = 64.21923076923078%, Loss = 0.007785352161870553
Epoch: 4811, Batch Gradient Norm: 4.446548470548075
Epoch: 4811, Batch Gradient Norm after: 4.446548470548075
Epoch 4812/10000, Prediction Accuracy = 64.71538461538464%, Loss = 0.007766126762502468
Epoch: 4812, Batch Gradient Norm: 4.652402786092369
Epoch: 4812, Batch Gradient Norm after: 4.652402786092369
Epoch 4813/10000, Prediction Accuracy = 64.45384615384616%, Loss = 0.007866861083759712
Epoch: 4813, Batch Gradient Norm: 4.370412618478932
Epoch: 4813, Batch Gradient Norm after: 4.370412618478932
Epoch 4814/10000, Prediction Accuracy = 64.75384615384614%, Loss = 0.007818183718392482
Epoch: 4814, Batch Gradient Norm: 4.31832953828534
Epoch: 4814, Batch Gradient Norm after: 4.31832953828534
Epoch 4815/10000, Prediction Accuracy = 64.54615384615384%, Loss = 0.007805488179796017
Epoch: 4815, Batch Gradient Norm: 4.321967161905689
Epoch: 4815, Batch Gradient Norm after: 4.321967161905689
Epoch 4816/10000, Prediction Accuracy = 64.46538461538461%, Loss = 0.007762135436328558
Epoch: 4816, Batch Gradient Norm: 3.900273152486092
Epoch: 4816, Batch Gradient Norm after: 3.900273152486092
Epoch 4817/10000, Prediction Accuracy = 65.52692307692308%, Loss = 0.007413548023368304
Epoch: 4817, Batch Gradient Norm: 3.941013574445552
Epoch: 4817, Batch Gradient Norm after: 3.941013574445552
Epoch 4818/10000, Prediction Accuracy = 65.26923076923076%, Loss = 0.0074980157928971145
Epoch: 4818, Batch Gradient Norm: 4.094310615933953
Epoch: 4818, Batch Gradient Norm after: 4.094310615933953
Epoch 4819/10000, Prediction Accuracy = 64.96538461538461%, Loss = 0.007585318365062659
Epoch: 4819, Batch Gradient Norm: 4.420301257040693
Epoch: 4819, Batch Gradient Norm after: 4.420301257040693
Epoch 4820/10000, Prediction Accuracy = 64.38076923076923%, Loss = 0.007757064313269579
Epoch: 4820, Batch Gradient Norm: 4.359859259596566
Epoch: 4820, Batch Gradient Norm after: 4.359859259596566
Epoch 4821/10000, Prediction Accuracy = 64.47307692307693%, Loss = 0.007799772044213919
Epoch: 4821, Batch Gradient Norm: 4.280956186421665
Epoch: 4821, Batch Gradient Norm after: 4.280956186421665
Epoch 4822/10000, Prediction Accuracy = 64.98076923076923%, Loss = 0.007693579707008142
Epoch: 4822, Batch Gradient Norm: 4.532734723228252
Epoch: 4822, Batch Gradient Norm after: 4.532734723228252
Epoch 4823/10000, Prediction Accuracy = 63.98846153846155%, Loss = 0.007824464916036679
Epoch: 4823, Batch Gradient Norm: 4.37572526595937
Epoch: 4823, Batch Gradient Norm after: 4.37572526595937
Epoch 4824/10000, Prediction Accuracy = 64.38846153846154%, Loss = 0.0078111195650238255
Epoch: 4824, Batch Gradient Norm: 4.270872767178087
Epoch: 4824, Batch Gradient Norm after: 4.270872767178087
Epoch 4825/10000, Prediction Accuracy = 64.68076923076923%, Loss = 0.007656244202875174
Epoch: 4825, Batch Gradient Norm: 4.238828702122943
Epoch: 4825, Batch Gradient Norm after: 4.238828702122943
Epoch 4826/10000, Prediction Accuracy = 65.02307692307694%, Loss = 0.007615069822909741
Epoch: 4826, Batch Gradient Norm: 4.3174943003896
Epoch: 4826, Batch Gradient Norm after: 4.3174943003896
Epoch 4827/10000, Prediction Accuracy = 64.91153846153847%, Loss = 0.007644597584238419
Epoch: 4827, Batch Gradient Norm: 3.7286953623164267
Epoch: 4827, Batch Gradient Norm after: 3.7286953623164267
Epoch 4828/10000, Prediction Accuracy = 65.33846153846156%, Loss = 0.007533039432018995
Epoch: 4828, Batch Gradient Norm: 4.109838287022617
Epoch: 4828, Batch Gradient Norm after: 4.109838287022617
Epoch 4829/10000, Prediction Accuracy = 64.40384615384615%, Loss = 0.0076983282700754125
Epoch: 4829, Batch Gradient Norm: 4.246774867080181
Epoch: 4829, Batch Gradient Norm after: 4.246774867080181
Epoch 4830/10000, Prediction Accuracy = 64.44230769230771%, Loss = 0.007745938053211341
Epoch: 4830, Batch Gradient Norm: 4.026062612087536
Epoch: 4830, Batch Gradient Norm after: 4.026062612087536
Epoch 4831/10000, Prediction Accuracy = 64.9923076923077%, Loss = 0.007581145968288183
Epoch: 4831, Batch Gradient Norm: 3.7021997779278872
Epoch: 4831, Batch Gradient Norm after: 3.7021997779278872
Epoch 4832/10000, Prediction Accuracy = 65.3576923076923%, Loss = 0.007379905750545172
Epoch: 4832, Batch Gradient Norm: 4.00479665485601
Epoch: 4832, Batch Gradient Norm after: 4.00479665485601
Epoch 4833/10000, Prediction Accuracy = 64.93461538461538%, Loss = 0.007540882278520327
Epoch: 4833, Batch Gradient Norm: 4.040451427979095
Epoch: 4833, Batch Gradient Norm after: 4.040451427979095
Epoch 4834/10000, Prediction Accuracy = 65.10384615384616%, Loss = 0.007518819175087488
Epoch: 4834, Batch Gradient Norm: 4.385974411094701
Epoch: 4834, Batch Gradient Norm after: 4.385974411094701
Epoch 4835/10000, Prediction Accuracy = 64.45384615384616%, Loss = 0.007696416694670916
Epoch: 4835, Batch Gradient Norm: 4.770768073612575
Epoch: 4835, Batch Gradient Norm after: 4.770768073612575
Epoch 4836/10000, Prediction Accuracy = 63.87692307692306%, Loss = 0.007938099523576407
Epoch: 4836, Batch Gradient Norm: 4.378029290509625
Epoch: 4836, Batch Gradient Norm after: 4.378029290509625
Epoch 4837/10000, Prediction Accuracy = 64.30384615384615%, Loss = 0.007794664169733341
Epoch: 4837, Batch Gradient Norm: 3.6886100408704543
Epoch: 4837, Batch Gradient Norm after: 3.6886100408704543
Epoch 4838/10000, Prediction Accuracy = 64.8153846153846%, Loss = 0.007534464928679741
Epoch: 4838, Batch Gradient Norm: 4.226807269450804
Epoch: 4838, Batch Gradient Norm after: 4.226807269450804
Epoch 4839/10000, Prediction Accuracy = 63.780769230769224%, Loss = 0.007741018592451627
Epoch: 4839, Batch Gradient Norm: 4.132578360023515
Epoch: 4839, Batch Gradient Norm after: 4.132578360023515
Epoch 4840/10000, Prediction Accuracy = 64.86538461538461%, Loss = 0.007592270508981668
Epoch: 4840, Batch Gradient Norm: 3.9337123044819307
Epoch: 4840, Batch Gradient Norm after: 3.9337123044819307
Epoch 4841/10000, Prediction Accuracy = 65.22692307692309%, Loss = 0.0075111991654221825
Epoch: 4841, Batch Gradient Norm: 4.387225335463637
Epoch: 4841, Batch Gradient Norm after: 4.387225335463637
Epoch 4842/10000, Prediction Accuracy = 64.57692307692307%, Loss = 0.007708335617700448
Epoch: 4842, Batch Gradient Norm: 4.154426338678147
Epoch: 4842, Batch Gradient Norm after: 4.154426338678147
Epoch 4843/10000, Prediction Accuracy = 64.87692307692308%, Loss = 0.007576841323708112
Epoch: 4843, Batch Gradient Norm: 4.027362390018002
Epoch: 4843, Batch Gradient Norm after: 4.027362390018002
Epoch 4844/10000, Prediction Accuracy = 65.28461538461538%, Loss = 0.0074991448782384396
Epoch: 4844, Batch Gradient Norm: 4.0467000628845975
Epoch: 4844, Batch Gradient Norm after: 4.0467000628845975
Epoch 4845/10000, Prediction Accuracy = 65.45384615384616%, Loss = 0.007544749810432012
Epoch: 4845, Batch Gradient Norm: 4.435838797299121
Epoch: 4845, Batch Gradient Norm after: 4.435838797299121
Epoch 4846/10000, Prediction Accuracy = 64.78846153846155%, Loss = 0.007787154629253424
Epoch: 4846, Batch Gradient Norm: 4.476975193933847
Epoch: 4846, Batch Gradient Norm after: 4.476975193933847
Epoch 4847/10000, Prediction Accuracy = 64.85%, Loss = 0.007746199468294015
Epoch: 4847, Batch Gradient Norm: 4.022943966897697
Epoch: 4847, Batch Gradient Norm after: 4.022943966897697
Epoch 4848/10000, Prediction Accuracy = 65.20384615384616%, Loss = 0.007519114798364731
Epoch: 4848, Batch Gradient Norm: 4.246968092181522
Epoch: 4848, Batch Gradient Norm after: 4.246968092181522
Epoch 4849/10000, Prediction Accuracy = 64.75769230769232%, Loss = 0.007548543660400005
Epoch: 4849, Batch Gradient Norm: 4.395850409514121
Epoch: 4849, Batch Gradient Norm after: 4.395850409514121
Epoch 4850/10000, Prediction Accuracy = 64.82307692307694%, Loss = 0.007730610776119507
Epoch: 4850, Batch Gradient Norm: 4.013151304533245
Epoch: 4850, Batch Gradient Norm after: 4.013151304533245
Epoch 4851/10000, Prediction Accuracy = 64.73846153846155%, Loss = 0.007653433722085678
Epoch: 4851, Batch Gradient Norm: 3.9784480370149367
Epoch: 4851, Batch Gradient Norm after: 3.9784480370149367
Epoch 4852/10000, Prediction Accuracy = 65.24615384615385%, Loss = 0.00749700151097316
Epoch: 4852, Batch Gradient Norm: 3.970318899803383
Epoch: 4852, Batch Gradient Norm after: 3.970318899803383
Epoch 4853/10000, Prediction Accuracy = 65.0923076923077%, Loss = 0.007467877155599685
Epoch: 4853, Batch Gradient Norm: 4.220912633404592
Epoch: 4853, Batch Gradient Norm after: 4.220912633404592
Epoch 4854/10000, Prediction Accuracy = 64.9576923076923%, Loss = 0.007496765814721584
Epoch: 4854, Batch Gradient Norm: 4.226807704998665
Epoch: 4854, Batch Gradient Norm after: 4.226807704998665
Epoch 4855/10000, Prediction Accuracy = 64.6076923076923%, Loss = 0.007597922848967405
Epoch: 4855, Batch Gradient Norm: 4.9329970104257965
Epoch: 4855, Batch Gradient Norm after: 4.9329970104257965
Epoch 4856/10000, Prediction Accuracy = 64.23076923076924%, Loss = 0.007996872497292666
Epoch: 4856, Batch Gradient Norm: 4.930166326650657
Epoch: 4856, Batch Gradient Norm after: 4.930166326650657
Epoch 4857/10000, Prediction Accuracy = 63.88846153846153%, Loss = 0.008043653725718077
Epoch: 4857, Batch Gradient Norm: 4.132209944174611
Epoch: 4857, Batch Gradient Norm after: 4.132209944174611
Epoch 4858/10000, Prediction Accuracy = 64.82307692307691%, Loss = 0.007657183656612268
Epoch: 4858, Batch Gradient Norm: 4.313410620973726
Epoch: 4858, Batch Gradient Norm after: 4.313410620973726
Epoch 4859/10000, Prediction Accuracy = 64.58076923076923%, Loss = 0.007780424569948361
Epoch: 4859, Batch Gradient Norm: 4.067020865054471
Epoch: 4859, Batch Gradient Norm after: 4.067020865054471
Epoch 4860/10000, Prediction Accuracy = 64.94615384615385%, Loss = 0.007511018238102014
Epoch: 4860, Batch Gradient Norm: 4.19591226934351
Epoch: 4860, Batch Gradient Norm after: 4.19591226934351
Epoch 4861/10000, Prediction Accuracy = 64.76538461538462%, Loss = 0.007584189100620838
Epoch: 4861, Batch Gradient Norm: 4.539823172980882
Epoch: 4861, Batch Gradient Norm after: 4.539823172980882
Epoch 4862/10000, Prediction Accuracy = 64.1576923076923%, Loss = 0.007846214127941774
Epoch: 4862, Batch Gradient Norm: 4.5407198832716515
Epoch: 4862, Batch Gradient Norm after: 4.5407198832716515
Epoch 4863/10000, Prediction Accuracy = 64.36923076923077%, Loss = 0.007793611524483332
Epoch: 4863, Batch Gradient Norm: 4.478867800817282
Epoch: 4863, Batch Gradient Norm after: 4.478867800817282
Epoch 4864/10000, Prediction Accuracy = 64.70384615384616%, Loss = 0.007821089050804194
Epoch: 4864, Batch Gradient Norm: 4.048138212347579
Epoch: 4864, Batch Gradient Norm after: 4.048138212347579
Epoch 4865/10000, Prediction Accuracy = 64.9346153846154%, Loss = 0.007528680305068309
Epoch: 4865, Batch Gradient Norm: 4.213170259122383
Epoch: 4865, Batch Gradient Norm after: 4.213170259122383
Epoch 4866/10000, Prediction Accuracy = 65.26538461538462%, Loss = 0.007638076714311655
Epoch: 4866, Batch Gradient Norm: 4.371492847283172
Epoch: 4866, Batch Gradient Norm after: 4.371492847283172
Epoch 4867/10000, Prediction Accuracy = 65.14615384615385%, Loss = 0.007653891610411497
Epoch: 4867, Batch Gradient Norm: 5.108409350177019
Epoch: 4867, Batch Gradient Norm after: 5.108409350177019
Epoch 4868/10000, Prediction Accuracy = 63.80769230769233%, Loss = 0.008186735642644076
Epoch: 4868, Batch Gradient Norm: 4.118499800022526
Epoch: 4868, Batch Gradient Norm after: 4.118499800022526
Epoch 4869/10000, Prediction Accuracy = 64.53076923076922%, Loss = 0.0077212493365200665
Epoch: 4869, Batch Gradient Norm: 4.633058507378768
Epoch: 4869, Batch Gradient Norm after: 4.633058507378768
Epoch 4870/10000, Prediction Accuracy = 63.58076923076922%, Loss = 0.008062412604116477
Epoch: 4870, Batch Gradient Norm: 4.095870037395392
Epoch: 4870, Batch Gradient Norm after: 4.095870037395392
Epoch 4871/10000, Prediction Accuracy = 64.9846153846154%, Loss = 0.007628097772025145
Epoch: 4871, Batch Gradient Norm: 3.853356460094557
Epoch: 4871, Batch Gradient Norm after: 3.853356460094557
Epoch 4872/10000, Prediction Accuracy = 64.80000000000001%, Loss = 0.007656263151707558
Epoch: 4872, Batch Gradient Norm: 4.213361357152134
Epoch: 4872, Batch Gradient Norm after: 4.213361357152134
Epoch 4873/10000, Prediction Accuracy = 64.24615384615385%, Loss = 0.007753137033432722
Epoch: 4873, Batch Gradient Norm: 5.128363154551765
Epoch: 4873, Batch Gradient Norm after: 5.128363154551765
Epoch 4874/10000, Prediction Accuracy = 63.292307692307695%, Loss = 0.008262042421847582
Epoch: 4874, Batch Gradient Norm: 4.514156860491643
Epoch: 4874, Batch Gradient Norm after: 4.514156860491643
Epoch 4875/10000, Prediction Accuracy = 64.23846153846155%, Loss = 0.007906747301324056
Epoch: 4875, Batch Gradient Norm: 3.8337406137378873
Epoch: 4875, Batch Gradient Norm after: 3.8337406137378873
Epoch 4876/10000, Prediction Accuracy = 64.6923076923077%, Loss = 0.007656950145386732
Epoch: 4876, Batch Gradient Norm: 3.814980331706631
Epoch: 4876, Batch Gradient Norm after: 3.814980331706631
Epoch 4877/10000, Prediction Accuracy = 65.35769230769232%, Loss = 0.00748129550797435
Epoch: 4877, Batch Gradient Norm: 4.41623399662958
Epoch: 4877, Batch Gradient Norm after: 4.41623399662958
Epoch 4878/10000, Prediction Accuracy = 64.20384615384614%, Loss = 0.007855197020734731
Epoch: 4878, Batch Gradient Norm: 4.114315029934879
Epoch: 4878, Batch Gradient Norm after: 4.114315029934879
Epoch 4879/10000, Prediction Accuracy = 64.71538461538461%, Loss = 0.007687424417012013
Epoch: 4879, Batch Gradient Norm: 4.008277573072642
Epoch: 4879, Batch Gradient Norm after: 4.008277573072642
Epoch 4880/10000, Prediction Accuracy = 64.91538461538461%, Loss = 0.007539785753649015
Epoch: 4880, Batch Gradient Norm: 4.4942976234925345
Epoch: 4880, Batch Gradient Norm after: 4.4942976234925345
Epoch 4881/10000, Prediction Accuracy = 64.3%, Loss = 0.007891065297791591
Epoch: 4881, Batch Gradient Norm: 4.478707028523692
Epoch: 4881, Batch Gradient Norm after: 4.478707028523692
Epoch 4882/10000, Prediction Accuracy = 64.11923076923077%, Loss = 0.007852667620262275
Epoch: 4882, Batch Gradient Norm: 4.288084601557467
Epoch: 4882, Batch Gradient Norm after: 4.288084601557467
Epoch 4883/10000, Prediction Accuracy = 64.56153846153846%, Loss = 0.007810353229825313
Epoch: 4883, Batch Gradient Norm: 4.147470289868102
Epoch: 4883, Batch Gradient Norm after: 4.147470289868102
Epoch 4884/10000, Prediction Accuracy = 65.11538461538461%, Loss = 0.007670244309478081
Epoch: 4884, Batch Gradient Norm: 4.161286783662094
Epoch: 4884, Batch Gradient Norm after: 4.161286783662094
Epoch 4885/10000, Prediction Accuracy = 65.05384615384615%, Loss = 0.007559943120353497
Epoch: 4885, Batch Gradient Norm: 4.39835634733204
Epoch: 4885, Batch Gradient Norm after: 4.39835634733204
Epoch 4886/10000, Prediction Accuracy = 64.38076923076923%, Loss = 0.007795490646878114
Epoch: 4886, Batch Gradient Norm: 4.404717425306752
Epoch: 4886, Batch Gradient Norm after: 4.404717425306752
Epoch 4887/10000, Prediction Accuracy = 64.88076923076923%, Loss = 0.007725499606189819
Epoch: 4887, Batch Gradient Norm: 4.372712364836853
Epoch: 4887, Batch Gradient Norm after: 4.372712364836853
Epoch 4888/10000, Prediction Accuracy = 64.53076923076925%, Loss = 0.007827571378304409
Epoch: 4888, Batch Gradient Norm: 4.05365296025055
Epoch: 4888, Batch Gradient Norm after: 4.05365296025055
Epoch 4889/10000, Prediction Accuracy = 64.81153846153846%, Loss = 0.00755509350878688
Epoch: 4889, Batch Gradient Norm: 4.148234291596481
Epoch: 4889, Batch Gradient Norm after: 4.148234291596481
Epoch 4890/10000, Prediction Accuracy = 65.16538461538461%, Loss = 0.0076165697537362576
Epoch: 4890, Batch Gradient Norm: 3.998553882376376
Epoch: 4890, Batch Gradient Norm after: 3.998553882376376
Epoch 4891/10000, Prediction Accuracy = 65.07307692307691%, Loss = 0.007550837722821877
Epoch: 4891, Batch Gradient Norm: 4.488836779485753
Epoch: 4891, Batch Gradient Norm after: 4.488836779485753
Epoch 4892/10000, Prediction Accuracy = 64.33846153846156%, Loss = 0.007802521738295372
Epoch: 4892, Batch Gradient Norm: 4.690846438418327
Epoch: 4892, Batch Gradient Norm after: 4.690846438418327
Epoch 4893/10000, Prediction Accuracy = 64.21153846153847%, Loss = 0.007916530271848807
Epoch: 4893, Batch Gradient Norm: 4.7463792802429445
Epoch: 4893, Batch Gradient Norm after: 4.7463792802429445
Epoch 4894/10000, Prediction Accuracy = 63.82307692307693%, Loss = 0.008017887791188864
Epoch: 4894, Batch Gradient Norm: 4.117915286173439
Epoch: 4894, Batch Gradient Norm after: 4.117915286173439
Epoch 4895/10000, Prediction Accuracy = 64.49615384615386%, Loss = 0.007733894153856314
Epoch: 4895, Batch Gradient Norm: 4.364937055742754
Epoch: 4895, Batch Gradient Norm after: 4.364937055742754
Epoch 4896/10000, Prediction Accuracy = 64.82307692307691%, Loss = 0.007743199355900288
Epoch: 4896, Batch Gradient Norm: 4.373004186623194
Epoch: 4896, Batch Gradient Norm after: 4.373004186623194
Epoch 4897/10000, Prediction Accuracy = 64.52307692307693%, Loss = 0.007762437722144218
Epoch: 4897, Batch Gradient Norm: 3.673387313121996
Epoch: 4897, Batch Gradient Norm after: 3.673387313121996
Epoch 4898/10000, Prediction Accuracy = 65.08846153846156%, Loss = 0.007412910962907167
Epoch: 4898, Batch Gradient Norm: 4.080340003469951
Epoch: 4898, Batch Gradient Norm after: 4.080340003469951
Epoch 4899/10000, Prediction Accuracy = 64.81538461538462%, Loss = 0.007668304149634563
Epoch: 4899, Batch Gradient Norm: 4.16447728430238
Epoch: 4899, Batch Gradient Norm after: 4.16447728430238
Epoch 4900/10000, Prediction Accuracy = 64.80769230769229%, Loss = 0.007628609999441183
Epoch: 4900, Batch Gradient Norm: 4.205995625455864
Epoch: 4900, Batch Gradient Norm after: 4.205995625455864
Epoch 4901/10000, Prediction Accuracy = 64.58846153846154%, Loss = 0.007618647964241413
Epoch: 4901, Batch Gradient Norm: 4.1685316156062315
Epoch: 4901, Batch Gradient Norm after: 4.1685316156062315
Epoch 4902/10000, Prediction Accuracy = 64.80769230769232%, Loss = 0.0076600801772796195
Epoch: 4902, Batch Gradient Norm: 4.270275358542789
Epoch: 4902, Batch Gradient Norm after: 4.270275358542789
Epoch 4903/10000, Prediction Accuracy = 64.8576923076923%, Loss = 0.007661211017805796
Epoch: 4903, Batch Gradient Norm: 4.020302026012546
Epoch: 4903, Batch Gradient Norm after: 4.020302026012546
Epoch 4904/10000, Prediction Accuracy = 65.12692307692308%, Loss = 0.0075305623288911125
Epoch: 4904, Batch Gradient Norm: 4.408171655364391
Epoch: 4904, Batch Gradient Norm after: 4.408171655364391
Epoch 4905/10000, Prediction Accuracy = 64.6846153846154%, Loss = 0.007671425942904674
Epoch: 4905, Batch Gradient Norm: 3.9539636945570855
Epoch: 4905, Batch Gradient Norm after: 3.9539636945570855
Epoch 4906/10000, Prediction Accuracy = 65.23846153846154%, Loss = 0.007507720568145697
Epoch: 4906, Batch Gradient Norm: 3.7748017147262343
Epoch: 4906, Batch Gradient Norm after: 3.7748017147262343
Epoch 4907/10000, Prediction Accuracy = 65.3423076923077%, Loss = 0.007379353153877533
Epoch: 4907, Batch Gradient Norm: 4.317687954695727
Epoch: 4907, Batch Gradient Norm after: 4.317687954695727
Epoch 4908/10000, Prediction Accuracy = 64.48846153846154%, Loss = 0.007652697726511038
Epoch: 4908, Batch Gradient Norm: 4.098509086614634
Epoch: 4908, Batch Gradient Norm after: 4.098509086614634
Epoch 4909/10000, Prediction Accuracy = 64.85384615384615%, Loss = 0.007563845827602423
Epoch: 4909, Batch Gradient Norm: 4.6479506886139275
Epoch: 4909, Batch Gradient Norm after: 4.6479506886139275
Epoch 4910/10000, Prediction Accuracy = 64.83846153846154%, Loss = 0.007841508513173232
Epoch: 4910, Batch Gradient Norm: 4.469128788069652
Epoch: 4910, Batch Gradient Norm after: 4.469128788069652
Epoch 4911/10000, Prediction Accuracy = 64.33846153846153%, Loss = 0.0077838583562809685
Epoch: 4911, Batch Gradient Norm: 4.211715262218649
Epoch: 4911, Batch Gradient Norm after: 4.211715262218649
Epoch 4912/10000, Prediction Accuracy = 64.55384615384615%, Loss = 0.0075911913210382825
Epoch: 4912, Batch Gradient Norm: 4.113229795664664
Epoch: 4912, Batch Gradient Norm after: 4.113229795664664
Epoch 4913/10000, Prediction Accuracy = 65.21153846153845%, Loss = 0.007515925770768752
Epoch: 4913, Batch Gradient Norm: 3.7428590991837005
Epoch: 4913, Batch Gradient Norm after: 3.7428590991837005
Epoch 4914/10000, Prediction Accuracy = 65.46923076923076%, Loss = 0.0074537054707224555
Epoch: 4914, Batch Gradient Norm: 3.9813713400909982
Epoch: 4914, Batch Gradient Norm after: 3.9813713400909982
Epoch 4915/10000, Prediction Accuracy = 65.0423076923077%, Loss = 0.007549451198428869
Epoch: 4915, Batch Gradient Norm: 4.27577084945776
Epoch: 4915, Batch Gradient Norm after: 4.27577084945776
Epoch 4916/10000, Prediction Accuracy = 64.83461538461539%, Loss = 0.007604725587253387
Epoch: 4916, Batch Gradient Norm: 4.184146475839493
Epoch: 4916, Batch Gradient Norm after: 4.184146475839493
Epoch 4917/10000, Prediction Accuracy = 64.74615384615385%, Loss = 0.007553135832914939
Epoch: 4917, Batch Gradient Norm: 4.153941836484055
Epoch: 4917, Batch Gradient Norm after: 4.153941836484055
Epoch 4918/10000, Prediction Accuracy = 65.03461538461539%, Loss = 0.0075078883136694245
Epoch: 4918, Batch Gradient Norm: 4.024968900891913
Epoch: 4918, Batch Gradient Norm after: 4.024968900891913
Epoch 4919/10000, Prediction Accuracy = 65.73461538461538%, Loss = 0.007443194098484058
Epoch: 4919, Batch Gradient Norm: 4.135247918753089
Epoch: 4919, Batch Gradient Norm after: 4.135247918753089
Epoch 4920/10000, Prediction Accuracy = 65.52692307692308%, Loss = 0.007430115463928535
Epoch: 4920, Batch Gradient Norm: 4.25904332174791
Epoch: 4920, Batch Gradient Norm after: 4.25904332174791
Epoch 4921/10000, Prediction Accuracy = 64.9076923076923%, Loss = 0.007549735717475414
Epoch: 4921, Batch Gradient Norm: 4.359026466111723
Epoch: 4921, Batch Gradient Norm after: 4.359026466111723
Epoch 4922/10000, Prediction Accuracy = 64.27692307692308%, Loss = 0.007765158222844968
Epoch: 4922, Batch Gradient Norm: 4.3979848985024725
Epoch: 4922, Batch Gradient Norm after: 4.3979848985024725
Epoch 4923/10000, Prediction Accuracy = 64.57307692307691%, Loss = 0.007736640337568063
Epoch: 4923, Batch Gradient Norm: 4.234143127716929
Epoch: 4923, Batch Gradient Norm after: 4.234143127716929
Epoch 4924/10000, Prediction Accuracy = 64.83076923076922%, Loss = 0.007643489740215815
Epoch: 4924, Batch Gradient Norm: 4.528291482006715
Epoch: 4924, Batch Gradient Norm after: 4.528291482006715
Epoch 4925/10000, Prediction Accuracy = 64.50000000000001%, Loss = 0.007772361107457142
Epoch: 4925, Batch Gradient Norm: 4.748696569038376
Epoch: 4925, Batch Gradient Norm after: 4.748696569038376
Epoch 4926/10000, Prediction Accuracy = 64.38076923076923%, Loss = 0.007866523765887205
Epoch: 4926, Batch Gradient Norm: 4.263020328707836
Epoch: 4926, Batch Gradient Norm after: 4.263020328707836
Epoch 4927/10000, Prediction Accuracy = 64.63846153846154%, Loss = 0.007713005376549868
Epoch: 4927, Batch Gradient Norm: 4.1153894594501335
Epoch: 4927, Batch Gradient Norm after: 4.1153894594501335
Epoch 4928/10000, Prediction Accuracy = 65.01538461538462%, Loss = 0.007539346312674193
Epoch: 4928, Batch Gradient Norm: 3.957125341697868
Epoch: 4928, Batch Gradient Norm after: 3.957125341697868
Epoch 4929/10000, Prediction Accuracy = 65.0653846153846%, Loss = 0.007426736088326344
Epoch: 4929, Batch Gradient Norm: 3.8223783082445153
Epoch: 4929, Batch Gradient Norm after: 3.8223783082445153
Epoch 4930/10000, Prediction Accuracy = 65.6923076923077%, Loss = 0.007347945553752093
Epoch: 4930, Batch Gradient Norm: 4.342881732634112
Epoch: 4930, Batch Gradient Norm after: 4.342881732634112
Epoch 4931/10000, Prediction Accuracy = 64.62692307692308%, Loss = 0.007586360156822663
Epoch: 4931, Batch Gradient Norm: 3.9650009784037423
Epoch: 4931, Batch Gradient Norm after: 3.9650009784037423
Epoch 4932/10000, Prediction Accuracy = 64.83076923076925%, Loss = 0.007585161329748539
Epoch: 4932, Batch Gradient Norm: 3.798016797020662
Epoch: 4932, Batch Gradient Norm after: 3.798016797020662
Epoch 4933/10000, Prediction Accuracy = 65.16153846153847%, Loss = 0.0074640091938468125
Epoch: 4933, Batch Gradient Norm: 4.115797703279952
Epoch: 4933, Batch Gradient Norm after: 4.115797703279952
Epoch 4934/10000, Prediction Accuracy = 64.61923076923077%, Loss = 0.007614217626933868
Epoch: 4934, Batch Gradient Norm: 4.176225972719886
Epoch: 4934, Batch Gradient Norm after: 4.176225972719886
Epoch 4935/10000, Prediction Accuracy = 65.16923076923078%, Loss = 0.00757586988262259
Epoch: 4935, Batch Gradient Norm: 4.244672000537032
Epoch: 4935, Batch Gradient Norm after: 4.244672000537032
Epoch 4936/10000, Prediction Accuracy = 65.1076923076923%, Loss = 0.007677670604047867
Epoch: 4936, Batch Gradient Norm: 4.670273676090904
Epoch: 4936, Batch Gradient Norm after: 4.670273676090904
Epoch 4937/10000, Prediction Accuracy = 64.22692307692309%, Loss = 0.007817610381887509
Epoch: 4937, Batch Gradient Norm: 4.819642528824734
Epoch: 4937, Batch Gradient Norm after: 4.819642528824734
Epoch 4938/10000, Prediction Accuracy = 63.650000000000006%, Loss = 0.007982138580141159
Epoch: 4938, Batch Gradient Norm: 3.99974369843944
Epoch: 4938, Batch Gradient Norm after: 3.99974369843944
Epoch 4939/10000, Prediction Accuracy = 65.05384615384617%, Loss = 0.0076035627593787816
Epoch: 4939, Batch Gradient Norm: 4.29819884535756
Epoch: 4939, Batch Gradient Norm after: 4.29819884535756
Epoch 4940/10000, Prediction Accuracy = 64.64999999999999%, Loss = 0.007694213149639277
Epoch: 4940, Batch Gradient Norm: 4.403546238389745
Epoch: 4940, Batch Gradient Norm after: 4.403546238389745
Epoch 4941/10000, Prediction Accuracy = 64.08846153846153%, Loss = 0.0077877304015251305
Epoch: 4941, Batch Gradient Norm: 4.137243295071453
Epoch: 4941, Batch Gradient Norm after: 4.137243295071453
Epoch 4942/10000, Prediction Accuracy = 64.84615384615384%, Loss = 0.007541296788706229
Epoch: 4942, Batch Gradient Norm: 4.120770094180018
Epoch: 4942, Batch Gradient Norm after: 4.120770094180018
Epoch 4943/10000, Prediction Accuracy = 65.51538461538462%, Loss = 0.00749006992779099
Epoch: 4943, Batch Gradient Norm: 4.062412121006823
Epoch: 4943, Batch Gradient Norm after: 4.062412121006823
Epoch 4944/10000, Prediction Accuracy = 64.87307692307692%, Loss = 0.007516220140342529
Epoch: 4944, Batch Gradient Norm: 4.330451844505846
Epoch: 4944, Batch Gradient Norm after: 4.330451844505846
Epoch 4945/10000, Prediction Accuracy = 64.88846153846151%, Loss = 0.0076650020379859666
Epoch: 4945, Batch Gradient Norm: 4.342939513543066
Epoch: 4945, Batch Gradient Norm after: 4.342939513543066
Epoch 4946/10000, Prediction Accuracy = 65.17307692307693%, Loss = 0.00758867678590692
Epoch: 4946, Batch Gradient Norm: 4.590042612874944
Epoch: 4946, Batch Gradient Norm after: 4.590042612874944
Epoch 4947/10000, Prediction Accuracy = 63.88461538461539%, Loss = 0.007887818420735689
Epoch: 4947, Batch Gradient Norm: 4.568829575573372
Epoch: 4947, Batch Gradient Norm after: 4.568829575573372
Epoch 4948/10000, Prediction Accuracy = 64.13846153846153%, Loss = 0.007835295409537278
Epoch: 4948, Batch Gradient Norm: 4.434260721079796
Epoch: 4948, Batch Gradient Norm after: 4.434260721079796
Epoch 4949/10000, Prediction Accuracy = 64.76923076923076%, Loss = 0.007782486446488362
Epoch: 4949, Batch Gradient Norm: 4.284646843214818
Epoch: 4949, Batch Gradient Norm after: 4.284646843214818
Epoch 4950/10000, Prediction Accuracy = 64.6%, Loss = 0.007749037924580849
Epoch: 4950, Batch Gradient Norm: 4.204754520260498
Epoch: 4950, Batch Gradient Norm after: 4.204754520260498
Epoch 4951/10000, Prediction Accuracy = 64.9346153846154%, Loss = 0.007674616976426198
Epoch: 4951, Batch Gradient Norm: 4.333084509078497
Epoch: 4951, Batch Gradient Norm after: 4.333084509078497
Epoch 4952/10000, Prediction Accuracy = 64.71538461538461%, Loss = 0.007622131003210178
Epoch: 4952, Batch Gradient Norm: 4.521367008138099
Epoch: 4952, Batch Gradient Norm after: 4.521367008138099
Epoch 4953/10000, Prediction Accuracy = 64.45769230769233%, Loss = 0.0077141682044244726
Epoch: 4953, Batch Gradient Norm: 4.638174663521964
Epoch: 4953, Batch Gradient Norm after: 4.638174663521964
Epoch 4954/10000, Prediction Accuracy = 63.77692307692307%, Loss = 0.007863845532903304
Epoch: 4954, Batch Gradient Norm: 4.199807854787061
Epoch: 4954, Batch Gradient Norm after: 4.199807854787061
Epoch 4955/10000, Prediction Accuracy = 64.91153846153846%, Loss = 0.007683306072766964
Epoch: 4955, Batch Gradient Norm: 4.306735450196698
Epoch: 4955, Batch Gradient Norm after: 4.306735450196698
Epoch 4956/10000, Prediction Accuracy = 64.48846153846155%, Loss = 0.007732843442891653
Epoch: 4956, Batch Gradient Norm: 4.322801878337004
Epoch: 4956, Batch Gradient Norm after: 4.322801878337004
Epoch 4957/10000, Prediction Accuracy = 64.79615384615384%, Loss = 0.007757557985874323
Epoch: 4957, Batch Gradient Norm: 4.143471276533041
Epoch: 4957, Batch Gradient Norm after: 4.143471276533041
Epoch 4958/10000, Prediction Accuracy = 64.62692307692306%, Loss = 0.007648138508487206
Epoch: 4958, Batch Gradient Norm: 4.075298349449371
Epoch: 4958, Batch Gradient Norm after: 4.075298349449371
Epoch 4959/10000, Prediction Accuracy = 64.61153846153847%, Loss = 0.007564976453208006
Epoch: 4959, Batch Gradient Norm: 4.2001741885138
Epoch: 4959, Batch Gradient Norm after: 4.2001741885138
Epoch 4960/10000, Prediction Accuracy = 64.79615384615384%, Loss = 0.007577116636989208
Epoch: 4960, Batch Gradient Norm: 3.9736057206157365
Epoch: 4960, Batch Gradient Norm after: 3.9736057206157365
Epoch 4961/10000, Prediction Accuracy = 65.16923076923077%, Loss = 0.0074173962840667134
Epoch: 4961, Batch Gradient Norm: 4.132502185106644
Epoch: 4961, Batch Gradient Norm after: 4.132502185106644
Epoch 4962/10000, Prediction Accuracy = 65.54230769230767%, Loss = 0.007478940873765028
Epoch: 4962, Batch Gradient Norm: 4.520663284273916
Epoch: 4962, Batch Gradient Norm after: 4.520663284273916
Epoch 4963/10000, Prediction Accuracy = 64.2923076923077%, Loss = 0.007848855322943283
Epoch: 4963, Batch Gradient Norm: 4.486145797727435
Epoch: 4963, Batch Gradient Norm after: 4.486145797727435
Epoch 4964/10000, Prediction Accuracy = 64.27307692307693%, Loss = 0.007859587812652955
Epoch: 4964, Batch Gradient Norm: 4.145950021850259
Epoch: 4964, Batch Gradient Norm after: 4.145950021850259
Epoch 4965/10000, Prediction Accuracy = 64.94615384615385%, Loss = 0.007626906502991915
Epoch: 4965, Batch Gradient Norm: 4.008782112427994
Epoch: 4965, Batch Gradient Norm after: 4.008782112427994
Epoch 4966/10000, Prediction Accuracy = 64.82692307692308%, Loss = 0.007599107455462217
Epoch: 4966, Batch Gradient Norm: 4.32022728715838
Epoch: 4966, Batch Gradient Norm after: 4.32022728715838
Epoch 4967/10000, Prediction Accuracy = 64.36153846153846%, Loss = 0.007681658312391777
Epoch: 4967, Batch Gradient Norm: 4.553344813875525
Epoch: 4967, Batch Gradient Norm after: 4.553344813875525
Epoch 4968/10000, Prediction Accuracy = 64.57307692307693%, Loss = 0.007809394719795539
Epoch: 4968, Batch Gradient Norm: 4.098494813782164
Epoch: 4968, Batch Gradient Norm after: 4.098494813782164
Epoch 4969/10000, Prediction Accuracy = 65.0576923076923%, Loss = 0.007555844584623208
Epoch: 4969, Batch Gradient Norm: 4.193117840163067
Epoch: 4969, Batch Gradient Norm after: 4.193117840163067
Epoch 4970/10000, Prediction Accuracy = 65.28461538461538%, Loss = 0.007531787304637523
Epoch: 4970, Batch Gradient Norm: 3.9950325606944905
Epoch: 4970, Batch Gradient Norm after: 3.9950325606944905
Epoch 4971/10000, Prediction Accuracy = 65.38846153846154%, Loss = 0.007535728482672801
Epoch: 4971, Batch Gradient Norm: 4.198263383946487
Epoch: 4971, Batch Gradient Norm after: 4.198263383946487
Epoch 4972/10000, Prediction Accuracy = 64.55384615384615%, Loss = 0.007653027880363739
Epoch: 4972, Batch Gradient Norm: 4.6682174427541
Epoch: 4972, Batch Gradient Norm after: 4.6682174427541
Epoch 4973/10000, Prediction Accuracy = 64.18076923076923%, Loss = 0.007784465077118232
Epoch: 4973, Batch Gradient Norm: 4.345192161939437
Epoch: 4973, Batch Gradient Norm after: 4.345192161939437
Epoch 4974/10000, Prediction Accuracy = 64.72692307692307%, Loss = 0.007747448013665585
Epoch: 4974, Batch Gradient Norm: 4.136275388819971
Epoch: 4974, Batch Gradient Norm after: 4.136275388819971
Epoch 4975/10000, Prediction Accuracy = 64.9423076923077%, Loss = 0.007544142516473165
Epoch: 4975, Batch Gradient Norm: 4.378580783879534
Epoch: 4975, Batch Gradient Norm after: 4.378580783879534
Epoch 4976/10000, Prediction Accuracy = 64.80384615384614%, Loss = 0.007681326940655708
Epoch: 4976, Batch Gradient Norm: 3.9684130758328737
Epoch: 4976, Batch Gradient Norm after: 3.9684130758328737
Epoch 4977/10000, Prediction Accuracy = 65.33076923076922%, Loss = 0.007508167602981512
Epoch: 4977, Batch Gradient Norm: 3.787806066266596
Epoch: 4977, Batch Gradient Norm after: 3.787806066266596
Epoch 4978/10000, Prediction Accuracy = 65.40384615384616%, Loss = 0.007402574106191213
Epoch: 4978, Batch Gradient Norm: 4.094102612582462
Epoch: 4978, Batch Gradient Norm after: 4.094102612582462
Epoch 4979/10000, Prediction Accuracy = 65.07307692307691%, Loss = 0.0075872302628480475
Epoch: 4979, Batch Gradient Norm: 3.7445559296406854
Epoch: 4979, Batch Gradient Norm after: 3.7445559296406854
Epoch 4980/10000, Prediction Accuracy = 65.36153846153846%, Loss = 0.007359821492662797
Epoch: 4980, Batch Gradient Norm: 4.327691689508305
Epoch: 4980, Batch Gradient Norm after: 4.327691689508305
Epoch 4981/10000, Prediction Accuracy = 65.13076923076923%, Loss = 0.0075658094496108014
Epoch: 4981, Batch Gradient Norm: 4.811756285700225
Epoch: 4981, Batch Gradient Norm after: 4.811756285700225
Epoch 4982/10000, Prediction Accuracy = 63.70384615384615%, Loss = 0.00787253867691526
Epoch: 4982, Batch Gradient Norm: 4.381973006591558
Epoch: 4982, Batch Gradient Norm after: 4.381973006591558
Epoch 4983/10000, Prediction Accuracy = 64.69615384615385%, Loss = 0.007742568026654995
Epoch: 4983, Batch Gradient Norm: 3.9638592913454826
Epoch: 4983, Batch Gradient Norm after: 3.9638592913454826
Epoch 4984/10000, Prediction Accuracy = 65.15384615384616%, Loss = 0.007444680489313144
Epoch: 4984, Batch Gradient Norm: 3.9208694029968405
Epoch: 4984, Batch Gradient Norm after: 3.9208694029968405
Epoch 4985/10000, Prediction Accuracy = 65.45769230769231%, Loss = 0.007359927018674521
Epoch: 4985, Batch Gradient Norm: 3.725680835984087
Epoch: 4985, Batch Gradient Norm after: 3.725680835984087
Epoch 4986/10000, Prediction Accuracy = 65.0923076923077%, Loss = 0.007396601355419709
Epoch: 4986, Batch Gradient Norm: 4.285178894464295
Epoch: 4986, Batch Gradient Norm after: 4.285178894464295
Epoch 4987/10000, Prediction Accuracy = 65.3%, Loss = 0.007533068195558512
Epoch: 4987, Batch Gradient Norm: 4.547052554763543
Epoch: 4987, Batch Gradient Norm after: 4.547052554763543
Epoch 4988/10000, Prediction Accuracy = 64.6423076923077%, Loss = 0.0076670737292331
Epoch: 4988, Batch Gradient Norm: 4.217161677173947
Epoch: 4988, Batch Gradient Norm after: 4.217161677173947
Epoch 4989/10000, Prediction Accuracy = 64.93846153846154%, Loss = 0.007508106959553866
Epoch: 4989, Batch Gradient Norm: 3.8574857680555628
Epoch: 4989, Batch Gradient Norm after: 3.8574857680555628
Epoch 4990/10000, Prediction Accuracy = 65.87692307692308%, Loss = 0.007320903743115755
Epoch: 4990, Batch Gradient Norm: 4.174244323546275
Epoch: 4990, Batch Gradient Norm after: 4.174244323546275
Epoch 4991/10000, Prediction Accuracy = 65.0153846153846%, Loss = 0.007486385221664722
Epoch: 4991, Batch Gradient Norm: 4.215217526251708
Epoch: 4991, Batch Gradient Norm after: 4.215217526251708
Epoch 4992/10000, Prediction Accuracy = 65.15384615384616%, Loss = 0.007444429856080275
Epoch: 4992, Batch Gradient Norm: 4.478272302196082
Epoch: 4992, Batch Gradient Norm after: 4.478272302196082
Epoch 4993/10000, Prediction Accuracy = 64.88076923076923%, Loss = 0.007619940783255375
Epoch: 4993, Batch Gradient Norm: 4.378720570813245
Epoch: 4993, Batch Gradient Norm after: 4.378720570813245
Epoch 4994/10000, Prediction Accuracy = 64.63076923076923%, Loss = 0.007732624402986123
Epoch: 4994, Batch Gradient Norm: 4.34563455720909
Epoch: 4994, Batch Gradient Norm after: 4.34563455720909
Epoch 4995/10000, Prediction Accuracy = 65.16923076923077%, Loss = 0.007542481323560843
Epoch: 4995, Batch Gradient Norm: 4.396403311540039
Epoch: 4995, Batch Gradient Norm after: 4.396403311540039
Epoch 4996/10000, Prediction Accuracy = 65.15769230769232%, Loss = 0.0075759414511804395
Epoch: 4996, Batch Gradient Norm: 4.742400090100962
Epoch: 4996, Batch Gradient Norm after: 4.742400090100962
Epoch 4997/10000, Prediction Accuracy = 64.55384615384615%, Loss = 0.007746550576904645
Epoch: 4997, Batch Gradient Norm: 4.130221991101963
Epoch: 4997, Batch Gradient Norm after: 4.130221991101963
Epoch 4998/10000, Prediction Accuracy = 65.06153846153846%, Loss = 0.007600291202274652
Epoch: 4998, Batch Gradient Norm: 4.364981579903934
Epoch: 4998, Batch Gradient Norm after: 4.364981579903934
Epoch 4999/10000, Prediction Accuracy = 64.96153846153847%, Loss = 0.007559331886183757
Epoch: 4999, Batch Gradient Norm: 4.11746913379945
Epoch: 4999, Batch Gradient Norm after: 4.11746913379945
Epoch 5000/10000, Prediction Accuracy = 65.55384615384615%, Loss = 0.007440218451217963
Epoch: 5000, Batch Gradient Norm: 4.457975842722353
Epoch: 5000, Batch Gradient Norm after: 4.457975842722353
Epoch 5001/10000, Prediction Accuracy = 64.3923076923077%, Loss = 0.007763056335254357
Epoch: 5001, Batch Gradient Norm: 4.404839025203745
Epoch: 5001, Batch Gradient Norm after: 4.404839025203745
Epoch 5002/10000, Prediction Accuracy = 64.74615384615385%, Loss = 0.007663319603754924
Epoch: 5002, Batch Gradient Norm: 4.653540399897127
Epoch: 5002, Batch Gradient Norm after: 4.653540399897127
Epoch 5003/10000, Prediction Accuracy = 64.08076923076923%, Loss = 0.007816810125055222
Epoch: 5003, Batch Gradient Norm: 4.537711488201551
Epoch: 5003, Batch Gradient Norm after: 4.537711488201551
Epoch 5004/10000, Prediction Accuracy = 64.28076923076924%, Loss = 0.007855307203359328
Epoch: 5004, Batch Gradient Norm: 4.450527561491551
Epoch: 5004, Batch Gradient Norm after: 4.450527561491551
Epoch 5005/10000, Prediction Accuracy = 64.46153846153847%, Loss = 0.007853064900980545
Epoch: 5005, Batch Gradient Norm: 4.22500210280573
Epoch: 5005, Batch Gradient Norm after: 4.22500210280573
Epoch 5006/10000, Prediction Accuracy = 64.97307692307692%, Loss = 0.007654608549693456
Epoch: 5006, Batch Gradient Norm: 3.9844741013626455
Epoch: 5006, Batch Gradient Norm after: 3.9844741013626455
Epoch 5007/10000, Prediction Accuracy = 65.13076923076925%, Loss = 0.007485016929702117
Epoch: 5007, Batch Gradient Norm: 4.011166074565562
Epoch: 5007, Batch Gradient Norm after: 4.011166074565562
Epoch 5008/10000, Prediction Accuracy = 64.86923076923077%, Loss = 0.007438991612826402
Epoch: 5008, Batch Gradient Norm: 4.603100395625677
Epoch: 5008, Batch Gradient Norm after: 4.603100395625677
Epoch 5009/10000, Prediction Accuracy = 64.87692307692308%, Loss = 0.00773293489160446
Epoch: 5009, Batch Gradient Norm: 4.695590990779048
Epoch: 5009, Batch Gradient Norm after: 4.695590990779048
Epoch 5010/10000, Prediction Accuracy = 64.12307692307692%, Loss = 0.00786634237290575
Epoch: 5010, Batch Gradient Norm: 4.589233927921191
Epoch: 5010, Batch Gradient Norm after: 4.589233927921191
Epoch 5011/10000, Prediction Accuracy = 64.3423076923077%, Loss = 0.007954768800678162
Epoch: 5011, Batch Gradient Norm: 4.362910966599263
Epoch: 5011, Batch Gradient Norm after: 4.362910966599263
Epoch 5012/10000, Prediction Accuracy = 64.37307692307692%, Loss = 0.007786487587369406
Epoch: 5012, Batch Gradient Norm: 3.936162191979644
Epoch: 5012, Batch Gradient Norm after: 3.936162191979644
Epoch 5013/10000, Prediction Accuracy = 65.1%, Loss = 0.007497052841175061
Epoch: 5013, Batch Gradient Norm: 3.992992078187874
Epoch: 5013, Batch Gradient Norm after: 3.992992078187874
Epoch 5014/10000, Prediction Accuracy = 65.46153846153845%, Loss = 0.007466944400221109
Epoch: 5014, Batch Gradient Norm: 4.101475777027545
Epoch: 5014, Batch Gradient Norm after: 4.101475777027545
Epoch 5015/10000, Prediction Accuracy = 65.51538461538462%, Loss = 0.007513884813166582
Epoch: 5015, Batch Gradient Norm: 3.900746026559788
Epoch: 5015, Batch Gradient Norm after: 3.900746026559788
Epoch 5016/10000, Prediction Accuracy = 64.98461538461537%, Loss = 0.007435932074888394
Epoch: 5016, Batch Gradient Norm: 4.6326661969302565
Epoch: 5016, Batch Gradient Norm after: 4.6326661969302565
Epoch 5017/10000, Prediction Accuracy = 64.04615384615384%, Loss = 0.007821664787255801
Epoch: 5017, Batch Gradient Norm: 4.388248994774316
Epoch: 5017, Batch Gradient Norm after: 4.388248994774316
Epoch 5018/10000, Prediction Accuracy = 64.86538461538461%, Loss = 0.0075994471016411595
Epoch: 5018, Batch Gradient Norm: 4.519937051306319
Epoch: 5018, Batch Gradient Norm after: 4.519937051306319
Epoch 5019/10000, Prediction Accuracy = 64.62307692307692%, Loss = 0.007803725580183359
Epoch: 5019, Batch Gradient Norm: 4.205812268371262
Epoch: 5019, Batch Gradient Norm after: 4.205812268371262
Epoch 5020/10000, Prediction Accuracy = 64.22692307692309%, Loss = 0.007715659001125739
Epoch: 5020, Batch Gradient Norm: 4.034861989189195
Epoch: 5020, Batch Gradient Norm after: 4.034861989189195
Epoch 5021/10000, Prediction Accuracy = 65.03076923076924%, Loss = 0.007589593529701233
Epoch: 5021, Batch Gradient Norm: 4.137314666594812
Epoch: 5021, Batch Gradient Norm after: 4.137314666594812
Epoch 5022/10000, Prediction Accuracy = 64.89999999999999%, Loss = 0.0074829881867537135
Epoch: 5022, Batch Gradient Norm: 4.557666483064314
Epoch: 5022, Batch Gradient Norm after: 4.557666483064314
Epoch 5023/10000, Prediction Accuracy = 63.73461538461539%, Loss = 0.007816040172026707
Epoch: 5023, Batch Gradient Norm: 4.48306432374346
Epoch: 5023, Batch Gradient Norm after: 4.48306432374346
Epoch 5024/10000, Prediction Accuracy = 64.01538461538463%, Loss = 0.0077735499765437385
Epoch: 5024, Batch Gradient Norm: 4.093995643001334
Epoch: 5024, Batch Gradient Norm after: 4.093995643001334
Epoch 5025/10000, Prediction Accuracy = 64.53076923076922%, Loss = 0.0076576931617007805
Epoch: 5025, Batch Gradient Norm: 4.379273581070956
Epoch: 5025, Batch Gradient Norm after: 4.379273581070956
Epoch 5026/10000, Prediction Accuracy = 64.39999999999999%, Loss = 0.007772946479515388
Epoch: 5026, Batch Gradient Norm: 4.182443723549505
Epoch: 5026, Batch Gradient Norm after: 4.182443723549505
Epoch 5027/10000, Prediction Accuracy = 64.43076923076923%, Loss = 0.0077391456311138775
Epoch: 5027, Batch Gradient Norm: 3.6285082714066483
Epoch: 5027, Batch Gradient Norm after: 3.6285082714066483
Epoch 5028/10000, Prediction Accuracy = 65.73846153846154%, Loss = 0.007304356970752661
Epoch: 5028, Batch Gradient Norm: 3.9359587461698573
Epoch: 5028, Batch Gradient Norm after: 3.9359587461698573
Epoch 5029/10000, Prediction Accuracy = 65.21538461538462%, Loss = 0.007532602068609917
Epoch: 5029, Batch Gradient Norm: 4.008562634156684
Epoch: 5029, Batch Gradient Norm after: 4.008562634156684
Epoch 5030/10000, Prediction Accuracy = 64.98846153846154%, Loss = 0.007462920262836493
Epoch: 5030, Batch Gradient Norm: 4.300374663468802
Epoch: 5030, Batch Gradient Norm after: 4.300374663468802
Epoch 5031/10000, Prediction Accuracy = 64.78846153846153%, Loss = 0.007560632979640594
Epoch: 5031, Batch Gradient Norm: 4.243624677854545
Epoch: 5031, Batch Gradient Norm after: 4.243624677854545
Epoch 5032/10000, Prediction Accuracy = 64.61153846153846%, Loss = 0.007630519139078947
Epoch: 5032, Batch Gradient Norm: 4.410562603468025
Epoch: 5032, Batch Gradient Norm after: 4.410562603468025
Epoch 5033/10000, Prediction Accuracy = 64.93846153846154%, Loss = 0.007620105770631478
Epoch: 5033, Batch Gradient Norm: 4.202867250874378
Epoch: 5033, Batch Gradient Norm after: 4.202867250874378
Epoch 5034/10000, Prediction Accuracy = 65.99615384615385%, Loss = 0.0074513432426521415
Epoch: 5034, Batch Gradient Norm: 3.9903060372533985
Epoch: 5034, Batch Gradient Norm after: 3.9903060372533985
Epoch 5035/10000, Prediction Accuracy = 64.88846153846154%, Loss = 0.007420919190805692
Epoch: 5035, Batch Gradient Norm: 4.2613886858106
Epoch: 5035, Batch Gradient Norm after: 4.2613886858106
Epoch 5036/10000, Prediction Accuracy = 65.33461538461539%, Loss = 0.007510556588665797
Epoch: 5036, Batch Gradient Norm: 4.418619520486248
Epoch: 5036, Batch Gradient Norm after: 4.418619520486248
Epoch 5037/10000, Prediction Accuracy = 64.36538461538461%, Loss = 0.007734528671090419
Epoch: 5037, Batch Gradient Norm: 4.296190510224481
Epoch: 5037, Batch Gradient Norm after: 4.296190510224481
Epoch 5038/10000, Prediction Accuracy = 64.5423076923077%, Loss = 0.007631296578508157
Epoch: 5038, Batch Gradient Norm: 3.8503368672518143
Epoch: 5038, Batch Gradient Norm after: 3.8503368672518143
Epoch 5039/10000, Prediction Accuracy = 65.79230769230767%, Loss = 0.0073572997576915305
Epoch: 5039, Batch Gradient Norm: 4.205930737091455
Epoch: 5039, Batch Gradient Norm after: 4.205930737091455
Epoch 5040/10000, Prediction Accuracy = 64.83461538461539%, Loss = 0.007640665504508293
Epoch: 5040, Batch Gradient Norm: 4.615932041018189
Epoch: 5040, Batch Gradient Norm after: 4.615932041018189
Epoch 5041/10000, Prediction Accuracy = 64.45384615384616%, Loss = 0.007755937269673898
Epoch: 5041, Batch Gradient Norm: 4.4852205932658515
Epoch: 5041, Batch Gradient Norm after: 4.4852205932658515
Epoch 5042/10000, Prediction Accuracy = 64.34615384615384%, Loss = 0.007762541636251486
Epoch: 5042, Batch Gradient Norm: 4.925763010908383
Epoch: 5042, Batch Gradient Norm after: 4.925763010908383
Epoch 5043/10000, Prediction Accuracy = 63.534615384615385%, Loss = 0.008025629911571741
Epoch: 5043, Batch Gradient Norm: 4.654829110698386
Epoch: 5043, Batch Gradient Norm after: 4.654829110698386
Epoch 5044/10000, Prediction Accuracy = 63.54615384615385%, Loss = 0.008016178348603157
Epoch: 5044, Batch Gradient Norm: 4.096492436324564
Epoch: 5044, Batch Gradient Norm after: 4.096492436324564
Epoch 5045/10000, Prediction Accuracy = 64.91538461538462%, Loss = 0.007563580185748064
Epoch: 5045, Batch Gradient Norm: 4.505934822334878
Epoch: 5045, Batch Gradient Norm after: 4.505934822334878
Epoch 5046/10000, Prediction Accuracy = 64.71153846153845%, Loss = 0.0076976638430586225
Epoch: 5046, Batch Gradient Norm: 4.076337715271822
Epoch: 5046, Batch Gradient Norm after: 4.076337715271822
Epoch 5047/10000, Prediction Accuracy = 64.94615384615385%, Loss = 0.007523256174933452
Epoch: 5047, Batch Gradient Norm: 4.016903395210879
Epoch: 5047, Batch Gradient Norm after: 4.016903395210879
Epoch 5048/10000, Prediction Accuracy = 65.4423076923077%, Loss = 0.007499066253121083
Epoch: 5048, Batch Gradient Norm: 4.069081940508034
Epoch: 5048, Batch Gradient Norm after: 4.069081940508034
Epoch 5049/10000, Prediction Accuracy = 65.24615384615383%, Loss = 0.007427159768457596
Epoch: 5049, Batch Gradient Norm: 4.446606441983568
Epoch: 5049, Batch Gradient Norm after: 4.446606441983568
Epoch 5050/10000, Prediction Accuracy = 64.41153846153847%, Loss = 0.007710577454417944
Epoch: 5050, Batch Gradient Norm: 3.9751233832387483
Epoch: 5050, Batch Gradient Norm after: 3.9751233832387483
Epoch 5051/10000, Prediction Accuracy = 65.3923076923077%, Loss = 0.007480698494383922
Epoch: 5051, Batch Gradient Norm: 3.872080144180959
Epoch: 5051, Batch Gradient Norm after: 3.872080144180959
Epoch 5052/10000, Prediction Accuracy = 65.6076923076923%, Loss = 0.007364348938258795
Epoch: 5052, Batch Gradient Norm: 4.325354432768784
Epoch: 5052, Batch Gradient Norm after: 4.325354432768784
Epoch 5053/10000, Prediction Accuracy = 65.03461538461539%, Loss = 0.007553011644631624
Epoch: 5053, Batch Gradient Norm: 4.355456242106402
Epoch: 5053, Batch Gradient Norm after: 4.355456242106402
Epoch 5054/10000, Prediction Accuracy = 65.01153846153846%, Loss = 0.007583088528078336
Epoch: 5054, Batch Gradient Norm: 4.259941527427124
Epoch: 5054, Batch Gradient Norm after: 4.259941527427124
Epoch 5055/10000, Prediction Accuracy = 64.94230769230771%, Loss = 0.0075883326622156
Epoch: 5055, Batch Gradient Norm: 4.5346821010318425
Epoch: 5055, Batch Gradient Norm after: 4.5346821010318425
Epoch 5056/10000, Prediction Accuracy = 64.56538461538462%, Loss = 0.007738640925918634
Epoch: 5056, Batch Gradient Norm: 4.260758686533301
Epoch: 5056, Batch Gradient Norm after: 4.260758686533301
Epoch 5057/10000, Prediction Accuracy = 64.24615384615385%, Loss = 0.007810628005804924
Epoch: 5057, Batch Gradient Norm: 4.130554254602999
Epoch: 5057, Batch Gradient Norm after: 4.130554254602999
Epoch 5058/10000, Prediction Accuracy = 64.79615384615384%, Loss = 0.007576126820192887
Epoch: 5058, Batch Gradient Norm: 4.224545931742839
Epoch: 5058, Batch Gradient Norm after: 4.224545931742839
Epoch 5059/10000, Prediction Accuracy = 65.1076923076923%, Loss = 0.007495754398405552
Epoch: 5059, Batch Gradient Norm: 4.515645686208805
Epoch: 5059, Batch Gradient Norm after: 4.515645686208805
Epoch 5060/10000, Prediction Accuracy = 64.5576923076923%, Loss = 0.007774375379085541
Epoch: 5060, Batch Gradient Norm: 4.318128352825501
Epoch: 5060, Batch Gradient Norm after: 4.318128352825501
Epoch 5061/10000, Prediction Accuracy = 65.05769230769232%, Loss = 0.007613987697718235
Epoch: 5061, Batch Gradient Norm: 3.8251141329172604
Epoch: 5061, Batch Gradient Norm after: 3.8251141329172604
Epoch 5062/10000, Prediction Accuracy = 65.25%, Loss = 0.0074497861429475825
Epoch: 5062, Batch Gradient Norm: 3.828651450396642
Epoch: 5062, Batch Gradient Norm after: 3.828651450396642
Epoch 5063/10000, Prediction Accuracy = 65.5576923076923%, Loss = 0.007353202081643618
Epoch: 5063, Batch Gradient Norm: 3.7872067117793615
Epoch: 5063, Batch Gradient Norm after: 3.7872067117793615
Epoch 5064/10000, Prediction Accuracy = 65.48076923076923%, Loss = 0.007326210490786112
Epoch: 5064, Batch Gradient Norm: 4.582144288076715
Epoch: 5064, Batch Gradient Norm after: 4.582144288076715
Epoch 5065/10000, Prediction Accuracy = 64.3423076923077%, Loss = 0.007778648072137282
Epoch: 5065, Batch Gradient Norm: 4.341890087237391
Epoch: 5065, Batch Gradient Norm after: 4.341890087237391
Epoch 5066/10000, Prediction Accuracy = 64.76923076923077%, Loss = 0.007610567845404148
Epoch: 5066, Batch Gradient Norm: 4.0203493039775475
Epoch: 5066, Batch Gradient Norm after: 4.0203493039775475
Epoch 5067/10000, Prediction Accuracy = 65.4846153846154%, Loss = 0.007388687692582607
Epoch: 5067, Batch Gradient Norm: 3.7946417864563733
Epoch: 5067, Batch Gradient Norm after: 3.7946417864563733
Epoch 5068/10000, Prediction Accuracy = 65.62307692307692%, Loss = 0.00731915317905637
Epoch: 5068, Batch Gradient Norm: 4.290187977377441
Epoch: 5068, Batch Gradient Norm after: 4.290187977377441
Epoch 5069/10000, Prediction Accuracy = 65.19615384615385%, Loss = 0.007494070316449954
Epoch: 5069, Batch Gradient Norm: 4.244423034769026
Epoch: 5069, Batch Gradient Norm after: 4.244423034769026
Epoch 5070/10000, Prediction Accuracy = 65.45384615384616%, Loss = 0.007532637029026563
Epoch: 5070, Batch Gradient Norm: 3.9404898208212242
Epoch: 5070, Batch Gradient Norm after: 3.9404898208212242
Epoch 5071/10000, Prediction Accuracy = 65.06923076923077%, Loss = 0.007341846966972718
Epoch: 5071, Batch Gradient Norm: 4.563097854085454
Epoch: 5071, Batch Gradient Norm after: 4.563097854085454
Epoch 5072/10000, Prediction Accuracy = 64.65384615384616%, Loss = 0.007666713701417813
Epoch: 5072, Batch Gradient Norm: 4.72582290270267
Epoch: 5072, Batch Gradient Norm after: 4.72582290270267
Epoch 5073/10000, Prediction Accuracy = 64.53461538461538%, Loss = 0.007774867332325532
Epoch: 5073, Batch Gradient Norm: 4.3510843441335005
Epoch: 5073, Batch Gradient Norm after: 4.3510843441335005
Epoch 5074/10000, Prediction Accuracy = 64.99615384615385%, Loss = 0.007618511847865123
Epoch: 5074, Batch Gradient Norm: 4.398980776860906
Epoch: 5074, Batch Gradient Norm after: 4.398980776860906
Epoch 5075/10000, Prediction Accuracy = 64.51538461538463%, Loss = 0.007664514669718651
Epoch: 5075, Batch Gradient Norm: 4.128972674386339
Epoch: 5075, Batch Gradient Norm after: 4.128972674386339
Epoch 5076/10000, Prediction Accuracy = 65.04230769230769%, Loss = 0.00746006009956965
Epoch: 5076, Batch Gradient Norm: 4.083394040711661
Epoch: 5076, Batch Gradient Norm after: 4.083394040711661
Epoch 5077/10000, Prediction Accuracy = 64.85769230769232%, Loss = 0.007498133820123398
Epoch: 5077, Batch Gradient Norm: 4.320070407095685
Epoch: 5077, Batch Gradient Norm after: 4.320070407095685
Epoch 5078/10000, Prediction Accuracy = 64.92307692307692%, Loss = 0.007605905178934336
Epoch: 5078, Batch Gradient Norm: 4.336771405200154
Epoch: 5078, Batch Gradient Norm after: 4.336771405200154
Epoch 5079/10000, Prediction Accuracy = 65.12307692307692%, Loss = 0.00768419666788899
Epoch: 5079, Batch Gradient Norm: 4.457057837814077
Epoch: 5079, Batch Gradient Norm after: 4.457057837814077
Epoch 5080/10000, Prediction Accuracy = 64.68076923076923%, Loss = 0.007736726377445918
Epoch: 5080, Batch Gradient Norm: 4.568509194022792
Epoch: 5080, Batch Gradient Norm after: 4.568509194022792
Epoch 5081/10000, Prediction Accuracy = 64.17692307692307%, Loss = 0.007821953497253932
Epoch: 5081, Batch Gradient Norm: 4.534099889227631
Epoch: 5081, Batch Gradient Norm after: 4.534099889227631
Epoch 5082/10000, Prediction Accuracy = 64.57307692307693%, Loss = 0.00775810366926285
Epoch: 5082, Batch Gradient Norm: 4.286313885724741
Epoch: 5082, Batch Gradient Norm after: 4.286313885724741
Epoch 5083/10000, Prediction Accuracy = 64.6076923076923%, Loss = 0.007663726018598447
Epoch: 5083, Batch Gradient Norm: 4.037008580079877
Epoch: 5083, Batch Gradient Norm after: 4.037008580079877
Epoch 5084/10000, Prediction Accuracy = 64.98076923076923%, Loss = 0.007513259143496935
Epoch: 5084, Batch Gradient Norm: 4.220602539759349
Epoch: 5084, Batch Gradient Norm after: 4.220602539759349
Epoch 5085/10000, Prediction Accuracy = 64.95769230769231%, Loss = 0.007526242854790046
Epoch: 5085, Batch Gradient Norm: 4.092419739708658
Epoch: 5085, Batch Gradient Norm after: 4.092419739708658
Epoch 5086/10000, Prediction Accuracy = 64.68461538461538%, Loss = 0.00759183235753041
Epoch: 5086, Batch Gradient Norm: 4.468370958599916
Epoch: 5086, Batch Gradient Norm after: 4.468370958599916
Epoch 5087/10000, Prediction Accuracy = 64.61153846153846%, Loss = 0.007693702820688486
Epoch: 5087, Batch Gradient Norm: 4.275117230903209
Epoch: 5087, Batch Gradient Norm after: 4.275117230903209
Epoch 5088/10000, Prediction Accuracy = 65.2653846153846%, Loss = 0.007504653042325607
Epoch: 5088, Batch Gradient Norm: 4.801532581814899
Epoch: 5088, Batch Gradient Norm after: 4.801532581814899
Epoch 5089/10000, Prediction Accuracy = 64.33846153846154%, Loss = 0.007735846671633995
Epoch: 5089, Batch Gradient Norm: 4.40348323906416
Epoch: 5089, Batch Gradient Norm after: 4.40348323906416
Epoch 5090/10000, Prediction Accuracy = 64.73846153846154%, Loss = 0.007694201185726202
Epoch: 5090, Batch Gradient Norm: 4.002440702912529
Epoch: 5090, Batch Gradient Norm after: 4.002440702912529
Epoch 5091/10000, Prediction Accuracy = 65.18076923076923%, Loss = 0.0075225610142717
Epoch: 5091, Batch Gradient Norm: 4.110225155613865
Epoch: 5091, Batch Gradient Norm after: 4.110225155613865
Epoch 5092/10000, Prediction Accuracy = 65.0923076923077%, Loss = 0.007487234516212573
Epoch: 5092, Batch Gradient Norm: 3.9988211822464574
Epoch: 5092, Batch Gradient Norm after: 3.9988211822464574
Epoch 5093/10000, Prediction Accuracy = 65.30384615384615%, Loss = 0.0074135006691973945
Epoch: 5093, Batch Gradient Norm: 4.183513241865407
Epoch: 5093, Batch Gradient Norm after: 4.183513241865407
Epoch 5094/10000, Prediction Accuracy = 65.28846153846153%, Loss = 0.007467567884864716
Epoch: 5094, Batch Gradient Norm: 4.319626070345324
Epoch: 5094, Batch Gradient Norm after: 4.319626070345324
Epoch 5095/10000, Prediction Accuracy = 65.16923076923078%, Loss = 0.0075248772135147685
Epoch: 5095, Batch Gradient Norm: 4.276769395217417
Epoch: 5095, Batch Gradient Norm after: 4.276769395217417
Epoch 5096/10000, Prediction Accuracy = 64.27307692307693%, Loss = 0.007587902785207217
Epoch: 5096, Batch Gradient Norm: 4.72715160898331
Epoch: 5096, Batch Gradient Norm after: 4.72715160898331
Epoch 5097/10000, Prediction Accuracy = 64.30384615384615%, Loss = 0.007861056329252629
Epoch: 5097, Batch Gradient Norm: 4.644790109689229
Epoch: 5097, Batch Gradient Norm after: 4.644790109689229
Epoch 5098/10000, Prediction Accuracy = 64.24615384615385%, Loss = 0.0078561447489147
Epoch: 5098, Batch Gradient Norm: 4.341034611439422
Epoch: 5098, Batch Gradient Norm after: 4.341034611439422
Epoch 5099/10000, Prediction Accuracy = 64.78846153846153%, Loss = 0.007733194515682184
Epoch: 5099, Batch Gradient Norm: 4.237004885438954
Epoch: 5099, Batch Gradient Norm after: 4.237004885438954
Epoch 5100/10000, Prediction Accuracy = 64.5576923076923%, Loss = 0.007666722656442569
Epoch: 5100, Batch Gradient Norm: 4.464840864356241
Epoch: 5100, Batch Gradient Norm after: 4.464840864356241
Epoch 5101/10000, Prediction Accuracy = 64.41923076923077%, Loss = 0.00781249924777792
Epoch: 5101, Batch Gradient Norm: 4.053184685002136
Epoch: 5101, Batch Gradient Norm after: 4.053184685002136
Epoch 5102/10000, Prediction Accuracy = 64.77307692307693%, Loss = 0.007585351641934652
Epoch: 5102, Batch Gradient Norm: 4.295946847305585
Epoch: 5102, Batch Gradient Norm after: 4.295946847305585
Epoch 5103/10000, Prediction Accuracy = 64.80384615384615%, Loss = 0.007569754567856972
Epoch: 5103, Batch Gradient Norm: 4.446728877194382
Epoch: 5103, Batch Gradient Norm after: 4.446728877194382
Epoch 5104/10000, Prediction Accuracy = 64.44230769230771%, Loss = 0.007740644881358514
Epoch: 5104, Batch Gradient Norm: 4.5260692246067045
Epoch: 5104, Batch Gradient Norm after: 4.5260692246067045
Epoch 5105/10000, Prediction Accuracy = 64.11538461538461%, Loss = 0.007776036249616971
Epoch: 5105, Batch Gradient Norm: 4.302913609777063
Epoch: 5105, Batch Gradient Norm after: 4.302913609777063
Epoch 5106/10000, Prediction Accuracy = 64.97692307692309%, Loss = 0.007540071024917639
Epoch: 5106, Batch Gradient Norm: 4.256292183570311
Epoch: 5106, Batch Gradient Norm after: 4.256292183570311
Epoch 5107/10000, Prediction Accuracy = 64.85000000000001%, Loss = 0.007594421470107941
Epoch: 5107, Batch Gradient Norm: 4.229859583199234
Epoch: 5107, Batch Gradient Norm after: 4.229859583199234
Epoch 5108/10000, Prediction Accuracy = 64.80769230769232%, Loss = 0.007557754333202655
Epoch: 5108, Batch Gradient Norm: 4.551712608983473
Epoch: 5108, Batch Gradient Norm after: 4.551712608983473
Epoch 5109/10000, Prediction Accuracy = 64.49230769230768%, Loss = 0.0077451045553271584
Epoch: 5109, Batch Gradient Norm: 4.793381801113615
Epoch: 5109, Batch Gradient Norm after: 4.793381801113615
Epoch 5110/10000, Prediction Accuracy = 64.57307692307693%, Loss = 0.007811672197511563
Epoch: 5110, Batch Gradient Norm: 4.104170618307845
Epoch: 5110, Batch Gradient Norm after: 4.104170618307845
Epoch 5111/10000, Prediction Accuracy = 65.07307692307691%, Loss = 0.00764012888360482
Epoch: 5111, Batch Gradient Norm: 3.992400426268154
Epoch: 5111, Batch Gradient Norm after: 3.992400426268154
Epoch 5112/10000, Prediction Accuracy = 65.38076923076925%, Loss = 0.00749230169906066
Epoch: 5112, Batch Gradient Norm: 4.230102738835542
Epoch: 5112, Batch Gradient Norm after: 4.230102738835542
Epoch 5113/10000, Prediction Accuracy = 65.26153846153846%, Loss = 0.007589405115980368
Epoch: 5113, Batch Gradient Norm: 4.539037326356208
Epoch: 5113, Batch Gradient Norm after: 4.539037326356208
Epoch 5114/10000, Prediction Accuracy = 64.54615384615384%, Loss = 0.007831959089694114
Epoch: 5114, Batch Gradient Norm: 4.881428935681463
Epoch: 5114, Batch Gradient Norm after: 4.881428935681463
Epoch 5115/10000, Prediction Accuracy = 63.99230769230769%, Loss = 0.007938803997463904
Epoch: 5115, Batch Gradient Norm: 4.7156302238438625
Epoch: 5115, Batch Gradient Norm after: 4.7156302238438625
Epoch 5116/10000, Prediction Accuracy = 64.6576923076923%, Loss = 0.00780245063539881
Epoch: 5116, Batch Gradient Norm: 4.297000093099702
Epoch: 5116, Batch Gradient Norm after: 4.297000093099702
Epoch 5117/10000, Prediction Accuracy = 65.06153846153846%, Loss = 0.0076890342797224336
Epoch: 5117, Batch Gradient Norm: 4.103705295465689
Epoch: 5117, Batch Gradient Norm after: 4.103705295465689
Epoch 5118/10000, Prediction Accuracy = 65.35384615384613%, Loss = 0.007553429199525943
Epoch: 5118, Batch Gradient Norm: 4.348865300653298
Epoch: 5118, Batch Gradient Norm after: 4.348865300653298
Epoch 5119/10000, Prediction Accuracy = 64.75384615384615%, Loss = 0.007695341088737433
Epoch: 5119, Batch Gradient Norm: 4.258210295672511
Epoch: 5119, Batch Gradient Norm after: 4.258210295672511
Epoch 5120/10000, Prediction Accuracy = 64.91538461538462%, Loss = 0.007645553909242153
Epoch: 5120, Batch Gradient Norm: 3.9609612157923464
Epoch: 5120, Batch Gradient Norm after: 3.9609612157923464
Epoch 5121/10000, Prediction Accuracy = 65.72692307692309%, Loss = 0.007315001737039823
Epoch: 5121, Batch Gradient Norm: 4.41825084460105
Epoch: 5121, Batch Gradient Norm after: 4.41825084460105
Epoch 5122/10000, Prediction Accuracy = 65.50769230769231%, Loss = 0.007451178720937326
Epoch: 5122, Batch Gradient Norm: 4.284309621912877
Epoch: 5122, Batch Gradient Norm after: 4.284309621912877
Epoch 5123/10000, Prediction Accuracy = 65.27692307692307%, Loss = 0.007585420058323787
Epoch: 5123, Batch Gradient Norm: 4.357409569252321
Epoch: 5123, Batch Gradient Norm after: 4.357409569252321
Epoch 5124/10000, Prediction Accuracy = 64.44230769230768%, Loss = 0.007752282759891107
Epoch: 5124, Batch Gradient Norm: 4.118006951237513
Epoch: 5124, Batch Gradient Norm after: 4.118006951237513
Epoch 5125/10000, Prediction Accuracy = 64.6923076923077%, Loss = 0.007508498401595996
Epoch: 5125, Batch Gradient Norm: 3.872532598329513
Epoch: 5125, Batch Gradient Norm after: 3.872532598329513
Epoch 5126/10000, Prediction Accuracy = 65.41153846153847%, Loss = 0.007466633481761584
Epoch: 5126, Batch Gradient Norm: 4.51235024136519
Epoch: 5126, Batch Gradient Norm after: 4.51235024136519
Epoch 5127/10000, Prediction Accuracy = 64.66538461538461%, Loss = 0.007635131693230226
Epoch: 5127, Batch Gradient Norm: 4.107645833978057
Epoch: 5127, Batch Gradient Norm after: 4.107645833978057
Epoch 5128/10000, Prediction Accuracy = 65.13846153846154%, Loss = 0.007433181843505456
Epoch: 5128, Batch Gradient Norm: 3.808333795946125
Epoch: 5128, Batch Gradient Norm after: 3.808333795946125
Epoch 5129/10000, Prediction Accuracy = 65.39615384615385%, Loss = 0.007414145574260216
Epoch: 5129, Batch Gradient Norm: 4.200517347452441
Epoch: 5129, Batch Gradient Norm after: 4.200517347452441
Epoch 5130/10000, Prediction Accuracy = 64.86923076923077%, Loss = 0.007428139663086488
Epoch: 5130, Batch Gradient Norm: 4.687253507740761
Epoch: 5130, Batch Gradient Norm after: 4.687253507740761
Epoch 5131/10000, Prediction Accuracy = 64.3076923076923%, Loss = 0.007773149185455763
Epoch: 5131, Batch Gradient Norm: 4.3356870538676375
Epoch: 5131, Batch Gradient Norm after: 4.3356870538676375
Epoch 5132/10000, Prediction Accuracy = 65.08461538461538%, Loss = 0.007582020910026936
Epoch: 5132, Batch Gradient Norm: 3.695070194266366
Epoch: 5132, Batch Gradient Norm after: 3.695070194266366
Epoch 5133/10000, Prediction Accuracy = 65.48461538461538%, Loss = 0.007247546472801612
Epoch: 5133, Batch Gradient Norm: 4.277786057848076
Epoch: 5133, Batch Gradient Norm after: 4.277786057848076
Epoch 5134/10000, Prediction Accuracy = 64.95384615384616%, Loss = 0.007587767958354492
Epoch: 5134, Batch Gradient Norm: 4.541077341010331
Epoch: 5134, Batch Gradient Norm after: 4.541077341010331
Epoch 5135/10000, Prediction Accuracy = 64.08461538461538%, Loss = 0.007815674520455874
Epoch: 5135, Batch Gradient Norm: 4.29556484032688
Epoch: 5135, Batch Gradient Norm after: 4.29556484032688
Epoch 5136/10000, Prediction Accuracy = 65.02307692307693%, Loss = 0.0075964853167533875
Epoch: 5136, Batch Gradient Norm: 3.9309245568449462
Epoch: 5136, Batch Gradient Norm after: 3.9309245568449462
Epoch 5137/10000, Prediction Accuracy = 64.88846153846154%, Loss = 0.007556305875858435
Epoch: 5137, Batch Gradient Norm: 4.424082165392672
Epoch: 5137, Batch Gradient Norm after: 4.424082165392672
Epoch 5138/10000, Prediction Accuracy = 64.77307692307693%, Loss = 0.0075556106077363855
Epoch: 5138, Batch Gradient Norm: 4.30666534503723
Epoch: 5138, Batch Gradient Norm after: 4.30666534503723
Epoch 5139/10000, Prediction Accuracy = 64.7576923076923%, Loss = 0.007648118413411654
Epoch: 5139, Batch Gradient Norm: 4.271441965097905
Epoch: 5139, Batch Gradient Norm after: 4.271441965097905
Epoch 5140/10000, Prediction Accuracy = 64.78846153846153%, Loss = 0.007661360996560409
Epoch: 5140, Batch Gradient Norm: 4.288791109378879
Epoch: 5140, Batch Gradient Norm after: 4.288791109378879
Epoch 5141/10000, Prediction Accuracy = 65.21538461538464%, Loss = 0.007590362300666479
Epoch: 5141, Batch Gradient Norm: 4.320181444505156
Epoch: 5141, Batch Gradient Norm after: 4.320181444505156
Epoch 5142/10000, Prediction Accuracy = 65.17307692307692%, Loss = 0.007571908179670572
Epoch: 5142, Batch Gradient Norm: 4.38601708415484
Epoch: 5142, Batch Gradient Norm after: 4.38601708415484
Epoch 5143/10000, Prediction Accuracy = 64.93846153846155%, Loss = 0.007634221683614529
Epoch: 5143, Batch Gradient Norm: 3.9829736896262156
Epoch: 5143, Batch Gradient Norm after: 3.9829736896262156
Epoch 5144/10000, Prediction Accuracy = 65.04615384615384%, Loss = 0.007441278188847578
Epoch: 5144, Batch Gradient Norm: 4.028035830231274
Epoch: 5144, Batch Gradient Norm after: 4.028035830231274
Epoch 5145/10000, Prediction Accuracy = 65.39615384615385%, Loss = 0.007391669680006229
Epoch: 5145, Batch Gradient Norm: 4.600067874398807
Epoch: 5145, Batch Gradient Norm after: 4.600067874398807
Epoch 5146/10000, Prediction Accuracy = 64.55384615384615%, Loss = 0.007666000021764865
Epoch: 5146, Batch Gradient Norm: 4.821555435244363
Epoch: 5146, Batch Gradient Norm after: 4.821555435244363
Epoch 5147/10000, Prediction Accuracy = 64.5153846153846%, Loss = 0.007858827172850188
Epoch: 5147, Batch Gradient Norm: 4.084928911462523
Epoch: 5147, Batch Gradient Norm after: 4.084928911462523
Epoch 5148/10000, Prediction Accuracy = 65.57692307692308%, Loss = 0.007409866254490156
Epoch: 5148, Batch Gradient Norm: 4.28629518932057
Epoch: 5148, Batch Gradient Norm after: 4.28629518932057
Epoch 5149/10000, Prediction Accuracy = 65.01923076923077%, Loss = 0.007526287952294717
Epoch: 5149, Batch Gradient Norm: 4.391040241410992
Epoch: 5149, Batch Gradient Norm after: 4.391040241410992
Epoch 5150/10000, Prediction Accuracy = 64.66538461538461%, Loss = 0.007619263783383828
Epoch: 5150, Batch Gradient Norm: 4.679011979530806
Epoch: 5150, Batch Gradient Norm after: 4.679011979530806
Epoch 5151/10000, Prediction Accuracy = 63.93846153846154%, Loss = 0.007881441332686406
Epoch: 5151, Batch Gradient Norm: 4.184102438223432
Epoch: 5151, Batch Gradient Norm after: 4.184102438223432
Epoch 5152/10000, Prediction Accuracy = 65.19615384615385%, Loss = 0.007586090718037807
Epoch: 5152, Batch Gradient Norm: 3.9897370240249215
Epoch: 5152, Batch Gradient Norm after: 3.9897370240249215
Epoch 5153/10000, Prediction Accuracy = 65.11153846153846%, Loss = 0.007482514788325016
Epoch: 5153, Batch Gradient Norm: 4.117920850045172
Epoch: 5153, Batch Gradient Norm after: 4.117920850045172
Epoch 5154/10000, Prediction Accuracy = 64.90769230769232%, Loss = 0.0075235999762438815
Epoch: 5154, Batch Gradient Norm: 4.2117108781168975
Epoch: 5154, Batch Gradient Norm after: 4.2117108781168975
Epoch 5155/10000, Prediction Accuracy = 65.28461538461538%, Loss = 0.00750457001133607
Epoch: 5155, Batch Gradient Norm: 4.285722242192905
Epoch: 5155, Batch Gradient Norm after: 4.285722242192905
Epoch 5156/10000, Prediction Accuracy = 65.07307692307691%, Loss = 0.007557048892172484
Epoch: 5156, Batch Gradient Norm: 4.3492214996174665
Epoch: 5156, Batch Gradient Norm after: 4.3492214996174665
Epoch 5157/10000, Prediction Accuracy = 64.91153846153847%, Loss = 0.0076288427942647384
Epoch: 5157, Batch Gradient Norm: 4.3017753810036625
Epoch: 5157, Batch Gradient Norm after: 4.3017753810036625
Epoch 5158/10000, Prediction Accuracy = 64.61538461538461%, Loss = 0.0074356247026186725
Epoch: 5158, Batch Gradient Norm: 3.981311264894806
Epoch: 5158, Batch Gradient Norm after: 3.981311264894806
Epoch 5159/10000, Prediction Accuracy = 65.05384615384615%, Loss = 0.007415004002933319
Epoch: 5159, Batch Gradient Norm: 3.6225365336012927
Epoch: 5159, Batch Gradient Norm after: 3.6225365336012927
Epoch 5160/10000, Prediction Accuracy = 65.69230769230771%, Loss = 0.007204554186990628
Epoch: 5160, Batch Gradient Norm: 3.860896660748468
Epoch: 5160, Batch Gradient Norm after: 3.860896660748468
Epoch 5161/10000, Prediction Accuracy = 65.66153846153846%, Loss = 0.007248741610405536
Epoch: 5161, Batch Gradient Norm: 4.443567747559091
Epoch: 5161, Batch Gradient Norm after: 4.443567747559091
Epoch 5162/10000, Prediction Accuracy = 65.16538461538461%, Loss = 0.007495145814923139
Epoch: 5162, Batch Gradient Norm: 4.451546900790363
Epoch: 5162, Batch Gradient Norm after: 4.451546900790363
Epoch 5163/10000, Prediction Accuracy = 64.96153846153847%, Loss = 0.00760366556306298
Epoch: 5163, Batch Gradient Norm: 4.4086791689292095
Epoch: 5163, Batch Gradient Norm after: 4.4086791689292095
Epoch 5164/10000, Prediction Accuracy = 64.71923076923078%, Loss = 0.007557311525138525
Epoch: 5164, Batch Gradient Norm: 4.131713634832371
Epoch: 5164, Batch Gradient Norm after: 4.131713634832371
Epoch 5165/10000, Prediction Accuracy = 65.23846153846154%, Loss = 0.007462019029145057
Epoch: 5165, Batch Gradient Norm: 4.405579820462036
Epoch: 5165, Batch Gradient Norm after: 4.405579820462036
Epoch 5166/10000, Prediction Accuracy = 64.97692307692307%, Loss = 0.007607401993412238
Epoch: 5166, Batch Gradient Norm: 4.960215614713187
Epoch: 5166, Batch Gradient Norm after: 4.960215614713187
Epoch 5167/10000, Prediction Accuracy = 63.71153846153845%, Loss = 0.007963460655166553
Epoch: 5167, Batch Gradient Norm: 4.775799991049291
Epoch: 5167, Batch Gradient Norm after: 4.775799991049291
Epoch 5168/10000, Prediction Accuracy = 63.62307692307692%, Loss = 0.007910480472044302
Epoch: 5168, Batch Gradient Norm: 4.4543914464887315
Epoch: 5168, Batch Gradient Norm after: 4.4543914464887315
Epoch 5169/10000, Prediction Accuracy = 64.46153846153848%, Loss = 0.007639961102260993
Epoch: 5169, Batch Gradient Norm: 4.515022116293851
Epoch: 5169, Batch Gradient Norm after: 4.515022116293851
Epoch 5170/10000, Prediction Accuracy = 64.17307692307693%, Loss = 0.007705407217144966
Epoch: 5170, Batch Gradient Norm: 4.510543699494937
Epoch: 5170, Batch Gradient Norm after: 4.510543699494937
Epoch 5171/10000, Prediction Accuracy = 64.9076923076923%, Loss = 0.007705657742917538
Epoch: 5171, Batch Gradient Norm: 4.11084966922771
Epoch: 5171, Batch Gradient Norm after: 4.11084966922771
Epoch 5172/10000, Prediction Accuracy = 65.16538461538462%, Loss = 0.007504485977383761
Epoch: 5172, Batch Gradient Norm: 4.4033217210271225
Epoch: 5172, Batch Gradient Norm after: 4.4033217210271225
Epoch 5173/10000, Prediction Accuracy = 65.01153846153846%, Loss = 0.007581466486534247
Epoch: 5173, Batch Gradient Norm: 3.8833925598512296
Epoch: 5173, Batch Gradient Norm after: 3.8833925598512296
Epoch 5174/10000, Prediction Accuracy = 65.14615384615385%, Loss = 0.0074285951156455735
Epoch: 5174, Batch Gradient Norm: 4.519805316917056
Epoch: 5174, Batch Gradient Norm after: 4.519805316917056
Epoch 5175/10000, Prediction Accuracy = 64.85384615384615%, Loss = 0.0076082275034143375
Epoch: 5175, Batch Gradient Norm: 4.441318488440507
Epoch: 5175, Batch Gradient Norm after: 4.441318488440507
Epoch 5176/10000, Prediction Accuracy = 64.65%, Loss = 0.007666288516842402
Epoch: 5176, Batch Gradient Norm: 4.650249838473896
Epoch: 5176, Batch Gradient Norm after: 4.650249838473896
Epoch 5177/10000, Prediction Accuracy = 64.09615384615384%, Loss = 0.007908441627827974
Epoch: 5177, Batch Gradient Norm: 4.244568060218764
Epoch: 5177, Batch Gradient Norm after: 4.244568060218764
Epoch 5178/10000, Prediction Accuracy = 65.01923076923076%, Loss = 0.00752022357370991
Epoch: 5178, Batch Gradient Norm: 4.374586947448659
Epoch: 5178, Batch Gradient Norm after: 4.374586947448659
Epoch 5179/10000, Prediction Accuracy = 64.66153846153847%, Loss = 0.0076631407898205975
Epoch: 5179, Batch Gradient Norm: 4.120232795071291
Epoch: 5179, Batch Gradient Norm after: 4.120232795071291
Epoch 5180/10000, Prediction Accuracy = 65.35%, Loss = 0.007462144900973027
Epoch: 5180, Batch Gradient Norm: 3.9638056555413157
Epoch: 5180, Batch Gradient Norm after: 3.9638056555413157
Epoch 5181/10000, Prediction Accuracy = 65.61538461538461%, Loss = 0.007329896164055054
Epoch: 5181, Batch Gradient Norm: 4.692903374841545
Epoch: 5181, Batch Gradient Norm after: 4.692903374841545
Epoch 5182/10000, Prediction Accuracy = 65.0153846153846%, Loss = 0.007611279053470263
Epoch: 5182, Batch Gradient Norm: 4.602431751290375
Epoch: 5182, Batch Gradient Norm after: 4.602431751290375
Epoch 5183/10000, Prediction Accuracy = 64.74999999999999%, Loss = 0.007709278975828336
Epoch: 5183, Batch Gradient Norm: 4.016987589243008
Epoch: 5183, Batch Gradient Norm after: 4.016987589243008
Epoch 5184/10000, Prediction Accuracy = 65.65%, Loss = 0.007358142532981359
Epoch: 5184, Batch Gradient Norm: 3.8346269354782647
Epoch: 5184, Batch Gradient Norm after: 3.8346269354782647
Epoch 5185/10000, Prediction Accuracy = 65.76923076923077%, Loss = 0.007257737326793945
Epoch: 5185, Batch Gradient Norm: 4.138556266447108
Epoch: 5185, Batch Gradient Norm after: 4.138556266447108
Epoch 5186/10000, Prediction Accuracy = 65.0153846153846%, Loss = 0.007468815749654403
Epoch: 5186, Batch Gradient Norm: 4.309671160544345
Epoch: 5186, Batch Gradient Norm after: 4.309671160544345
Epoch 5187/10000, Prediction Accuracy = 64.96923076923078%, Loss = 0.007602654684048433
Epoch: 5187, Batch Gradient Norm: 4.4548448566615235
Epoch: 5187, Batch Gradient Norm after: 4.4548448566615235
Epoch 5188/10000, Prediction Accuracy = 65.05384615384615%, Loss = 0.0076756775737381894
Epoch: 5188, Batch Gradient Norm: 4.2155416146222775
Epoch: 5188, Batch Gradient Norm after: 4.2155416146222775
Epoch 5189/10000, Prediction Accuracy = 64.71153846153847%, Loss = 0.007577920260910804
Epoch: 5189, Batch Gradient Norm: 3.94905289608343
Epoch: 5189, Batch Gradient Norm after: 3.94905289608343
Epoch 5190/10000, Prediction Accuracy = 65.51923076923077%, Loss = 0.007415295936740362
Epoch: 5190, Batch Gradient Norm: 4.196100859065492
Epoch: 5190, Batch Gradient Norm after: 4.196100859065492
Epoch 5191/10000, Prediction Accuracy = 64.43846153846154%, Loss = 0.007570759608195378
Epoch: 5191, Batch Gradient Norm: 3.8483567734606843
Epoch: 5191, Batch Gradient Norm after: 3.8483567734606843
Epoch 5192/10000, Prediction Accuracy = 65.11923076923077%, Loss = 0.007367853755847766
Epoch: 5192, Batch Gradient Norm: 3.955861589899436
Epoch: 5192, Batch Gradient Norm after: 3.955861589899436
Epoch 5193/10000, Prediction Accuracy = 65.7576923076923%, Loss = 0.007276390715000721
Epoch: 5193, Batch Gradient Norm: 4.309538168311668
Epoch: 5193, Batch Gradient Norm after: 4.309538168311668
Epoch 5194/10000, Prediction Accuracy = 64.99615384615385%, Loss = 0.007494235769487345
Epoch: 5194, Batch Gradient Norm: 4.393211499987687
Epoch: 5194, Batch Gradient Norm after: 4.393211499987687
Epoch 5195/10000, Prediction Accuracy = 64.99230769230769%, Loss = 0.007548309647693084
Epoch: 5195, Batch Gradient Norm: 4.028042755140517
Epoch: 5195, Batch Gradient Norm after: 4.028042755140517
Epoch 5196/10000, Prediction Accuracy = 64.89615384615387%, Loss = 0.0074955875483842995
Epoch: 5196, Batch Gradient Norm: 4.551829161802901
Epoch: 5196, Batch Gradient Norm after: 4.551829161802901
Epoch 5197/10000, Prediction Accuracy = 64.45769230769233%, Loss = 0.007630691720316043
Epoch: 5197, Batch Gradient Norm: 4.3843353328474155
Epoch: 5197, Batch Gradient Norm after: 4.3843353328474155
Epoch 5198/10000, Prediction Accuracy = 64.75384615384615%, Loss = 0.007604112239697805
Epoch: 5198, Batch Gradient Norm: 4.514795900807189
Epoch: 5198, Batch Gradient Norm after: 4.514795900807189
Epoch 5199/10000, Prediction Accuracy = 64.78461538461539%, Loss = 0.0075962120810380345
Epoch: 5199, Batch Gradient Norm: 4.685722929136542
Epoch: 5199, Batch Gradient Norm after: 4.685722929136542
Epoch 5200/10000, Prediction Accuracy = 64.33076923076922%, Loss = 0.00775804016022728
Epoch: 5200, Batch Gradient Norm: 4.5296689493088325
Epoch: 5200, Batch Gradient Norm after: 4.5296689493088325
Epoch 5201/10000, Prediction Accuracy = 64.78461538461539%, Loss = 0.0076786039325480275
Epoch: 5201, Batch Gradient Norm: 4.369190295585688
Epoch: 5201, Batch Gradient Norm after: 4.369190295585688
Epoch 5202/10000, Prediction Accuracy = 65.03461538461539%, Loss = 0.007600427891772527
Epoch: 5202, Batch Gradient Norm: 3.9212278720315057
Epoch: 5202, Batch Gradient Norm after: 3.9212278720315057
Epoch 5203/10000, Prediction Accuracy = 65.53846153846153%, Loss = 0.007421518210321665
Epoch: 5203, Batch Gradient Norm: 4.261220308871706
Epoch: 5203, Batch Gradient Norm after: 4.261220308871706
Epoch 5204/10000, Prediction Accuracy = 65.08461538461539%, Loss = 0.0075494029129353855
Epoch: 5204, Batch Gradient Norm: 4.023872906988447
Epoch: 5204, Batch Gradient Norm after: 4.023872906988447
Epoch 5205/10000, Prediction Accuracy = 65.12692307692308%, Loss = 0.007518124659187519
Epoch: 5205, Batch Gradient Norm: 3.955206671655952
Epoch: 5205, Batch Gradient Norm after: 3.955206671655952
Epoch 5206/10000, Prediction Accuracy = 65.68846153846155%, Loss = 0.007335627988840525
Epoch: 5206, Batch Gradient Norm: 4.041927807376877
Epoch: 5206, Batch Gradient Norm after: 4.041927807376877
Epoch 5207/10000, Prediction Accuracy = 65.52692307692307%, Loss = 0.007374941980322966
Epoch: 5207, Batch Gradient Norm: 3.9984915496587017
Epoch: 5207, Batch Gradient Norm after: 3.9984915496587017
Epoch 5208/10000, Prediction Accuracy = 65.4346153846154%, Loss = 0.007470929350417394
Epoch: 5208, Batch Gradient Norm: 4.0899909600291835
Epoch: 5208, Batch Gradient Norm after: 4.0899909600291835
Epoch 5209/10000, Prediction Accuracy = 65.48846153846154%, Loss = 0.007383687242579002
Epoch: 5209, Batch Gradient Norm: 4.289268801823478
Epoch: 5209, Batch Gradient Norm after: 4.289268801823478
Epoch 5210/10000, Prediction Accuracy = 65.3923076923077%, Loss = 0.007472899026022508
Epoch: 5210, Batch Gradient Norm: 4.287521278617214
Epoch: 5210, Batch Gradient Norm after: 4.287521278617214
Epoch 5211/10000, Prediction Accuracy = 65.38461538461537%, Loss = 0.00751703827140423
Epoch: 5211, Batch Gradient Norm: 4.393115299717723
Epoch: 5211, Batch Gradient Norm after: 4.393115299717723
Epoch 5212/10000, Prediction Accuracy = 65.10384615384613%, Loss = 0.007604535633268265
Epoch: 5212, Batch Gradient Norm: 4.146460002273033
Epoch: 5212, Batch Gradient Norm after: 4.146460002273033
Epoch 5213/10000, Prediction Accuracy = 64.88846153846154%, Loss = 0.007492208423522802
Epoch: 5213, Batch Gradient Norm: 4.223402200043365
Epoch: 5213, Batch Gradient Norm after: 4.223402200043365
Epoch 5214/10000, Prediction Accuracy = 65.11153846153846%, Loss = 0.0074718565178605225
Epoch: 5214, Batch Gradient Norm: 4.491620557257773
Epoch: 5214, Batch Gradient Norm after: 4.491620557257773
Epoch 5215/10000, Prediction Accuracy = 64.91153846153847%, Loss = 0.007606526120350911
Epoch: 5215, Batch Gradient Norm: 4.275041897008898
Epoch: 5215, Batch Gradient Norm after: 4.275041897008898
Epoch 5216/10000, Prediction Accuracy = 65.11538461538461%, Loss = 0.007455035650099699
Epoch: 5216, Batch Gradient Norm: 3.9716909586324496
Epoch: 5216, Batch Gradient Norm after: 3.9716909586324496
Epoch 5217/10000, Prediction Accuracy = 66.1423076923077%, Loss = 0.007296736602886365
Epoch: 5217, Batch Gradient Norm: 4.433653407465171
Epoch: 5217, Batch Gradient Norm after: 4.433653407465171
Epoch 5218/10000, Prediction Accuracy = 64.72692307692307%, Loss = 0.007587953578107632
Epoch: 5218, Batch Gradient Norm: 4.674111389907262
Epoch: 5218, Batch Gradient Norm after: 4.674111389907262
Epoch 5219/10000, Prediction Accuracy = 64.57692307692308%, Loss = 0.007715618022932456
Epoch: 5219, Batch Gradient Norm: 4.694980928325174
Epoch: 5219, Batch Gradient Norm after: 4.694980928325174
Epoch 5220/10000, Prediction Accuracy = 64.75769230769232%, Loss = 0.007712627331224771
Epoch: 5220, Batch Gradient Norm: 4.951308007851382
Epoch: 5220, Batch Gradient Norm after: 4.951308007851382
Epoch 5221/10000, Prediction Accuracy = 63.97692307692307%, Loss = 0.007874207320408179
Epoch: 5221, Batch Gradient Norm: 4.605399695878513
Epoch: 5221, Batch Gradient Norm after: 4.605399695878513
Epoch 5222/10000, Prediction Accuracy = 64.5%, Loss = 0.007734878740918178
Epoch: 5222, Batch Gradient Norm: 4.23800386691284
Epoch: 5222, Batch Gradient Norm after: 4.23800386691284
Epoch 5223/10000, Prediction Accuracy = 65.0576923076923%, Loss = 0.007512112327206593
Epoch: 5223, Batch Gradient Norm: 4.122311033492566
Epoch: 5223, Batch Gradient Norm after: 4.122311033492566
Epoch 5224/10000, Prediction Accuracy = 65.52307692307691%, Loss = 0.007469732206887924
Epoch: 5224, Batch Gradient Norm: 4.177268223722565
Epoch: 5224, Batch Gradient Norm after: 4.177268223722565
Epoch 5225/10000, Prediction Accuracy = 65.41538461538462%, Loss = 0.00744645487373838
Epoch: 5225, Batch Gradient Norm: 4.145191960800143
Epoch: 5225, Batch Gradient Norm after: 4.145191960800143
Epoch 5226/10000, Prediction Accuracy = 65.60384615384615%, Loss = 0.007357103785929771
Epoch: 5226, Batch Gradient Norm: 4.147646064498648
Epoch: 5226, Batch Gradient Norm after: 4.147646064498648
Epoch 5227/10000, Prediction Accuracy = 65.37692307692306%, Loss = 0.007409619418187783
Epoch: 5227, Batch Gradient Norm: 3.9279077975275665
Epoch: 5227, Batch Gradient Norm after: 3.9279077975275665
Epoch 5228/10000, Prediction Accuracy = 65.2%, Loss = 0.007363122350607927
Epoch: 5228, Batch Gradient Norm: 3.8938117812239565
Epoch: 5228, Batch Gradient Norm after: 3.8938117812239565
Epoch 5229/10000, Prediction Accuracy = 65.56923076923077%, Loss = 0.007321729862059538
Epoch: 5229, Batch Gradient Norm: 4.272255005843466
Epoch: 5229, Batch Gradient Norm after: 4.272255005843466
Epoch 5230/10000, Prediction Accuracy = 64.66153846153847%, Loss = 0.007491580138985927
Epoch: 5230, Batch Gradient Norm: 4.200660805123928
Epoch: 5230, Batch Gradient Norm after: 4.200660805123928
Epoch 5231/10000, Prediction Accuracy = 65.13846153846151%, Loss = 0.007465152643047846
Epoch: 5231, Batch Gradient Norm: 4.711688157741338
Epoch: 5231, Batch Gradient Norm after: 4.711688157741338
Epoch 5232/10000, Prediction Accuracy = 64.43846153846152%, Loss = 0.007806218981456298
Epoch: 5232, Batch Gradient Norm: 4.2640819839704704
Epoch: 5232, Batch Gradient Norm after: 4.2640819839704704
Epoch 5233/10000, Prediction Accuracy = 64.93076923076924%, Loss = 0.007622617547615216
Epoch: 5233, Batch Gradient Norm: 4.145435021626246
Epoch: 5233, Batch Gradient Norm after: 4.145435021626246
Epoch 5234/10000, Prediction Accuracy = 64.77307692307691%, Loss = 0.007550300636257117
Epoch: 5234, Batch Gradient Norm: 4.139866762531368
Epoch: 5234, Batch Gradient Norm after: 4.139866762531368
Epoch 5235/10000, Prediction Accuracy = 64.98846153846154%, Loss = 0.007485557705737078
Epoch: 5235, Batch Gradient Norm: 4.610572401993209
Epoch: 5235, Batch Gradient Norm after: 4.610572401993209
Epoch 5236/10000, Prediction Accuracy = 64.46923076923078%, Loss = 0.007641621507131136
Epoch: 5236, Batch Gradient Norm: 4.802878949336028
Epoch: 5236, Batch Gradient Norm after: 4.802878949336028
Epoch 5237/10000, Prediction Accuracy = 64.35%, Loss = 0.007758744920675571
Epoch: 5237, Batch Gradient Norm: 4.608682496231138
Epoch: 5237, Batch Gradient Norm after: 4.608682496231138
Epoch 5238/10000, Prediction Accuracy = 64.40384615384616%, Loss = 0.0077344004709560136
Epoch: 5238, Batch Gradient Norm: 4.566142116037913
Epoch: 5238, Batch Gradient Norm after: 4.566142116037913
Epoch 5239/10000, Prediction Accuracy = 64.27307692307693%, Loss = 0.007812175469902845
Epoch: 5239, Batch Gradient Norm: 4.217538080675334
Epoch: 5239, Batch Gradient Norm after: 4.217538080675334
Epoch 5240/10000, Prediction Accuracy = 64.53846153846153%, Loss = 0.0077289559591848115
Epoch: 5240, Batch Gradient Norm: 4.235458075421842
Epoch: 5240, Batch Gradient Norm after: 4.235458075421842
Epoch 5241/10000, Prediction Accuracy = 64.99615384615385%, Loss = 0.007559745393406887
Epoch: 5241, Batch Gradient Norm: 4.064266492422811
Epoch: 5241, Batch Gradient Norm after: 4.064266492422811
Epoch 5242/10000, Prediction Accuracy = 65.45384615384616%, Loss = 0.007476259094591324
Epoch: 5242, Batch Gradient Norm: 4.362831281186373
Epoch: 5242, Batch Gradient Norm after: 4.362831281186373
Epoch 5243/10000, Prediction Accuracy = 64.93846153846155%, Loss = 0.007633754410422766
Epoch: 5243, Batch Gradient Norm: 4.642779055574757
Epoch: 5243, Batch Gradient Norm after: 4.642779055574757
Epoch 5244/10000, Prediction Accuracy = 64.43846153846154%, Loss = 0.00779835800998486
Epoch: 5244, Batch Gradient Norm: 3.9173797945800284
Epoch: 5244, Batch Gradient Norm after: 3.9173797945800284
Epoch 5245/10000, Prediction Accuracy = 65.13076923076923%, Loss = 0.007371069218676824
Epoch: 5245, Batch Gradient Norm: 4.223866448245601
Epoch: 5245, Batch Gradient Norm after: 4.223866448245601
Epoch 5246/10000, Prediction Accuracy = 65.48461538461537%, Loss = 0.007388001092924521
Epoch: 5246, Batch Gradient Norm: 3.987582968137566
Epoch: 5246, Batch Gradient Norm after: 3.987582968137566
Epoch 5247/10000, Prediction Accuracy = 65.61923076923077%, Loss = 0.007339190906630113
Epoch: 5247, Batch Gradient Norm: 4.202406929519022
Epoch: 5247, Batch Gradient Norm after: 4.202406929519022
Epoch 5248/10000, Prediction Accuracy = 64.94999999999999%, Loss = 0.007430919804252111
Epoch: 5248, Batch Gradient Norm: 4.3005534847916405
Epoch: 5248, Batch Gradient Norm after: 4.3005534847916405
Epoch 5249/10000, Prediction Accuracy = 64.97692307692307%, Loss = 0.007533126259939029
Epoch: 5249, Batch Gradient Norm: 4.155864241653919
Epoch: 5249, Batch Gradient Norm after: 4.155864241653919
Epoch 5250/10000, Prediction Accuracy = 65.27692307692308%, Loss = 0.007451886203713142
Epoch: 5250, Batch Gradient Norm: 4.572228636887563
Epoch: 5250, Batch Gradient Norm after: 4.572228636887563
Epoch 5251/10000, Prediction Accuracy = 64.86923076923075%, Loss = 0.00762282139979876
Epoch: 5251, Batch Gradient Norm: 4.59520413343251
Epoch: 5251, Batch Gradient Norm after: 4.59520413343251
Epoch 5252/10000, Prediction Accuracy = 64.56153846153846%, Loss = 0.007682277391163202
Epoch: 5252, Batch Gradient Norm: 4.347658936839871
Epoch: 5252, Batch Gradient Norm after: 4.347658936839871
Epoch 5253/10000, Prediction Accuracy = 64.68076923076924%, Loss = 0.007532200238739069
Epoch: 5253, Batch Gradient Norm: 4.327001954324002
Epoch: 5253, Batch Gradient Norm after: 4.327001954324002
Epoch 5254/10000, Prediction Accuracy = 65.05384615384615%, Loss = 0.007581581289951618
Epoch: 5254, Batch Gradient Norm: 4.493301890254229
Epoch: 5254, Batch Gradient Norm after: 4.493301890254229
Epoch 5255/10000, Prediction Accuracy = 64.60769230769232%, Loss = 0.007694336263319621
Epoch: 5255, Batch Gradient Norm: 4.468026108260553
Epoch: 5255, Batch Gradient Norm after: 4.468026108260553
Epoch 5256/10000, Prediction Accuracy = 64.46153846153845%, Loss = 0.007635278412355826
Epoch: 5256, Batch Gradient Norm: 4.5939142922163825
Epoch: 5256, Batch Gradient Norm after: 4.5939142922163825
Epoch 5257/10000, Prediction Accuracy = 64.8076923076923%, Loss = 0.007765719810357461
Epoch: 5257, Batch Gradient Norm: 4.525903489682881
Epoch: 5257, Batch Gradient Norm after: 4.525903489682881
Epoch 5258/10000, Prediction Accuracy = 64.9076923076923%, Loss = 0.007735162436102445
Epoch: 5258, Batch Gradient Norm: 4.368911692146848
Epoch: 5258, Batch Gradient Norm after: 4.368911692146848
Epoch 5259/10000, Prediction Accuracy = 64.9576923076923%, Loss = 0.007651639779886374
Epoch: 5259, Batch Gradient Norm: 4.253207323340398
Epoch: 5259, Batch Gradient Norm after: 4.253207323340398
Epoch 5260/10000, Prediction Accuracy = 64.67307692307693%, Loss = 0.0076359603195809405
Epoch: 5260, Batch Gradient Norm: 4.076979201854134
Epoch: 5260, Batch Gradient Norm after: 4.076979201854134
Epoch 5261/10000, Prediction Accuracy = 64.8923076923077%, Loss = 0.0075636118865356995
Epoch: 5261, Batch Gradient Norm: 4.102677114293271
Epoch: 5261, Batch Gradient Norm after: 4.102677114293271
Epoch 5262/10000, Prediction Accuracy = 65.03076923076924%, Loss = 0.007471216842532158
Epoch: 5262, Batch Gradient Norm: 3.9138997190937523
Epoch: 5262, Batch Gradient Norm after: 3.9138997190937523
Epoch 5263/10000, Prediction Accuracy = 64.8923076923077%, Loss = 0.007491125510289119
Epoch: 5263, Batch Gradient Norm: 4.216338068240508
Epoch: 5263, Batch Gradient Norm after: 4.216338068240508
Epoch 5264/10000, Prediction Accuracy = 64.96153846153847%, Loss = 0.007474339638765042
Epoch: 5264, Batch Gradient Norm: 4.633927557093354
Epoch: 5264, Batch Gradient Norm after: 4.633927557093354
Epoch 5265/10000, Prediction Accuracy = 64.84615384615384%, Loss = 0.007630994471792991
Epoch: 5265, Batch Gradient Norm: 4.164345049955528
Epoch: 5265, Batch Gradient Norm after: 4.164345049955528
Epoch 5266/10000, Prediction Accuracy = 65.08461538461539%, Loss = 0.007385931085222042
Epoch: 5266, Batch Gradient Norm: 4.205874574596124
Epoch: 5266, Batch Gradient Norm after: 4.205874574596124
Epoch 5267/10000, Prediction Accuracy = 65.12692307692308%, Loss = 0.007462267369891589
Epoch: 5267, Batch Gradient Norm: 4.107329985184264
Epoch: 5267, Batch Gradient Norm after: 4.107329985184264
Epoch 5268/10000, Prediction Accuracy = 65.31153846153845%, Loss = 0.007379805633368401
Epoch: 5268, Batch Gradient Norm: 4.477410115181778
Epoch: 5268, Batch Gradient Norm after: 4.477410115181778
Epoch 5269/10000, Prediction Accuracy = 64.78846153846153%, Loss = 0.007706130496584452
Epoch: 5269, Batch Gradient Norm: 4.140297028831781
Epoch: 5269, Batch Gradient Norm after: 4.140297028831781
Epoch 5270/10000, Prediction Accuracy = 65.31538461538462%, Loss = 0.007404714822769165
Epoch: 5270, Batch Gradient Norm: 4.676014736098835
Epoch: 5270, Batch Gradient Norm after: 4.676014736098835
Epoch 5271/10000, Prediction Accuracy = 64.48076923076923%, Loss = 0.0077890552437076205
Epoch: 5271, Batch Gradient Norm: 4.213542058763995
Epoch: 5271, Batch Gradient Norm after: 4.213542058763995
Epoch 5272/10000, Prediction Accuracy = 65.41923076923078%, Loss = 0.007395229517267301
Epoch: 5272, Batch Gradient Norm: 4.317705133932859
Epoch: 5272, Batch Gradient Norm after: 4.317705133932859
Epoch 5273/10000, Prediction Accuracy = 65.16538461538462%, Loss = 0.00749381438184243
Epoch: 5273, Batch Gradient Norm: 4.300149600229184
Epoch: 5273, Batch Gradient Norm after: 4.300149600229184
Epoch 5274/10000, Prediction Accuracy = 65.10384615384616%, Loss = 0.0075196731262482126
Epoch: 5274, Batch Gradient Norm: 4.372572913581573
Epoch: 5274, Batch Gradient Norm after: 4.372572913581573
Epoch 5275/10000, Prediction Accuracy = 65.26153846153846%, Loss = 0.007582296868069814
Epoch: 5275, Batch Gradient Norm: 4.367752636066997
Epoch: 5275, Batch Gradient Norm after: 4.367752636066997
Epoch 5276/10000, Prediction Accuracy = 64.99615384615386%, Loss = 0.007571566061904797
Epoch: 5276, Batch Gradient Norm: 4.15834961293154
Epoch: 5276, Batch Gradient Norm after: 4.15834961293154
Epoch 5277/10000, Prediction Accuracy = 65.02692307692308%, Loss = 0.007450917735695839
Epoch: 5277, Batch Gradient Norm: 4.358120032706903
Epoch: 5277, Batch Gradient Norm after: 4.358120032706903
Epoch 5278/10000, Prediction Accuracy = 65.03846153846155%, Loss = 0.007386916424505985
Epoch: 5278, Batch Gradient Norm: 4.1732813091194805
Epoch: 5278, Batch Gradient Norm after: 4.1732813091194805
Epoch 5279/10000, Prediction Accuracy = 65.47307692307693%, Loss = 0.007357863888431054
Epoch: 5279, Batch Gradient Norm: 4.3018491196246655
Epoch: 5279, Batch Gradient Norm after: 4.3018491196246655
Epoch 5280/10000, Prediction Accuracy = 65.19230769230771%, Loss = 0.007475034333765507
Epoch: 5280, Batch Gradient Norm: 4.328843288543989
Epoch: 5280, Batch Gradient Norm after: 4.328843288543989
Epoch 5281/10000, Prediction Accuracy = 65.21153846153845%, Loss = 0.007443043510787762
Epoch: 5281, Batch Gradient Norm: 4.6583487388158185
Epoch: 5281, Batch Gradient Norm after: 4.6583487388158185
Epoch 5282/10000, Prediction Accuracy = 64.23846153846154%, Loss = 0.0077207607145492844
Epoch: 5282, Batch Gradient Norm: 4.399753877656792
Epoch: 5282, Batch Gradient Norm after: 4.399753877656792
Epoch 5283/10000, Prediction Accuracy = 64.79615384615384%, Loss = 0.0075856131286575245
Epoch: 5283, Batch Gradient Norm: 4.622774459487892
Epoch: 5283, Batch Gradient Norm after: 4.622774459487892
Epoch 5284/10000, Prediction Accuracy = 64.61923076923077%, Loss = 0.00761389212969404
Epoch: 5284, Batch Gradient Norm: 4.258451409238639
Epoch: 5284, Batch Gradient Norm after: 4.258451409238639
Epoch 5285/10000, Prediction Accuracy = 65.26153846153846%, Loss = 0.0075568682872332055
Epoch: 5285, Batch Gradient Norm: 4.249955882400643
Epoch: 5285, Batch Gradient Norm after: 4.249955882400643
Epoch 5286/10000, Prediction Accuracy = 65.42307692307692%, Loss = 0.007440987258003308
Epoch: 5286, Batch Gradient Norm: 4.294178138633488
Epoch: 5286, Batch Gradient Norm after: 4.294178138633488
Epoch 5287/10000, Prediction Accuracy = 65.07692307692308%, Loss = 0.007563352405738372
Epoch: 5287, Batch Gradient Norm: 4.086481256993183
Epoch: 5287, Batch Gradient Norm after: 4.086481256993183
Epoch 5288/10000, Prediction Accuracy = 65.3923076923077%, Loss = 0.0073957005873895604
Epoch: 5288, Batch Gradient Norm: 4.150947135249674
Epoch: 5288, Batch Gradient Norm after: 4.150947135249674
Epoch 5289/10000, Prediction Accuracy = 64.6576923076923%, Loss = 0.007479601682951817
Epoch: 5289, Batch Gradient Norm: 3.95361034552281
Epoch: 5289, Batch Gradient Norm after: 3.95361034552281
Epoch 5290/10000, Prediction Accuracy = 65.72692307692309%, Loss = 0.007271318087497583
Epoch: 5290, Batch Gradient Norm: 4.468545833895651
Epoch: 5290, Batch Gradient Norm after: 4.468545833895651
Epoch 5291/10000, Prediction Accuracy = 65.06153846153846%, Loss = 0.007656962574961094
Epoch: 5291, Batch Gradient Norm: 4.558736708855945
Epoch: 5291, Batch Gradient Norm after: 4.558736708855945
Epoch 5292/10000, Prediction Accuracy = 65.10384615384615%, Loss = 0.007623101047311838
Epoch: 5292, Batch Gradient Norm: 4.834947374174089
Epoch: 5292, Batch Gradient Norm after: 4.834947374174089
Epoch 5293/10000, Prediction Accuracy = 64.21923076923078%, Loss = 0.007864545099437237
Epoch: 5293, Batch Gradient Norm: 4.191301716578181
Epoch: 5293, Batch Gradient Norm after: 4.191301716578181
Epoch 5294/10000, Prediction Accuracy = 65.30769230769229%, Loss = 0.0073897108220710205
Epoch: 5294, Batch Gradient Norm: 4.397708364160117
Epoch: 5294, Batch Gradient Norm after: 4.397708364160117
Epoch 5295/10000, Prediction Accuracy = 64.93076923076923%, Loss = 0.00756872187440212
Epoch: 5295, Batch Gradient Norm: 4.614763064451548
Epoch: 5295, Batch Gradient Norm after: 4.614763064451548
Epoch 5296/10000, Prediction Accuracy = 64.5076923076923%, Loss = 0.007703371883298342
Epoch: 5296, Batch Gradient Norm: 4.210288454952548
Epoch: 5296, Batch Gradient Norm after: 4.210288454952548
Epoch 5297/10000, Prediction Accuracy = 65.28846153846153%, Loss = 0.00745558778110605
Epoch: 5297, Batch Gradient Norm: 4.711777136035394
Epoch: 5297, Batch Gradient Norm after: 4.711777136035394
Epoch 5298/10000, Prediction Accuracy = 64.44615384615383%, Loss = 0.0077639278740837024
Epoch: 5298, Batch Gradient Norm: 4.292624767510282
Epoch: 5298, Batch Gradient Norm after: 4.292624767510282
Epoch 5299/10000, Prediction Accuracy = 64.85%, Loss = 0.007531108657041421
Epoch: 5299, Batch Gradient Norm: 4.491765168560322
Epoch: 5299, Batch Gradient Norm after: 4.491765168560322
Epoch 5300/10000, Prediction Accuracy = 65.34615384615384%, Loss = 0.00752896901506644
Epoch: 5300, Batch Gradient Norm: 4.503840472568982
Epoch: 5300, Batch Gradient Norm after: 4.503840472568982
Epoch 5301/10000, Prediction Accuracy = 65.17307692307692%, Loss = 0.007597212787144459
Epoch: 5301, Batch Gradient Norm: 4.240461934734124
Epoch: 5301, Batch Gradient Norm after: 4.240461934734124
Epoch 5302/10000, Prediction Accuracy = 65.25%, Loss = 0.007476695598318026
Epoch: 5302, Batch Gradient Norm: 4.390038167837599
Epoch: 5302, Batch Gradient Norm after: 4.390038167837599
Epoch 5303/10000, Prediction Accuracy = 65.19615384615385%, Loss = 0.0075153741412437875
Epoch: 5303, Batch Gradient Norm: 4.515655395195331
Epoch: 5303, Batch Gradient Norm after: 4.515655395195331
Epoch 5304/10000, Prediction Accuracy = 64.3%, Loss = 0.007645338272246031
Epoch: 5304, Batch Gradient Norm: 4.597070647684885
Epoch: 5304, Batch Gradient Norm after: 4.597070647684885
Epoch 5305/10000, Prediction Accuracy = 64.67307692307692%, Loss = 0.007734765406124867
Epoch: 5305, Batch Gradient Norm: 4.25242410312724
Epoch: 5305, Batch Gradient Norm after: 4.25242410312724
Epoch 5306/10000, Prediction Accuracy = 64.88461538461539%, Loss = 0.007607401133729861
Epoch: 5306, Batch Gradient Norm: 4.297344987450119
Epoch: 5306, Batch Gradient Norm after: 4.297344987450119
Epoch 5307/10000, Prediction Accuracy = 64.94999999999999%, Loss = 0.007549206976993726
Epoch: 5307, Batch Gradient Norm: 4.460144317409837
Epoch: 5307, Batch Gradient Norm after: 4.460144317409837
Epoch 5308/10000, Prediction Accuracy = 64.07692307692308%, Loss = 0.007769017229573085
Epoch: 5308, Batch Gradient Norm: 3.977408671878656
Epoch: 5308, Batch Gradient Norm after: 3.977408671878656
Epoch 5309/10000, Prediction Accuracy = 65.1923076923077%, Loss = 0.00746373556411037
Epoch: 5309, Batch Gradient Norm: 4.12206141049974
Epoch: 5309, Batch Gradient Norm after: 4.12206141049974
Epoch 5310/10000, Prediction Accuracy = 65.23461538461538%, Loss = 0.007527602514108786
Epoch: 5310, Batch Gradient Norm: 4.222578021671581
Epoch: 5310, Batch Gradient Norm after: 4.222578021671581
Epoch 5311/10000, Prediction Accuracy = 65.39999999999999%, Loss = 0.007553886443089981
Epoch: 5311, Batch Gradient Norm: 4.135594505101499
Epoch: 5311, Batch Gradient Norm after: 4.135594505101499
Epoch 5312/10000, Prediction Accuracy = 65.4076923076923%, Loss = 0.007474724812289843
Epoch: 5312, Batch Gradient Norm: 4.032344802568779
Epoch: 5312, Batch Gradient Norm after: 4.032344802568779
Epoch 5313/10000, Prediction Accuracy = 65.33846153846154%, Loss = 0.007400512552032104
Epoch: 5313, Batch Gradient Norm: 4.34362953456674
Epoch: 5313, Batch Gradient Norm after: 4.34362953456674
Epoch 5314/10000, Prediction Accuracy = 65.02307692307691%, Loss = 0.007507931978370135
Epoch: 5314, Batch Gradient Norm: 4.191015495314575
Epoch: 5314, Batch Gradient Norm after: 4.191015495314575
Epoch 5315/10000, Prediction Accuracy = 65.21538461538461%, Loss = 0.007446290960965248
Epoch: 5315, Batch Gradient Norm: 4.587902194369109
Epoch: 5315, Batch Gradient Norm after: 4.587902194369109
Epoch 5316/10000, Prediction Accuracy = 64.53461538461539%, Loss = 0.007586066109629778
Epoch: 5316, Batch Gradient Norm: 4.0400509174568
Epoch: 5316, Batch Gradient Norm after: 4.0400509174568
Epoch 5317/10000, Prediction Accuracy = 65.63076923076923%, Loss = 0.00733796191903261
Epoch: 5317, Batch Gradient Norm: 4.671073316796861
Epoch: 5317, Batch Gradient Norm after: 4.671073316796861
Epoch 5318/10000, Prediction Accuracy = 64.85%, Loss = 0.007609817450149701
Epoch: 5318, Batch Gradient Norm: 4.907711742194409
Epoch: 5318, Batch Gradient Norm after: 4.907711742194409
Epoch 5319/10000, Prediction Accuracy = 64.79615384615386%, Loss = 0.007786282588942693
Epoch: 5319, Batch Gradient Norm: 4.56420074239114
Epoch: 5319, Batch Gradient Norm after: 4.56420074239114
Epoch 5320/10000, Prediction Accuracy = 64.81538461538462%, Loss = 0.0076284430777797336
Epoch: 5320, Batch Gradient Norm: 4.3771501138399085
Epoch: 5320, Batch Gradient Norm after: 4.3771501138399085
Epoch 5321/10000, Prediction Accuracy = 64.63076923076923%, Loss = 0.007667110803035589
Epoch: 5321, Batch Gradient Norm: 4.281894395929716
Epoch: 5321, Batch Gradient Norm after: 4.281894395929716
Epoch 5322/10000, Prediction Accuracy = 65.02692307692307%, Loss = 0.007497829062720904
Epoch: 5322, Batch Gradient Norm: 3.9171345452041053
Epoch: 5322, Batch Gradient Norm after: 3.9171345452041053
Epoch 5323/10000, Prediction Accuracy = 65.67307692307692%, Loss = 0.007299562629598837
Epoch: 5323, Batch Gradient Norm: 3.914260649128605
Epoch: 5323, Batch Gradient Norm after: 3.914260649128605
Epoch 5324/10000, Prediction Accuracy = 65.57692307692307%, Loss = 0.007286487254672325
Epoch: 5324, Batch Gradient Norm: 4.167361642339426
Epoch: 5324, Batch Gradient Norm after: 4.167361642339426
Epoch 5325/10000, Prediction Accuracy = 65.21923076923078%, Loss = 0.007447999328947985
Epoch: 5325, Batch Gradient Norm: 4.5738817760525485
Epoch: 5325, Batch Gradient Norm after: 4.5738817760525485
Epoch 5326/10000, Prediction Accuracy = 64.1846153846154%, Loss = 0.007610655282265865
Epoch: 5326, Batch Gradient Norm: 4.7025932924632565
Epoch: 5326, Batch Gradient Norm after: 4.7025932924632565
Epoch 5327/10000, Prediction Accuracy = 64.52307692307693%, Loss = 0.007653127352778728
Epoch: 5327, Batch Gradient Norm: 4.411078486974907
Epoch: 5327, Batch Gradient Norm after: 4.411078486974907
Epoch 5328/10000, Prediction Accuracy = 64.86923076923077%, Loss = 0.007533609293974363
Epoch: 5328, Batch Gradient Norm: 4.025211754913943
Epoch: 5328, Batch Gradient Norm after: 4.025211754913943
Epoch 5329/10000, Prediction Accuracy = 65.88461538461539%, Loss = 0.007294919341802597
Epoch: 5329, Batch Gradient Norm: 4.156076421331361
Epoch: 5329, Batch Gradient Norm after: 4.156076421331361
Epoch 5330/10000, Prediction Accuracy = 65.21153846153847%, Loss = 0.0073606780228706505
Epoch: 5330, Batch Gradient Norm: 4.036090429314014
Epoch: 5330, Batch Gradient Norm after: 4.036090429314014
Epoch 5331/10000, Prediction Accuracy = 65.8%, Loss = 0.007281481216733272
Epoch: 5331, Batch Gradient Norm: 4.040677925180944
Epoch: 5331, Batch Gradient Norm after: 4.040677925180944
Epoch 5332/10000, Prediction Accuracy = 65.01153846153845%, Loss = 0.007399938857326141
Epoch: 5332, Batch Gradient Norm: 4.015681282610793
Epoch: 5332, Batch Gradient Norm after: 4.015681282610793
Epoch 5333/10000, Prediction Accuracy = 65.49230769230769%, Loss = 0.007358537234652501
Epoch: 5333, Batch Gradient Norm: 4.297795430861397
Epoch: 5333, Batch Gradient Norm after: 4.297795430861397
Epoch 5334/10000, Prediction Accuracy = 65.12307692307692%, Loss = 0.007409506943076849
Epoch: 5334, Batch Gradient Norm: 4.2567300524199645
Epoch: 5334, Batch Gradient Norm after: 4.2567300524199645
Epoch 5335/10000, Prediction Accuracy = 64.9346153846154%, Loss = 0.007520483627628822
Epoch: 5335, Batch Gradient Norm: 4.411510356361122
Epoch: 5335, Batch Gradient Norm after: 4.411510356361122
Epoch 5336/10000, Prediction Accuracy = 65.20769230769233%, Loss = 0.007464866153895855
Epoch: 5336, Batch Gradient Norm: 4.684776840393041
Epoch: 5336, Batch Gradient Norm after: 4.684776840393041
Epoch 5337/10000, Prediction Accuracy = 64.89615384615385%, Loss = 0.007615596664926181
Epoch: 5337, Batch Gradient Norm: 4.28227908355757
Epoch: 5337, Batch Gradient Norm after: 4.28227908355757
Epoch 5338/10000, Prediction Accuracy = 65.43461538461538%, Loss = 0.007434247204890618
Epoch: 5338, Batch Gradient Norm: 4.220741925784626
Epoch: 5338, Batch Gradient Norm after: 4.220741925784626
Epoch 5339/10000, Prediction Accuracy = 65.31153846153846%, Loss = 0.0074805832611253625
Epoch: 5339, Batch Gradient Norm: 4.404913418179817
Epoch: 5339, Batch Gradient Norm after: 4.404913418179817
Epoch 5340/10000, Prediction Accuracy = 64.68076923076923%, Loss = 0.007601399583598742
Epoch: 5340, Batch Gradient Norm: 4.433790830566418
Epoch: 5340, Batch Gradient Norm after: 4.433790830566418
Epoch 5341/10000, Prediction Accuracy = 64.53076923076922%, Loss = 0.007659863214939833
Epoch: 5341, Batch Gradient Norm: 4.3223362829527
Epoch: 5341, Batch Gradient Norm after: 4.3223362829527
Epoch 5342/10000, Prediction Accuracy = 64.71923076923076%, Loss = 0.007668443418179567
Epoch: 5342, Batch Gradient Norm: 4.301286341548132
Epoch: 5342, Batch Gradient Norm after: 4.301286341548132
Epoch 5343/10000, Prediction Accuracy = 64.93461538461538%, Loss = 0.007525284738781361
Epoch: 5343, Batch Gradient Norm: 4.260118525699262
Epoch: 5343, Batch Gradient Norm after: 4.260118525699262
Epoch 5344/10000, Prediction Accuracy = 65.05769230769232%, Loss = 0.007522402617793817
Epoch: 5344, Batch Gradient Norm: 4.4707466581146935
Epoch: 5344, Batch Gradient Norm after: 4.4707466581146935
Epoch 5345/10000, Prediction Accuracy = 64.6846153846154%, Loss = 0.0076102933559853295
Epoch: 5345, Batch Gradient Norm: 4.43873604588398
Epoch: 5345, Batch Gradient Norm after: 4.43873604588398
Epoch 5346/10000, Prediction Accuracy = 65.12692307692308%, Loss = 0.007489439135847183
Epoch: 5346, Batch Gradient Norm: 4.571619576491593
Epoch: 5346, Batch Gradient Norm after: 4.571619576491593
Epoch 5347/10000, Prediction Accuracy = 64.67692307692309%, Loss = 0.00760011518230805
Epoch: 5347, Batch Gradient Norm: 4.3171203393405
Epoch: 5347, Batch Gradient Norm after: 4.3171203393405
Epoch 5348/10000, Prediction Accuracy = 65.08461538461538%, Loss = 0.007539876987441228
Epoch: 5348, Batch Gradient Norm: 3.949955237656071
Epoch: 5348, Batch Gradient Norm after: 3.949955237656071
Epoch 5349/10000, Prediction Accuracy = 65.28846153846153%, Loss = 0.007322179655042978
Epoch: 5349, Batch Gradient Norm: 3.8445951981942024
Epoch: 5349, Batch Gradient Norm after: 3.8445951981942024
Epoch 5350/10000, Prediction Accuracy = 66.01923076923077%, Loss = 0.0071954342464988046
Epoch: 5350, Batch Gradient Norm: 3.7247339020681984
Epoch: 5350, Batch Gradient Norm after: 3.7247339020681984
Epoch 5351/10000, Prediction Accuracy = 66.09615384615385%, Loss = 0.007151400885329797
Epoch: 5351, Batch Gradient Norm: 3.9174905229292243
Epoch: 5351, Batch Gradient Norm after: 3.9174905229292243
Epoch 5352/10000, Prediction Accuracy = 65.70769230769231%, Loss = 0.007258606394036458
Epoch: 5352, Batch Gradient Norm: 4.382140658083907
Epoch: 5352, Batch Gradient Norm after: 4.382140658083907
Epoch 5353/10000, Prediction Accuracy = 65.2923076923077%, Loss = 0.007441303227096796
Epoch: 5353, Batch Gradient Norm: 3.9128726055048224
Epoch: 5353, Batch Gradient Norm after: 3.9128726055048224
Epoch 5354/10000, Prediction Accuracy = 65.38846153846154%, Loss = 0.00721131766644808
Epoch: 5354, Batch Gradient Norm: 4.6170544894003935
Epoch: 5354, Batch Gradient Norm after: 4.6170544894003935
Epoch 5355/10000, Prediction Accuracy = 64.90384615384616%, Loss = 0.00758083791543658
Epoch: 5355, Batch Gradient Norm: 4.573859247467211
Epoch: 5355, Batch Gradient Norm after: 4.573859247467211
Epoch 5356/10000, Prediction Accuracy = 64.61923076923075%, Loss = 0.007486438199591178
Epoch: 5356, Batch Gradient Norm: 4.776972405873848
Epoch: 5356, Batch Gradient Norm after: 4.776972405873848
Epoch 5357/10000, Prediction Accuracy = 64.68076923076923%, Loss = 0.007621477644603986
Epoch: 5357, Batch Gradient Norm: 4.6168171769143616
Epoch: 5357, Batch Gradient Norm after: 4.6168171769143616
Epoch 5358/10000, Prediction Accuracy = 64.53461538461539%, Loss = 0.00768852262542798
Epoch: 5358, Batch Gradient Norm: 4.355480593481624
Epoch: 5358, Batch Gradient Norm after: 4.355480593481624
Epoch 5359/10000, Prediction Accuracy = 65.16153846153847%, Loss = 0.0074921101331710815
Epoch: 5359, Batch Gradient Norm: 4.18542189787671
Epoch: 5359, Batch Gradient Norm after: 4.18542189787671
Epoch 5360/10000, Prediction Accuracy = 65.35384615384615%, Loss = 0.007306856640542929
Epoch: 5360, Batch Gradient Norm: 4.129293889020882
Epoch: 5360, Batch Gradient Norm after: 4.129293889020882
Epoch 5361/10000, Prediction Accuracy = 65.17692307692307%, Loss = 0.007430395720383296
Epoch: 5361, Batch Gradient Norm: 4.1018953021393765
Epoch: 5361, Batch Gradient Norm after: 4.1018953021393765
Epoch 5362/10000, Prediction Accuracy = 65.35384615384615%, Loss = 0.0073312093647053605
Epoch: 5362, Batch Gradient Norm: 3.9992443301637355
Epoch: 5362, Batch Gradient Norm after: 3.9992443301637355
Epoch 5363/10000, Prediction Accuracy = 65.45%, Loss = 0.007362446461159449
Epoch: 5363, Batch Gradient Norm: 4.1566535777873685
Epoch: 5363, Batch Gradient Norm after: 4.1566535777873685
Epoch 5364/10000, Prediction Accuracy = 65.15%, Loss = 0.007450967919654571
Epoch: 5364, Batch Gradient Norm: 4.562684897875826
Epoch: 5364, Batch Gradient Norm after: 4.562684897875826
Epoch 5365/10000, Prediction Accuracy = 64.64615384615385%, Loss = 0.007617326883169321
Epoch: 5365, Batch Gradient Norm: 4.258662879882648
Epoch: 5365, Batch Gradient Norm after: 4.258662879882648
Epoch 5366/10000, Prediction Accuracy = 64.93076923076923%, Loss = 0.0074914825292160874
Epoch: 5366, Batch Gradient Norm: 4.824165600303541
Epoch: 5366, Batch Gradient Norm after: 4.824165600303541
Epoch 5367/10000, Prediction Accuracy = 63.98846153846154%, Loss = 0.007783238382007067
Epoch: 5367, Batch Gradient Norm: 4.467372661781674
Epoch: 5367, Batch Gradient Norm after: 4.467372661781674
Epoch 5368/10000, Prediction Accuracy = 64.96923076923078%, Loss = 0.007554013568621416
Epoch: 5368, Batch Gradient Norm: 4.483866822666998
Epoch: 5368, Batch Gradient Norm after: 4.483866822666998
Epoch 5369/10000, Prediction Accuracy = 65.25384615384615%, Loss = 0.007508743088692427
Epoch: 5369, Batch Gradient Norm: 4.385979307888748
Epoch: 5369, Batch Gradient Norm after: 4.385979307888748
Epoch 5370/10000, Prediction Accuracy = 64.5%, Loss = 0.007646289868996694
Epoch: 5370, Batch Gradient Norm: 4.749730324434237
Epoch: 5370, Batch Gradient Norm after: 4.749730324434237
Epoch 5371/10000, Prediction Accuracy = 64.68461538461538%, Loss = 0.007769448109544241
Epoch: 5371, Batch Gradient Norm: 4.378022064788956
Epoch: 5371, Batch Gradient Norm after: 4.378022064788956
Epoch 5372/10000, Prediction Accuracy = 64.53076923076922%, Loss = 0.007689403549123269
Epoch: 5372, Batch Gradient Norm: 4.56581037426788
Epoch: 5372, Batch Gradient Norm after: 4.56581037426788
Epoch 5373/10000, Prediction Accuracy = 64.66538461538462%, Loss = 0.007658431055740668
Epoch: 5373, Batch Gradient Norm: 4.220116913666524
Epoch: 5373, Batch Gradient Norm after: 4.220116913666524
Epoch 5374/10000, Prediction Accuracy = 65.26153846153846%, Loss = 0.007480975383749375
Epoch: 5374, Batch Gradient Norm: 4.0763631583844
Epoch: 5374, Batch Gradient Norm after: 4.0763631583844
Epoch 5375/10000, Prediction Accuracy = 65.20769230769233%, Loss = 0.0073875941765996125
Epoch: 5375, Batch Gradient Norm: 4.365652593581551
Epoch: 5375, Batch Gradient Norm after: 4.365652593581551
Epoch 5376/10000, Prediction Accuracy = 64.79615384615384%, Loss = 0.007627455983310938
Epoch: 5376, Batch Gradient Norm: 4.237495524271202
Epoch: 5376, Batch Gradient Norm after: 4.237495524271202
Epoch 5377/10000, Prediction Accuracy = 65.08461538461539%, Loss = 0.007472768748322358
Epoch: 5377, Batch Gradient Norm: 4.023784304155924
Epoch: 5377, Batch Gradient Norm after: 4.023784304155924
Epoch 5378/10000, Prediction Accuracy = 65.67692307692309%, Loss = 0.007310703683357973
Epoch: 5378, Batch Gradient Norm: 3.9987496569546517
Epoch: 5378, Batch Gradient Norm after: 3.9987496569546517
Epoch 5379/10000, Prediction Accuracy = 65.88461538461539%, Loss = 0.007253387548889105
Epoch: 5379, Batch Gradient Norm: 4.50813511637455
Epoch: 5379, Batch Gradient Norm after: 4.50813511637455
Epoch 5380/10000, Prediction Accuracy = 64.69999999999999%, Loss = 0.0075752159867149135
Epoch: 5380, Batch Gradient Norm: 4.41384145033108
Epoch: 5380, Batch Gradient Norm after: 4.41384145033108
Epoch 5381/10000, Prediction Accuracy = 65.42307692307692%, Loss = 0.007505096745892213
Epoch: 5381, Batch Gradient Norm: 4.287231655001831
Epoch: 5381, Batch Gradient Norm after: 4.287231655001831
Epoch 5382/10000, Prediction Accuracy = 64.86153846153846%, Loss = 0.007549635528658445
Epoch: 5382, Batch Gradient Norm: 4.5188678623197855
Epoch: 5382, Batch Gradient Norm after: 4.5188678623197855
Epoch 5383/10000, Prediction Accuracy = 64.88076923076923%, Loss = 0.0076193464203522755
Epoch: 5383, Batch Gradient Norm: 4.584272419067547
Epoch: 5383, Batch Gradient Norm after: 4.584272419067547
Epoch 5384/10000, Prediction Accuracy = 65.04999999999998%, Loss = 0.007554219677471197
Epoch: 5384, Batch Gradient Norm: 4.235434037479308
Epoch: 5384, Batch Gradient Norm after: 4.235434037479308
Epoch 5385/10000, Prediction Accuracy = 64.73846153846155%, Loss = 0.0075111314296149295
Epoch: 5385, Batch Gradient Norm: 4.309135313338864
Epoch: 5385, Batch Gradient Norm after: 4.309135313338864
Epoch 5386/10000, Prediction Accuracy = 64.64999999999999%, Loss = 0.0074944458543681185
Epoch: 5386, Batch Gradient Norm: 4.774753524990928
Epoch: 5386, Batch Gradient Norm after: 4.774753524990928
Epoch 5387/10000, Prediction Accuracy = 64.68076923076923%, Loss = 0.007665565917984798
Epoch: 5387, Batch Gradient Norm: 4.310448555437116
Epoch: 5387, Batch Gradient Norm after: 4.310448555437116
Epoch 5388/10000, Prediction Accuracy = 64.93076923076923%, Loss = 0.0074899369635834144
Epoch: 5388, Batch Gradient Norm: 3.91356923548728
Epoch: 5388, Batch Gradient Norm after: 3.91356923548728
Epoch 5389/10000, Prediction Accuracy = 65.94615384615385%, Loss = 0.007204563428576176
Epoch: 5389, Batch Gradient Norm: 4.017090589137911
Epoch: 5389, Batch Gradient Norm after: 4.017090589137911
Epoch 5390/10000, Prediction Accuracy = 65.41923076923078%, Loss = 0.007257404020772531
Epoch: 5390, Batch Gradient Norm: 3.93707616990787
Epoch: 5390, Batch Gradient Norm after: 3.93707616990787
Epoch 5391/10000, Prediction Accuracy = 65.61923076923077%, Loss = 0.007289193284053069
Epoch: 5391, Batch Gradient Norm: 4.138812551358716
Epoch: 5391, Batch Gradient Norm after: 4.138812551358716
Epoch 5392/10000, Prediction Accuracy = 65.59230769230768%, Loss = 0.007315262220799923
Epoch: 5392, Batch Gradient Norm: 3.854742463674453
Epoch: 5392, Batch Gradient Norm after: 3.854742463674453
Epoch 5393/10000, Prediction Accuracy = 66.03846153846153%, Loss = 0.007162279915064573
Epoch: 5393, Batch Gradient Norm: 4.338594466789712
Epoch: 5393, Batch Gradient Norm after: 4.338594466789712
Epoch 5394/10000, Prediction Accuracy = 65.00769230769232%, Loss = 0.007465117503530704
Epoch: 5394, Batch Gradient Norm: 4.441830161701752
Epoch: 5394, Batch Gradient Norm after: 4.441830161701752
Epoch 5395/10000, Prediction Accuracy = 64.99615384615385%, Loss = 0.0075552178403505916
Epoch: 5395, Batch Gradient Norm: 4.517173595988927
Epoch: 5395, Batch Gradient Norm after: 4.517173595988927
Epoch 5396/10000, Prediction Accuracy = 65.1576923076923%, Loss = 0.007559349473852377
Epoch: 5396, Batch Gradient Norm: 4.461708572657636
Epoch: 5396, Batch Gradient Norm after: 4.461708572657636
Epoch 5397/10000, Prediction Accuracy = 65.30384615384615%, Loss = 0.007379309274256229
Epoch: 5397, Batch Gradient Norm: 4.28395510048187
Epoch: 5397, Batch Gradient Norm after: 4.28395510048187
Epoch 5398/10000, Prediction Accuracy = 65.55769230769232%, Loss = 0.007334491882759791
Epoch: 5398, Batch Gradient Norm: 4.556319757290885
Epoch: 5398, Batch Gradient Norm after: 4.556319757290885
Epoch 5399/10000, Prediction Accuracy = 65.49230769230769%, Loss = 0.007478481731735743
Epoch: 5399, Batch Gradient Norm: 4.486229385121889
Epoch: 5399, Batch Gradient Norm after: 4.486229385121889
Epoch 5400/10000, Prediction Accuracy = 65.11923076923077%, Loss = 0.007446917275396677
Epoch: 5400, Batch Gradient Norm: 3.985077158120606
Epoch: 5400, Batch Gradient Norm after: 3.985077158120606
Epoch 5401/10000, Prediction Accuracy = 65.71538461538462%, Loss = 0.0073473865094666295
Epoch: 5401, Batch Gradient Norm: 4.258618382026611
Epoch: 5401, Batch Gradient Norm after: 4.258618382026611
Epoch 5402/10000, Prediction Accuracy = 65.41923076923078%, Loss = 0.00741868491212909
Epoch: 5402, Batch Gradient Norm: 4.947950361198787
Epoch: 5402, Batch Gradient Norm after: 4.947950361198787
Epoch 5403/10000, Prediction Accuracy = 64.71538461538461%, Loss = 0.007770592597528146
Epoch: 5403, Batch Gradient Norm: 4.684257862728262
Epoch: 5403, Batch Gradient Norm after: 4.684257862728262
Epoch 5404/10000, Prediction Accuracy = 65.21923076923078%, Loss = 0.00771001296547743
Epoch: 5404, Batch Gradient Norm: 4.603450880942831
Epoch: 5404, Batch Gradient Norm after: 4.603450880942831
Epoch 5405/10000, Prediction Accuracy = 64.38846153846154%, Loss = 0.007662104585996041
Epoch: 5405, Batch Gradient Norm: 4.369941656004248
Epoch: 5405, Batch Gradient Norm after: 4.369941656004248
Epoch 5406/10000, Prediction Accuracy = 65.00384615384615%, Loss = 0.007550701355704894
Epoch: 5406, Batch Gradient Norm: 4.0818292661242355
Epoch: 5406, Batch Gradient Norm after: 4.0818292661242355
Epoch 5407/10000, Prediction Accuracy = 65.3576923076923%, Loss = 0.007400969437395151
Epoch: 5407, Batch Gradient Norm: 4.327225033183451
Epoch: 5407, Batch Gradient Norm after: 4.327225033183451
Epoch 5408/10000, Prediction Accuracy = 64.83461538461539%, Loss = 0.00748030343451179
Epoch: 5408, Batch Gradient Norm: 4.587338556561638
Epoch: 5408, Batch Gradient Norm after: 4.587338556561638
Epoch 5409/10000, Prediction Accuracy = 64.48076923076923%, Loss = 0.007618282455950975
Epoch: 5409, Batch Gradient Norm: 4.646262714163266
Epoch: 5409, Batch Gradient Norm after: 4.646262714163266
Epoch 5410/10000, Prediction Accuracy = 65.03076923076924%, Loss = 0.007615934735020766
Epoch: 5410, Batch Gradient Norm: 4.272934037018416
Epoch: 5410, Batch Gradient Norm after: 4.272934037018416
Epoch 5411/10000, Prediction Accuracy = 64.91923076923078%, Loss = 0.00754440282113277
Epoch: 5411, Batch Gradient Norm: 4.225576563795625
Epoch: 5411, Batch Gradient Norm after: 4.225576563795625
Epoch 5412/10000, Prediction Accuracy = 65.31538461538462%, Loss = 0.007423585531516717
Epoch: 5412, Batch Gradient Norm: 4.275963441654946
Epoch: 5412, Batch Gradient Norm after: 4.275963441654946
Epoch 5413/10000, Prediction Accuracy = 65.13076923076923%, Loss = 0.007384015497966454
Epoch: 5413, Batch Gradient Norm: 4.220081265605237
Epoch: 5413, Batch Gradient Norm after: 4.220081265605237
Epoch 5414/10000, Prediction Accuracy = 64.89999999999999%, Loss = 0.007416027777183514
Epoch: 5414, Batch Gradient Norm: 4.259956892776358
Epoch: 5414, Batch Gradient Norm after: 4.259956892776358
Epoch 5415/10000, Prediction Accuracy = 65.29615384615384%, Loss = 0.007459008027441227
Epoch: 5415, Batch Gradient Norm: 4.128238060370818
Epoch: 5415, Batch Gradient Norm after: 4.128238060370818
Epoch 5416/10000, Prediction Accuracy = 65.07307692307691%, Loss = 0.0073757488996936725
Epoch: 5416, Batch Gradient Norm: 3.9327621227199048
Epoch: 5416, Batch Gradient Norm after: 3.9327621227199048
Epoch 5417/10000, Prediction Accuracy = 65.68846153846154%, Loss = 0.007269778468001347
Epoch: 5417, Batch Gradient Norm: 4.159031734495437
Epoch: 5417, Batch Gradient Norm after: 4.159031734495437
Epoch 5418/10000, Prediction Accuracy = 65.45384615384616%, Loss = 0.007321412316881693
Epoch: 5418, Batch Gradient Norm: 4.177990081647867
Epoch: 5418, Batch Gradient Norm after: 4.177990081647867
Epoch 5419/10000, Prediction Accuracy = 65.23846153846155%, Loss = 0.0073889539433786506
Epoch: 5419, Batch Gradient Norm: 4.610483465428703
Epoch: 5419, Batch Gradient Norm after: 4.610483465428703
Epoch 5420/10000, Prediction Accuracy = 64.98846153846154%, Loss = 0.007612503850116179
Epoch: 5420, Batch Gradient Norm: 4.657979677901391
Epoch: 5420, Batch Gradient Norm after: 4.657979677901391
Epoch 5421/10000, Prediction Accuracy = 64.70384615384616%, Loss = 0.0076638565112191895
Epoch: 5421, Batch Gradient Norm: 4.260195126117513
Epoch: 5421, Batch Gradient Norm after: 4.260195126117513
Epoch 5422/10000, Prediction Accuracy = 65.70769230769231%, Loss = 0.0074322173156990455
Epoch: 5422, Batch Gradient Norm: 4.275847019961062
Epoch: 5422, Batch Gradient Norm after: 4.275847019961062
Epoch 5423/10000, Prediction Accuracy = 65.41538461538461%, Loss = 0.00741991142813976
Epoch: 5423, Batch Gradient Norm: 4.326423464894552
Epoch: 5423, Batch Gradient Norm after: 4.326423464894552
Epoch 5424/10000, Prediction Accuracy = 64.8%, Loss = 0.007514088736990323
Epoch: 5424, Batch Gradient Norm: 4.250170635373914
Epoch: 5424, Batch Gradient Norm after: 4.250170635373914
Epoch 5425/10000, Prediction Accuracy = 65.13846153846154%, Loss = 0.007569564470591454
Epoch: 5425, Batch Gradient Norm: 4.104258309812571
Epoch: 5425, Batch Gradient Norm after: 4.104258309812571
Epoch 5426/10000, Prediction Accuracy = 65.12307692307692%, Loss = 0.007411535471104658
Epoch: 5426, Batch Gradient Norm: 4.396711716829123
Epoch: 5426, Batch Gradient Norm after: 4.396711716829123
Epoch 5427/10000, Prediction Accuracy = 65.0576923076923%, Loss = 0.007483221805439546
Epoch: 5427, Batch Gradient Norm: 4.57648235863431
Epoch: 5427, Batch Gradient Norm after: 4.57648235863431
Epoch 5428/10000, Prediction Accuracy = 65.03846153846153%, Loss = 0.007538349188577671
Epoch: 5428, Batch Gradient Norm: 4.035762333199623
Epoch: 5428, Batch Gradient Norm after: 4.035762333199623
Epoch 5429/10000, Prediction Accuracy = 65.21153846153847%, Loss = 0.007401311626801124
Epoch: 5429, Batch Gradient Norm: 4.1262316487776864
Epoch: 5429, Batch Gradient Norm after: 4.1262316487776864
Epoch 5430/10000, Prediction Accuracy = 64.6%, Loss = 0.007446592064717641
Epoch: 5430, Batch Gradient Norm: 4.36998252165239
Epoch: 5430, Batch Gradient Norm after: 4.36998252165239
Epoch 5431/10000, Prediction Accuracy = 65.00769230769231%, Loss = 0.0075014173411406
Epoch: 5431, Batch Gradient Norm: 4.443586942169156
Epoch: 5431, Batch Gradient Norm after: 4.443586942169156
Epoch 5432/10000, Prediction Accuracy = 64.79615384615386%, Loss = 0.0075877617614773605
Epoch: 5432, Batch Gradient Norm: 4.648430099359715
Epoch: 5432, Batch Gradient Norm after: 4.648430099359715
Epoch 5433/10000, Prediction Accuracy = 64.54615384615384%, Loss = 0.00769324700992841
Epoch: 5433, Batch Gradient Norm: 5.303097333433219
Epoch: 5433, Batch Gradient Norm after: 5.303097333433219
Epoch 5434/10000, Prediction Accuracy = 64.00769230769231%, Loss = 0.00791482960518736
Epoch: 5434, Batch Gradient Norm: 4.9280649829971495
Epoch: 5434, Batch Gradient Norm after: 4.9280649829971495
Epoch 5435/10000, Prediction Accuracy = 63.95384615384614%, Loss = 0.007997174174166642
Epoch: 5435, Batch Gradient Norm: 4.174482828695153
Epoch: 5435, Batch Gradient Norm after: 4.174482828695153
Epoch 5436/10000, Prediction Accuracy = 64.89615384615385%, Loss = 0.007614090214841641
Epoch: 5436, Batch Gradient Norm: 4.7953833389272065
Epoch: 5436, Batch Gradient Norm after: 4.7953833389272065
Epoch 5437/10000, Prediction Accuracy = 64.50384615384614%, Loss = 0.007819335262935895
Epoch: 5437, Batch Gradient Norm: 4.448583119794745
Epoch: 5437, Batch Gradient Norm after: 4.448583119794745
Epoch 5438/10000, Prediction Accuracy = 64.57692307692308%, Loss = 0.007792675366195349
Epoch: 5438, Batch Gradient Norm: 4.212119566439863
Epoch: 5438, Batch Gradient Norm after: 4.212119566439863
Epoch 5439/10000, Prediction Accuracy = 64.84615384615385%, Loss = 0.0075871760312181255
Epoch: 5439, Batch Gradient Norm: 4.878562642236623
Epoch: 5439, Batch Gradient Norm after: 4.878562642236623
Epoch 5440/10000, Prediction Accuracy = 63.49615384615384%, Loss = 0.00796800285864335
Epoch: 5440, Batch Gradient Norm: 4.07011973542298
Epoch: 5440, Batch Gradient Norm after: 4.07011973542298
Epoch 5441/10000, Prediction Accuracy = 65.11153846153846%, Loss = 0.007475792609441739
Epoch: 5441, Batch Gradient Norm: 3.8276634353269583
Epoch: 5441, Batch Gradient Norm after: 3.8276634353269583
Epoch 5442/10000, Prediction Accuracy = 65.98846153846154%, Loss = 0.007200538503149381
Epoch: 5442, Batch Gradient Norm: 4.006956089086215
Epoch: 5442, Batch Gradient Norm after: 4.006956089086215
Epoch 5443/10000, Prediction Accuracy = 65.64615384615384%, Loss = 0.0072579267792976816
Epoch: 5443, Batch Gradient Norm: 4.294112689112491
Epoch: 5443, Batch Gradient Norm after: 4.294112689112491
Epoch 5444/10000, Prediction Accuracy = 65.77692307692308%, Loss = 0.007342702494217799
Epoch: 5444, Batch Gradient Norm: 4.329311206058389
Epoch: 5444, Batch Gradient Norm after: 4.329311206058389
Epoch 5445/10000, Prediction Accuracy = 65.61538461538461%, Loss = 0.007458665193273471
Epoch: 5445, Batch Gradient Norm: 4.128912635129878
Epoch: 5445, Batch Gradient Norm after: 4.128912635129878
Epoch 5446/10000, Prediction Accuracy = 65.17307692307692%, Loss = 0.007432982898675478
Epoch: 5446, Batch Gradient Norm: 4.575718923326176
Epoch: 5446, Batch Gradient Norm after: 4.575718923326176
Epoch 5447/10000, Prediction Accuracy = 65.06153846153846%, Loss = 0.007642828716108432
Epoch: 5447, Batch Gradient Norm: 4.467759891664597
Epoch: 5447, Batch Gradient Norm after: 4.467759891664597
Epoch 5448/10000, Prediction Accuracy = 64.78076923076922%, Loss = 0.007566693167273815
Epoch: 5448, Batch Gradient Norm: 3.9325166024683718
Epoch: 5448, Batch Gradient Norm after: 3.9325166024683718
Epoch 5449/10000, Prediction Accuracy = 66.1423076923077%, Loss = 0.007250609270368631
Epoch: 5449, Batch Gradient Norm: 4.482562944148267
Epoch: 5449, Batch Gradient Norm after: 4.482562944148267
Epoch 5450/10000, Prediction Accuracy = 65.14615384615382%, Loss = 0.007476819106019461
Epoch: 5450, Batch Gradient Norm: 4.317604568574417
Epoch: 5450, Batch Gradient Norm after: 4.317604568574417
Epoch 5451/10000, Prediction Accuracy = 65.3%, Loss = 0.007419942519985712
Epoch: 5451, Batch Gradient Norm: 4.145483515894576
Epoch: 5451, Batch Gradient Norm after: 4.145483515894576
Epoch 5452/10000, Prediction Accuracy = 65.56923076923077%, Loss = 0.007328245538071944
Epoch: 5452, Batch Gradient Norm: 4.457573728651939
Epoch: 5452, Batch Gradient Norm after: 4.457573728651939
Epoch 5453/10000, Prediction Accuracy = 64.51538461538462%, Loss = 0.007613449500730405
Epoch: 5453, Batch Gradient Norm: 4.561924160000703
Epoch: 5453, Batch Gradient Norm after: 4.561924160000703
Epoch 5454/10000, Prediction Accuracy = 65.03076923076922%, Loss = 0.007530401389186199
Epoch: 5454, Batch Gradient Norm: 3.976321792982198
Epoch: 5454, Batch Gradient Norm after: 3.976321792982198
Epoch 5455/10000, Prediction Accuracy = 65.4%, Loss = 0.007174286848077407
Epoch: 5455, Batch Gradient Norm: 4.066283362101351
Epoch: 5455, Batch Gradient Norm after: 4.066283362101351
Epoch 5456/10000, Prediction Accuracy = 65.50384615384615%, Loss = 0.007318102468091708
Epoch: 5456, Batch Gradient Norm: 4.587938869054902
Epoch: 5456, Batch Gradient Norm after: 4.587938869054902
Epoch 5457/10000, Prediction Accuracy = 65.05384615384615%, Loss = 0.00749015908401746
Epoch: 5457, Batch Gradient Norm: 3.958723356981701
Epoch: 5457, Batch Gradient Norm after: 3.958723356981701
Epoch 5458/10000, Prediction Accuracy = 65.80769230769232%, Loss = 0.00731093121262697
Epoch: 5458, Batch Gradient Norm: 4.189959461273927
Epoch: 5458, Batch Gradient Norm after: 4.189959461273927
Epoch 5459/10000, Prediction Accuracy = 65.36538461538461%, Loss = 0.007443649264482351
Epoch: 5459, Batch Gradient Norm: 4.236295143480787
Epoch: 5459, Batch Gradient Norm after: 4.236295143480787
Epoch 5460/10000, Prediction Accuracy = 65.71538461538461%, Loss = 0.007413924385148745
Epoch: 5460, Batch Gradient Norm: 4.426528972092832
Epoch: 5460, Batch Gradient Norm after: 4.426528972092832
Epoch 5461/10000, Prediction Accuracy = 65.14615384615382%, Loss = 0.007525419064152699
Epoch: 5461, Batch Gradient Norm: 4.176841581097905
Epoch: 5461, Batch Gradient Norm after: 4.176841581097905
Epoch 5462/10000, Prediction Accuracy = 65.06153846153846%, Loss = 0.007447862782730506
Epoch: 5462, Batch Gradient Norm: 4.5371823767309385
Epoch: 5462, Batch Gradient Norm after: 4.5371823767309385
Epoch 5463/10000, Prediction Accuracy = 65.04615384615384%, Loss = 0.007551939549067846
Epoch: 5463, Batch Gradient Norm: 4.414353183824034
Epoch: 5463, Batch Gradient Norm after: 4.414353183824034
Epoch 5464/10000, Prediction Accuracy = 64.20384615384616%, Loss = 0.00768114784016059
Epoch: 5464, Batch Gradient Norm: 4.546348085874837
Epoch: 5464, Batch Gradient Norm after: 4.546348085874837
Epoch 5465/10000, Prediction Accuracy = 65.40384615384616%, Loss = 0.007572054039113796
Epoch: 5465, Batch Gradient Norm: 4.370643891842933
Epoch: 5465, Batch Gradient Norm after: 4.370643891842933
Epoch 5466/10000, Prediction Accuracy = 65.20769230769231%, Loss = 0.007557881243813496
Epoch: 5466, Batch Gradient Norm: 4.501363989623499
Epoch: 5466, Batch Gradient Norm after: 4.501363989623499
Epoch 5467/10000, Prediction Accuracy = 64.87307692307692%, Loss = 0.007570474157826259
Epoch: 5467, Batch Gradient Norm: 4.570767638045207
Epoch: 5467, Batch Gradient Norm after: 4.570767638045207
Epoch 5468/10000, Prediction Accuracy = 64.28846153846155%, Loss = 0.007728756405413151
Epoch: 5468, Batch Gradient Norm: 4.27138596040073
Epoch: 5468, Batch Gradient Norm after: 4.27138596040073
Epoch 5469/10000, Prediction Accuracy = 64.72692307692307%, Loss = 0.007527981168375566
Epoch: 5469, Batch Gradient Norm: 4.319319418839761
Epoch: 5469, Batch Gradient Norm after: 4.319319418839761
Epoch 5470/10000, Prediction Accuracy = 64.98846153846155%, Loss = 0.007478847275846279
Epoch: 5470, Batch Gradient Norm: 4.15531361448276
Epoch: 5470, Batch Gradient Norm after: 4.15531361448276
Epoch 5471/10000, Prediction Accuracy = 65.41153846153846%, Loss = 0.007463458889665512
Epoch: 5471, Batch Gradient Norm: 4.167910541516336
Epoch: 5471, Batch Gradient Norm after: 4.167910541516336
Epoch 5472/10000, Prediction Accuracy = 65.88461538461539%, Loss = 0.007398297222187886
Epoch: 5472, Batch Gradient Norm: 4.405790900531383
Epoch: 5472, Batch Gradient Norm after: 4.405790900531383
Epoch 5473/10000, Prediction Accuracy = 65.37307692307694%, Loss = 0.007515872792842297
Epoch: 5473, Batch Gradient Norm: 4.047707839692019
Epoch: 5473, Batch Gradient Norm after: 4.047707839692019
Epoch 5474/10000, Prediction Accuracy = 65.31923076923077%, Loss = 0.007401520923639719
Epoch: 5474, Batch Gradient Norm: 4.499984772151214
Epoch: 5474, Batch Gradient Norm after: 4.499984772151214
Epoch 5475/10000, Prediction Accuracy = 64.96923076923078%, Loss = 0.00750671739045244
Epoch: 5475, Batch Gradient Norm: 4.214039884793766
Epoch: 5475, Batch Gradient Norm after: 4.214039884793766
Epoch 5476/10000, Prediction Accuracy = 64.78076923076922%, Loss = 0.00747878928310596
Epoch: 5476, Batch Gradient Norm: 4.527792661124183
Epoch: 5476, Batch Gradient Norm after: 4.527792661124183
Epoch 5477/10000, Prediction Accuracy = 64.6076923076923%, Loss = 0.007586958818137646
Epoch: 5477, Batch Gradient Norm: 4.002689391822275
Epoch: 5477, Batch Gradient Norm after: 4.002689391822275
Epoch 5478/10000, Prediction Accuracy = 65.4346153846154%, Loss = 0.007322754782552903
Epoch: 5478, Batch Gradient Norm: 4.4283060814217405
Epoch: 5478, Batch Gradient Norm after: 4.4283060814217405
Epoch 5479/10000, Prediction Accuracy = 64.96538461538462%, Loss = 0.007498086143571597
Epoch: 5479, Batch Gradient Norm: 4.142727550204861
Epoch: 5479, Batch Gradient Norm after: 4.142727550204861
Epoch 5480/10000, Prediction Accuracy = 65.31538461538463%, Loss = 0.007380315174277012
Epoch: 5480, Batch Gradient Norm: 3.92722860379873
Epoch: 5480, Batch Gradient Norm after: 3.92722860379873
Epoch 5481/10000, Prediction Accuracy = 65.54230769230769%, Loss = 0.00732546213727731
Epoch: 5481, Batch Gradient Norm: 3.996656240220868
Epoch: 5481, Batch Gradient Norm after: 3.996656240220868
Epoch 5482/10000, Prediction Accuracy = 64.93461538461537%, Loss = 0.007337058751055827
Epoch: 5482, Batch Gradient Norm: 4.175190300276471
Epoch: 5482, Batch Gradient Norm after: 4.175190300276471
Epoch 5483/10000, Prediction Accuracy = 65.08461538461538%, Loss = 0.007422678351688843
Epoch: 5483, Batch Gradient Norm: 4.417263426445453
Epoch: 5483, Batch Gradient Norm after: 4.417263426445453
Epoch 5484/10000, Prediction Accuracy = 64.78076923076924%, Loss = 0.007569799092240059
Epoch: 5484, Batch Gradient Norm: 4.223207882086586
Epoch: 5484, Batch Gradient Norm after: 4.223207882086586
Epoch 5485/10000, Prediction Accuracy = 65.21538461538462%, Loss = 0.007433858091154924
Epoch: 5485, Batch Gradient Norm: 4.161384531891085
Epoch: 5485, Batch Gradient Norm after: 4.161384531891085
Epoch 5486/10000, Prediction Accuracy = 65.4923076923077%, Loss = 0.007391870594941652
Epoch: 5486, Batch Gradient Norm: 3.986128485588558
Epoch: 5486, Batch Gradient Norm after: 3.986128485588558
Epoch 5487/10000, Prediction Accuracy = 65.54615384615384%, Loss = 0.007378125061782507
Epoch: 5487, Batch Gradient Norm: 4.303181441226621
Epoch: 5487, Batch Gradient Norm after: 4.303181441226621
Epoch 5488/10000, Prediction Accuracy = 65.00769230769232%, Loss = 0.007435276173055172
Epoch: 5488, Batch Gradient Norm: 4.5016168942775145
Epoch: 5488, Batch Gradient Norm after: 4.5016168942775145
Epoch 5489/10000, Prediction Accuracy = 65.12692307692308%, Loss = 0.007552637826078213
Epoch: 5489, Batch Gradient Norm: 4.431232447619642
Epoch: 5489, Batch Gradient Norm after: 4.431232447619642
Epoch 5490/10000, Prediction Accuracy = 65.3923076923077%, Loss = 0.007316876847583514
Epoch: 5490, Batch Gradient Norm: 4.532883492640737
Epoch: 5490, Batch Gradient Norm after: 4.532883492640737
Epoch 5491/10000, Prediction Accuracy = 64.82692307692307%, Loss = 0.007503959636848707
Epoch: 5491, Batch Gradient Norm: 4.358445459504474
Epoch: 5491, Batch Gradient Norm after: 4.358445459504474
Epoch 5492/10000, Prediction Accuracy = 65.05769230769229%, Loss = 0.007412137606969247
Epoch: 5492, Batch Gradient Norm: 4.330980816442653
Epoch: 5492, Batch Gradient Norm after: 4.330980816442653
Epoch 5493/10000, Prediction Accuracy = 65.48846153846154%, Loss = 0.007366263558371709
Epoch: 5493, Batch Gradient Norm: 4.522338718580723
Epoch: 5493, Batch Gradient Norm after: 4.522338718580723
Epoch 5494/10000, Prediction Accuracy = 64.95384615384616%, Loss = 0.007491477406941927
Epoch: 5494, Batch Gradient Norm: 4.6383299220361325
Epoch: 5494, Batch Gradient Norm after: 4.6383299220361325
Epoch 5495/10000, Prediction Accuracy = 64.65384615384616%, Loss = 0.007620353108415237
Epoch: 5495, Batch Gradient Norm: 4.319743945099805
Epoch: 5495, Batch Gradient Norm after: 4.319743945099805
Epoch 5496/10000, Prediction Accuracy = 65.13076923076923%, Loss = 0.007466346168747315
Epoch: 5496, Batch Gradient Norm: 4.339128565059771
Epoch: 5496, Batch Gradient Norm after: 4.339128565059771
Epoch 5497/10000, Prediction Accuracy = 65.7346153846154%, Loss = 0.007402680885906403
Epoch: 5497, Batch Gradient Norm: 4.496970067466491
Epoch: 5497, Batch Gradient Norm after: 4.496970067466491
Epoch 5498/10000, Prediction Accuracy = 64.86923076923077%, Loss = 0.007583159236953809
Epoch: 5498, Batch Gradient Norm: 4.033219509692693
Epoch: 5498, Batch Gradient Norm after: 4.033219509692693
Epoch 5499/10000, Prediction Accuracy = 65.29615384615384%, Loss = 0.007378263828846125
Epoch: 5499, Batch Gradient Norm: 3.93016192370415
Epoch: 5499, Batch Gradient Norm after: 3.93016192370415
Epoch 5500/10000, Prediction Accuracy = 65.91923076923075%, Loss = 0.007249709970962543
Epoch: 5500, Batch Gradient Norm: 4.087257090511333
Epoch: 5500, Batch Gradient Norm after: 4.087257090511333
Epoch 5501/10000, Prediction Accuracy = 65.41153846153847%, Loss = 0.0073564274666401055
Epoch: 5501, Batch Gradient Norm: 4.0627646719712835
Epoch: 5501, Batch Gradient Norm after: 4.0627646719712835
Epoch 5502/10000, Prediction Accuracy = 65.97692307692309%, Loss = 0.007209750823676586
Epoch: 5502, Batch Gradient Norm: 4.023590649341629
Epoch: 5502, Batch Gradient Norm after: 4.023590649341629
Epoch 5503/10000, Prediction Accuracy = 65.47307692307692%, Loss = 0.007304375059902668
Epoch: 5503, Batch Gradient Norm: 4.307933515268647
Epoch: 5503, Batch Gradient Norm after: 4.307933515268647
Epoch 5504/10000, Prediction Accuracy = 65.5153846153846%, Loss = 0.007436564765297449
Epoch: 5504, Batch Gradient Norm: 4.669519983171229
Epoch: 5504, Batch Gradient Norm after: 4.669519983171229
Epoch 5505/10000, Prediction Accuracy = 64.78076923076924%, Loss = 0.007612769527790638
Epoch: 5505, Batch Gradient Norm: 4.29402242714971
Epoch: 5505, Batch Gradient Norm after: 4.29402242714971
Epoch 5506/10000, Prediction Accuracy = 65.13846153846154%, Loss = 0.007406221523594398
Epoch: 5506, Batch Gradient Norm: 4.30340812394496
Epoch: 5506, Batch Gradient Norm after: 4.30340812394496
Epoch 5507/10000, Prediction Accuracy = 65.20384615384616%, Loss = 0.0073801043371741586
Epoch: 5507, Batch Gradient Norm: 4.532395955786797
Epoch: 5507, Batch Gradient Norm after: 4.532395955786797
Epoch 5508/10000, Prediction Accuracy = 64.54230769230769%, Loss = 0.0075844696436363915
Epoch: 5508, Batch Gradient Norm: 3.8386591136481307
Epoch: 5508, Batch Gradient Norm after: 3.8386591136481307
Epoch 5509/10000, Prediction Accuracy = 65.67307692307692%, Loss = 0.007228301551479559
Epoch: 5509, Batch Gradient Norm: 4.09823301838004
Epoch: 5509, Batch Gradient Norm after: 4.09823301838004
Epoch 5510/10000, Prediction Accuracy = 65.4576923076923%, Loss = 0.007237812826553216
Epoch: 5510, Batch Gradient Norm: 4.4944263554361115
Epoch: 5510, Batch Gradient Norm after: 4.4944263554361115
Epoch 5511/10000, Prediction Accuracy = 64.75769230769231%, Loss = 0.007429710660989468
Epoch: 5511, Batch Gradient Norm: 4.5409090660846365
Epoch: 5511, Batch Gradient Norm after: 4.5409090660846365
Epoch 5512/10000, Prediction Accuracy = 65.13076923076923%, Loss = 0.00749266015079159
Epoch: 5512, Batch Gradient Norm: 4.634117661344045
Epoch: 5512, Batch Gradient Norm after: 4.634117661344045
Epoch 5513/10000, Prediction Accuracy = 64.50384615384615%, Loss = 0.007625961640419869
Epoch: 5513, Batch Gradient Norm: 4.362200624856483
Epoch: 5513, Batch Gradient Norm after: 4.362200624856483
Epoch 5514/10000, Prediction Accuracy = 64.65384615384615%, Loss = 0.007568134245677636
Epoch: 5514, Batch Gradient Norm: 4.157464341496456
Epoch: 5514, Batch Gradient Norm after: 4.157464341496456
Epoch 5515/10000, Prediction Accuracy = 65.24615384615385%, Loss = 0.007363308185281662
Epoch: 5515, Batch Gradient Norm: 4.18825506883128
Epoch: 5515, Batch Gradient Norm after: 4.18825506883128
Epoch 5516/10000, Prediction Accuracy = 65.01153846153846%, Loss = 0.0072674833667966034
Epoch: 5516, Batch Gradient Norm: 4.055028361853391
Epoch: 5516, Batch Gradient Norm after: 4.055028361853391
Epoch 5517/10000, Prediction Accuracy = 65.4%, Loss = 0.007267898629204585
Epoch: 5517, Batch Gradient Norm: 4.2524005357919386
Epoch: 5517, Batch Gradient Norm after: 4.2524005357919386
Epoch 5518/10000, Prediction Accuracy = 65.30769230769232%, Loss = 0.007430038737276426
Epoch: 5518, Batch Gradient Norm: 4.8809282500453355
Epoch: 5518, Batch Gradient Norm after: 4.8809282500453355
Epoch 5519/10000, Prediction Accuracy = 64.69615384615385%, Loss = 0.007669206028087781
Epoch: 5519, Batch Gradient Norm: 4.52617658777064
Epoch: 5519, Batch Gradient Norm after: 4.52617658777064
Epoch 5520/10000, Prediction Accuracy = 64.97692307692309%, Loss = 0.0076052828047138
Epoch: 5520, Batch Gradient Norm: 4.530240785680245
Epoch: 5520, Batch Gradient Norm after: 4.530240785680245
Epoch 5521/10000, Prediction Accuracy = 64.86538461538461%, Loss = 0.007662313918654735
Epoch: 5521, Batch Gradient Norm: 4.452740628391621
Epoch: 5521, Batch Gradient Norm after: 4.452740628391621
Epoch 5522/10000, Prediction Accuracy = 65.18461538461537%, Loss = 0.007605709816114261
Epoch: 5522, Batch Gradient Norm: 4.06000682557266
Epoch: 5522, Batch Gradient Norm after: 4.06000682557266
Epoch 5523/10000, Prediction Accuracy = 65.10384615384615%, Loss = 0.007412067113014368
Epoch: 5523, Batch Gradient Norm: 4.632045140546756
Epoch: 5523, Batch Gradient Norm after: 4.632045140546756
Epoch 5524/10000, Prediction Accuracy = 64.96153846153847%, Loss = 0.007535795108056986
Epoch: 5524, Batch Gradient Norm: 4.438187019178157
Epoch: 5524, Batch Gradient Norm after: 4.438187019178157
Epoch 5525/10000, Prediction Accuracy = 64.48076923076923%, Loss = 0.007523292997995248
Epoch: 5525, Batch Gradient Norm: 4.713229363388488
Epoch: 5525, Batch Gradient Norm after: 4.713229363388488
Epoch 5526/10000, Prediction Accuracy = 64.04615384615383%, Loss = 0.007686233362899377
Epoch: 5526, Batch Gradient Norm: 4.387983886362753
Epoch: 5526, Batch Gradient Norm after: 4.387983886362753
Epoch 5527/10000, Prediction Accuracy = 65.2653846153846%, Loss = 0.007431163882406859
Epoch: 5527, Batch Gradient Norm: 4.048922741416473
Epoch: 5527, Batch Gradient Norm after: 4.048922741416473
Epoch 5528/10000, Prediction Accuracy = 65.63461538461539%, Loss = 0.007206721732822748
Epoch: 5528, Batch Gradient Norm: 4.283454596595206
Epoch: 5528, Batch Gradient Norm after: 4.283454596595206
Epoch 5529/10000, Prediction Accuracy = 65.24999999999999%, Loss = 0.007413756854545612
Epoch: 5529, Batch Gradient Norm: 4.0486394004980575
Epoch: 5529, Batch Gradient Norm after: 4.0486394004980575
Epoch 5530/10000, Prediction Accuracy = 65.5576923076923%, Loss = 0.007248829656208937
Epoch: 5530, Batch Gradient Norm: 4.603528063463765
Epoch: 5530, Batch Gradient Norm after: 4.603528063463765
Epoch 5531/10000, Prediction Accuracy = 64.77307692307693%, Loss = 0.007546874551245799
Epoch: 5531, Batch Gradient Norm: 4.814436416893016
Epoch: 5531, Batch Gradient Norm after: 4.814436416893016
Epoch 5532/10000, Prediction Accuracy = 65.01538461538462%, Loss = 0.007619351721726931
Epoch: 5532, Batch Gradient Norm: 4.4487624102306444
Epoch: 5532, Batch Gradient Norm after: 4.4487624102306444
Epoch 5533/10000, Prediction Accuracy = 64.86153846153846%, Loss = 0.007515243756083341
Epoch: 5533, Batch Gradient Norm: 3.6613953678170614
Epoch: 5533, Batch Gradient Norm after: 3.6613953678170614
Epoch 5534/10000, Prediction Accuracy = 66.21153846153848%, Loss = 0.007171532748123774
Epoch: 5534, Batch Gradient Norm: 3.9171882256726316
Epoch: 5534, Batch Gradient Norm after: 3.9171882256726316
Epoch 5535/10000, Prediction Accuracy = 65.57307692307691%, Loss = 0.007174291934531469
Epoch: 5535, Batch Gradient Norm: 4.348751394843214
Epoch: 5535, Batch Gradient Norm after: 4.348751394843214
Epoch 5536/10000, Prediction Accuracy = 65.56153846153846%, Loss = 0.007389837732681861
Epoch: 5536, Batch Gradient Norm: 3.9884368504969636
Epoch: 5536, Batch Gradient Norm after: 3.9884368504969636
Epoch 5537/10000, Prediction Accuracy = 65.94230769230768%, Loss = 0.007307408341708092
Epoch: 5537, Batch Gradient Norm: 4.262704710701792
Epoch: 5537, Batch Gradient Norm after: 4.262704710701792
Epoch 5538/10000, Prediction Accuracy = 65.14615384615385%, Loss = 0.007489856547461106
Epoch: 5538, Batch Gradient Norm: 4.5598042731522845
Epoch: 5538, Batch Gradient Norm after: 4.5598042731522845
Epoch 5539/10000, Prediction Accuracy = 64.8076923076923%, Loss = 0.0075538909564224575
Epoch: 5539, Batch Gradient Norm: 4.7617575546653645
Epoch: 5539, Batch Gradient Norm after: 4.7617575546653645
Epoch 5540/10000, Prediction Accuracy = 64.41538461538462%, Loss = 0.007746748984433138
Epoch: 5540, Batch Gradient Norm: 4.067245257401843
Epoch: 5540, Batch Gradient Norm after: 4.067245257401843
Epoch 5541/10000, Prediction Accuracy = 65.44230769230768%, Loss = 0.007311577049012368
Epoch: 5541, Batch Gradient Norm: 4.358886457691293
Epoch: 5541, Batch Gradient Norm after: 4.358886457691293
Epoch 5542/10000, Prediction Accuracy = 65.06923076923077%, Loss = 0.007432831128915915
Epoch: 5542, Batch Gradient Norm: 4.870379044010501
Epoch: 5542, Batch Gradient Norm after: 4.870379044010501
Epoch 5543/10000, Prediction Accuracy = 64.32307692307693%, Loss = 0.007849593754284657
Epoch: 5543, Batch Gradient Norm: 4.33112152779806
Epoch: 5543, Batch Gradient Norm after: 4.33112152779806
Epoch 5544/10000, Prediction Accuracy = 65.0923076923077%, Loss = 0.007639396326759687
Epoch: 5544, Batch Gradient Norm: 4.293543625748938
Epoch: 5544, Batch Gradient Norm after: 4.293543625748938
Epoch 5545/10000, Prediction Accuracy = 65.05000000000001%, Loss = 0.007424504209596377
Epoch: 5545, Batch Gradient Norm: 4.6709336193824775
Epoch: 5545, Batch Gradient Norm after: 4.6709336193824775
Epoch 5546/10000, Prediction Accuracy = 64.5769230769231%, Loss = 0.0076924903461566335
Epoch: 5546, Batch Gradient Norm: 4.402283217242924
Epoch: 5546, Batch Gradient Norm after: 4.402283217242924
Epoch 5547/10000, Prediction Accuracy = 64.7923076923077%, Loss = 0.007568118914675254
Epoch: 5547, Batch Gradient Norm: 4.412522027429975
Epoch: 5547, Batch Gradient Norm after: 4.412522027429975
Epoch 5548/10000, Prediction Accuracy = 64.80384615384617%, Loss = 0.007549815238095247
Epoch: 5548, Batch Gradient Norm: 4.0155686852557055
Epoch: 5548, Batch Gradient Norm after: 4.0155686852557055
Epoch 5549/10000, Prediction Accuracy = 65.34230769230768%, Loss = 0.0073444691415016465
Epoch: 5549, Batch Gradient Norm: 4.4641809261311645
Epoch: 5549, Batch Gradient Norm after: 4.4641809261311645
Epoch 5550/10000, Prediction Accuracy = 64.61923076923077%, Loss = 0.007494280114769936
Epoch: 5550, Batch Gradient Norm: 4.252886638441703
Epoch: 5550, Batch Gradient Norm after: 4.252886638441703
Epoch 5551/10000, Prediction Accuracy = 65.68076923076923%, Loss = 0.007395903221689737
Epoch: 5551, Batch Gradient Norm: 4.1756387671468405
Epoch: 5551, Batch Gradient Norm after: 4.1756387671468405
Epoch 5552/10000, Prediction Accuracy = 65.43846153846154%, Loss = 0.007375261244865565
Epoch: 5552, Batch Gradient Norm: 4.305763231784211
Epoch: 5552, Batch Gradient Norm after: 4.305763231784211
Epoch 5553/10000, Prediction Accuracy = 65.32307692307691%, Loss = 0.00743423724690309
Epoch: 5553, Batch Gradient Norm: 4.583534962561436
Epoch: 5553, Batch Gradient Norm after: 4.583534962561436
Epoch 5554/10000, Prediction Accuracy = 65.28846153846153%, Loss = 0.007584073509161289
Epoch: 5554, Batch Gradient Norm: 4.244622660401751
Epoch: 5554, Batch Gradient Norm after: 4.244622660401751
Epoch 5555/10000, Prediction Accuracy = 65.23846153846154%, Loss = 0.007438590463537436
Epoch: 5555, Batch Gradient Norm: 3.793423686885812
Epoch: 5555, Batch Gradient Norm after: 3.793423686885812
Epoch 5556/10000, Prediction Accuracy = 65.84230769230768%, Loss = 0.0071113463133000415
Epoch: 5556, Batch Gradient Norm: 4.043328134867944
Epoch: 5556, Batch Gradient Norm after: 4.043328134867944
Epoch 5557/10000, Prediction Accuracy = 65.55769230769229%, Loss = 0.007313126017554448
Epoch: 5557, Batch Gradient Norm: 4.234347774066916
Epoch: 5557, Batch Gradient Norm after: 4.234347774066916
Epoch 5558/10000, Prediction Accuracy = 65.19615384615385%, Loss = 0.007429417401838761
Epoch: 5558, Batch Gradient Norm: 4.252668961547598
Epoch: 5558, Batch Gradient Norm after: 4.252668961547598
Epoch 5559/10000, Prediction Accuracy = 65.14615384615384%, Loss = 0.007405714919933906
Epoch: 5559, Batch Gradient Norm: 4.458311552721226
Epoch: 5559, Batch Gradient Norm after: 4.458311552721226
Epoch 5560/10000, Prediction Accuracy = 64.62692307692308%, Loss = 0.007490737542796593
Epoch: 5560, Batch Gradient Norm: 4.4007062032015325
Epoch: 5560, Batch Gradient Norm after: 4.4007062032015325
Epoch 5561/10000, Prediction Accuracy = 65.14615384615385%, Loss = 0.007455734392771354
Epoch: 5561, Batch Gradient Norm: 4.130405642099963
Epoch: 5561, Batch Gradient Norm after: 4.130405642099963
Epoch 5562/10000, Prediction Accuracy = 65.58076923076925%, Loss = 0.007306489305427441
Epoch: 5562, Batch Gradient Norm: 4.518165470423121
Epoch: 5562, Batch Gradient Norm after: 4.518165470423121
Epoch 5563/10000, Prediction Accuracy = 65.01153846153845%, Loss = 0.007516420661256864
Epoch: 5563, Batch Gradient Norm: 4.085572827266723
Epoch: 5563, Batch Gradient Norm after: 4.085572827266723
Epoch 5564/10000, Prediction Accuracy = 65.28076923076922%, Loss = 0.007419025489630608
Epoch: 5564, Batch Gradient Norm: 4.238494493207431
Epoch: 5564, Batch Gradient Norm after: 4.238494493207431
Epoch 5565/10000, Prediction Accuracy = 65.73461538461538%, Loss = 0.007269456731871917
Epoch: 5565, Batch Gradient Norm: 4.618889051335102
Epoch: 5565, Batch Gradient Norm after: 4.618889051335102
Epoch 5566/10000, Prediction Accuracy = 65.13076923076923%, Loss = 0.0075860873151284
Epoch: 5566, Batch Gradient Norm: 4.325889852614671
Epoch: 5566, Batch Gradient Norm after: 4.325889852614671
Epoch 5567/10000, Prediction Accuracy = 65.73076923076923%, Loss = 0.007342753215478017
Epoch: 5567, Batch Gradient Norm: 4.121398133203436
Epoch: 5567, Batch Gradient Norm after: 4.121398133203436
Epoch 5568/10000, Prediction Accuracy = 66.03846153846155%, Loss = 0.007258057021177732
Epoch: 5568, Batch Gradient Norm: 4.326716631632404
Epoch: 5568, Batch Gradient Norm after: 4.326716631632404
Epoch 5569/10000, Prediction Accuracy = 64.79230769230769%, Loss = 0.007366476616320701
Epoch: 5569, Batch Gradient Norm: 4.396513150627267
Epoch: 5569, Batch Gradient Norm after: 4.396513150627267
Epoch 5570/10000, Prediction Accuracy = 65.4346153846154%, Loss = 0.007384887896478176
Epoch: 5570, Batch Gradient Norm: 4.6015548120439576
Epoch: 5570, Batch Gradient Norm after: 4.6015548120439576
Epoch 5571/10000, Prediction Accuracy = 64.46923076923076%, Loss = 0.007579486458920515
Epoch: 5571, Batch Gradient Norm: 3.996231237907167
Epoch: 5571, Batch Gradient Norm after: 3.996231237907167
Epoch 5572/10000, Prediction Accuracy = 65.82692307692307%, Loss = 0.007245568164552634
Epoch: 5572, Batch Gradient Norm: 4.196446202095802
Epoch: 5572, Batch Gradient Norm after: 4.196446202095802
Epoch 5573/10000, Prediction Accuracy = 65.58461538461539%, Loss = 0.007386195724113629
Epoch: 5573, Batch Gradient Norm: 3.960589168510066
Epoch: 5573, Batch Gradient Norm after: 3.960589168510066
Epoch 5574/10000, Prediction Accuracy = 65.61538461538461%, Loss = 0.007238490112985556
Epoch: 5574, Batch Gradient Norm: 4.213820029100207
Epoch: 5574, Batch Gradient Norm after: 4.213820029100207
Epoch 5575/10000, Prediction Accuracy = 65.59615384615384%, Loss = 0.007327537303074048
Epoch: 5575, Batch Gradient Norm: 4.606087731228024
Epoch: 5575, Batch Gradient Norm after: 4.606087731228024
Epoch 5576/10000, Prediction Accuracy = 65.1076923076923%, Loss = 0.007385247422812076
Epoch: 5576, Batch Gradient Norm: 4.679556485273594
Epoch: 5576, Batch Gradient Norm after: 4.679556485273594
Epoch 5577/10000, Prediction Accuracy = 64.78846153846153%, Loss = 0.0075746417905275636
Epoch: 5577, Batch Gradient Norm: 4.388543132282474
Epoch: 5577, Batch Gradient Norm after: 4.388543132282474
Epoch 5578/10000, Prediction Accuracy = 65.41538461538461%, Loss = 0.007449949625879526
Epoch: 5578, Batch Gradient Norm: 4.773249686653722
Epoch: 5578, Batch Gradient Norm after: 4.773249686653722
Epoch 5579/10000, Prediction Accuracy = 64.75384615384615%, Loss = 0.007713336605005539
Epoch: 5579, Batch Gradient Norm: 4.3083295089544515
Epoch: 5579, Batch Gradient Norm after: 4.3083295089544515
Epoch 5580/10000, Prediction Accuracy = 64.82307692307691%, Loss = 0.00737071202064936
Epoch: 5580, Batch Gradient Norm: 4.776741188103779
Epoch: 5580, Batch Gradient Norm after: 4.776741188103779
Epoch 5581/10000, Prediction Accuracy = 64.56538461538462%, Loss = 0.007666687194544535
Epoch: 5581, Batch Gradient Norm: 4.377062805896651
Epoch: 5581, Batch Gradient Norm after: 4.377062805896651
Epoch 5582/10000, Prediction Accuracy = 65.21153846153845%, Loss = 0.007454044400499417
Epoch: 5582, Batch Gradient Norm: 4.136315556702602
Epoch: 5582, Batch Gradient Norm after: 4.136315556702602
Epoch 5583/10000, Prediction Accuracy = 65.34615384615384%, Loss = 0.0072552013354232675
Epoch: 5583, Batch Gradient Norm: 4.21551154331162
Epoch: 5583, Batch Gradient Norm after: 4.21551154331162
Epoch 5584/10000, Prediction Accuracy = 65.46153846153847%, Loss = 0.007340416777879
Epoch: 5584, Batch Gradient Norm: 4.221731414331687
Epoch: 5584, Batch Gradient Norm after: 4.221731414331687
Epoch 5585/10000, Prediction Accuracy = 65.15769230769232%, Loss = 0.007354880038362283
Epoch: 5585, Batch Gradient Norm: 4.405823763028407
Epoch: 5585, Batch Gradient Norm after: 4.405823763028407
Epoch 5586/10000, Prediction Accuracy = 65.15384615384616%, Loss = 0.00743572492725574
Epoch: 5586, Batch Gradient Norm: 4.440574801939224
Epoch: 5586, Batch Gradient Norm after: 4.440574801939224
Epoch 5587/10000, Prediction Accuracy = 65.07692307692308%, Loss = 0.007582369475410535
Epoch: 5587, Batch Gradient Norm: 4.140092185098226
Epoch: 5587, Batch Gradient Norm after: 4.140092185098226
Epoch 5588/10000, Prediction Accuracy = 65.01538461538463%, Loss = 0.0074288464294603234
Epoch: 5588, Batch Gradient Norm: 4.077563016140097
Epoch: 5588, Batch Gradient Norm after: 4.077563016140097
Epoch 5589/10000, Prediction Accuracy = 65.55769230769232%, Loss = 0.0072927430200462155
Epoch: 5589, Batch Gradient Norm: 4.0809346813665055
Epoch: 5589, Batch Gradient Norm after: 4.0809346813665055
Epoch 5590/10000, Prediction Accuracy = 65.6076923076923%, Loss = 0.007227928485148228
Epoch: 5590, Batch Gradient Norm: 4.0417047808638245
Epoch: 5590, Batch Gradient Norm after: 4.0417047808638245
Epoch 5591/10000, Prediction Accuracy = 65.37307692307692%, Loss = 0.007291556658366552
Epoch: 5591, Batch Gradient Norm: 4.184881338253178
Epoch: 5591, Batch Gradient Norm after: 4.184881338253178
Epoch 5592/10000, Prediction Accuracy = 65.5769230769231%, Loss = 0.007260025228158786
Epoch: 5592, Batch Gradient Norm: 4.183696594790698
Epoch: 5592, Batch Gradient Norm after: 4.183696594790698
Epoch 5593/10000, Prediction Accuracy = 65.57692307692308%, Loss = 0.00728676557684174
Epoch: 5593, Batch Gradient Norm: 4.13752614263139
Epoch: 5593, Batch Gradient Norm after: 4.13752614263139
Epoch 5594/10000, Prediction Accuracy = 65.38461538461539%, Loss = 0.007335479299609478
Epoch: 5594, Batch Gradient Norm: 4.231469963277457
Epoch: 5594, Batch Gradient Norm after: 4.231469963277457
Epoch 5595/10000, Prediction Accuracy = 65.82692307692307%, Loss = 0.007242636647648537
Epoch: 5595, Batch Gradient Norm: 4.392631554166104
Epoch: 5595, Batch Gradient Norm after: 4.392631554166104
Epoch 5596/10000, Prediction Accuracy = 65.43461538461538%, Loss = 0.007412046767198122
Epoch: 5596, Batch Gradient Norm: 4.313453698672757
Epoch: 5596, Batch Gradient Norm after: 4.313453698672757
Epoch 5597/10000, Prediction Accuracy = 65.10384615384613%, Loss = 0.0074805452201801995
Epoch: 5597, Batch Gradient Norm: 4.455591840649813
Epoch: 5597, Batch Gradient Norm after: 4.455591840649813
Epoch 5598/10000, Prediction Accuracy = 64.71923076923078%, Loss = 0.007565755003060286
Epoch: 5598, Batch Gradient Norm: 4.198806347206916
Epoch: 5598, Batch Gradient Norm after: 4.198806347206916
Epoch 5599/10000, Prediction Accuracy = 65.2423076923077%, Loss = 0.007379230792419269
Epoch: 5599, Batch Gradient Norm: 4.918634265453253
Epoch: 5599, Batch Gradient Norm after: 4.918634265453253
Epoch 5600/10000, Prediction Accuracy = 64.12307692307692%, Loss = 0.007652380109692995
Epoch: 5600, Batch Gradient Norm: 4.551730312007663
Epoch: 5600, Batch Gradient Norm after: 4.551730312007663
Epoch 5601/10000, Prediction Accuracy = 65.2%, Loss = 0.007470219790075834
Epoch: 5601, Batch Gradient Norm: 4.45065278918573
Epoch: 5601, Batch Gradient Norm after: 4.45065278918573
Epoch 5602/10000, Prediction Accuracy = 64.96923076923076%, Loss = 0.007448249389059269
Epoch: 5602, Batch Gradient Norm: 4.088316863367111
Epoch: 5602, Batch Gradient Norm after: 4.088316863367111
Epoch 5603/10000, Prediction Accuracy = 65.76923076923077%, Loss = 0.007299339649482415
Epoch: 5603, Batch Gradient Norm: 4.064815551265099
Epoch: 5603, Batch Gradient Norm after: 4.064815551265099
Epoch 5604/10000, Prediction Accuracy = 65.53846153846153%, Loss = 0.007320203460179842
Epoch: 5604, Batch Gradient Norm: 4.302584193044947
Epoch: 5604, Batch Gradient Norm after: 4.302584193044947
Epoch 5605/10000, Prediction Accuracy = 65.06153846153846%, Loss = 0.007381953585606355
Epoch: 5605, Batch Gradient Norm: 4.373578593194272
Epoch: 5605, Batch Gradient Norm after: 4.373578593194272
Epoch 5606/10000, Prediction Accuracy = 65.1846153846154%, Loss = 0.007452192107358804
Epoch: 5606, Batch Gradient Norm: 4.2700606057417145
Epoch: 5606, Batch Gradient Norm after: 4.2700606057417145
Epoch 5607/10000, Prediction Accuracy = 65.0423076923077%, Loss = 0.007446341753865664
Epoch: 5607, Batch Gradient Norm: 4.279496231503062
Epoch: 5607, Batch Gradient Norm after: 4.279496231503062
Epoch 5608/10000, Prediction Accuracy = 65.12692307692308%, Loss = 0.007445121578012521
Epoch: 5608, Batch Gradient Norm: 4.1669058545991735
Epoch: 5608, Batch Gradient Norm after: 4.1669058545991735
Epoch 5609/10000, Prediction Accuracy = 65.63461538461537%, Loss = 0.0073781562969088554
Epoch: 5609, Batch Gradient Norm: 4.068501135800145
Epoch: 5609, Batch Gradient Norm after: 4.068501135800145
Epoch 5610/10000, Prediction Accuracy = 65.43461538461537%, Loss = 0.007361043029679702
Epoch: 5610, Batch Gradient Norm: 4.296929279817641
Epoch: 5610, Batch Gradient Norm after: 4.296929279817641
Epoch 5611/10000, Prediction Accuracy = 65.35000000000001%, Loss = 0.007477320694866089
Epoch: 5611, Batch Gradient Norm: 4.223513589656954
Epoch: 5611, Batch Gradient Norm after: 4.223513589656954
Epoch 5612/10000, Prediction Accuracy = 65.3576923076923%, Loss = 0.0073681851992240316
Epoch: 5612, Batch Gradient Norm: 4.307113406406633
Epoch: 5612, Batch Gradient Norm after: 4.307113406406633
Epoch 5613/10000, Prediction Accuracy = 65.53076923076924%, Loss = 0.0073371723724099305
Epoch: 5613, Batch Gradient Norm: 4.57256761103151
Epoch: 5613, Batch Gradient Norm after: 4.57256761103151
Epoch 5614/10000, Prediction Accuracy = 65.53461538461538%, Loss = 0.007352941991904607
Epoch: 5614, Batch Gradient Norm: 4.364062246413307
Epoch: 5614, Batch Gradient Norm after: 4.364062246413307
Epoch 5615/10000, Prediction Accuracy = 64.94999999999999%, Loss = 0.007375041703478648
Epoch: 5615, Batch Gradient Norm: 4.298445392814108
Epoch: 5615, Batch Gradient Norm after: 4.298445392814108
Epoch 5616/10000, Prediction Accuracy = 65.32692307692307%, Loss = 0.007366960330937917
Epoch: 5616, Batch Gradient Norm: 4.4311743584111305
Epoch: 5616, Batch Gradient Norm after: 4.4311743584111305
Epoch 5617/10000, Prediction Accuracy = 65.45384615384616%, Loss = 0.007398911823446934
Epoch: 5617, Batch Gradient Norm: 4.827344767461684
Epoch: 5617, Batch Gradient Norm after: 4.827344767461684
Epoch 5618/10000, Prediction Accuracy = 64.53461538461539%, Loss = 0.007624044154699032
Epoch: 5618, Batch Gradient Norm: 4.897881515454458
Epoch: 5618, Batch Gradient Norm after: 4.897881515454458
Epoch 5619/10000, Prediction Accuracy = 64.19615384615385%, Loss = 0.007779073901474476
Epoch: 5619, Batch Gradient Norm: 4.039199750334224
Epoch: 5619, Batch Gradient Norm after: 4.039199750334224
Epoch 5620/10000, Prediction Accuracy = 65.05769230769229%, Loss = 0.00737174922743669
Epoch: 5620, Batch Gradient Norm: 4.01029092540125
Epoch: 5620, Batch Gradient Norm after: 4.01029092540125
Epoch 5621/10000, Prediction Accuracy = 65.24999999999999%, Loss = 0.007345097067837532
Epoch: 5621, Batch Gradient Norm: 4.389316049760751
Epoch: 5621, Batch Gradient Norm after: 4.389316049760751
Epoch 5622/10000, Prediction Accuracy = 65.03461538461539%, Loss = 0.007419622861422026
Epoch: 5622, Batch Gradient Norm: 4.623760812577267
Epoch: 5622, Batch Gradient Norm after: 4.623760812577267
Epoch 5623/10000, Prediction Accuracy = 64.90384615384616%, Loss = 0.0076961280921330815
Epoch: 5623, Batch Gradient Norm: 4.1856464806915215
Epoch: 5623, Batch Gradient Norm after: 4.1856464806915215
Epoch 5624/10000, Prediction Accuracy = 65.15%, Loss = 0.007546062760341626
Epoch: 5624, Batch Gradient Norm: 4.326159499117722
Epoch: 5624, Batch Gradient Norm after: 4.326159499117722
Epoch 5625/10000, Prediction Accuracy = 65.46923076923076%, Loss = 0.007366222866739218
Epoch: 5625, Batch Gradient Norm: 4.4756185377197015
Epoch: 5625, Batch Gradient Norm after: 4.4756185377197015
Epoch 5626/10000, Prediction Accuracy = 65.27307692307693%, Loss = 0.007431360212369607
Epoch: 5626, Batch Gradient Norm: 4.757530238432932
Epoch: 5626, Batch Gradient Norm after: 4.757530238432932
Epoch 5627/10000, Prediction Accuracy = 65.14999999999999%, Loss = 0.007599316250819426
Epoch: 5627, Batch Gradient Norm: 4.4148585823147615
Epoch: 5627, Batch Gradient Norm after: 4.4148585823147615
Epoch 5628/10000, Prediction Accuracy = 65.12692307692308%, Loss = 0.007424650248140097
Epoch: 5628, Batch Gradient Norm: 4.152429237882268
Epoch: 5628, Batch Gradient Norm after: 4.152429237882268
Epoch 5629/10000, Prediction Accuracy = 65.12692307692308%, Loss = 0.00744238502990741
Epoch: 5629, Batch Gradient Norm: 3.9812498753620686
Epoch: 5629, Batch Gradient Norm after: 3.9812498753620686
Epoch 5630/10000, Prediction Accuracy = 65.1923076923077%, Loss = 0.0071898508243835885
Epoch: 5630, Batch Gradient Norm: 4.2065830726461195
Epoch: 5630, Batch Gradient Norm after: 4.2065830726461195
Epoch 5631/10000, Prediction Accuracy = 65.46153846153847%, Loss = 0.00728638291072387
Epoch: 5631, Batch Gradient Norm: 4.586763997614871
Epoch: 5631, Batch Gradient Norm after: 4.586763997614871
Epoch 5632/10000, Prediction Accuracy = 64.95769230769231%, Loss = 0.007579518732829736
Epoch: 5632, Batch Gradient Norm: 4.272318740854838
Epoch: 5632, Batch Gradient Norm after: 4.272318740854838
Epoch 5633/10000, Prediction Accuracy = 65.98076923076923%, Loss = 0.007334841415286064
Epoch: 5633, Batch Gradient Norm: 4.379171276082806
Epoch: 5633, Batch Gradient Norm after: 4.379171276082806
Epoch 5634/10000, Prediction Accuracy = 65.46923076923076%, Loss = 0.007376277890916054
Epoch: 5634, Batch Gradient Norm: 4.043975838518098
Epoch: 5634, Batch Gradient Norm after: 4.043975838518098
Epoch 5635/10000, Prediction Accuracy = 65.6076923076923%, Loss = 0.007306507394577448
Epoch: 5635, Batch Gradient Norm: 4.4678035603657715
Epoch: 5635, Batch Gradient Norm after: 4.4678035603657715
Epoch 5636/10000, Prediction Accuracy = 65.27692307692308%, Loss = 0.007508191709908156
Epoch: 5636, Batch Gradient Norm: 4.549902613771677
Epoch: 5636, Batch Gradient Norm after: 4.549902613771677
Epoch 5637/10000, Prediction Accuracy = 65.00384615384614%, Loss = 0.007523118052631617
Epoch: 5637, Batch Gradient Norm: 3.8951227959282444
Epoch: 5637, Batch Gradient Norm after: 3.8951227959282444
Epoch 5638/10000, Prediction Accuracy = 65.68461538461538%, Loss = 0.007181494532582851
Epoch: 5638, Batch Gradient Norm: 4.146897578893268
Epoch: 5638, Batch Gradient Norm after: 4.146897578893268
Epoch 5639/10000, Prediction Accuracy = 66.13076923076923%, Loss = 0.007258611014829232
Epoch: 5639, Batch Gradient Norm: 4.435260517641059
Epoch: 5639, Batch Gradient Norm after: 4.435260517641059
Epoch 5640/10000, Prediction Accuracy = 65.24230769230768%, Loss = 0.007467042547292435
Epoch: 5640, Batch Gradient Norm: 4.243016212546957
Epoch: 5640, Batch Gradient Norm after: 4.243016212546957
Epoch 5641/10000, Prediction Accuracy = 64.94615384615385%, Loss = 0.007375552677191221
Epoch: 5641, Batch Gradient Norm: 4.240472720896831
Epoch: 5641, Batch Gradient Norm after: 4.240472720896831
Epoch 5642/10000, Prediction Accuracy = 65.34230769230768%, Loss = 0.007328048026045928
Epoch: 5642, Batch Gradient Norm: 4.700382338363804
Epoch: 5642, Batch Gradient Norm after: 4.700382338363804
Epoch 5643/10000, Prediction Accuracy = 64.71923076923076%, Loss = 0.0076482812157617165
Epoch: 5643, Batch Gradient Norm: 4.7677235106683025
Epoch: 5643, Batch Gradient Norm after: 4.7677235106683025
Epoch 5644/10000, Prediction Accuracy = 64.56923076923077%, Loss = 0.007574850048583288
Epoch: 5644, Batch Gradient Norm: 4.5387663246325936
Epoch: 5644, Batch Gradient Norm after: 4.5387663246325936
Epoch 5645/10000, Prediction Accuracy = 64.39615384615385%, Loss = 0.007632564287632704
Epoch: 5645, Batch Gradient Norm: 4.5811610487711345
Epoch: 5645, Batch Gradient Norm after: 4.5811610487711345
Epoch 5646/10000, Prediction Accuracy = 64.8576923076923%, Loss = 0.007529151196090074
Epoch: 5646, Batch Gradient Norm: 4.254334231736674
Epoch: 5646, Batch Gradient Norm after: 4.254334231736674
Epoch 5647/10000, Prediction Accuracy = 64.75000000000001%, Loss = 0.0075454291027898975
Epoch: 5647, Batch Gradient Norm: 4.156719395090559
Epoch: 5647, Batch Gradient Norm after: 4.156719395090559
Epoch 5648/10000, Prediction Accuracy = 65.16153846153847%, Loss = 0.007364503896007171
Epoch: 5648, Batch Gradient Norm: 4.331962231745822
Epoch: 5648, Batch Gradient Norm after: 4.331962231745822
Epoch 5649/10000, Prediction Accuracy = 65.17692307692309%, Loss = 0.007364552862082536
Epoch: 5649, Batch Gradient Norm: 4.342997650053578
Epoch: 5649, Batch Gradient Norm after: 4.342997650053578
Epoch 5650/10000, Prediction Accuracy = 65.30384615384615%, Loss = 0.007414190277743798
Epoch: 5650, Batch Gradient Norm: 4.015439284220906
Epoch: 5650, Batch Gradient Norm after: 4.015439284220906
Epoch 5651/10000, Prediction Accuracy = 66.14615384615384%, Loss = 0.007259576115757227
Epoch: 5651, Batch Gradient Norm: 4.1720662177664725
Epoch: 5651, Batch Gradient Norm after: 4.1720662177664725
Epoch 5652/10000, Prediction Accuracy = 65.17307692307693%, Loss = 0.00737051572650671
Epoch: 5652, Batch Gradient Norm: 4.147912850194025
Epoch: 5652, Batch Gradient Norm after: 4.147912850194025
Epoch 5653/10000, Prediction Accuracy = 65.53846153846155%, Loss = 0.007353842831574953
Epoch: 5653, Batch Gradient Norm: 4.585040687964942
Epoch: 5653, Batch Gradient Norm after: 4.585040687964942
Epoch 5654/10000, Prediction Accuracy = 64.83846153846153%, Loss = 0.0075471940665290905
Epoch: 5654, Batch Gradient Norm: 4.802030860962718
Epoch: 5654, Batch Gradient Norm after: 4.802030860962718
Epoch 5655/10000, Prediction Accuracy = 64.0923076923077%, Loss = 0.007760166584585722
Epoch: 5655, Batch Gradient Norm: 4.41821894221011
Epoch: 5655, Batch Gradient Norm after: 4.41821894221011
Epoch 5656/10000, Prediction Accuracy = 64.74615384615385%, Loss = 0.007549930113152816
Epoch: 5656, Batch Gradient Norm: 4.437321828182108
Epoch: 5656, Batch Gradient Norm after: 4.437321828182108
Epoch 5657/10000, Prediction Accuracy = 65.16538461538461%, Loss = 0.0074967736593232704
Epoch: 5657, Batch Gradient Norm: 4.325448349737597
Epoch: 5657, Batch Gradient Norm after: 4.325448349737597
Epoch 5658/10000, Prediction Accuracy = 65.53461538461539%, Loss = 0.0073720276570664
Epoch: 5658, Batch Gradient Norm: 4.138708281067041
Epoch: 5658, Batch Gradient Norm after: 4.138708281067041
Epoch 5659/10000, Prediction Accuracy = 65.66923076923077%, Loss = 0.00728427292779088
Epoch: 5659, Batch Gradient Norm: 4.836999877402664
Epoch: 5659, Batch Gradient Norm after: 4.836999877402664
Epoch 5660/10000, Prediction Accuracy = 64.39615384615385%, Loss = 0.0077124571499343104
Epoch: 5660, Batch Gradient Norm: 4.093719124763697
Epoch: 5660, Batch Gradient Norm after: 4.093719124763697
Epoch 5661/10000, Prediction Accuracy = 65.4576923076923%, Loss = 0.007322993774253588
Epoch: 5661, Batch Gradient Norm: 3.8890876639477607
Epoch: 5661, Batch Gradient Norm after: 3.8890876639477607
Epoch 5662/10000, Prediction Accuracy = 65.9076923076923%, Loss = 0.00718912801060539
Epoch: 5662, Batch Gradient Norm: 3.859602520937777
Epoch: 5662, Batch Gradient Norm after: 3.859602520937777
Epoch 5663/10000, Prediction Accuracy = 65.83461538461539%, Loss = 0.007144355179312138
Epoch: 5663, Batch Gradient Norm: 4.0829464622685245
Epoch: 5663, Batch Gradient Norm after: 4.0829464622685245
Epoch 5664/10000, Prediction Accuracy = 66.18846153846152%, Loss = 0.007261499153593412
Epoch: 5664, Batch Gradient Norm: 4.105876992207146
Epoch: 5664, Batch Gradient Norm after: 4.105876992207146
Epoch 5665/10000, Prediction Accuracy = 65.40769230769232%, Loss = 0.00732116956407061
Epoch: 5665, Batch Gradient Norm: 4.091929535559391
Epoch: 5665, Batch Gradient Norm after: 4.091929535559391
Epoch 5666/10000, Prediction Accuracy = 65.88461538461539%, Loss = 0.007200295392137308
Epoch: 5666, Batch Gradient Norm: 4.642001948857704
Epoch: 5666, Batch Gradient Norm after: 4.642001948857704
Epoch 5667/10000, Prediction Accuracy = 64.89615384615385%, Loss = 0.0075654763226898816
Epoch: 5667, Batch Gradient Norm: 4.230180557916849
Epoch: 5667, Batch Gradient Norm after: 4.230180557916849
Epoch 5668/10000, Prediction Accuracy = 65.54615384615384%, Loss = 0.007339455832082491
Epoch: 5668, Batch Gradient Norm: 4.3084960089734885
Epoch: 5668, Batch Gradient Norm after: 4.3084960089734885
Epoch 5669/10000, Prediction Accuracy = 65.25384615384614%, Loss = 0.0073556719849315975
Epoch: 5669, Batch Gradient Norm: 4.445817948823219
Epoch: 5669, Batch Gradient Norm after: 4.445817948823219
Epoch 5670/10000, Prediction Accuracy = 65.08846153846154%, Loss = 0.00749948201701045
Epoch: 5670, Batch Gradient Norm: 4.6093379144358115
Epoch: 5670, Batch Gradient Norm after: 4.6093379144358115
Epoch 5671/10000, Prediction Accuracy = 64.63846153846156%, Loss = 0.007592138117895677
Epoch: 5671, Batch Gradient Norm: 4.862221030222401
Epoch: 5671, Batch Gradient Norm after: 4.862221030222401
Epoch 5672/10000, Prediction Accuracy = 64.5153846153846%, Loss = 0.007737688111284604
Epoch: 5672, Batch Gradient Norm: 4.384719851295652
Epoch: 5672, Batch Gradient Norm after: 4.384719851295652
Epoch 5673/10000, Prediction Accuracy = 65.11153846153846%, Loss = 0.007561971039439623
Epoch: 5673, Batch Gradient Norm: 4.5030791343845085
Epoch: 5673, Batch Gradient Norm after: 4.5030791343845085
Epoch 5674/10000, Prediction Accuracy = 65.04999999999998%, Loss = 0.007597009794643292
Epoch: 5674, Batch Gradient Norm: 4.207909652668625
Epoch: 5674, Batch Gradient Norm after: 4.207909652668625
Epoch 5675/10000, Prediction Accuracy = 65.10384615384613%, Loss = 0.007480051153554366
Epoch: 5675, Batch Gradient Norm: 4.43104214750501
Epoch: 5675, Batch Gradient Norm after: 4.43104214750501
Epoch 5676/10000, Prediction Accuracy = 64.60384615384615%, Loss = 0.0075495202237596875
Epoch: 5676, Batch Gradient Norm: 4.317994227433355
Epoch: 5676, Batch Gradient Norm after: 4.317994227433355
Epoch 5677/10000, Prediction Accuracy = 64.59615384615384%, Loss = 0.007458761979181033
Epoch: 5677, Batch Gradient Norm: 3.910963351855428
Epoch: 5677, Batch Gradient Norm after: 3.910963351855428
Epoch 5678/10000, Prediction Accuracy = 65.77307692307693%, Loss = 0.007121914961876778
Epoch: 5678, Batch Gradient Norm: 3.7939964365152132
Epoch: 5678, Batch Gradient Norm after: 3.7939964365152132
Epoch 5679/10000, Prediction Accuracy = 66.07307692307691%, Loss = 0.007048476236657455
Epoch: 5679, Batch Gradient Norm: 4.175461491139856
Epoch: 5679, Batch Gradient Norm after: 4.175461491139856
Epoch 5680/10000, Prediction Accuracy = 65.33076923076922%, Loss = 0.007208985240700154
Epoch: 5680, Batch Gradient Norm: 4.119350180608246
Epoch: 5680, Batch Gradient Norm after: 4.119350180608246
Epoch 5681/10000, Prediction Accuracy = 65.65769230769232%, Loss = 0.007187295096138349
Epoch: 5681, Batch Gradient Norm: 4.414253487637323
Epoch: 5681, Batch Gradient Norm after: 4.414253487637323
Epoch 5682/10000, Prediction Accuracy = 64.93846153846154%, Loss = 0.007491261375924716
Epoch: 5682, Batch Gradient Norm: 4.207377537588137
Epoch: 5682, Batch Gradient Norm after: 4.207377537588137
Epoch 5683/10000, Prediction Accuracy = 65.31153846153846%, Loss = 0.007288156614567225
Epoch: 5683, Batch Gradient Norm: 4.222740497137057
Epoch: 5683, Batch Gradient Norm after: 4.222740497137057
Epoch 5684/10000, Prediction Accuracy = 65.22307692307695%, Loss = 0.00733531409731278
Epoch: 5684, Batch Gradient Norm: 4.473719867400006
Epoch: 5684, Batch Gradient Norm after: 4.473719867400006
Epoch 5685/10000, Prediction Accuracy = 65.28461538461538%, Loss = 0.0074133721466820976
Epoch: 5685, Batch Gradient Norm: 5.008676179334025
Epoch: 5685, Batch Gradient Norm after: 5.008676179334025
Epoch 5686/10000, Prediction Accuracy = 64.56538461538462%, Loss = 0.007693243750299399
Epoch: 5686, Batch Gradient Norm: 4.426267738762958
Epoch: 5686, Batch Gradient Norm after: 4.426267738762958
Epoch 5687/10000, Prediction Accuracy = 64.7653846153846%, Loss = 0.007486025587870524
Epoch: 5687, Batch Gradient Norm: 4.255386847043497
Epoch: 5687, Batch Gradient Norm after: 4.255386847043497
Epoch 5688/10000, Prediction Accuracy = 65.30384615384615%, Loss = 0.007381103646296721
Epoch: 5688, Batch Gradient Norm: 3.9405428863010017
Epoch: 5688, Batch Gradient Norm after: 3.9405428863010017
Epoch 5689/10000, Prediction Accuracy = 66.15%, Loss = 0.007129975881140966
Epoch: 5689, Batch Gradient Norm: 4.514318540261108
Epoch: 5689, Batch Gradient Norm after: 4.514318540261108
Epoch 5690/10000, Prediction Accuracy = 64.70769230769231%, Loss = 0.007524420722172811
Epoch: 5690, Batch Gradient Norm: 4.244826537547491
Epoch: 5690, Batch Gradient Norm after: 4.244826537547491
Epoch 5691/10000, Prediction Accuracy = 64.9846153846154%, Loss = 0.0074126629803616265
Epoch: 5691, Batch Gradient Norm: 3.961709334396258
Epoch: 5691, Batch Gradient Norm after: 3.961709334396258
Epoch 5692/10000, Prediction Accuracy = 65.56153846153846%, Loss = 0.007242135775203888
Epoch: 5692, Batch Gradient Norm: 4.779688449850809
Epoch: 5692, Batch Gradient Norm after: 4.779688449850809
Epoch 5693/10000, Prediction Accuracy = 64.65384615384615%, Loss = 0.007622960954904556
Epoch: 5693, Batch Gradient Norm: 4.182901800427188
Epoch: 5693, Batch Gradient Norm after: 4.182901800427188
Epoch 5694/10000, Prediction Accuracy = 65.48076923076923%, Loss = 0.007331521895069342
Epoch: 5694, Batch Gradient Norm: 4.249663176521838
Epoch: 5694, Batch Gradient Norm after: 4.249663176521838
Epoch 5695/10000, Prediction Accuracy = 65.41538461538461%, Loss = 0.00731399401019399
Epoch: 5695, Batch Gradient Norm: 4.050951573554686
Epoch: 5695, Batch Gradient Norm after: 4.050951573554686
Epoch 5696/10000, Prediction Accuracy = 65.91153846153847%, Loss = 0.007177323425331941
Epoch: 5696, Batch Gradient Norm: 4.122436879400341
Epoch: 5696, Batch Gradient Norm after: 4.122436879400341
Epoch 5697/10000, Prediction Accuracy = 66.05384615384615%, Loss = 0.007112021916187727
Epoch: 5697, Batch Gradient Norm: 4.498535968184403
Epoch: 5697, Batch Gradient Norm after: 4.498535968184403
Epoch 5698/10000, Prediction Accuracy = 65.61538461538461%, Loss = 0.007410867533718164
Epoch: 5698, Batch Gradient Norm: 4.620540830341768
Epoch: 5698, Batch Gradient Norm after: 4.620540830341768
Epoch 5699/10000, Prediction Accuracy = 64.70384615384616%, Loss = 0.007566406355740933
Epoch: 5699, Batch Gradient Norm: 4.625769789955092
Epoch: 5699, Batch Gradient Norm after: 4.625769789955092
Epoch 5700/10000, Prediction Accuracy = 64.81923076923076%, Loss = 0.007537652308551164
Epoch: 5700, Batch Gradient Norm: 4.31934979708983
Epoch: 5700, Batch Gradient Norm after: 4.31934979708983
Epoch 5701/10000, Prediction Accuracy = 65.00000000000001%, Loss = 0.007320564096936813
Epoch: 5701, Batch Gradient Norm: 4.348970231187097
Epoch: 5701, Batch Gradient Norm after: 4.348970231187097
Epoch 5702/10000, Prediction Accuracy = 65.17692307692309%, Loss = 0.007319356314837933
Epoch: 5702, Batch Gradient Norm: 3.9806151121761033
Epoch: 5702, Batch Gradient Norm after: 3.9806151121761033
Epoch 5703/10000, Prediction Accuracy = 65.75384615384614%, Loss = 0.007122960049085892
Epoch: 5703, Batch Gradient Norm: 3.903981502026665
Epoch: 5703, Batch Gradient Norm after: 3.903981502026665
Epoch 5704/10000, Prediction Accuracy = 66.33846153846156%, Loss = 0.007038959302008152
Epoch: 5704, Batch Gradient Norm: 4.569010920977234
Epoch: 5704, Batch Gradient Norm after: 4.569010920977234
Epoch 5705/10000, Prediction Accuracy = 65.49999999999999%, Loss = 0.00735495132035934
Epoch: 5705, Batch Gradient Norm: 4.049664735961928
Epoch: 5705, Batch Gradient Norm after: 4.049664735961928
Epoch 5706/10000, Prediction Accuracy = 66.18846153846154%, Loss = 0.007103792212616939
Epoch: 5706, Batch Gradient Norm: 4.656567262729808
Epoch: 5706, Batch Gradient Norm after: 4.656567262729808
Epoch 5707/10000, Prediction Accuracy = 65.03076923076922%, Loss = 0.007442432921379805
Epoch: 5707, Batch Gradient Norm: 4.182447440623872
Epoch: 5707, Batch Gradient Norm after: 4.182447440623872
Epoch 5708/10000, Prediction Accuracy = 65.97692307692309%, Loss = 0.0072702313056932045
Epoch: 5708, Batch Gradient Norm: 4.593896569751866
Epoch: 5708, Batch Gradient Norm after: 4.593896569751866
Epoch 5709/10000, Prediction Accuracy = 64.78076923076924%, Loss = 0.0075062314191689855
Epoch: 5709, Batch Gradient Norm: 4.2212913024628005
Epoch: 5709, Batch Gradient Norm after: 4.2212913024628005
Epoch 5710/10000, Prediction Accuracy = 64.8076923076923%, Loss = 0.007380941775269234
Epoch: 5710, Batch Gradient Norm: 3.7810968993455027
Epoch: 5710, Batch Gradient Norm after: 3.7810968993455027
Epoch 5711/10000, Prediction Accuracy = 66.38076923076923%, Loss = 0.007014439262163181
Epoch: 5711, Batch Gradient Norm: 4.360313106660331
Epoch: 5711, Batch Gradient Norm after: 4.360313106660331
Epoch 5712/10000, Prediction Accuracy = 65.30384615384615%, Loss = 0.007351117566801035
Epoch: 5712, Batch Gradient Norm: 4.612503446622223
Epoch: 5712, Batch Gradient Norm after: 4.612503446622223
Epoch 5713/10000, Prediction Accuracy = 65.01923076923077%, Loss = 0.007473921976410425
Epoch: 5713, Batch Gradient Norm: 4.814356594341433
Epoch: 5713, Batch Gradient Norm after: 4.814356594341433
Epoch 5714/10000, Prediction Accuracy = 64.86153846153846%, Loss = 0.007556813446661601
Epoch: 5714, Batch Gradient Norm: 4.77123397354583
Epoch: 5714, Batch Gradient Norm after: 4.77123397354583
Epoch 5715/10000, Prediction Accuracy = 64.3423076923077%, Loss = 0.007670021042800867
Epoch: 5715, Batch Gradient Norm: 4.7107392956773175
Epoch: 5715, Batch Gradient Norm after: 4.7107392956773175
Epoch 5716/10000, Prediction Accuracy = 64.71538461538461%, Loss = 0.007613174688930695
Epoch: 5716, Batch Gradient Norm: 4.760600111692401
Epoch: 5716, Batch Gradient Norm after: 4.760600111692401
Epoch 5717/10000, Prediction Accuracy = 65.00384615384614%, Loss = 0.007549089236328235
Epoch: 5717, Batch Gradient Norm: 4.380223524330509
Epoch: 5717, Batch Gradient Norm after: 4.380223524330509
Epoch 5718/10000, Prediction Accuracy = 64.87692307692308%, Loss = 0.007491510218152633
Epoch: 5718, Batch Gradient Norm: 4.225553208245941
Epoch: 5718, Batch Gradient Norm after: 4.225553208245941
Epoch 5719/10000, Prediction Accuracy = 65.88461538461537%, Loss = 0.007296069310261653
Epoch: 5719, Batch Gradient Norm: 4.279833479605594
Epoch: 5719, Batch Gradient Norm after: 4.279833479605594
Epoch 5720/10000, Prediction Accuracy = 65.18076923076923%, Loss = 0.007447153508949738
Epoch: 5720, Batch Gradient Norm: 3.8484109765817016
Epoch: 5720, Batch Gradient Norm after: 3.8484109765817016
Epoch 5721/10000, Prediction Accuracy = 65.83846153846153%, Loss = 0.007101828769709055
Epoch: 5721, Batch Gradient Norm: 3.8727965328753418
Epoch: 5721, Batch Gradient Norm after: 3.8727965328753418
Epoch 5722/10000, Prediction Accuracy = 66.0576923076923%, Loss = 0.007079810369759798
Epoch: 5722, Batch Gradient Norm: 4.837989295200575
Epoch: 5722, Batch Gradient Norm after: 4.837989295200575
Epoch 5723/10000, Prediction Accuracy = 64.5153846153846%, Loss = 0.0075828525810860675
Epoch: 5723, Batch Gradient Norm: 4.7977204908683175
Epoch: 5723, Batch Gradient Norm after: 4.7977204908683175
Epoch 5724/10000, Prediction Accuracy = 64.15384615384615%, Loss = 0.00759306438983633
Epoch: 5724, Batch Gradient Norm: 4.217273799597266
Epoch: 5724, Batch Gradient Norm after: 4.217273799597266
Epoch 5725/10000, Prediction Accuracy = 65.47692307692307%, Loss = 0.007375386077910662
Epoch: 5725, Batch Gradient Norm: 4.212230351343988
Epoch: 5725, Batch Gradient Norm after: 4.212230351343988
Epoch 5726/10000, Prediction Accuracy = 65.50769230769231%, Loss = 0.007279447530611203
Epoch: 5726, Batch Gradient Norm: 4.167395729520446
Epoch: 5726, Batch Gradient Norm after: 4.167395729520446
Epoch 5727/10000, Prediction Accuracy = 65.3423076923077%, Loss = 0.007272768873148239
Epoch: 5727, Batch Gradient Norm: 4.576408734778525
Epoch: 5727, Batch Gradient Norm after: 4.576408734778525
Epoch 5728/10000, Prediction Accuracy = 65.42307692307692%, Loss = 0.007369561550708918
Epoch: 5728, Batch Gradient Norm: 4.417938393661855
Epoch: 5728, Batch Gradient Norm after: 4.417938393661855
Epoch 5729/10000, Prediction Accuracy = 65.35769230769232%, Loss = 0.00738281448586629
Epoch: 5729, Batch Gradient Norm: 4.158183673414826
Epoch: 5729, Batch Gradient Norm after: 4.158183673414826
Epoch 5730/10000, Prediction Accuracy = 65.71538461538462%, Loss = 0.007303114693898421
Epoch: 5730, Batch Gradient Norm: 4.365275950486449
Epoch: 5730, Batch Gradient Norm after: 4.365275950486449
Epoch 5731/10000, Prediction Accuracy = 65.26153846153845%, Loss = 0.007435937268802753
Epoch: 5731, Batch Gradient Norm: 4.224053521811802
Epoch: 5731, Batch Gradient Norm after: 4.224053521811802
Epoch 5732/10000, Prediction Accuracy = 65.14230769230768%, Loss = 0.007322045186391244
Epoch: 5732, Batch Gradient Norm: 4.281674375645211
Epoch: 5732, Batch Gradient Norm after: 4.281674375645211
Epoch 5733/10000, Prediction Accuracy = 65.83846153846153%, Loss = 0.00726738041983201
Epoch: 5733, Batch Gradient Norm: 4.276325755739268
Epoch: 5733, Batch Gradient Norm after: 4.276325755739268
Epoch 5734/10000, Prediction Accuracy = 66.2%, Loss = 0.007213906850665808
Epoch: 5734, Batch Gradient Norm: 4.256553215681337
Epoch: 5734, Batch Gradient Norm after: 4.256553215681337
Epoch 5735/10000, Prediction Accuracy = 65.5653846153846%, Loss = 0.007382960094568821
Epoch: 5735, Batch Gradient Norm: 4.1307393864805055
Epoch: 5735, Batch Gradient Norm after: 4.1307393864805055
Epoch 5736/10000, Prediction Accuracy = 65.64615384615384%, Loss = 0.007215459616138385
Epoch: 5736, Batch Gradient Norm: 4.381248464681014
Epoch: 5736, Batch Gradient Norm after: 4.381248464681014
Epoch 5737/10000, Prediction Accuracy = 65.62692307692308%, Loss = 0.0073204927791196564
Epoch: 5737, Batch Gradient Norm: 4.36312567716279
Epoch: 5737, Batch Gradient Norm after: 4.36312567716279
Epoch 5738/10000, Prediction Accuracy = 65.14615384615385%, Loss = 0.0073813538496884015
Epoch: 5738, Batch Gradient Norm: 4.389486988694904
Epoch: 5738, Batch Gradient Norm after: 4.389486988694904
Epoch 5739/10000, Prediction Accuracy = 65.35769230769232%, Loss = 0.007296820959219566
Epoch: 5739, Batch Gradient Norm: 4.471076230805904
Epoch: 5739, Batch Gradient Norm after: 4.471076230805904
Epoch 5740/10000, Prediction Accuracy = 64.63461538461539%, Loss = 0.007444850419862912
Epoch: 5740, Batch Gradient Norm: 4.127744744945579
Epoch: 5740, Batch Gradient Norm after: 4.127744744945579
Epoch 5741/10000, Prediction Accuracy = 65.89615384615385%, Loss = 0.00718522985250904
Epoch: 5741, Batch Gradient Norm: 4.22953907943133
Epoch: 5741, Batch Gradient Norm after: 4.22953907943133
Epoch 5742/10000, Prediction Accuracy = 65.16538461538461%, Loss = 0.007316546944471506
Epoch: 5742, Batch Gradient Norm: 4.28135336033537
Epoch: 5742, Batch Gradient Norm after: 4.28135336033537
Epoch 5743/10000, Prediction Accuracy = 65.16153846153846%, Loss = 0.0073469455640476486
Epoch: 5743, Batch Gradient Norm: 4.334853691694561
Epoch: 5743, Batch Gradient Norm after: 4.334853691694561
Epoch 5744/10000, Prediction Accuracy = 65.86923076923077%, Loss = 0.00723095925954672
Epoch: 5744, Batch Gradient Norm: 3.989591426606143
Epoch: 5744, Batch Gradient Norm after: 3.989591426606143
Epoch 5745/10000, Prediction Accuracy = 65.89615384615385%, Loss = 0.007083497834033691
Epoch: 5745, Batch Gradient Norm: 4.4500715009909575
Epoch: 5745, Batch Gradient Norm after: 4.4500715009909575
Epoch 5746/10000, Prediction Accuracy = 65.17692307692309%, Loss = 0.007358835436976873
Epoch: 5746, Batch Gradient Norm: 4.649441384668407
Epoch: 5746, Batch Gradient Norm after: 4.649441384668407
Epoch 5747/10000, Prediction Accuracy = 65.01923076923077%, Loss = 0.0074984675918061
Epoch: 5747, Batch Gradient Norm: 4.571478068433173
Epoch: 5747, Batch Gradient Norm after: 4.571478068433173
Epoch 5748/10000, Prediction Accuracy = 65.23076923076923%, Loss = 0.0074161047187562175
Epoch: 5748, Batch Gradient Norm: 4.354371005264241
Epoch: 5748, Batch Gradient Norm after: 4.354371005264241
Epoch 5749/10000, Prediction Accuracy = 65.03461538461539%, Loss = 0.00731034863453645
Epoch: 5749, Batch Gradient Norm: 4.591960205649294
Epoch: 5749, Batch Gradient Norm after: 4.591960205649294
Epoch 5750/10000, Prediction Accuracy = 65.36538461538463%, Loss = 0.007399549851050744
Epoch: 5750, Batch Gradient Norm: 4.588821955298189
Epoch: 5750, Batch Gradient Norm after: 4.588821955298189
Epoch 5751/10000, Prediction Accuracy = 65.53461538461538%, Loss = 0.0074391897337941024
Epoch: 5751, Batch Gradient Norm: 4.60306162979147
Epoch: 5751, Batch Gradient Norm after: 4.60306162979147
Epoch 5752/10000, Prediction Accuracy = 64.89615384615385%, Loss = 0.007531898024563606
Epoch: 5752, Batch Gradient Norm: 4.451535545010359
Epoch: 5752, Batch Gradient Norm after: 4.451535545010359
Epoch 5753/10000, Prediction Accuracy = 65.4076923076923%, Loss = 0.0074502227541345814
Epoch: 5753, Batch Gradient Norm: 4.661939153886632
Epoch: 5753, Batch Gradient Norm after: 4.661939153886632
Epoch 5754/10000, Prediction Accuracy = 64.76153846153846%, Loss = 0.007632078961111032
Epoch: 5754, Batch Gradient Norm: 4.828059863429452
Epoch: 5754, Batch Gradient Norm after: 4.828059863429452
Epoch 5755/10000, Prediction Accuracy = 63.92692307692308%, Loss = 0.0077822060467532045
Epoch: 5755, Batch Gradient Norm: 4.246375981869369
Epoch: 5755, Batch Gradient Norm after: 4.246375981869369
Epoch 5756/10000, Prediction Accuracy = 64.73461538461538%, Loss = 0.007502411420528705
Epoch: 5756, Batch Gradient Norm: 4.5570158590082395
Epoch: 5756, Batch Gradient Norm after: 4.5570158590082395
Epoch 5757/10000, Prediction Accuracy = 64.88846153846154%, Loss = 0.007616667793347285
Epoch: 5757, Batch Gradient Norm: 3.9049714484584492
Epoch: 5757, Batch Gradient Norm after: 3.9049714484584492
Epoch 5758/10000, Prediction Accuracy = 65.85384615384615%, Loss = 0.007144120486023335
Epoch: 5758, Batch Gradient Norm: 4.463295792532572
Epoch: 5758, Batch Gradient Norm after: 4.463295792532572
Epoch 5759/10000, Prediction Accuracy = 65.53461538461538%, Loss = 0.007388400236287942
Epoch: 5759, Batch Gradient Norm: 4.598123450903168
Epoch: 5759, Batch Gradient Norm after: 4.598123450903168
Epoch 5760/10000, Prediction Accuracy = 64.85384615384615%, Loss = 0.007500845115058697
Epoch: 5760, Batch Gradient Norm: 4.497290498681806
Epoch: 5760, Batch Gradient Norm after: 4.497290498681806
Epoch 5761/10000, Prediction Accuracy = 64.77692307692308%, Loss = 0.007483923162978429
Epoch: 5761, Batch Gradient Norm: 4.696044258853401
Epoch: 5761, Batch Gradient Norm after: 4.696044258853401
Epoch 5762/10000, Prediction Accuracy = 65.23461538461538%, Loss = 0.007568511037299266
Epoch: 5762, Batch Gradient Norm: 4.376807236814716
Epoch: 5762, Batch Gradient Norm after: 4.376807236814716
Epoch 5763/10000, Prediction Accuracy = 65.10384615384616%, Loss = 0.007507633274564376
Epoch: 5763, Batch Gradient Norm: 4.355214932898579
Epoch: 5763, Batch Gradient Norm after: 4.355214932898579
Epoch 5764/10000, Prediction Accuracy = 65.32307692307693%, Loss = 0.007400485221296549
Epoch: 5764, Batch Gradient Norm: 4.391637681742997
Epoch: 5764, Batch Gradient Norm after: 4.391637681742997
Epoch 5765/10000, Prediction Accuracy = 65.63846153846154%, Loss = 0.007401905918064026
Epoch: 5765, Batch Gradient Norm: 4.434696603009326
Epoch: 5765, Batch Gradient Norm after: 4.434696603009326
Epoch 5766/10000, Prediction Accuracy = 65.15384615384616%, Loss = 0.0074678619678777
Epoch: 5766, Batch Gradient Norm: 3.9016133336396326
Epoch: 5766, Batch Gradient Norm after: 3.9016133336396326
Epoch 5767/10000, Prediction Accuracy = 66.02307692307691%, Loss = 0.0072881465849394984
Epoch: 5767, Batch Gradient Norm: 4.210678972617729
Epoch: 5767, Batch Gradient Norm after: 4.210678972617729
Epoch 5768/10000, Prediction Accuracy = 65.48846153846154%, Loss = 0.007271540924333609
Epoch: 5768, Batch Gradient Norm: 4.324529418571899
Epoch: 5768, Batch Gradient Norm after: 4.324529418571899
Epoch 5769/10000, Prediction Accuracy = 65.33461538461539%, Loss = 0.007345504199083035
Epoch: 5769, Batch Gradient Norm: 4.28204332864873
Epoch: 5769, Batch Gradient Norm after: 4.28204332864873
Epoch 5770/10000, Prediction Accuracy = 65.15769230769232%, Loss = 0.007343411517257874
Epoch: 5770, Batch Gradient Norm: 4.470873100809516
Epoch: 5770, Batch Gradient Norm after: 4.470873100809516
Epoch 5771/10000, Prediction Accuracy = 65.33076923076923%, Loss = 0.007404717115255503
Epoch: 5771, Batch Gradient Norm: 4.0559617256877205
Epoch: 5771, Batch Gradient Norm after: 4.0559617256877205
Epoch 5772/10000, Prediction Accuracy = 65.63846153846156%, Loss = 0.0072060792635266595
Epoch: 5772, Batch Gradient Norm: 4.048309449698783
Epoch: 5772, Batch Gradient Norm after: 4.048309449698783
Epoch 5773/10000, Prediction Accuracy = 65.78461538461538%, Loss = 0.007207625402280917
Epoch: 5773, Batch Gradient Norm: 4.112551818767909
Epoch: 5773, Batch Gradient Norm after: 4.112551818767909
Epoch 5774/10000, Prediction Accuracy = 65.65769230769232%, Loss = 0.007274818355933978
Epoch: 5774, Batch Gradient Norm: 3.9067753475331153
Epoch: 5774, Batch Gradient Norm after: 3.9067753475331153
Epoch 5775/10000, Prediction Accuracy = 65.8076923076923%, Loss = 0.007153711138436427
Epoch: 5775, Batch Gradient Norm: 4.585704103853206
Epoch: 5775, Batch Gradient Norm after: 4.585704103853206
Epoch 5776/10000, Prediction Accuracy = 65.17692307692309%, Loss = 0.0073510853645320125
Epoch: 5776, Batch Gradient Norm: 5.01031610997781
Epoch: 5776, Batch Gradient Norm after: 5.01031610997781
Epoch 5777/10000, Prediction Accuracy = 64.8576923076923%, Loss = 0.007698465102853684
Epoch: 5777, Batch Gradient Norm: 4.830328635425347
Epoch: 5777, Batch Gradient Norm after: 4.830328635425347
Epoch 5778/10000, Prediction Accuracy = 64.55384615384615%, Loss = 0.007779133112098162
Epoch: 5778, Batch Gradient Norm: 4.170884504289705
Epoch: 5778, Batch Gradient Norm after: 4.170884504289705
Epoch 5779/10000, Prediction Accuracy = 65.27307692307693%, Loss = 0.007341754192916246
Epoch: 5779, Batch Gradient Norm: 4.000696977394703
Epoch: 5779, Batch Gradient Norm after: 4.000696977394703
Epoch 5780/10000, Prediction Accuracy = 65.66153846153846%, Loss = 0.007260409721101706
Epoch: 5780, Batch Gradient Norm: 3.910798883730493
Epoch: 5780, Batch Gradient Norm after: 3.910798883730493
Epoch 5781/10000, Prediction Accuracy = 65.64615384615385%, Loss = 0.00717858443609797
Epoch: 5781, Batch Gradient Norm: 4.065563106624963
Epoch: 5781, Batch Gradient Norm after: 4.065563106624963
Epoch 5782/10000, Prediction Accuracy = 65.02307692307693%, Loss = 0.007294246389602239
Epoch: 5782, Batch Gradient Norm: 4.661137902248409
Epoch: 5782, Batch Gradient Norm after: 4.661137902248409
Epoch 5783/10000, Prediction Accuracy = 65.0923076923077%, Loss = 0.007533136217926557
Epoch: 5783, Batch Gradient Norm: 4.13865481285445
Epoch: 5783, Batch Gradient Norm after: 4.13865481285445
Epoch 5784/10000, Prediction Accuracy = 65.58846153846153%, Loss = 0.007205957761750772
Epoch: 5784, Batch Gradient Norm: 3.7914638595700274
Epoch: 5784, Batch Gradient Norm after: 3.7914638595700274
Epoch 5785/10000, Prediction Accuracy = 66.13846153846154%, Loss = 0.007066314466870748
Epoch: 5785, Batch Gradient Norm: 4.399324371597198
Epoch: 5785, Batch Gradient Norm after: 4.399324371597198
Epoch 5786/10000, Prediction Accuracy = 65.3%, Loss = 0.007325342032485283
Epoch: 5786, Batch Gradient Norm: 4.3964097638826765
Epoch: 5786, Batch Gradient Norm after: 4.3964097638826765
Epoch 5787/10000, Prediction Accuracy = 65.4%, Loss = 0.007409660145640373
Epoch: 5787, Batch Gradient Norm: 4.314147738013419
Epoch: 5787, Batch Gradient Norm after: 4.314147738013419
Epoch 5788/10000, Prediction Accuracy = 65.30384615384615%, Loss = 0.007376918354286597
Epoch: 5788, Batch Gradient Norm: 4.328357897433612
Epoch: 5788, Batch Gradient Norm after: 4.328357897433612
Epoch 5789/10000, Prediction Accuracy = 65.66923076923077%, Loss = 0.007362205069512129
Epoch: 5789, Batch Gradient Norm: 4.737049917736122
Epoch: 5789, Batch Gradient Norm after: 4.737049917736122
Epoch 5790/10000, Prediction Accuracy = 64.52307692307693%, Loss = 0.007600089821677942
Epoch: 5790, Batch Gradient Norm: 4.258721673690048
Epoch: 5790, Batch Gradient Norm after: 4.258721673690048
Epoch 5791/10000, Prediction Accuracy = 65.12692307692308%, Loss = 0.0073932551492292145
Epoch: 5791, Batch Gradient Norm: 4.387442995472851
Epoch: 5791, Batch Gradient Norm after: 4.387442995472851
Epoch 5792/10000, Prediction Accuracy = 65.7%, Loss = 0.007361991474261651
Epoch: 5792, Batch Gradient Norm: 4.637388834913934
Epoch: 5792, Batch Gradient Norm after: 4.637388834913934
Epoch 5793/10000, Prediction Accuracy = 64.77692307692308%, Loss = 0.007639220521713679
Epoch: 5793, Batch Gradient Norm: 4.432484928816714
Epoch: 5793, Batch Gradient Norm after: 4.432484928816714
Epoch 5794/10000, Prediction Accuracy = 64.80384615384615%, Loss = 0.0075273188905647164
Epoch: 5794, Batch Gradient Norm: 4.510298410731046
Epoch: 5794, Batch Gradient Norm after: 4.510298410731046
Epoch 5795/10000, Prediction Accuracy = 64.54615384615384%, Loss = 0.007573371323255392
Epoch: 5795, Batch Gradient Norm: 4.504871573008636
Epoch: 5795, Batch Gradient Norm after: 4.504871573008636
Epoch 5796/10000, Prediction Accuracy = 65.2076923076923%, Loss = 0.00752221062206305
Epoch: 5796, Batch Gradient Norm: 4.344111812355666
Epoch: 5796, Batch Gradient Norm after: 4.344111812355666
Epoch 5797/10000, Prediction Accuracy = 65.01538461538462%, Loss = 0.007402520376042678
Epoch: 5797, Batch Gradient Norm: 4.403302910081868
Epoch: 5797, Batch Gradient Norm after: 4.403302910081868
Epoch 5798/10000, Prediction Accuracy = 65.40384615384616%, Loss = 0.00736802382967793
Epoch: 5798, Batch Gradient Norm: 4.450244577746488
Epoch: 5798, Batch Gradient Norm after: 4.450244577746488
Epoch 5799/10000, Prediction Accuracy = 65.73461538461538%, Loss = 0.007382434900276936
Epoch: 5799, Batch Gradient Norm: 4.337992773710896
Epoch: 5799, Batch Gradient Norm after: 4.337992773710896
Epoch 5800/10000, Prediction Accuracy = 65.50769230769231%, Loss = 0.0073576081687441236
Epoch: 5800, Batch Gradient Norm: 4.403801485576276
Epoch: 5800, Batch Gradient Norm after: 4.403801485576276
Epoch 5801/10000, Prediction Accuracy = 65.26153846153846%, Loss = 0.0074267353361042645
Epoch: 5801, Batch Gradient Norm: 4.431618596058671
Epoch: 5801, Batch Gradient Norm after: 4.431618596058671
Epoch 5802/10000, Prediction Accuracy = 65.05%, Loss = 0.007411966458536112
Epoch: 5802, Batch Gradient Norm: 4.486988054176122
Epoch: 5802, Batch Gradient Norm after: 4.486988054176122
Epoch 5803/10000, Prediction Accuracy = 65.63076923076923%, Loss = 0.0074420661952060005
Epoch: 5803, Batch Gradient Norm: 4.42761560921212
Epoch: 5803, Batch Gradient Norm after: 4.42761560921212
Epoch 5804/10000, Prediction Accuracy = 65.18846153846154%, Loss = 0.007463114837614389
Epoch: 5804, Batch Gradient Norm: 4.360726604760584
Epoch: 5804, Batch Gradient Norm after: 4.360726604760584
Epoch 5805/10000, Prediction Accuracy = 65.28076923076924%, Loss = 0.007385230193344446
Epoch: 5805, Batch Gradient Norm: 4.947168092062614
Epoch: 5805, Batch Gradient Norm after: 4.947168092062614
Epoch 5806/10000, Prediction Accuracy = 64.40769230769232%, Loss = 0.007715398911386728
Epoch: 5806, Batch Gradient Norm: 4.066553787257647
Epoch: 5806, Batch Gradient Norm after: 4.066553787257647
Epoch 5807/10000, Prediction Accuracy = 65.37307692307692%, Loss = 0.007271903459555828
Epoch: 5807, Batch Gradient Norm: 4.411487852702488
Epoch: 5807, Batch Gradient Norm after: 4.411487852702488
Epoch 5808/10000, Prediction Accuracy = 65.21923076923078%, Loss = 0.007387449105198567
Epoch: 5808, Batch Gradient Norm: 4.25749358158894
Epoch: 5808, Batch Gradient Norm after: 4.25749358158894
Epoch 5809/10000, Prediction Accuracy = 65.66538461538461%, Loss = 0.0072279243300167415
Epoch: 5809, Batch Gradient Norm: 4.381845240945434
Epoch: 5809, Batch Gradient Norm after: 4.381845240945434
Epoch 5810/10000, Prediction Accuracy = 65.38076923076923%, Loss = 0.007323053701279255
Epoch: 5810, Batch Gradient Norm: 3.9872833864065527
Epoch: 5810, Batch Gradient Norm after: 3.9872833864065527
Epoch 5811/10000, Prediction Accuracy = 65.75384615384615%, Loss = 0.007182655390352011
Epoch: 5811, Batch Gradient Norm: 4.149696513278592
Epoch: 5811, Batch Gradient Norm after: 4.149696513278592
Epoch: 5812, Batch Gradient Norm: 4.33440626516016
Epoch: 5812, Batch Gradient Norm after: 4.33440626516016
Epoch 5813/10000, Prediction Accuracy = 65.25384615384615%, Loss = 0.007390922508560694
Epoch: 5813, Batch Gradient Norm: 4.3525443293620105
Epoch: 5813, Batch Gradient Norm after: 4.3525443293620105
Epoch 5814/10000, Prediction Accuracy = 65.10384615384615%, Loss = 0.007332182453515438
Epoch: 5814, Batch Gradient Norm: 3.860128507679936
Epoch: 5814, Batch Gradient Norm after: 3.860128507679936
Epoch 5815/10000, Prediction Accuracy = 66.04230769230767%, Loss = 0.00704288539978174
Epoch: 5815, Batch Gradient Norm: 4.2836796771847725
Epoch: 5815, Batch Gradient Norm after: 4.2836796771847725
Epoch 5816/10000, Prediction Accuracy = 65.82307692307693%, Loss = 0.007244039900027788
Epoch: 5816, Batch Gradient Norm: 4.52406299862803
Epoch: 5816, Batch Gradient Norm after: 4.52406299862803
Epoch 5817/10000, Prediction Accuracy = 65.34615384615384%, Loss = 0.007379177241371228
Epoch: 5817, Batch Gradient Norm: 4.183282538336323
Epoch: 5817, Batch Gradient Norm after: 4.183282538336323
Epoch 5818/10000, Prediction Accuracy = 65.10384615384615%, Loss = 0.007315660540301066
Epoch: 5818, Batch Gradient Norm: 4.418694002002836
Epoch: 5818, Batch Gradient Norm after: 4.418694002002836
Epoch 5819/10000, Prediction Accuracy = 65.00384615384615%, Loss = 0.007404451831602133
Epoch: 5819, Batch Gradient Norm: 4.503966958259692
Epoch: 5819, Batch Gradient Norm after: 4.503966958259692
Epoch 5820/10000, Prediction Accuracy = 64.83461538461538%, Loss = 0.007482583706195538
Epoch: 5820, Batch Gradient Norm: 4.234905168369401
Epoch: 5820, Batch Gradient Norm after: 4.234905168369401
Epoch 5821/10000, Prediction Accuracy = 65.22307692307692%, Loss = 0.007279304357675405
Epoch: 5821, Batch Gradient Norm: 4.578565817954963
Epoch: 5821, Batch Gradient Norm after: 4.578565817954963
Epoch 5822/10000, Prediction Accuracy = 65.7076923076923%, Loss = 0.007435507714175261
Epoch: 5822, Batch Gradient Norm: 5.092529425871035
Epoch: 5822, Batch Gradient Norm after: 5.092529425871035
Epoch 5823/10000, Prediction Accuracy = 64.40384615384616%, Loss = 0.007918789158933438
Epoch: 5823, Batch Gradient Norm: 4.317383634905494
Epoch: 5823, Batch Gradient Norm after: 4.317383634905494
Epoch 5824/10000, Prediction Accuracy = 65.63846153846154%, Loss = 0.007390062611263532
Epoch: 5824, Batch Gradient Norm: 4.000047067165545
Epoch: 5824, Batch Gradient Norm after: 4.000047067165545
Epoch 5825/10000, Prediction Accuracy = 66.00769230769231%, Loss = 0.0071851886235750635
Epoch: 5825, Batch Gradient Norm: 3.75147025074104
Epoch: 5825, Batch Gradient Norm after: 3.75147025074104
Epoch 5826/10000, Prediction Accuracy = 66.48846153846154%, Loss = 0.007001360090306172
Epoch: 5826, Batch Gradient Norm: 3.982146992663117
Epoch: 5826, Batch Gradient Norm after: 3.982146992663117
Epoch 5827/10000, Prediction Accuracy = 65.81538461538462%, Loss = 0.007208668949225774
Epoch: 5827, Batch Gradient Norm: 4.061871040192941
Epoch: 5827, Batch Gradient Norm after: 4.061871040192941
Epoch 5828/10000, Prediction Accuracy = 65.61923076923077%, Loss = 0.007220597364581549
Epoch: 5828, Batch Gradient Norm: 3.8458988877891374
Epoch: 5828, Batch Gradient Norm after: 3.8458988877891374
Epoch 5829/10000, Prediction Accuracy = 66.30384615384614%, Loss = 0.007108403154863761
Epoch: 5829, Batch Gradient Norm: 4.065055530197957
Epoch: 5829, Batch Gradient Norm after: 4.065055530197957
Epoch 5830/10000, Prediction Accuracy = 65.96153846153847%, Loss = 0.007102448815623155
Epoch: 5830, Batch Gradient Norm: 4.182187181095486
Epoch: 5830, Batch Gradient Norm after: 4.182187181095486
Epoch 5831/10000, Prediction Accuracy = 65.97692307692307%, Loss = 0.007165305029887419
Epoch: 5831, Batch Gradient Norm: 5.125366563372681
Epoch: 5831, Batch Gradient Norm after: 5.125366563372681
Epoch 5832/10000, Prediction Accuracy = 64.65769230769232%, Loss = 0.007790813938929484
Epoch: 5832, Batch Gradient Norm: 4.724729999064145
Epoch: 5832, Batch Gradient Norm after: 4.724729999064145
Epoch 5833/10000, Prediction Accuracy = 64.36538461538463%, Loss = 0.007724865841177793
Epoch: 5833, Batch Gradient Norm: 4.822871465050345
Epoch: 5833, Batch Gradient Norm after: 4.822871465050345
Epoch 5834/10000, Prediction Accuracy = 64.6576923076923%, Loss = 0.0075656515546143055
Epoch: 5834, Batch Gradient Norm: 4.339281830032042
Epoch: 5834, Batch Gradient Norm after: 4.339281830032042
Epoch 5835/10000, Prediction Accuracy = 64.60769230769232%, Loss = 0.00740198608344564
Epoch: 5835, Batch Gradient Norm: 4.568078855899804
Epoch: 5835, Batch Gradient Norm after: 4.568078855899804
Epoch 5836/10000, Prediction Accuracy = 64.7423076923077%, Loss = 0.007526369335559698
Epoch: 5836, Batch Gradient Norm: 4.404836026901694
Epoch: 5836, Batch Gradient Norm after: 4.404836026901694
Epoch 5837/10000, Prediction Accuracy = 65.49230769230769%, Loss = 0.007358801515343098
Epoch: 5837, Batch Gradient Norm: 4.33794606497579
Epoch: 5837, Batch Gradient Norm after: 4.33794606497579
Epoch 5838/10000, Prediction Accuracy = 64.97692307692309%, Loss = 0.007559113992521396
Epoch: 5838, Batch Gradient Norm: 4.578533200723414
Epoch: 5838, Batch Gradient Norm after: 4.578533200723414
Epoch 5839/10000, Prediction Accuracy = 64.81538461538462%, Loss = 0.007557044343019907
Epoch: 5839, Batch Gradient Norm: 4.417440230361772
Epoch: 5839, Batch Gradient Norm after: 4.417440230361772
Epoch 5840/10000, Prediction Accuracy = 65.43846153846154%, Loss = 0.0074798249138089325
Epoch: 5840, Batch Gradient Norm: 4.071599469428156
Epoch: 5840, Batch Gradient Norm after: 4.071599469428156
Epoch 5841/10000, Prediction Accuracy = 65.61153846153846%, Loss = 0.007247213668261583
Epoch: 5841, Batch Gradient Norm: 4.081586345472591
Epoch: 5841, Batch Gradient Norm after: 4.081586345472591
Epoch 5842/10000, Prediction Accuracy = 65.87692307692308%, Loss = 0.007179643600606001
Epoch: 5842, Batch Gradient Norm: 4.6579553185897815
Epoch: 5842, Batch Gradient Norm after: 4.6579553185897815
Epoch 5843/10000, Prediction Accuracy = 64.90384615384616%, Loss = 0.007592008807338201
Epoch: 5843, Batch Gradient Norm: 4.646491917355351
Epoch: 5843, Batch Gradient Norm after: 4.646491917355351
Epoch 5844/10000, Prediction Accuracy = 64.89615384615385%, Loss = 0.007531901140912221
Epoch: 5844, Batch Gradient Norm: 4.584566848978275
Epoch: 5844, Batch Gradient Norm after: 4.584566848978275
Epoch 5845/10000, Prediction Accuracy = 64.53461538461538%, Loss = 0.00755356982923471
Epoch: 5845, Batch Gradient Norm: 4.645289691687755
Epoch: 5845, Batch Gradient Norm after: 4.645289691687755
Epoch 5846/10000, Prediction Accuracy = 64.93076923076923%, Loss = 0.007465047403596914
Epoch: 5846, Batch Gradient Norm: 4.531137079862435
Epoch: 5846, Batch Gradient Norm after: 4.531137079862435
Epoch 5847/10000, Prediction Accuracy = 65.28461538461539%, Loss = 0.007522138981865003
Epoch: 5847, Batch Gradient Norm: 4.068513524935448
Epoch: 5847, Batch Gradient Norm after: 4.068513524935448
Epoch 5848/10000, Prediction Accuracy = 65.22692307692307%, Loss = 0.007276799207409987
Epoch: 5848, Batch Gradient Norm: 3.9850509291464515
Epoch: 5848, Batch Gradient Norm after: 3.9850509291464515
Epoch 5849/10000, Prediction Accuracy = 65.50384615384615%, Loss = 0.00726722703816799
Epoch: 5849, Batch Gradient Norm: 4.399439440645708
Epoch: 5849, Batch Gradient Norm after: 4.399439440645708
Epoch 5850/10000, Prediction Accuracy = 64.73076923076923%, Loss = 0.0074759181947089155
Epoch: 5850, Batch Gradient Norm: 4.313911828903405
Epoch: 5850, Batch Gradient Norm after: 4.313911828903405
Epoch 5851/10000, Prediction Accuracy = 65.16538461538462%, Loss = 0.007343725552066014
Epoch: 5851, Batch Gradient Norm: 3.8793548530308084
Epoch: 5851, Batch Gradient Norm after: 3.8793548530308084
Epoch 5852/10000, Prediction Accuracy = 65.83846153846153%, Loss = 0.007071545884872858
Epoch: 5852, Batch Gradient Norm: 4.581387000176047
Epoch: 5852, Batch Gradient Norm after: 4.581387000176047
Epoch 5853/10000, Prediction Accuracy = 65.26538461538463%, Loss = 0.007363416290340515
Epoch: 5853, Batch Gradient Norm: 4.286723508576808
Epoch: 5853, Batch Gradient Norm after: 4.286723508576808
Epoch 5854/10000, Prediction Accuracy = 65.38461538461537%, Loss = 0.007296422281517432
Epoch: 5854, Batch Gradient Norm: 4.19428232048947
Epoch: 5854, Batch Gradient Norm after: 4.19428232048947
Epoch 5855/10000, Prediction Accuracy = 65.60384615384615%, Loss = 0.007165865005495457
Epoch: 5855, Batch Gradient Norm: 4.154064950584501
Epoch: 5855, Batch Gradient Norm after: 4.154064950584501
Epoch 5856/10000, Prediction Accuracy = 64.98076923076924%, Loss = 0.007215602896534479
Epoch: 5856, Batch Gradient Norm: 4.582970216872538
Epoch: 5856, Batch Gradient Norm after: 4.582970216872538
Epoch 5857/10000, Prediction Accuracy = 64.89999999999999%, Loss = 0.007472402702730436
Epoch: 5857, Batch Gradient Norm: 4.549238840658612
Epoch: 5857, Batch Gradient Norm after: 4.549238840658612
Epoch 5858/10000, Prediction Accuracy = 64.86153846153846%, Loss = 0.007421920255113106
Epoch: 5858, Batch Gradient Norm: 4.299729858659122
Epoch: 5858, Batch Gradient Norm after: 4.299729858659122
Epoch 5859/10000, Prediction Accuracy = 65.52307692307693%, Loss = 0.007278032636699768
Epoch: 5859, Batch Gradient Norm: 4.2533254762321375
Epoch: 5859, Batch Gradient Norm after: 4.2533254762321375
Epoch 5860/10000, Prediction Accuracy = 66.05000000000001%, Loss = 0.007190318276675848
Epoch: 5860, Batch Gradient Norm: 4.959121235619915
Epoch: 5860, Batch Gradient Norm after: 4.959121235619915
Epoch 5861/10000, Prediction Accuracy = 64.90384615384616%, Loss = 0.007653539140637104
Epoch: 5861, Batch Gradient Norm: 4.4861546428247285
Epoch: 5861, Batch Gradient Norm after: 4.4861546428247285
Epoch 5862/10000, Prediction Accuracy = 65.3%, Loss = 0.0074796533713547084
Epoch: 5862, Batch Gradient Norm: 4.412910426063945
Epoch: 5862, Batch Gradient Norm after: 4.412910426063945
Epoch 5863/10000, Prediction Accuracy = 64.86923076923077%, Loss = 0.007451671354759198
Epoch: 5863, Batch Gradient Norm: 4.645537774538531
Epoch: 5863, Batch Gradient Norm after: 4.645537774538531
Epoch 5864/10000, Prediction Accuracy = 64.63076923076923%, Loss = 0.0075149447298966925
Epoch: 5864, Batch Gradient Norm: 4.455524926282055
Epoch: 5864, Batch Gradient Norm after: 4.455524926282055
Epoch 5865/10000, Prediction Accuracy = 65.2653846153846%, Loss = 0.007454050704836845
Epoch: 5865, Batch Gradient Norm: 4.628269363532838
Epoch: 5865, Batch Gradient Norm after: 4.628269363532838
Epoch 5866/10000, Prediction Accuracy = 64.85384615384615%, Loss = 0.007571901839513045
Epoch: 5866, Batch Gradient Norm: 5.022270994784804
Epoch: 5866, Batch Gradient Norm after: 5.022270994784804
Epoch 5867/10000, Prediction Accuracy = 64.38846153846154%, Loss = 0.007781413204681415
Epoch: 5867, Batch Gradient Norm: 4.67097926478083
Epoch: 5867, Batch Gradient Norm after: 4.67097926478083
Epoch 5868/10000, Prediction Accuracy = 64.52307692307691%, Loss = 0.007648470739905651
Epoch: 5868, Batch Gradient Norm: 4.299591793595512
Epoch: 5868, Batch Gradient Norm after: 4.299591793595512
Epoch 5869/10000, Prediction Accuracy = 64.75769230769231%, Loss = 0.00748667146007602
Epoch: 5869, Batch Gradient Norm: 4.553053744877662
Epoch: 5869, Batch Gradient Norm after: 4.553053744877662
Epoch 5870/10000, Prediction Accuracy = 64.48846153846155%, Loss = 0.00761238643183158
Epoch: 5870, Batch Gradient Norm: 4.4399067075118195
Epoch: 5870, Batch Gradient Norm after: 4.4399067075118195
Epoch 5871/10000, Prediction Accuracy = 65.7653846153846%, Loss = 0.007462290402215261
Epoch: 5871, Batch Gradient Norm: 4.069130105692239
Epoch: 5871, Batch Gradient Norm after: 4.069130105692239
Epoch 5872/10000, Prediction Accuracy = 65.93076923076922%, Loss = 0.007228306494653225
Epoch: 5872, Batch Gradient Norm: 3.9268892870509946
Epoch: 5872, Batch Gradient Norm after: 3.9268892870509946
Epoch 5873/10000, Prediction Accuracy = 65.53461538461539%, Loss = 0.007183157409039827
Epoch: 5873, Batch Gradient Norm: 3.7751580999641217
Epoch: 5873, Batch Gradient Norm after: 3.7751580999641217
Epoch 5874/10000, Prediction Accuracy = 66.1423076923077%, Loss = 0.0070946379206501525
Epoch: 5874, Batch Gradient Norm: 4.019340528215438
Epoch: 5874, Batch Gradient Norm after: 4.019340528215438
Epoch 5875/10000, Prediction Accuracy = 65.74230769230768%, Loss = 0.007154262553040798
Epoch: 5875, Batch Gradient Norm: 4.673861755084237
Epoch: 5875, Batch Gradient Norm after: 4.673861755084237
Epoch 5876/10000, Prediction Accuracy = 65.07307692307693%, Loss = 0.007481390037215673
Epoch: 5876, Batch Gradient Norm: 4.264006123273022
Epoch: 5876, Batch Gradient Norm after: 4.264006123273022
Epoch 5877/10000, Prediction Accuracy = 65.66153846153847%, Loss = 0.007301507589335625
Epoch: 5877, Batch Gradient Norm: 4.335860645537932
Epoch: 5877, Batch Gradient Norm after: 4.335860645537932
Epoch 5878/10000, Prediction Accuracy = 65.20384615384616%, Loss = 0.007384014172622791
Epoch: 5878, Batch Gradient Norm: 4.327111770750178
Epoch: 5878, Batch Gradient Norm after: 4.327111770750178
Epoch 5879/10000, Prediction Accuracy = 65.54230769230769%, Loss = 0.00736700646722546
Epoch: 5879, Batch Gradient Norm: 4.6104281966137295
Epoch: 5879, Batch Gradient Norm after: 4.6104281966137295
Epoch 5880/10000, Prediction Accuracy = 64.94230769230771%, Loss = 0.007564650382846594
Epoch: 5880, Batch Gradient Norm: 4.529090261725931
Epoch: 5880, Batch Gradient Norm after: 4.529090261725931
Epoch 5881/10000, Prediction Accuracy = 64.82692307692307%, Loss = 0.0074841630143614914
Epoch: 5881, Batch Gradient Norm: 4.548070864896326
Epoch: 5881, Batch Gradient Norm after: 4.548070864896326
Epoch 5882/10000, Prediction Accuracy = 64.95000000000002%, Loss = 0.007527172099798918
Epoch: 5882, Batch Gradient Norm: 4.228404391508074
Epoch: 5882, Batch Gradient Norm after: 4.228404391508074
Epoch 5883/10000, Prediction Accuracy = 65.81153846153846%, Loss = 0.007267865388152691
Epoch: 5883, Batch Gradient Norm: 4.092726567604463
Epoch: 5883, Batch Gradient Norm after: 4.092726567604463
Epoch 5884/10000, Prediction Accuracy = 65.77307692307693%, Loss = 0.007185626381005232
Epoch: 5884, Batch Gradient Norm: 4.243005524967618
Epoch: 5884, Batch Gradient Norm after: 4.243005524967618
Epoch 5885/10000, Prediction Accuracy = 65.23076923076923%, Loss = 0.007327432206903513
Epoch: 5885, Batch Gradient Norm: 4.459307945610482
Epoch: 5885, Batch Gradient Norm after: 4.459307945610482
Epoch 5886/10000, Prediction Accuracy = 65.28076923076922%, Loss = 0.00736496439920022
Epoch: 5886, Batch Gradient Norm: 4.046719545754667
Epoch: 5886, Batch Gradient Norm after: 4.046719545754667
Epoch 5887/10000, Prediction Accuracy = 65.90769230769232%, Loss = 0.007251255608235414
Epoch: 5887, Batch Gradient Norm: 4.5107398235287794
Epoch: 5887, Batch Gradient Norm after: 4.5107398235287794
Epoch 5888/10000, Prediction Accuracy = 64.93846153846154%, Loss = 0.007444165718670075
Epoch: 5888, Batch Gradient Norm: 4.2891500432622145
Epoch: 5888, Batch Gradient Norm after: 4.2891500432622145
Epoch 5889/10000, Prediction Accuracy = 65.73076923076924%, Loss = 0.007261014830034513
Epoch: 5889, Batch Gradient Norm: 4.489640433457937
Epoch: 5889, Batch Gradient Norm after: 4.489640433457937
Epoch 5890/10000, Prediction Accuracy = 65.68846153846154%, Loss = 0.007399271851262221
Epoch: 5890, Batch Gradient Norm: 4.455552355679853
Epoch: 5890, Batch Gradient Norm after: 4.455552355679853
Epoch 5891/10000, Prediction Accuracy = 65.22307692307692%, Loss = 0.007330840632606011
Epoch: 5891, Batch Gradient Norm: 4.355514739016136
Epoch: 5891, Batch Gradient Norm after: 4.355514739016136
Epoch 5892/10000, Prediction Accuracy = 65.59615384615384%, Loss = 0.007294965979571526
Epoch: 5892, Batch Gradient Norm: 4.277036137516425
Epoch: 5892, Batch Gradient Norm after: 4.277036137516425
Epoch 5893/10000, Prediction Accuracy = 65.31153846153846%, Loss = 0.007305977364572195
Epoch: 5893, Batch Gradient Norm: 4.120648094718427
Epoch: 5893, Batch Gradient Norm after: 4.120648094718427
Epoch 5894/10000, Prediction Accuracy = 65.91923076923077%, Loss = 0.007192362673007525
Epoch: 5894, Batch Gradient Norm: 4.363933352163693
Epoch: 5894, Batch Gradient Norm after: 4.363933352163693
Epoch 5895/10000, Prediction Accuracy = 65.2923076923077%, Loss = 0.007336751342966006
Epoch: 5895, Batch Gradient Norm: 3.879856743795744
Epoch: 5895, Batch Gradient Norm after: 3.879856743795744
Epoch 5896/10000, Prediction Accuracy = 66.46538461538461%, Loss = 0.007041912096051069
Epoch: 5896, Batch Gradient Norm: 4.181858424068166
Epoch: 5896, Batch Gradient Norm after: 4.181858424068166
Epoch 5897/10000, Prediction Accuracy = 65.7576923076923%, Loss = 0.007145890213835698
Epoch: 5897, Batch Gradient Norm: 4.5420486392969295
Epoch: 5897, Batch Gradient Norm after: 4.5420486392969295
Epoch 5898/10000, Prediction Accuracy = 65.32692307692307%, Loss = 0.007425586800449169
Epoch: 5898, Batch Gradient Norm: 4.2339594382551065
Epoch: 5898, Batch Gradient Norm after: 4.2339594382551065
Epoch 5899/10000, Prediction Accuracy = 65.21538461538462%, Loss = 0.007338012210451639
Epoch: 5899, Batch Gradient Norm: 4.419158676332055
Epoch: 5899, Batch Gradient Norm after: 4.419158676332055
Epoch 5900/10000, Prediction Accuracy = 65.16153846153847%, Loss = 0.007453841945299735
Epoch: 5900, Batch Gradient Norm: 4.400339546498483
Epoch: 5900, Batch Gradient Norm after: 4.400339546498483
Epoch 5901/10000, Prediction Accuracy = 65.7423076923077%, Loss = 0.007336920843674586
Epoch: 5901, Batch Gradient Norm: 4.8442131446120795
Epoch: 5901, Batch Gradient Norm after: 4.8442131446120795
Epoch 5902/10000, Prediction Accuracy = 64.70384615384614%, Loss = 0.0075608689266328626
Epoch: 5902, Batch Gradient Norm: 4.647141834022664
Epoch: 5902, Batch Gradient Norm after: 4.647141834022664
Epoch 5903/10000, Prediction Accuracy = 64.82692307692307%, Loss = 0.0075876853572061425
Epoch: 5903, Batch Gradient Norm: 4.307750263051396
Epoch: 5903, Batch Gradient Norm after: 4.307750263051396
Epoch 5904/10000, Prediction Accuracy = 65.87692307692308%, Loss = 0.007266856658344085
Epoch: 5904, Batch Gradient Norm: 4.203248173634037
Epoch: 5904, Batch Gradient Norm after: 4.203248173634037
Epoch 5905/10000, Prediction Accuracy = 65.67692307692306%, Loss = 0.007157153235032008
Epoch: 5905, Batch Gradient Norm: 4.149135088770915
Epoch: 5905, Batch Gradient Norm after: 4.149135088770915
Epoch 5906/10000, Prediction Accuracy = 65.64230769230768%, Loss = 0.007203815719829156
Epoch: 5906, Batch Gradient Norm: 4.663102865908352
Epoch: 5906, Batch Gradient Norm after: 4.663102865908352
Epoch 5907/10000, Prediction Accuracy = 65.04999999999998%, Loss = 0.007489870266559033
Epoch: 5907, Batch Gradient Norm: 4.446635760845913
Epoch: 5907, Batch Gradient Norm after: 4.446635760845913
Epoch 5908/10000, Prediction Accuracy = 65.56923076923077%, Loss = 0.007311871096205253
Epoch: 5908, Batch Gradient Norm: 4.097808999335055
Epoch: 5908, Batch Gradient Norm after: 4.097808999335055
Epoch 5909/10000, Prediction Accuracy = 65.3576923076923%, Loss = 0.007257766555994749
Epoch: 5909, Batch Gradient Norm: 4.346197763349544
Epoch: 5909, Batch Gradient Norm after: 4.346197763349544
Epoch 5910/10000, Prediction Accuracy = 65.34615384615384%, Loss = 0.007267653870467956
Epoch: 5910, Batch Gradient Norm: 4.369022584916953
Epoch: 5910, Batch Gradient Norm after: 4.369022584916953
Epoch 5911/10000, Prediction Accuracy = 65.49230769230769%, Loss = 0.007318225402671557
Epoch: 5911, Batch Gradient Norm: 4.373997002677619
Epoch: 5911, Batch Gradient Norm after: 4.373997002677619
Epoch 5912/10000, Prediction Accuracy = 65.21538461538461%, Loss = 0.007472439489972133
Epoch: 5912, Batch Gradient Norm: 4.095996806109225
Epoch: 5912, Batch Gradient Norm after: 4.095996806109225
Epoch 5913/10000, Prediction Accuracy = 65.37692307692308%, Loss = 0.007216432490027868
Epoch: 5913, Batch Gradient Norm: 4.360722338771945
Epoch: 5913, Batch Gradient Norm after: 4.360722338771945
Epoch 5914/10000, Prediction Accuracy = 64.79615384615384%, Loss = 0.007306034676730633
Epoch: 5914, Batch Gradient Norm: 4.4749571908812165
Epoch: 5914, Batch Gradient Norm after: 4.4749571908812165
Epoch 5915/10000, Prediction Accuracy = 64.75384615384615%, Loss = 0.007450380971511969
Epoch: 5915, Batch Gradient Norm: 4.074833452380249
Epoch: 5915, Batch Gradient Norm after: 4.074833452380249
Epoch 5916/10000, Prediction Accuracy = 65.36923076923077%, Loss = 0.007191222161054611
Epoch: 5916, Batch Gradient Norm: 4.002177656668931
Epoch: 5916, Batch Gradient Norm after: 4.002177656668931
Epoch 5917/10000, Prediction Accuracy = 65.85%, Loss = 0.007227839185641362
Epoch: 5917, Batch Gradient Norm: 4.373910949534475
Epoch: 5917, Batch Gradient Norm after: 4.373910949534475
Epoch 5918/10000, Prediction Accuracy = 65.58461538461539%, Loss = 0.007290584715799644
Epoch: 5918, Batch Gradient Norm: 4.692917141656575
Epoch: 5918, Batch Gradient Norm after: 4.692917141656575
Epoch 5919/10000, Prediction Accuracy = 64.72692307692307%, Loss = 0.0075485009986620685
Epoch: 5919, Batch Gradient Norm: 4.03375262212607
Epoch: 5919, Batch Gradient Norm after: 4.03375262212607
Epoch 5920/10000, Prediction Accuracy = 65.45384615384614%, Loss = 0.007271992973983288
Epoch: 5920, Batch Gradient Norm: 4.030039129686452
Epoch: 5920, Batch Gradient Norm after: 4.030039129686452
Epoch 5921/10000, Prediction Accuracy = 65.83846153846153%, Loss = 0.00724847367606484
Epoch: 5921, Batch Gradient Norm: 4.461180549288022
Epoch: 5921, Batch Gradient Norm after: 4.461180549288022
Epoch 5922/10000, Prediction Accuracy = 65.12307692307692%, Loss = 0.007307851507973213
Epoch: 5922, Batch Gradient Norm: 4.095283775209263
Epoch: 5922, Batch Gradient Norm after: 4.095283775209263
Epoch 5923/10000, Prediction Accuracy = 66.02307692307693%, Loss = 0.007140612731186243
Epoch: 5923, Batch Gradient Norm: 4.505038825780906
Epoch: 5923, Batch Gradient Norm after: 4.505038825780906
Epoch 5924/10000, Prediction Accuracy = 64.92307692307692%, Loss = 0.00742856882369289
Epoch: 5924, Batch Gradient Norm: 4.516483565069567
Epoch: 5924, Batch Gradient Norm after: 4.516483565069567
Epoch 5925/10000, Prediction Accuracy = 65.13846153846154%, Loss = 0.00732306781439827
Epoch: 5925, Batch Gradient Norm: 4.494881736426076
Epoch: 5925, Batch Gradient Norm after: 4.494881736426076
Epoch 5926/10000, Prediction Accuracy = 65.44615384615383%, Loss = 0.007362801617441269
Epoch: 5926, Batch Gradient Norm: 4.637124423577198
Epoch: 5926, Batch Gradient Norm after: 4.637124423577198
Epoch 5927/10000, Prediction Accuracy = 65.09615384615384%, Loss = 0.007381213864741417
Epoch: 5927, Batch Gradient Norm: 4.712093065101412
Epoch: 5927, Batch Gradient Norm after: 4.712093065101412
Epoch 5928/10000, Prediction Accuracy = 64.08846153846154%, Loss = 0.00765008396970538
Epoch: 5928, Batch Gradient Norm: 4.29549681611536
Epoch: 5928, Batch Gradient Norm after: 4.29549681611536
Epoch 5929/10000, Prediction Accuracy = 65.60769230769232%, Loss = 0.007402739881609495
Epoch: 5929, Batch Gradient Norm: 4.309202646606499
Epoch: 5929, Batch Gradient Norm after: 4.309202646606499
Epoch 5930/10000, Prediction Accuracy = 65.3576923076923%, Loss = 0.007265840800335774
Epoch: 5930, Batch Gradient Norm: 4.5734036141921015
Epoch: 5930, Batch Gradient Norm after: 4.5734036141921015
Epoch 5931/10000, Prediction Accuracy = 65.12307692307692%, Loss = 0.0074032753562698
Epoch: 5931, Batch Gradient Norm: 4.043094658715371
Epoch: 5931, Batch Gradient Norm after: 4.043094658715371
Epoch 5932/10000, Prediction Accuracy = 66.03846153846155%, Loss = 0.007147340533825068
Epoch: 5932, Batch Gradient Norm: 4.3969727623968415
Epoch: 5932, Batch Gradient Norm after: 4.3969727623968415
Epoch 5933/10000, Prediction Accuracy = 65.77692307692308%, Loss = 0.007288149629647915
Epoch: 5933, Batch Gradient Norm: 4.203479067282817
Epoch: 5933, Batch Gradient Norm after: 4.203479067282817
Epoch 5934/10000, Prediction Accuracy = 65.81923076923077%, Loss = 0.0072747355398650355
Epoch: 5934, Batch Gradient Norm: 4.424971333176679
Epoch: 5934, Batch Gradient Norm after: 4.424971333176679
Epoch 5935/10000, Prediction Accuracy = 65.22692307692309%, Loss = 0.0073570950100055104
Epoch: 5935, Batch Gradient Norm: 4.742960761509951
Epoch: 5935, Batch Gradient Norm after: 4.742960761509951
Epoch 5936/10000, Prediction Accuracy = 64.96153846153847%, Loss = 0.007570467781848633
Epoch: 5936, Batch Gradient Norm: 5.075777710619762
Epoch: 5936, Batch Gradient Norm after: 5.075777710619762
Epoch 5937/10000, Prediction Accuracy = 64.25000000000001%, Loss = 0.007830405751099953
Epoch: 5937, Batch Gradient Norm: 4.447148011445632
Epoch: 5937, Batch Gradient Norm after: 4.447148011445632
Epoch 5938/10000, Prediction Accuracy = 65.41538461538461%, Loss = 0.007330651287562572
Epoch: 5938, Batch Gradient Norm: 4.087048161893981
Epoch: 5938, Batch Gradient Norm after: 4.087048161893981
Epoch 5939/10000, Prediction Accuracy = 65.80000000000001%, Loss = 0.0071926534247513
Epoch: 5939, Batch Gradient Norm: 4.142013006482577
Epoch: 5939, Batch Gradient Norm after: 4.142013006482577
Epoch 5940/10000, Prediction Accuracy = 66.08461538461539%, Loss = 0.007210990700584192
Epoch: 5940, Batch Gradient Norm: 3.804127446343861
Epoch: 5940, Batch Gradient Norm after: 3.804127446343861
Epoch 5941/10000, Prediction Accuracy = 66.4846153846154%, Loss = 0.006967775917683656
Epoch: 5941, Batch Gradient Norm: 4.078627120656865
Epoch: 5941, Batch Gradient Norm after: 4.078627120656865
Epoch 5942/10000, Prediction Accuracy = 66.05384615384615%, Loss = 0.007097968401817175
Epoch: 5942, Batch Gradient Norm: 4.368662239805571
Epoch: 5942, Batch Gradient Norm after: 4.368662239805571
Epoch 5943/10000, Prediction Accuracy = 65.00384615384615%, Loss = 0.00731753296433733
Epoch: 5943, Batch Gradient Norm: 4.183417483091136
Epoch: 5943, Batch Gradient Norm after: 4.183417483091136
Epoch 5944/10000, Prediction Accuracy = 66.26923076923077%, Loss = 0.007146915277609458
Epoch: 5944, Batch Gradient Norm: 4.027472836052634
Epoch: 5944, Batch Gradient Norm after: 4.027472836052634
Epoch 5945/10000, Prediction Accuracy = 65.82307692307694%, Loss = 0.007120939437299967
Epoch: 5945, Batch Gradient Norm: 4.1814391259610995
Epoch: 5945, Batch Gradient Norm after: 4.1814391259610995
Epoch 5946/10000, Prediction Accuracy = 65.77307692307691%, Loss = 0.007263316916158566
Epoch: 5946, Batch Gradient Norm: 4.153214403674378
Epoch: 5946, Batch Gradient Norm after: 4.153214403674378
Epoch 5947/10000, Prediction Accuracy = 65.66538461538462%, Loss = 0.007191496937034221
Epoch: 5947, Batch Gradient Norm: 4.802970189105364
Epoch: 5947, Batch Gradient Norm after: 4.802970189105364
Epoch 5948/10000, Prediction Accuracy = 65.13461538461539%, Loss = 0.007384228735015943
Epoch: 5948, Batch Gradient Norm: 4.626545831112117
Epoch: 5948, Batch Gradient Norm after: 4.626545831112117
Epoch 5949/10000, Prediction Accuracy = 65.24230769230769%, Loss = 0.007458004778107772
Epoch: 5949, Batch Gradient Norm: 4.260015876715376
Epoch: 5949, Batch Gradient Norm after: 4.260015876715376
Epoch 5950/10000, Prediction Accuracy = 65.81538461538462%, Loss = 0.007207819941238715
Epoch: 5950, Batch Gradient Norm: 5.07266504136077
Epoch: 5950, Batch Gradient Norm after: 5.07266504136077
Epoch 5951/10000, Prediction Accuracy = 64.77692307692308%, Loss = 0.007628467113066178
Epoch: 5951, Batch Gradient Norm: 4.683558402894307
Epoch: 5951, Batch Gradient Norm after: 4.683558402894307
Epoch 5952/10000, Prediction Accuracy = 64.58846153846153%, Loss = 0.007475662475021986
Epoch: 5952, Batch Gradient Norm: 4.675150932019649
Epoch: 5952, Batch Gradient Norm after: 4.675150932019649
Epoch 5953/10000, Prediction Accuracy = 64.79615384615384%, Loss = 0.007497641329581921
Epoch: 5953, Batch Gradient Norm: 4.131336753739774
Epoch: 5953, Batch Gradient Norm after: 4.131336753739774
Epoch 5954/10000, Prediction Accuracy = 66.00384615384615%, Loss = 0.00715565699367569
Epoch: 5954, Batch Gradient Norm: 4.35844719704619
Epoch: 5954, Batch Gradient Norm after: 4.35844719704619
Epoch 5955/10000, Prediction Accuracy = 65.5576923076923%, Loss = 0.007307986048265145
Epoch: 5955, Batch Gradient Norm: 4.220224105517258
Epoch: 5955, Batch Gradient Norm after: 4.220224105517258
Epoch 5956/10000, Prediction Accuracy = 65.87307692307692%, Loss = 0.007195213057387333
Epoch: 5956, Batch Gradient Norm: 4.493210051192257
Epoch: 5956, Batch Gradient Norm after: 4.493210051192257
Epoch 5957/10000, Prediction Accuracy = 64.85000000000001%, Loss = 0.007417241147217842
Epoch: 5957, Batch Gradient Norm: 4.381156143780315
Epoch: 5957, Batch Gradient Norm after: 4.381156143780315
Epoch 5958/10000, Prediction Accuracy = 65.43076923076923%, Loss = 0.007314212870999024
Epoch: 5958, Batch Gradient Norm: 4.124064697642099
Epoch: 5958, Batch Gradient Norm after: 4.124064697642099
Epoch 5959/10000, Prediction Accuracy = 65.83076923076923%, Loss = 0.007198077805626851
Epoch: 5959, Batch Gradient Norm: 4.138146102202499
Epoch: 5959, Batch Gradient Norm after: 4.138146102202499
Epoch 5960/10000, Prediction Accuracy = 65.8576923076923%, Loss = 0.007180907190419161
Epoch: 5960, Batch Gradient Norm: 4.561253350182046
Epoch: 5960, Batch Gradient Norm after: 4.561253350182046
Epoch 5961/10000, Prediction Accuracy = 64.86923076923078%, Loss = 0.0074083163546255
Epoch: 5961, Batch Gradient Norm: 4.610102355353978
Epoch: 5961, Batch Gradient Norm after: 4.610102355353978
Epoch 5962/10000, Prediction Accuracy = 65.18461538461538%, Loss = 0.007465036084445624
Epoch: 5962, Batch Gradient Norm: 4.63201749036363
Epoch: 5962, Batch Gradient Norm after: 4.63201749036363
Epoch 5963/10000, Prediction Accuracy = 65.0153846153846%, Loss = 0.007323161949618504
Epoch: 5963, Batch Gradient Norm: 4.640176745187321
Epoch: 5963, Batch Gradient Norm after: 4.640176745187321
Epoch 5964/10000, Prediction Accuracy = 65.1076923076923%, Loss = 0.0073904253972264435
Epoch: 5964, Batch Gradient Norm: 4.367597061647582
Epoch: 5964, Batch Gradient Norm after: 4.367597061647582
Epoch 5965/10000, Prediction Accuracy = 65.26923076923077%, Loss = 0.007307121064513922
Epoch: 5965, Batch Gradient Norm: 4.023050588797647
Epoch: 5965, Batch Gradient Norm after: 4.023050588797647
Epoch 5966/10000, Prediction Accuracy = 65.87307692307692%, Loss = 0.0071233582969468376
Epoch: 5966, Batch Gradient Norm: 4.043968806050256
Epoch: 5966, Batch Gradient Norm after: 4.043968806050256
Epoch 5967/10000, Prediction Accuracy = 65.68461538461537%, Loss = 0.007092556056494896
Epoch: 5967, Batch Gradient Norm: 4.502924639092826
Epoch: 5967, Batch Gradient Norm after: 4.502924639092826
Epoch 5968/10000, Prediction Accuracy = 65.56923076923077%, Loss = 0.007315316810630835
Epoch: 5968, Batch Gradient Norm: 4.1149921194122046
Epoch: 5968, Batch Gradient Norm after: 4.1149921194122046
Epoch 5969/10000, Prediction Accuracy = 65.84615384615384%, Loss = 0.007163097329724293
Epoch: 5969, Batch Gradient Norm: 3.9981074002589936
Epoch: 5969, Batch Gradient Norm after: 3.9981074002589936
Epoch 5970/10000, Prediction Accuracy = 65.91153846153847%, Loss = 0.00709344890828316
Epoch: 5970, Batch Gradient Norm: 4.153178269226713
Epoch: 5970, Batch Gradient Norm after: 4.153178269226713
Epoch 5971/10000, Prediction Accuracy = 65.94615384615385%, Loss = 0.007125950275132289
Epoch: 5971, Batch Gradient Norm: 4.41595436784852
Epoch: 5971, Batch Gradient Norm after: 4.41595436784852
Epoch 5972/10000, Prediction Accuracy = 65.40769230769232%, Loss = 0.007359124505175994
Epoch: 5972, Batch Gradient Norm: 5.166669966008592
Epoch: 5972, Batch Gradient Norm after: 5.166669966008592
Epoch 5973/10000, Prediction Accuracy = 63.48076923076923%, Loss = 0.007823594917471591
Epoch: 5973, Batch Gradient Norm: 4.99108060661005
Epoch: 5973, Batch Gradient Norm after: 4.99108060661005
Epoch 5974/10000, Prediction Accuracy = 64.3076923076923%, Loss = 0.0077877846331550525
Epoch: 5974, Batch Gradient Norm: 4.965652199128062
Epoch: 5974, Batch Gradient Norm after: 4.965652199128062
Epoch 5975/10000, Prediction Accuracy = 64.78076923076922%, Loss = 0.007714152371940704
Epoch: 5975, Batch Gradient Norm: 4.643497089036026
Epoch: 5975, Batch Gradient Norm after: 4.643497089036026
Epoch 5976/10000, Prediction Accuracy = 64.9576923076923%, Loss = 0.007577385359372084
Epoch: 5976, Batch Gradient Norm: 4.642652128506835
Epoch: 5976, Batch Gradient Norm after: 4.642652128506835
Epoch 5977/10000, Prediction Accuracy = 65.04615384615386%, Loss = 0.0075769849623051975
Epoch: 5977, Batch Gradient Norm: 4.254127432549154
Epoch: 5977, Batch Gradient Norm after: 4.254127432549154
Epoch 5978/10000, Prediction Accuracy = 65.35384615384615%, Loss = 0.0073543635841745595
Epoch: 5978, Batch Gradient Norm: 3.7907231749902817
Epoch: 5978, Batch Gradient Norm after: 3.7907231749902817
Epoch 5979/10000, Prediction Accuracy = 66.13461538461537%, Loss = 0.007070609834045172
Epoch: 5979, Batch Gradient Norm: 3.776424599707107
Epoch: 5979, Batch Gradient Norm after: 3.776424599707107
Epoch 5980/10000, Prediction Accuracy = 66.03846153846153%, Loss = 0.007001224582871566
Epoch: 5980, Batch Gradient Norm: 4.103281705267402
Epoch: 5980, Batch Gradient Norm after: 4.103281705267402
Epoch 5981/10000, Prediction Accuracy = 66.10384615384615%, Loss = 0.007083323354331346
Epoch: 5981, Batch Gradient Norm: 4.364014751837837
Epoch: 5981, Batch Gradient Norm after: 4.364014751837837
Epoch 5982/10000, Prediction Accuracy = 65.56153846153846%, Loss = 0.007179270104433482
Epoch: 5982, Batch Gradient Norm: 3.9176294721049825
Epoch: 5982, Batch Gradient Norm after: 3.9176294721049825
Epoch 5983/10000, Prediction Accuracy = 66.30000000000001%, Loss = 0.006979703580817351
Epoch: 5983, Batch Gradient Norm: 4.554127241040411
Epoch: 5983, Batch Gradient Norm after: 4.554127241040411
Epoch 5984/10000, Prediction Accuracy = 65.46538461538462%, Loss = 0.007264793707201114
Epoch: 5984, Batch Gradient Norm: 5.058910668625994
Epoch: 5984, Batch Gradient Norm after: 5.058910668625994
Epoch 5985/10000, Prediction Accuracy = 64.3923076923077%, Loss = 0.007654543894414718
Epoch: 5985, Batch Gradient Norm: 4.8571557944222565
Epoch: 5985, Batch Gradient Norm after: 4.8571557944222565
Epoch 5986/10000, Prediction Accuracy = 64.40384615384616%, Loss = 0.007646326441317797
Epoch: 5986, Batch Gradient Norm: 4.306014515265216
Epoch: 5986, Batch Gradient Norm after: 4.306014515265216
Epoch 5987/10000, Prediction Accuracy = 65.56923076923077%, Loss = 0.007277001949170461
Epoch: 5987, Batch Gradient Norm: 4.174467197525958
Epoch: 5987, Batch Gradient Norm after: 4.174467197525958
Epoch 5988/10000, Prediction Accuracy = 65.63076923076923%, Loss = 0.00724574694266686
Epoch: 5988, Batch Gradient Norm: 4.182187928154006
Epoch: 5988, Batch Gradient Norm after: 4.182187928154006
Epoch 5989/10000, Prediction Accuracy = 65.32692307692307%, Loss = 0.00727001760298243
Epoch: 5989, Batch Gradient Norm: 4.011695683907891
Epoch: 5989, Batch Gradient Norm after: 4.011695683907891
Epoch 5990/10000, Prediction Accuracy = 65.68461538461538%, Loss = 0.007185850399904526
Epoch: 5990, Batch Gradient Norm: 4.1428848911432885
Epoch: 5990, Batch Gradient Norm after: 4.1428848911432885
Epoch 5991/10000, Prediction Accuracy = 65.86923076923077%, Loss = 0.007154470309615135
Epoch: 5991, Batch Gradient Norm: 4.523918013943017
Epoch: 5991, Batch Gradient Norm after: 4.523918013943017
Epoch 5992/10000, Prediction Accuracy = 65.38846153846154%, Loss = 0.007297875359654427
Epoch: 5992, Batch Gradient Norm: 4.249725914832094
Epoch: 5992, Batch Gradient Norm after: 4.249725914832094
Epoch 5993/10000, Prediction Accuracy = 65.45384615384616%, Loss = 0.007236952463594766
Epoch: 5993, Batch Gradient Norm: 4.532612297959629
Epoch: 5993, Batch Gradient Norm after: 4.532612297959629
Epoch 5994/10000, Prediction Accuracy = 65.43461538461537%, Loss = 0.007370492479262443
Epoch: 5994, Batch Gradient Norm: 4.681574212227194
Epoch: 5994, Batch Gradient Norm after: 4.681574212227194
Epoch 5995/10000, Prediction Accuracy = 65.01538461538462%, Loss = 0.0075041226182992644
Epoch: 5995, Batch Gradient Norm: 4.401820918770616
Epoch: 5995, Batch Gradient Norm after: 4.401820918770616
Epoch 5996/10000, Prediction Accuracy = 65.1423076923077%, Loss = 0.007402797122127735
Epoch: 5996, Batch Gradient Norm: 4.842285516444376
Epoch: 5996, Batch Gradient Norm after: 4.842285516444376
Epoch 5997/10000, Prediction Accuracy = 64.86923076923077%, Loss = 0.007509573577688291
Epoch: 5997, Batch Gradient Norm: 4.877724437315261
Epoch: 5997, Batch Gradient Norm after: 4.877724437315261
Epoch 5998/10000, Prediction Accuracy = 64.48076923076923%, Loss = 0.007622442638071684
Epoch: 5998, Batch Gradient Norm: 4.503270718556729
Epoch: 5998, Batch Gradient Norm after: 4.503270718556729
Epoch 5999/10000, Prediction Accuracy = 64.9423076923077%, Loss = 0.0074663059785962105
Epoch: 5999, Batch Gradient Norm: 4.01530354878438
Epoch: 5999, Batch Gradient Norm after: 4.01530354878438
Epoch 6000/10000, Prediction Accuracy = 65.71538461538462%, Loss = 0.007176047585044916
Epoch: 6000, Batch Gradient Norm: 4.153024113501354
Epoch: 6000, Batch Gradient Norm after: 4.153024113501354
Epoch 6001/10000, Prediction Accuracy = 65.70769230769231%, Loss = 0.0071332299938568705
Epoch: 6001, Batch Gradient Norm: 4.665471890952363
Epoch: 6001, Batch Gradient Norm after: 4.665471890952363
Epoch 6002/10000, Prediction Accuracy = 65.31153846153846%, Loss = 0.007449411858732884
Epoch: 6002, Batch Gradient Norm: 4.572294526453364
Epoch: 6002, Batch Gradient Norm after: 4.572294526453364
Epoch 6003/10000, Prediction Accuracy = 65.33461538461539%, Loss = 0.007367424057939878
Epoch: 6003, Batch Gradient Norm: 4.385545946857845
Epoch: 6003, Batch Gradient Norm after: 4.385545946857845
Epoch 6004/10000, Prediction Accuracy = 65.19999999999999%, Loss = 0.007239102815779356
Epoch: 6004, Batch Gradient Norm: 4.307392156844823
Epoch: 6004, Batch Gradient Norm after: 4.307392156844823
Epoch 6005/10000, Prediction Accuracy = 65.23846153846154%, Loss = 0.007257864094124391
Epoch: 6005, Batch Gradient Norm: 4.1735730679012795
Epoch: 6005, Batch Gradient Norm after: 4.1735730679012795
Epoch 6006/10000, Prediction Accuracy = 65.85769230769232%, Loss = 0.007180384969195494
Epoch: 6006, Batch Gradient Norm: 4.4486185617480976
Epoch: 6006, Batch Gradient Norm after: 4.4486185617480976
Epoch 6007/10000, Prediction Accuracy = 65.46923076923076%, Loss = 0.007324153629059975
Epoch: 6007, Batch Gradient Norm: 4.625182469439803
Epoch: 6007, Batch Gradient Norm after: 4.625182469439803
Epoch 6008/10000, Prediction Accuracy = 64.63076923076925%, Loss = 0.007479258347302675
Epoch: 6008, Batch Gradient Norm: 4.259178934737322
Epoch: 6008, Batch Gradient Norm after: 4.259178934737322
Epoch 6009/10000, Prediction Accuracy = 65.23846153846154%, Loss = 0.00729880159577498
Epoch: 6009, Batch Gradient Norm: 4.151824575619958
Epoch: 6009, Batch Gradient Norm after: 4.151824575619958
Epoch 6010/10000, Prediction Accuracy = 65.7%, Loss = 0.007237858676279967
Epoch: 6010, Batch Gradient Norm: 4.353769096599165
Epoch: 6010, Batch Gradient Norm after: 4.353769096599165
Epoch 6011/10000, Prediction Accuracy = 65.72692307692309%, Loss = 0.007314531060938652
Epoch: 6011, Batch Gradient Norm: 4.750145477616653
Epoch: 6011, Batch Gradient Norm after: 4.750145477616653
Epoch 6012/10000, Prediction Accuracy = 64.60384615384615%, Loss = 0.0075672680440430455
Epoch: 6012, Batch Gradient Norm: 4.679982601044589
Epoch: 6012, Batch Gradient Norm after: 4.679982601044589
Epoch 6013/10000, Prediction Accuracy = 64.97692307692309%, Loss = 0.007504683059568589
Epoch: 6013, Batch Gradient Norm: 3.8528820312653718
Epoch: 6013, Batch Gradient Norm after: 3.8528820312653718
Epoch 6014/10000, Prediction Accuracy = 66.1576923076923%, Loss = 0.007028132354697356
Epoch: 6014, Batch Gradient Norm: 3.752974427956972
Epoch: 6014, Batch Gradient Norm after: 3.752974427956972
Epoch 6015/10000, Prediction Accuracy = 66.28076923076924%, Loss = 0.006946256814094691
Epoch: 6015, Batch Gradient Norm: 3.7579651553967865
Epoch: 6015, Batch Gradient Norm after: 3.7579651553967865
Epoch 6016/10000, Prediction Accuracy = 66.52692307692307%, Loss = 0.0070309217374485275
Epoch: 6016, Batch Gradient Norm: 4.604123453793648
Epoch: 6016, Batch Gradient Norm after: 4.604123453793648
Epoch 6017/10000, Prediction Accuracy = 64.84230769230768%, Loss = 0.007413555473948901
Epoch: 6017, Batch Gradient Norm: 5.288910161680238
Epoch: 6017, Batch Gradient Norm after: 5.288910161680238
Epoch 6018/10000, Prediction Accuracy = 63.85384615384615%, Loss = 0.007838106964929746
Epoch: 6018, Batch Gradient Norm: 4.475669561933064
Epoch: 6018, Batch Gradient Norm after: 4.475669561933064
Epoch 6019/10000, Prediction Accuracy = 65.0%, Loss = 0.007516613588310205
Epoch: 6019, Batch Gradient Norm: 4.19179859827052
Epoch: 6019, Batch Gradient Norm after: 4.19179859827052
Epoch 6020/10000, Prediction Accuracy = 65.13846153846154%, Loss = 0.0073585008414318925
Epoch: 6020, Batch Gradient Norm: 3.964233052168331
Epoch: 6020, Batch Gradient Norm after: 3.964233052168331
Epoch 6021/10000, Prediction Accuracy = 65.56153846153846%, Loss = 0.007233604394759123
Epoch: 6021, Batch Gradient Norm: 4.089380946315881
Epoch: 6021, Batch Gradient Norm after: 4.089380946315881
Epoch 6022/10000, Prediction Accuracy = 65.15%, Loss = 0.007193104149057315
Epoch: 6022, Batch Gradient Norm: 4.207090920155871
Epoch: 6022, Batch Gradient Norm after: 4.207090920155871
Epoch 6023/10000, Prediction Accuracy = 66.33461538461538%, Loss = 0.007069101055654196
Epoch: 6023, Batch Gradient Norm: 4.2458312297225875
Epoch: 6023, Batch Gradient Norm after: 4.2458312297225875
Epoch 6024/10000, Prediction Accuracy = 65.3923076923077%, Loss = 0.0072188824773407895
Epoch: 6024, Batch Gradient Norm: 4.714349063278063
Epoch: 6024, Batch Gradient Norm after: 4.714349063278063
Epoch 6025/10000, Prediction Accuracy = 64.88076923076923%, Loss = 0.0074544762476132466
Epoch: 6025, Batch Gradient Norm: 4.416244480794099
Epoch: 6025, Batch Gradient Norm after: 4.416244480794099
Epoch 6026/10000, Prediction Accuracy = 65.37692307692308%, Loss = 0.007319031856380976
Epoch: 6026, Batch Gradient Norm: 4.359779401590312
Epoch: 6026, Batch Gradient Norm after: 4.359779401590312
Epoch 6027/10000, Prediction Accuracy = 65.62307692307692%, Loss = 0.007297215875811302
Epoch: 6027, Batch Gradient Norm: 4.512716567555308
Epoch: 6027, Batch Gradient Norm after: 4.512716567555308
Epoch 6028/10000, Prediction Accuracy = 65.32307692307691%, Loss = 0.007403626178319638
Epoch: 6028, Batch Gradient Norm: 4.412170398834922
Epoch: 6028, Batch Gradient Norm after: 4.412170398834922
Epoch 6029/10000, Prediction Accuracy = 65.22692307692309%, Loss = 0.007365872259609974
Epoch: 6029, Batch Gradient Norm: 4.311731741682053
Epoch: 6029, Batch Gradient Norm after: 4.311731741682053
Epoch 6030/10000, Prediction Accuracy = 65.96923076923078%, Loss = 0.0072403049383025905
Epoch: 6030, Batch Gradient Norm: 4.30109563123717
Epoch: 6030, Batch Gradient Norm after: 4.30109563123717
Epoch 6031/10000, Prediction Accuracy = 65.61923076923077%, Loss = 0.007223588092109332
Epoch: 6031, Batch Gradient Norm: 4.356762662205521
Epoch: 6031, Batch Gradient Norm after: 4.356762662205521
Epoch 6032/10000, Prediction Accuracy = 65.57307692307693%, Loss = 0.0072134717439229674
Epoch: 6032, Batch Gradient Norm: 4.583597834935916
Epoch: 6032, Batch Gradient Norm after: 4.583597834935916
Epoch 6033/10000, Prediction Accuracy = 64.91153846153847%, Loss = 0.007373763534885187
Epoch: 6033, Batch Gradient Norm: 4.172043962153415
Epoch: 6033, Batch Gradient Norm after: 4.172043962153415
Epoch 6034/10000, Prediction Accuracy = 66.08461538461538%, Loss = 0.007211767638532015
Epoch: 6034, Batch Gradient Norm: 4.004540483105448
Epoch: 6034, Batch Gradient Norm after: 4.004540483105448
Epoch 6035/10000, Prediction Accuracy = 65.78846153846153%, Loss = 0.007122503987585123
Epoch: 6035, Batch Gradient Norm: 3.941631939270152
Epoch: 6035, Batch Gradient Norm after: 3.941631939270152
Epoch 6036/10000, Prediction Accuracy = 66.13846153846154%, Loss = 0.007077566133095668
Epoch: 6036, Batch Gradient Norm: 4.091858922770241
Epoch: 6036, Batch Gradient Norm after: 4.091858922770241
Epoch 6037/10000, Prediction Accuracy = 66.12307692307692%, Loss = 0.0071252690484890574
Epoch: 6037, Batch Gradient Norm: 4.479792289716387
Epoch: 6037, Batch Gradient Norm after: 4.479792289716387
Epoch 6038/10000, Prediction Accuracy = 65.31538461538462%, Loss = 0.007371148810936854
Epoch: 6038, Batch Gradient Norm: 4.204018517200658
Epoch: 6038, Batch Gradient Norm after: 4.204018517200658
Epoch 6039/10000, Prediction Accuracy = 65.45769230769231%, Loss = 0.007215018097597819
Epoch: 6039, Batch Gradient Norm: 4.513683743600545
Epoch: 6039, Batch Gradient Norm after: 4.513683743600545
Epoch 6040/10000, Prediction Accuracy = 65.65384615384616%, Loss = 0.00727946819880834
Epoch: 6040, Batch Gradient Norm: 5.074156813280209
Epoch: 6040, Batch Gradient Norm after: 5.074156813280209
Epoch 6041/10000, Prediction Accuracy = 64.59230769230768%, Loss = 0.007656740239606454
Epoch: 6041, Batch Gradient Norm: 4.890013534467538
Epoch: 6041, Batch Gradient Norm after: 4.890013534467538
Epoch 6042/10000, Prediction Accuracy = 64.79615384615386%, Loss = 0.0077154725216902215
Epoch: 6042, Batch Gradient Norm: 4.705838125045973
Epoch: 6042, Batch Gradient Norm after: 4.705838125045973
Epoch 6043/10000, Prediction Accuracy = 65.01153846153846%, Loss = 0.007474370408230103
Epoch: 6043, Batch Gradient Norm: 4.256299385330164
Epoch: 6043, Batch Gradient Norm after: 4.256299385330164
Epoch 6044/10000, Prediction Accuracy = 65.16538461538461%, Loss = 0.007248088753280731
Epoch: 6044, Batch Gradient Norm: 4.2276833577973925
Epoch: 6044, Batch Gradient Norm after: 4.2276833577973925
Epoch 6045/10000, Prediction Accuracy = 65.71538461538461%, Loss = 0.007206500543711277
Epoch: 6045, Batch Gradient Norm: 3.863905467543545
Epoch: 6045, Batch Gradient Norm after: 3.863905467543545
Epoch 6046/10000, Prediction Accuracy = 66.41538461538462%, Loss = 0.007021368588679112
Epoch: 6046, Batch Gradient Norm: 4.0333559748166845
Epoch: 6046, Batch Gradient Norm after: 4.0333559748166845
Epoch 6047/10000, Prediction Accuracy = 66.14999999999999%, Loss = 0.007007871324626299
Epoch: 6047, Batch Gradient Norm: 4.860585617049492
Epoch: 6047, Batch Gradient Norm after: 4.860585617049492
Epoch 6048/10000, Prediction Accuracy = 64.6576923076923%, Loss = 0.007523483202721064
Epoch: 6048, Batch Gradient Norm: 4.377965356475881
Epoch: 6048, Batch Gradient Norm after: 4.377965356475881
Epoch 6049/10000, Prediction Accuracy = 66.01153846153846%, Loss = 0.007257327329940521
Epoch: 6049, Batch Gradient Norm: 4.277178071167885
Epoch: 6049, Batch Gradient Norm after: 4.277178071167885
Epoch 6050/10000, Prediction Accuracy = 65.70769230769231%, Loss = 0.007253770609028065
Epoch: 6050, Batch Gradient Norm: 4.277841652154306
Epoch: 6050, Batch Gradient Norm after: 4.277841652154306
Epoch 6051/10000, Prediction Accuracy = 66.0076923076923%, Loss = 0.007215246164168303
Epoch: 6051, Batch Gradient Norm: 4.477573266195916
Epoch: 6051, Batch Gradient Norm after: 4.477573266195916
Epoch 6052/10000, Prediction Accuracy = 65.91538461538461%, Loss = 0.007304107770323753
Epoch: 6052, Batch Gradient Norm: 4.238045462496112
Epoch: 6052, Batch Gradient Norm after: 4.238045462496112
Epoch 6053/10000, Prediction Accuracy = 65.16153846153847%, Loss = 0.007195357340746201
Epoch: 6053, Batch Gradient Norm: 4.298780397254685
Epoch: 6053, Batch Gradient Norm after: 4.298780397254685
Epoch 6054/10000, Prediction Accuracy = 65.45384615384614%, Loss = 0.007124739985626478
Epoch: 6054, Batch Gradient Norm: 4.630037029526212
Epoch: 6054, Batch Gradient Norm after: 4.630037029526212
Epoch 6055/10000, Prediction Accuracy = 64.88076923076923%, Loss = 0.007380447565363004
Epoch: 6055, Batch Gradient Norm: 4.970107241373646
Epoch: 6055, Batch Gradient Norm after: 4.970107241373646
Epoch 6056/10000, Prediction Accuracy = 64.8576923076923%, Loss = 0.007575259651415623
Epoch: 6056, Batch Gradient Norm: 4.564125144462015
Epoch: 6056, Batch Gradient Norm after: 4.564125144462015
Epoch 6057/10000, Prediction Accuracy = 64.85000000000001%, Loss = 0.007466711712857852
Epoch: 6057, Batch Gradient Norm: 4.307761669861615
Epoch: 6057, Batch Gradient Norm after: 4.307761669861615
Epoch 6058/10000, Prediction Accuracy = 65.74615384615385%, Loss = 0.007221150319450176
Epoch: 6058, Batch Gradient Norm: 5.172775499014598
Epoch: 6058, Batch Gradient Norm after: 5.172775499014598
Epoch 6059/10000, Prediction Accuracy = 64.16923076923078%, Loss = 0.007758004734149346
Epoch: 6059, Batch Gradient Norm: 4.58927029380296
Epoch: 6059, Batch Gradient Norm after: 4.58927029380296
Epoch 6060/10000, Prediction Accuracy = 65.12692307692308%, Loss = 0.007442461541638925
Epoch: 6060, Batch Gradient Norm: 4.118912037327595
Epoch: 6060, Batch Gradient Norm after: 4.118912037327595
Epoch 6061/10000, Prediction Accuracy = 66.28846153846155%, Loss = 0.007159578542296703
Epoch: 6061, Batch Gradient Norm: 4.581327883288086
Epoch: 6061, Batch Gradient Norm after: 4.581327883288086
Epoch 6062/10000, Prediction Accuracy = 65.08076923076922%, Loss = 0.007374258926854684
Epoch: 6062, Batch Gradient Norm: 4.314191694148914
Epoch: 6062, Batch Gradient Norm after: 4.314191694148914
Epoch 6063/10000, Prediction Accuracy = 65.60000000000001%, Loss = 0.007258024711448412
Epoch: 6063, Batch Gradient Norm: 4.405887009434809
Epoch: 6063, Batch Gradient Norm after: 4.405887009434809
Epoch 6064/10000, Prediction Accuracy = 65.67692307692309%, Loss = 0.007281545370530624
Epoch: 6064, Batch Gradient Norm: 4.687272307695902
Epoch: 6064, Batch Gradient Norm after: 4.687272307695902
Epoch 6065/10000, Prediction Accuracy = 64.9153846153846%, Loss = 0.007493027450086979
Epoch: 6065, Batch Gradient Norm: 4.484372247303692
Epoch: 6065, Batch Gradient Norm after: 4.484372247303692
Epoch 6066/10000, Prediction Accuracy = 65.33461538461539%, Loss = 0.007393616430747967
Epoch: 6066, Batch Gradient Norm: 4.210562818039664
Epoch: 6066, Batch Gradient Norm after: 4.210562818039664
Epoch 6067/10000, Prediction Accuracy = 65.80000000000001%, Loss = 0.007146073899303491
Epoch: 6067, Batch Gradient Norm: 3.717827735499079
Epoch: 6067, Batch Gradient Norm after: 3.717827735499079
Epoch 6068/10000, Prediction Accuracy = 66.49615384615385%, Loss = 0.006879030547749538
Epoch: 6068, Batch Gradient Norm: 4.419501732963266
Epoch: 6068, Batch Gradient Norm after: 4.419501732963266
Epoch 6069/10000, Prediction Accuracy = 65.64999999999999%, Loss = 0.007222302401295075
Epoch: 6069, Batch Gradient Norm: 3.9421311069439495
Epoch: 6069, Batch Gradient Norm after: 3.9421311069439495
Epoch 6070/10000, Prediction Accuracy = 66.11538461538463%, Loss = 0.007011768766320669
Epoch: 6070, Batch Gradient Norm: 4.402056684325315
Epoch: 6070, Batch Gradient Norm after: 4.402056684325315
Epoch 6071/10000, Prediction Accuracy = 65.71153846153847%, Loss = 0.007179992488370492
Epoch: 6071, Batch Gradient Norm: 4.400930187787294
Epoch: 6071, Batch Gradient Norm after: 4.400930187787294
Epoch 6072/10000, Prediction Accuracy = 65.3576923076923%, Loss = 0.007350924353186901
Epoch: 6072, Batch Gradient Norm: 4.3970386022917465
Epoch: 6072, Batch Gradient Norm after: 4.3970386022917465
Epoch 6073/10000, Prediction Accuracy = 65.72692307692309%, Loss = 0.007309661211016087
Epoch: 6073, Batch Gradient Norm: 4.491693442903877
Epoch: 6073, Batch Gradient Norm after: 4.491693442903877
Epoch 6074/10000, Prediction Accuracy = 65.03076923076924%, Loss = 0.0073688700795173645
Epoch: 6074, Batch Gradient Norm: 4.065805206164505
Epoch: 6074, Batch Gradient Norm after: 4.065805206164505
Epoch 6075/10000, Prediction Accuracy = 65.74615384615385%, Loss = 0.007210138612068617
Epoch: 6075, Batch Gradient Norm: 4.3530218055851355
Epoch: 6075, Batch Gradient Norm after: 4.3530218055851355
Epoch 6076/10000, Prediction Accuracy = 65.65769230769232%, Loss = 0.007357107081378882
Epoch: 6076, Batch Gradient Norm: 4.307730413686602
Epoch: 6076, Batch Gradient Norm after: 4.307730413686602
Epoch 6077/10000, Prediction Accuracy = 65.6%, Loss = 0.007195419918459196
Epoch: 6077, Batch Gradient Norm: 4.221191257993536
Epoch: 6077, Batch Gradient Norm after: 4.221191257993536
Epoch 6078/10000, Prediction Accuracy = 65.87307692307694%, Loss = 0.007200326806364151
Epoch: 6078, Batch Gradient Norm: 4.443378723389225
Epoch: 6078, Batch Gradient Norm after: 4.443378723389225
Epoch 6079/10000, Prediction Accuracy = 65.41153846153847%, Loss = 0.007230598551149552
Epoch: 6079, Batch Gradient Norm: 4.3542310834472655
Epoch: 6079, Batch Gradient Norm after: 4.3542310834472655
Epoch 6080/10000, Prediction Accuracy = 65.38846153846154%, Loss = 0.00728258490562439
Epoch: 6080, Batch Gradient Norm: 4.190332526816151
Epoch: 6080, Batch Gradient Norm after: 4.190332526816151
Epoch 6081/10000, Prediction Accuracy = 65.49615384615385%, Loss = 0.007238733331457927
Epoch: 6081, Batch Gradient Norm: 4.594402497145186
Epoch: 6081, Batch Gradient Norm after: 4.594402497145186
Epoch 6082/10000, Prediction Accuracy = 65.19999999999999%, Loss = 0.0073445599454526715
Epoch: 6082, Batch Gradient Norm: 3.843575633490475
Epoch: 6082, Batch Gradient Norm after: 3.843575633490475
Epoch 6083/10000, Prediction Accuracy = 66.26923076923077%, Loss = 0.006985000298859982
Epoch: 6083, Batch Gradient Norm: 4.327272034989816
Epoch: 6083, Batch Gradient Norm after: 4.327272034989816
Epoch 6084/10000, Prediction Accuracy = 65.87307692307692%, Loss = 0.007144046374238455
Epoch: 6084, Batch Gradient Norm: 4.444205962155507
Epoch: 6084, Batch Gradient Norm after: 4.444205962155507
Epoch 6085/10000, Prediction Accuracy = 65.51538461538462%, Loss = 0.007271763796989734
Epoch: 6085, Batch Gradient Norm: 4.762083540509247
Epoch: 6085, Batch Gradient Norm after: 4.762083540509247
Epoch 6086/10000, Prediction Accuracy = 64.97692307692306%, Loss = 0.00741383945569396
Epoch: 6086, Batch Gradient Norm: 4.53205256199816
Epoch: 6086, Batch Gradient Norm after: 4.53205256199816
Epoch 6087/10000, Prediction Accuracy = 65.68076923076923%, Loss = 0.007301066643916643
Epoch: 6087, Batch Gradient Norm: 4.813746543976208
Epoch: 6087, Batch Gradient Norm after: 4.813746543976208
Epoch 6088/10000, Prediction Accuracy = 64.65769230769232%, Loss = 0.007543724746658252
Epoch: 6088, Batch Gradient Norm: 4.7333841908882475
Epoch: 6088, Batch Gradient Norm after: 4.7333841908882475
Epoch 6089/10000, Prediction Accuracy = 64.9423076923077%, Loss = 0.0074761520641354415
Epoch: 6089, Batch Gradient Norm: 4.291293589407675
Epoch: 6089, Batch Gradient Norm after: 4.291293589407675
Epoch 6090/10000, Prediction Accuracy = 65.50384615384615%, Loss = 0.007205568253993988
Epoch: 6090, Batch Gradient Norm: 4.067256077540048
Epoch: 6090, Batch Gradient Norm after: 4.067256077540048
Epoch 6091/10000, Prediction Accuracy = 65.91153846153846%, Loss = 0.007139487586055811
Epoch: 6091, Batch Gradient Norm: 4.622773056434868
Epoch: 6091, Batch Gradient Norm after: 4.622773056434868
Epoch 6092/10000, Prediction Accuracy = 65.25384615384615%, Loss = 0.007414630972422087
Epoch: 6092, Batch Gradient Norm: 4.288341989271758
Epoch: 6092, Batch Gradient Norm after: 4.288341989271758
Epoch 6093/10000, Prediction Accuracy = 65.54615384615386%, Loss = 0.007221794579751217
Epoch: 6093, Batch Gradient Norm: 4.571334291169741
Epoch: 6093, Batch Gradient Norm after: 4.571334291169741
Epoch 6094/10000, Prediction Accuracy = 65.3576923076923%, Loss = 0.007400250599647944
Epoch: 6094, Batch Gradient Norm: 4.5722067251891785
Epoch: 6094, Batch Gradient Norm after: 4.5722067251891785
Epoch 6095/10000, Prediction Accuracy = 65.27692307692307%, Loss = 0.007426581990260344
Epoch: 6095, Batch Gradient Norm: 4.316635705474525
Epoch: 6095, Batch Gradient Norm after: 4.316635705474525
Epoch 6096/10000, Prediction Accuracy = 65.74230769230768%, Loss = 0.007223831525502296
Epoch: 6096, Batch Gradient Norm: 4.386400552196195
Epoch: 6096, Batch Gradient Norm after: 4.386400552196195
Epoch 6097/10000, Prediction Accuracy = 65.35384615384615%, Loss = 0.007370352064474271
Epoch: 6097, Batch Gradient Norm: 4.242658769547205
Epoch: 6097, Batch Gradient Norm after: 4.242658769547205
Epoch 6098/10000, Prediction Accuracy = 65.71153846153847%, Loss = 0.007298858191531438
Epoch: 6098, Batch Gradient Norm: 4.26553130545549
Epoch: 6098, Batch Gradient Norm after: 4.26553130545549
Epoch 6099/10000, Prediction Accuracy = 65.88846153846154%, Loss = 0.007190486917702051
Epoch: 6099, Batch Gradient Norm: 3.979309130273076
Epoch: 6099, Batch Gradient Norm after: 3.979309130273076
Epoch 6100/10000, Prediction Accuracy = 65.85000000000001%, Loss = 0.007099041428703528
Epoch: 6100, Batch Gradient Norm: 4.282184761521013
Epoch: 6100, Batch Gradient Norm after: 4.282184761521013
Epoch 6101/10000, Prediction Accuracy = 65.86538461538461%, Loss = 0.007210250048396679
Epoch: 6101, Batch Gradient Norm: 4.280127618886768
Epoch: 6101, Batch Gradient Norm after: 4.280127618886768
Epoch 6102/10000, Prediction Accuracy = 65.81923076923077%, Loss = 0.007097974312133514
Epoch: 6102, Batch Gradient Norm: 4.903574815569854
Epoch: 6102, Batch Gradient Norm after: 4.903574815569854
Epoch 6103/10000, Prediction Accuracy = 65.2423076923077%, Loss = 0.0074481549314581435
Epoch: 6103, Batch Gradient Norm: 4.972523304513436
Epoch: 6103, Batch Gradient Norm after: 4.972523304513436
Epoch 6104/10000, Prediction Accuracy = 64.31153846153846%, Loss = 0.007574018807365344
Epoch: 6104, Batch Gradient Norm: 4.341658795958637
Epoch: 6104, Batch Gradient Norm after: 4.341658795958637
Epoch 6105/10000, Prediction Accuracy = 65.41538461538461%, Loss = 0.007345117879315064
Epoch: 6105, Batch Gradient Norm: 4.234249113153714
Epoch: 6105, Batch Gradient Norm after: 4.234249113153714
Epoch 6106/10000, Prediction Accuracy = 65.51153846153846%, Loss = 0.007267903393277755
Epoch: 6106, Batch Gradient Norm: 4.051712363053865
Epoch: 6106, Batch Gradient Norm after: 4.051712363053865
Epoch 6107/10000, Prediction Accuracy = 66.14615384615385%, Loss = 0.007152006925585179
Epoch: 6107, Batch Gradient Norm: 4.27158399989609
Epoch: 6107, Batch Gradient Norm after: 4.27158399989609
Epoch 6108/10000, Prediction Accuracy = 65.35000000000001%, Loss = 0.007286647692895853
Epoch: 6108, Batch Gradient Norm: 4.76518320676035
Epoch: 6108, Batch Gradient Norm after: 4.76518320676035
Epoch 6109/10000, Prediction Accuracy = 64.78076923076922%, Loss = 0.0074283639327264745
Epoch: 6109, Batch Gradient Norm: 4.845875414031185
Epoch: 6109, Batch Gradient Norm after: 4.845875414031185
Epoch 6110/10000, Prediction Accuracy = 64.76153846153846%, Loss = 0.007510153218530691
Epoch: 6110, Batch Gradient Norm: 4.825653076160257
Epoch: 6110, Batch Gradient Norm after: 4.825653076160257
Epoch 6111/10000, Prediction Accuracy = 64.29615384615384%, Loss = 0.007502201192367535
Epoch: 6111, Batch Gradient Norm: 4.6738182386234834
Epoch: 6111, Batch Gradient Norm after: 4.6738182386234834
Epoch 6112/10000, Prediction Accuracy = 64.68461538461538%, Loss = 0.007434513813887651
Epoch: 6112, Batch Gradient Norm: 4.744513141419435
Epoch: 6112, Batch Gradient Norm after: 4.744513141419435
Epoch 6113/10000, Prediction Accuracy = 64.87307692307692%, Loss = 0.007494135580670375
Epoch: 6113, Batch Gradient Norm: 4.391927286071808
Epoch: 6113, Batch Gradient Norm after: 4.391927286071808
Epoch 6114/10000, Prediction Accuracy = 65.7%, Loss = 0.007260369101109413
Epoch: 6114, Batch Gradient Norm: 4.549256151269145
Epoch: 6114, Batch Gradient Norm after: 4.549256151269145
Epoch 6115/10000, Prediction Accuracy = 64.98461538461538%, Loss = 0.0074771537015644405
Epoch: 6115, Batch Gradient Norm: 4.2075322800515
Epoch: 6115, Batch Gradient Norm after: 4.2075322800515
Epoch 6116/10000, Prediction Accuracy = 65.43846153846154%, Loss = 0.007318665022746875
Epoch: 6116, Batch Gradient Norm: 4.336082889672314
Epoch: 6116, Batch Gradient Norm after: 4.336082889672314
Epoch 6117/10000, Prediction Accuracy = 65.14615384615385%, Loss = 0.007324947474094538
Epoch: 6117, Batch Gradient Norm: 4.335664266017772
Epoch: 6117, Batch Gradient Norm after: 4.335664266017772
Epoch 6118/10000, Prediction Accuracy = 65.83461538461538%, Loss = 0.007251332048326731
Epoch: 6118, Batch Gradient Norm: 4.514297127638224
Epoch: 6118, Batch Gradient Norm after: 4.514297127638224
Epoch 6119/10000, Prediction Accuracy = 65.06538461538463%, Loss = 0.007397937337652995
Epoch: 6119, Batch Gradient Norm: 4.215635626773208
Epoch: 6119, Batch Gradient Norm after: 4.215635626773208
Epoch 6120/10000, Prediction Accuracy = 65.63846153846154%, Loss = 0.007263994954812985
Epoch: 6120, Batch Gradient Norm: 3.893151858331569
Epoch: 6120, Batch Gradient Norm after: 3.893151858331569
Epoch 6121/10000, Prediction Accuracy = 66.22692307692309%, Loss = 0.007071477719224417
Epoch: 6121, Batch Gradient Norm: 3.983720464636654
Epoch: 6121, Batch Gradient Norm after: 3.983720464636654
Epoch 6122/10000, Prediction Accuracy = 66.31923076923077%, Loss = 0.0070050283191868895
Epoch: 6122, Batch Gradient Norm: 4.29549539159137
Epoch: 6122, Batch Gradient Norm after: 4.29549539159137
Epoch 6123/10000, Prediction Accuracy = 65.70384615384616%, Loss = 0.007228930444958119
Epoch: 6123, Batch Gradient Norm: 4.555785572215043
Epoch: 6123, Batch Gradient Norm after: 4.555785572215043
Epoch 6124/10000, Prediction Accuracy = 64.76923076923076%, Loss = 0.007452387649279375
Epoch: 6124, Batch Gradient Norm: 5.049397921142261
Epoch: 6124, Batch Gradient Norm after: 5.049397921142261
Epoch 6125/10000, Prediction Accuracy = 64.45769230769231%, Loss = 0.007731980966547361
Epoch: 6125, Batch Gradient Norm: 4.477630088016387
Epoch: 6125, Batch Gradient Norm after: 4.477630088016387
Epoch 6126/10000, Prediction Accuracy = 65.33461538461539%, Loss = 0.007406392457106939
Epoch: 6126, Batch Gradient Norm: 4.582003744947103
Epoch: 6126, Batch Gradient Norm after: 4.582003744947103
Epoch 6127/10000, Prediction Accuracy = 65.39615384615384%, Loss = 0.00740163278980897
Epoch: 6127, Batch Gradient Norm: 4.832773104460275
Epoch: 6127, Batch Gradient Norm after: 4.832773104460275
Epoch 6128/10000, Prediction Accuracy = 64.79230769230767%, Loss = 0.007628874208491582
Epoch: 6128, Batch Gradient Norm: 4.306840877522876
Epoch: 6128, Batch Gradient Norm after: 4.306840877522876
Epoch 6129/10000, Prediction Accuracy = 65.33846153846153%, Loss = 0.007285333202721981
Epoch: 6129, Batch Gradient Norm: 4.302684776254749
Epoch: 6129, Batch Gradient Norm after: 4.302684776254749
Epoch 6130/10000, Prediction Accuracy = 65.66923076923077%, Loss = 0.007335279495097124
Epoch: 6130, Batch Gradient Norm: 3.9031638189966262
Epoch: 6130, Batch Gradient Norm after: 3.9031638189966262
Epoch 6131/10000, Prediction Accuracy = 66.26538461538462%, Loss = 0.00708153650451165
Epoch: 6131, Batch Gradient Norm: 3.7289566162860415
Epoch: 6131, Batch Gradient Norm after: 3.7289566162860415
Epoch 6132/10000, Prediction Accuracy = 66.51153846153846%, Loss = 0.006942955812869163
Epoch: 6132, Batch Gradient Norm: 4.423050033184028
Epoch: 6132, Batch Gradient Norm after: 4.423050033184028
Epoch 6133/10000, Prediction Accuracy = 65.36923076923077%, Loss = 0.007237086645685709
Epoch: 6133, Batch Gradient Norm: 4.81327389724764
Epoch: 6133, Batch Gradient Norm after: 4.81327389724764
Epoch 6134/10000, Prediction Accuracy = 64.85384615384615%, Loss = 0.007505936798854516
Epoch: 6134, Batch Gradient Norm: 4.480538002687665
Epoch: 6134, Batch Gradient Norm after: 4.480538002687665
Epoch 6135/10000, Prediction Accuracy = 65.36923076923078%, Loss = 0.007305391491032564
Epoch: 6135, Batch Gradient Norm: 4.305447689958378
Epoch: 6135, Batch Gradient Norm after: 4.305447689958378
Epoch 6136/10000, Prediction Accuracy = 65.75%, Loss = 0.007200632710009813
Epoch: 6136, Batch Gradient Norm: 4.691257661681197
Epoch: 6136, Batch Gradient Norm after: 4.691257661681197
Epoch 6137/10000, Prediction Accuracy = 65.78461538461539%, Loss = 0.007336773873808293
Epoch: 6137, Batch Gradient Norm: 4.321318926598432
Epoch: 6137, Batch Gradient Norm after: 4.321318926598432
Epoch 6138/10000, Prediction Accuracy = 65.3423076923077%, Loss = 0.0072979548802742595
Epoch: 6138, Batch Gradient Norm: 4.29563808889071
Epoch: 6138, Batch Gradient Norm after: 4.29563808889071
Epoch 6139/10000, Prediction Accuracy = 65.16538461538462%, Loss = 0.007263502177710717
Epoch: 6139, Batch Gradient Norm: 4.609491564670715
Epoch: 6139, Batch Gradient Norm after: 4.609491564670715
Epoch 6140/10000, Prediction Accuracy = 64.96153846153847%, Loss = 0.007456687852167166
Epoch: 6140, Batch Gradient Norm: 4.610757524364316
Epoch: 6140, Batch Gradient Norm after: 4.610757524364316
Epoch 6141/10000, Prediction Accuracy = 64.88076923076922%, Loss = 0.007560273811507683
Epoch: 6141, Batch Gradient Norm: 4.538053732077825
Epoch: 6141, Batch Gradient Norm after: 4.538053732077825
Epoch 6142/10000, Prediction Accuracy = 64.85769230769232%, Loss = 0.007392585492477967
Epoch: 6142, Batch Gradient Norm: 5.083797626453076
Epoch: 6142, Batch Gradient Norm after: 5.083797626453076
Epoch 6143/10000, Prediction Accuracy = 64.18076923076924%, Loss = 0.0077400772402492855
Epoch: 6143, Batch Gradient Norm: 4.651370416621001
Epoch: 6143, Batch Gradient Norm after: 4.651370416621001
Epoch 6144/10000, Prediction Accuracy = 64.9730769230769%, Loss = 0.007384374379538572
Epoch: 6144, Batch Gradient Norm: 4.249634904430769
Epoch: 6144, Batch Gradient Norm after: 4.249634904430769
Epoch 6145/10000, Prediction Accuracy = 65.44615384615385%, Loss = 0.007393895397679164
Epoch: 6145, Batch Gradient Norm: 4.040030638717968
Epoch: 6145, Batch Gradient Norm after: 4.040030638717968
Epoch 6146/10000, Prediction Accuracy = 65.92692307692307%, Loss = 0.0071421075397386
Epoch: 6146, Batch Gradient Norm: 4.16047698371118
Epoch: 6146, Batch Gradient Norm after: 4.16047698371118
Epoch 6147/10000, Prediction Accuracy = 65.35000000000001%, Loss = 0.007212897046254232
Epoch: 6147, Batch Gradient Norm: 4.042644889133057
Epoch: 6147, Batch Gradient Norm after: 4.042644889133057
Epoch 6148/10000, Prediction Accuracy = 66.13846153846153%, Loss = 0.007152539857018452
Epoch: 6148, Batch Gradient Norm: 3.9294595740637503
Epoch: 6148, Batch Gradient Norm after: 3.9294595740637503
Epoch 6149/10000, Prediction Accuracy = 66.15384615384616%, Loss = 0.0070211177763457484
Epoch: 6149, Batch Gradient Norm: 4.222272561732206
Epoch: 6149, Batch Gradient Norm after: 4.222272561732206
Epoch 6150/10000, Prediction Accuracy = 65.77307692307691%, Loss = 0.007099663086522084
Epoch: 6150, Batch Gradient Norm: 3.930014950066116
Epoch: 6150, Batch Gradient Norm after: 3.930014950066116
Epoch 6151/10000, Prediction Accuracy = 66.16538461538461%, Loss = 0.0069791523453134755
Epoch: 6151, Batch Gradient Norm: 4.169716457401921
Epoch: 6151, Batch Gradient Norm after: 4.169716457401921
Epoch 6152/10000, Prediction Accuracy = 66.26923076923077%, Loss = 0.0070242417546419
Epoch: 6152, Batch Gradient Norm: 4.293290683888149
Epoch: 6152, Batch Gradient Norm after: 4.293290683888149
Epoch 6153/10000, Prediction Accuracy = 65.65384615384617%, Loss = 0.007175440434366465
Epoch: 6153, Batch Gradient Norm: 4.5339441939298935
Epoch: 6153, Batch Gradient Norm after: 4.5339441939298935
Epoch 6154/10000, Prediction Accuracy = 65.67692307692309%, Loss = 0.007243710677497662
Epoch: 6154, Batch Gradient Norm: 4.345197161586705
Epoch: 6154, Batch Gradient Norm after: 4.345197161586705
Epoch 6155/10000, Prediction Accuracy = 66.00384615384615%, Loss = 0.007188202956548104
Epoch: 6155, Batch Gradient Norm: 4.790580982440255
Epoch: 6155, Batch Gradient Norm after: 4.790580982440255
Epoch 6156/10000, Prediction Accuracy = 64.7923076923077%, Loss = 0.007550285126154239
Epoch: 6156, Batch Gradient Norm: 4.519503398155566
Epoch: 6156, Batch Gradient Norm after: 4.519503398155566
Epoch 6157/10000, Prediction Accuracy = 65.08076923076922%, Loss = 0.007345065367049896
Epoch: 6157, Batch Gradient Norm: 4.623735834597336
Epoch: 6157, Batch Gradient Norm after: 4.623735834597336
Epoch 6158/10000, Prediction Accuracy = 64.91538461538461%, Loss = 0.007386736070307402
Epoch: 6158, Batch Gradient Norm: 4.473350334898232
Epoch: 6158, Batch Gradient Norm after: 4.473350334898232
Epoch 6159/10000, Prediction Accuracy = 65.25384615384617%, Loss = 0.007259517585715422
Epoch: 6159, Batch Gradient Norm: 4.904522126672224
Epoch: 6159, Batch Gradient Norm after: 4.904522126672224
Epoch 6160/10000, Prediction Accuracy = 64.51538461538462%, Loss = 0.007590055573158539
Epoch: 6160, Batch Gradient Norm: 4.520302031600368
Epoch: 6160, Batch Gradient Norm after: 4.520302031600368
Epoch 6161/10000, Prediction Accuracy = 65.77692307692307%, Loss = 0.0071779178598752385
Epoch: 6161, Batch Gradient Norm: 5.017981537804348
Epoch: 6161, Batch Gradient Norm after: 5.017981537804348
Epoch 6162/10000, Prediction Accuracy = 64.52692307692308%, Loss = 0.007698857583678686
Epoch: 6162, Batch Gradient Norm: 4.76295836367768
Epoch: 6162, Batch Gradient Norm after: 4.76295836367768
Epoch 6163/10000, Prediction Accuracy = 64.90384615384615%, Loss = 0.0074610661428708295
Epoch: 6163, Batch Gradient Norm: 4.062292191814966
Epoch: 6163, Batch Gradient Norm after: 4.062292191814966
Epoch 6164/10000, Prediction Accuracy = 66.39999999999999%, Loss = 0.007115322809952956
Epoch: 6164, Batch Gradient Norm: 4.38062645392873
Epoch: 6164, Batch Gradient Norm after: 4.38062645392873
Epoch 6165/10000, Prediction Accuracy = 65.51153846153846%, Loss = 0.007277646173651402
Epoch: 6165, Batch Gradient Norm: 3.956627224086481
Epoch: 6165, Batch Gradient Norm after: 3.956627224086481
Epoch 6166/10000, Prediction Accuracy = 66.27692307692307%, Loss = 0.007041418280165929
Epoch: 6166, Batch Gradient Norm: 4.002845357007076
Epoch: 6166, Batch Gradient Norm after: 4.002845357007076
Epoch 6167/10000, Prediction Accuracy = 66.20384615384613%, Loss = 0.007002847663198526
Epoch: 6167, Batch Gradient Norm: 4.074436718562953
Epoch: 6167, Batch Gradient Norm after: 4.074436718562953
Epoch 6168/10000, Prediction Accuracy = 66.21538461538461%, Loss = 0.006969310235805237
Epoch: 6168, Batch Gradient Norm: 4.311898487560216
Epoch: 6168, Batch Gradient Norm after: 4.311898487560216
Epoch 6169/10000, Prediction Accuracy = 65.88076923076923%, Loss = 0.007125382132541675
Epoch: 6169, Batch Gradient Norm: 4.683661261366585
Epoch: 6169, Batch Gradient Norm after: 4.683661261366585
Epoch 6170/10000, Prediction Accuracy = 65.40384615384616%, Loss = 0.007295226284231131
Epoch: 6170, Batch Gradient Norm: 4.907105397161053
Epoch: 6170, Batch Gradient Norm after: 4.907105397161053
Epoch 6171/10000, Prediction Accuracy = 64.87692307692306%, Loss = 0.007461588901395981
Epoch: 6171, Batch Gradient Norm: 4.948779591865277
Epoch: 6171, Batch Gradient Norm after: 4.948779591865277
Epoch 6172/10000, Prediction Accuracy = 64.5576923076923%, Loss = 0.0075557178531128625
Epoch: 6172, Batch Gradient Norm: 5.052061496635439
Epoch: 6172, Batch Gradient Norm after: 5.052061496635439
Epoch 6173/10000, Prediction Accuracy = 65.10384615384613%, Loss = 0.007560175055494675
Epoch: 6173, Batch Gradient Norm: 4.448880930877118
Epoch: 6173, Batch Gradient Norm after: 4.448880930877118
Epoch 6174/10000, Prediction Accuracy = 65.7576923076923%, Loss = 0.0072614099973669416
Epoch: 6174, Batch Gradient Norm: 4.48800477687299
Epoch: 6174, Batch Gradient Norm after: 4.48800477687299
Epoch 6175/10000, Prediction Accuracy = 64.81153846153846%, Loss = 0.00731130581922256
Epoch: 6175, Batch Gradient Norm: 4.216914677830409
Epoch: 6175, Batch Gradient Norm after: 4.216914677830409
Epoch 6176/10000, Prediction Accuracy = 65.9%, Loss = 0.007241830480499909
Epoch: 6176, Batch Gradient Norm: 4.275465071798195
Epoch: 6176, Batch Gradient Norm after: 4.275465071798195
Epoch 6177/10000, Prediction Accuracy = 66.04615384615384%, Loss = 0.007120636220161731
Epoch: 6177, Batch Gradient Norm: 4.5510034715354895
Epoch: 6177, Batch Gradient Norm after: 4.5510034715354895
Epoch 6178/10000, Prediction Accuracy = 65.34615384615384%, Loss = 0.007250340727086251
Epoch: 6178, Batch Gradient Norm: 4.21522772085798
Epoch: 6178, Batch Gradient Norm after: 4.21522772085798
Epoch 6179/10000, Prediction Accuracy = 65.7076923076923%, Loss = 0.007191285741730378
Epoch: 6179, Batch Gradient Norm: 4.158589216886469
Epoch: 6179, Batch Gradient Norm after: 4.158589216886469
Epoch 6180/10000, Prediction Accuracy = 65.82692307692308%, Loss = 0.007145555260089727
Epoch: 6180, Batch Gradient Norm: 4.32217336924078
Epoch: 6180, Batch Gradient Norm after: 4.32217336924078
Epoch 6181/10000, Prediction Accuracy = 65.05384615384615%, Loss = 0.007209065012060679
Epoch: 6181, Batch Gradient Norm: 4.625775084611569
Epoch: 6181, Batch Gradient Norm after: 4.625775084611569
Epoch 6182/10000, Prediction Accuracy = 65.21153846153847%, Loss = 0.007377506985973854
Epoch: 6182, Batch Gradient Norm: 4.440237782807987
Epoch: 6182, Batch Gradient Norm after: 4.440237782807987
Epoch 6183/10000, Prediction Accuracy = 65.32692307692308%, Loss = 0.007391256996645377
Epoch: 6183, Batch Gradient Norm: 4.75609989849023
Epoch: 6183, Batch Gradient Norm after: 4.75609989849023
Epoch 6184/10000, Prediction Accuracy = 64.79615384615386%, Loss = 0.007480451622261451
Epoch: 6184, Batch Gradient Norm: 5.0587771827514905
Epoch: 6184, Batch Gradient Norm after: 5.0587771827514905
Epoch 6185/10000, Prediction Accuracy = 64.04615384615384%, Loss = 0.007848492859361263
Epoch: 6185, Batch Gradient Norm: 4.541657991774228
Epoch: 6185, Batch Gradient Norm after: 4.541657991774228
Epoch 6186/10000, Prediction Accuracy = 64.63461538461539%, Loss = 0.007524658603450427
Epoch: 6186, Batch Gradient Norm: 4.515242515514268
Epoch: 6186, Batch Gradient Norm after: 4.515242515514268
Epoch 6187/10000, Prediction Accuracy = 65.15384615384616%, Loss = 0.007496901966917973
Epoch: 6187, Batch Gradient Norm: 4.503127242894633
Epoch: 6187, Batch Gradient Norm after: 4.503127242894633
Epoch 6188/10000, Prediction Accuracy = 65.1%, Loss = 0.007371109301367631
Epoch: 6188, Batch Gradient Norm: 3.992118113595373
Epoch: 6188, Batch Gradient Norm after: 3.992118113595373
Epoch 6189/10000, Prediction Accuracy = 66.20769230769231%, Loss = 0.007115197511246571
Epoch: 6189, Batch Gradient Norm: 4.614157894020102
Epoch: 6189, Batch Gradient Norm after: 4.614157894020102
Epoch 6190/10000, Prediction Accuracy = 65.20384615384616%, Loss = 0.007339605452636113
Epoch: 6190, Batch Gradient Norm: 4.271075121513074
Epoch: 6190, Batch Gradient Norm after: 4.271075121513074
Epoch 6191/10000, Prediction Accuracy = 65.6423076923077%, Loss = 0.007226571369056518
Epoch: 6191, Batch Gradient Norm: 4.343529783942035
Epoch: 6191, Batch Gradient Norm after: 4.343529783942035
Epoch 6192/10000, Prediction Accuracy = 65.56153846153848%, Loss = 0.007193910925147625
Epoch: 6192, Batch Gradient Norm: 4.394782435200959
Epoch: 6192, Batch Gradient Norm after: 4.394782435200959
Epoch 6193/10000, Prediction Accuracy = 65.75384615384615%, Loss = 0.007237310628764904
Epoch: 6193, Batch Gradient Norm: 4.3391212905410335
Epoch: 6193, Batch Gradient Norm after: 4.3391212905410335
Epoch 6194/10000, Prediction Accuracy = 66.04230769230769%, Loss = 0.007206295007983079
Epoch: 6194, Batch Gradient Norm: 4.5125532345638595
Epoch: 6194, Batch Gradient Norm after: 4.5125532345638595
Epoch 6195/10000, Prediction Accuracy = 65.40384615384616%, Loss = 0.007291168440133333
Epoch: 6195, Batch Gradient Norm: 4.132788909804109
Epoch: 6195, Batch Gradient Norm after: 4.132788909804109
Epoch 6196/10000, Prediction Accuracy = 66.18846153846154%, Loss = 0.007152926714087908
Epoch: 6196, Batch Gradient Norm: 4.1573078566553745
Epoch: 6196, Batch Gradient Norm after: 4.1573078566553745
Epoch 6197/10000, Prediction Accuracy = 65.7%, Loss = 0.0072066246603543944
Epoch: 6197, Batch Gradient Norm: 4.276350039560351
Epoch: 6197, Batch Gradient Norm after: 4.276350039560351
Epoch 6198/10000, Prediction Accuracy = 65.24230769230769%, Loss = 0.007251705078837963
Epoch: 6198, Batch Gradient Norm: 4.299807100127282
Epoch: 6198, Batch Gradient Norm after: 4.299807100127282
Epoch 6199/10000, Prediction Accuracy = 65.68076923076923%, Loss = 0.007142121509577219
Epoch: 6199, Batch Gradient Norm: 3.957802390795526
Epoch: 6199, Batch Gradient Norm after: 3.957802390795526
Epoch 6200/10000, Prediction Accuracy = 66.0923076923077%, Loss = 0.0070659608150330875
Epoch: 6200, Batch Gradient Norm: 4.135598424437405
Epoch: 6200, Batch Gradient Norm after: 4.135598424437405
Epoch 6201/10000, Prediction Accuracy = 66.22692307692307%, Loss = 0.007094391335088473
Epoch: 6201, Batch Gradient Norm: 4.512102565637666
Epoch: 6201, Batch Gradient Norm after: 4.512102565637666
Epoch 6202/10000, Prediction Accuracy = 65.2423076923077%, Loss = 0.007381656242964359
Epoch: 6202, Batch Gradient Norm: 4.8906937066539795
Epoch: 6202, Batch Gradient Norm after: 4.8906937066539795
Epoch 6203/10000, Prediction Accuracy = 65.03846153846155%, Loss = 0.007539893034845591
Epoch: 6203, Batch Gradient Norm: 4.981445688346721
Epoch: 6203, Batch Gradient Norm after: 4.981445688346721
Epoch 6204/10000, Prediction Accuracy = 64.38461538461539%, Loss = 0.00765229847568732
Epoch: 6204, Batch Gradient Norm: 4.153313211298774
Epoch: 6204, Batch Gradient Norm after: 4.153313211298774
Epoch 6205/10000, Prediction Accuracy = 66.06153846153846%, Loss = 0.007166786441722741
Epoch: 6205, Batch Gradient Norm: 3.9830156380544506
Epoch: 6205, Batch Gradient Norm after: 3.9830156380544506
Epoch 6206/10000, Prediction Accuracy = 66.18846153846154%, Loss = 0.007041337971503918
Epoch: 6206, Batch Gradient Norm: 4.0063219156926575
Epoch: 6206, Batch Gradient Norm after: 4.0063219156926575
Epoch 6207/10000, Prediction Accuracy = 65.88076923076923%, Loss = 0.0070927882065566685
Epoch: 6207, Batch Gradient Norm: 4.831800741438275
Epoch: 6207, Batch Gradient Norm after: 4.831800741438275
Epoch 6208/10000, Prediction Accuracy = 64.98846153846154%, Loss = 0.007562367102274528
Epoch: 6208, Batch Gradient Norm: 4.473778486245221
Epoch: 6208, Batch Gradient Norm after: 4.473778486245221
Epoch 6209/10000, Prediction Accuracy = 65.1153846153846%, Loss = 0.007403617259114981
Epoch: 6209, Batch Gradient Norm: 4.395232530987776
Epoch: 6209, Batch Gradient Norm after: 4.395232530987776
Epoch 6210/10000, Prediction Accuracy = 65.54230769230769%, Loss = 0.007229984558832187
Epoch: 6210, Batch Gradient Norm: 4.586246584154085
Epoch: 6210, Batch Gradient Norm after: 4.586246584154085
Epoch 6211/10000, Prediction Accuracy = 64.75384615384615%, Loss = 0.007513482231073654
Epoch: 6211, Batch Gradient Norm: 4.504949444836776
Epoch: 6211, Batch Gradient Norm after: 4.504949444836776
Epoch 6212/10000, Prediction Accuracy = 65.06923076923077%, Loss = 0.0073777345868830495
Epoch: 6212, Batch Gradient Norm: 4.782583214482965
Epoch: 6212, Batch Gradient Norm after: 4.782583214482965
Epoch 6213/10000, Prediction Accuracy = 64.56153846153846%, Loss = 0.007560974201903894
Epoch: 6213, Batch Gradient Norm: 4.279258682976402
Epoch: 6213, Batch Gradient Norm after: 4.279258682976402
Epoch 6214/10000, Prediction Accuracy = 65.13076923076923%, Loss = 0.007347946628355063
Epoch: 6214, Batch Gradient Norm: 4.454996851477929
Epoch: 6214, Batch Gradient Norm after: 4.454996851477929
Epoch 6215/10000, Prediction Accuracy = 65.73076923076923%, Loss = 0.007363006042746397
Epoch: 6215, Batch Gradient Norm: 4.565652569567052
Epoch: 6215, Batch Gradient Norm after: 4.565652569567052
Epoch 6216/10000, Prediction Accuracy = 64.55384615384615%, Loss = 0.007633601028758746
Epoch: 6216, Batch Gradient Norm: 4.302400678147243
Epoch: 6216, Batch Gradient Norm after: 4.302400678147243
Epoch 6217/10000, Prediction Accuracy = 65.01923076923077%, Loss = 0.007400814443826675
Epoch: 6217, Batch Gradient Norm: 4.342193741354423
Epoch: 6217, Batch Gradient Norm after: 4.342193741354423
Epoch 6218/10000, Prediction Accuracy = 65.47692307692307%, Loss = 0.0073539367160544945
Epoch: 6218, Batch Gradient Norm: 4.534695118263276
Epoch: 6218, Batch Gradient Norm after: 4.534695118263276
Epoch 6219/10000, Prediction Accuracy = 65.49230769230768%, Loss = 0.007375757245776745
Epoch: 6219, Batch Gradient Norm: 5.11827065542408
Epoch: 6219, Batch Gradient Norm after: 5.11827065542408
Epoch 6220/10000, Prediction Accuracy = 64.67307692307692%, Loss = 0.007737218867987394
Epoch: 6220, Batch Gradient Norm: 4.3697105544130315
Epoch: 6220, Batch Gradient Norm after: 4.3697105544130315
Epoch 6221/10000, Prediction Accuracy = 65.23076923076924%, Loss = 0.007464592309238819
Epoch: 6221, Batch Gradient Norm: 4.035908145914065
Epoch: 6221, Batch Gradient Norm after: 4.035908145914065
Epoch 6222/10000, Prediction Accuracy = 66.06538461538462%, Loss = 0.007086070075344581
Epoch: 6222, Batch Gradient Norm: 4.071903441668179
Epoch: 6222, Batch Gradient Norm after: 4.071903441668179
Epoch 6223/10000, Prediction Accuracy = 65.67692307692309%, Loss = 0.007189603020938544
Epoch: 6223, Batch Gradient Norm: 4.675572379862411
Epoch: 6223, Batch Gradient Norm after: 4.675572379862411
Epoch 6224/10000, Prediction Accuracy = 64.85769230769232%, Loss = 0.007453215057746722
Epoch: 6224, Batch Gradient Norm: 4.312039781235943
Epoch: 6224, Batch Gradient Norm after: 4.312039781235943
Epoch 6225/10000, Prediction Accuracy = 65.74999999999999%, Loss = 0.007233572944712181
Epoch: 6225, Batch Gradient Norm: 4.396625316363056
Epoch: 6225, Batch Gradient Norm after: 4.396625316363056
Epoch 6226/10000, Prediction Accuracy = 64.98076923076923%, Loss = 0.007376632545716488
Epoch: 6226, Batch Gradient Norm: 4.829850604173464
Epoch: 6226, Batch Gradient Norm after: 4.829850604173464
Epoch 6227/10000, Prediction Accuracy = 64.83846153846154%, Loss = 0.007476318412675307
Epoch: 6227, Batch Gradient Norm: 4.535631797984417
Epoch: 6227, Batch Gradient Norm after: 4.535631797984417
Epoch 6228/10000, Prediction Accuracy = 64.97692307692307%, Loss = 0.0075155975512013985
Epoch: 6228, Batch Gradient Norm: 4.269142856834829
Epoch: 6228, Batch Gradient Norm after: 4.269142856834829
Epoch 6229/10000, Prediction Accuracy = 65.63461538461537%, Loss = 0.00730246717396837
Epoch: 6229, Batch Gradient Norm: 4.244036277241286
Epoch: 6229, Batch Gradient Norm after: 4.244036277241286
Epoch 6230/10000, Prediction Accuracy = 65.48076923076923%, Loss = 0.007170246340907537
Epoch: 6230, Batch Gradient Norm: 4.185233908100839
Epoch: 6230, Batch Gradient Norm after: 4.185233908100839
Epoch 6231/10000, Prediction Accuracy = 66.59230769230768%, Loss = 0.007030808402655216
Epoch: 6231, Batch Gradient Norm: 4.095443585066826
Epoch: 6231, Batch Gradient Norm after: 4.095443585066826
Epoch 6232/10000, Prediction Accuracy = 66.0%, Loss = 0.007134496879119139
Epoch: 6232, Batch Gradient Norm: 4.3983237127715
Epoch: 6232, Batch Gradient Norm after: 4.3983237127715
Epoch 6233/10000, Prediction Accuracy = 65.75769230769231%, Loss = 0.0072479619859502865
Epoch: 6233, Batch Gradient Norm: 4.595452166598808
Epoch: 6233, Batch Gradient Norm after: 4.595452166598808
Epoch 6234/10000, Prediction Accuracy = 65.06923076923077%, Loss = 0.007409764811969721
Epoch: 6234, Batch Gradient Norm: 4.6622593419139315
Epoch: 6234, Batch Gradient Norm after: 4.6622593419139315
Epoch 6235/10000, Prediction Accuracy = 65.04615384615384%, Loss = 0.007478951906355528
Epoch: 6235, Batch Gradient Norm: 4.584407421511561
Epoch: 6235, Batch Gradient Norm after: 4.584407421511561
Epoch 6236/10000, Prediction Accuracy = 65.1576923076923%, Loss = 0.007356214408691113
Epoch: 6236, Batch Gradient Norm: 4.186510333711793
Epoch: 6236, Batch Gradient Norm after: 4.186510333711793
Epoch 6237/10000, Prediction Accuracy = 65.64615384615385%, Loss = 0.007109847313796098
Epoch: 6237, Batch Gradient Norm: 4.394733719298207
Epoch: 6237, Batch Gradient Norm after: 4.394733719298207
Epoch 6238/10000, Prediction Accuracy = 65.17692307692309%, Loss = 0.007227622545682467
Epoch: 6238, Batch Gradient Norm: 4.3431305781272656
Epoch: 6238, Batch Gradient Norm after: 4.3431305781272656
Epoch 6239/10000, Prediction Accuracy = 65.84615384615384%, Loss = 0.007216335739940405
Epoch: 6239, Batch Gradient Norm: 4.21677562394267
Epoch: 6239, Batch Gradient Norm after: 4.21677562394267
Epoch 6240/10000, Prediction Accuracy = 65.75384615384615%, Loss = 0.007095470917052948
Epoch: 6240, Batch Gradient Norm: 4.339483158823628
Epoch: 6240, Batch Gradient Norm after: 4.339483158823628
Epoch 6241/10000, Prediction Accuracy = 65.61153846153847%, Loss = 0.0072501033472900205
Epoch: 6241, Batch Gradient Norm: 4.293325077077105
Epoch: 6241, Batch Gradient Norm after: 4.293325077077105
Epoch 6242/10000, Prediction Accuracy = 65.91538461538461%, Loss = 0.007268411752123099
Epoch: 6242, Batch Gradient Norm: 4.560877047987659
Epoch: 6242, Batch Gradient Norm after: 4.560877047987659
Epoch 6243/10000, Prediction Accuracy = 65.24615384615385%, Loss = 0.00738984475342127
Epoch: 6243, Batch Gradient Norm: 3.9697356579437324
Epoch: 6243, Batch Gradient Norm after: 3.9697356579437324
Epoch 6244/10000, Prediction Accuracy = 65.66153846153847%, Loss = 0.007050533778965473
Epoch: 6244, Batch Gradient Norm: 4.160779944718889
Epoch: 6244, Batch Gradient Norm after: 4.160779944718889
Epoch 6245/10000, Prediction Accuracy = 66.40384615384615%, Loss = 0.007081844485723055
Epoch: 6245, Batch Gradient Norm: 4.660822642827184
Epoch: 6245, Batch Gradient Norm after: 4.660822642827184
Epoch 6246/10000, Prediction Accuracy = 65.66923076923078%, Loss = 0.007216935547498556
Epoch: 6246, Batch Gradient Norm: 4.226783404696745
Epoch: 6246, Batch Gradient Norm after: 4.226783404696745
Epoch 6247/10000, Prediction Accuracy = 66.20384615384616%, Loss = 0.007051204653600087
Epoch: 6247, Batch Gradient Norm: 4.353056831971938
Epoch: 6247, Batch Gradient Norm after: 4.353056831971938
Epoch 6248/10000, Prediction Accuracy = 65.83461538461538%, Loss = 0.00717831883006371
Epoch: 6248, Batch Gradient Norm: 4.2461175087545175
Epoch: 6248, Batch Gradient Norm after: 4.2461175087545175
Epoch 6249/10000, Prediction Accuracy = 65.7346153846154%, Loss = 0.007099474816081615
Epoch: 6249, Batch Gradient Norm: 4.084740254386224
Epoch: 6249, Batch Gradient Norm after: 4.084740254386224
Epoch 6250/10000, Prediction Accuracy = 65.88076923076923%, Loss = 0.007110073231160641
Epoch: 6250, Batch Gradient Norm: 4.353243754618762
Epoch: 6250, Batch Gradient Norm after: 4.353243754618762
Epoch 6251/10000, Prediction Accuracy = 65.73461538461538%, Loss = 0.007183933523125374
Epoch: 6251, Batch Gradient Norm: 4.056123475544293
Epoch: 6251, Batch Gradient Norm after: 4.056123475544293
Epoch 6252/10000, Prediction Accuracy = 66.12692307692306%, Loss = 0.0071004734804423954
Epoch: 6252, Batch Gradient Norm: 4.468302731529029
Epoch: 6252, Batch Gradient Norm after: 4.468302731529029
Epoch 6253/10000, Prediction Accuracy = 65.98461538461537%, Loss = 0.007155501606086126
Epoch: 6253, Batch Gradient Norm: 4.309114826952163
Epoch: 6253, Batch Gradient Norm after: 4.309114826952163
Epoch 6254/10000, Prediction Accuracy = 65.81153846153846%, Loss = 0.007176963827357843
Epoch: 6254, Batch Gradient Norm: 4.385966597724255
Epoch: 6254, Batch Gradient Norm after: 4.385966597724255
Epoch 6255/10000, Prediction Accuracy = 65.33846153846154%, Loss = 0.007233163950821528
Epoch: 6255, Batch Gradient Norm: 4.690507174514722
Epoch: 6255, Batch Gradient Norm after: 4.690507174514722
Epoch 6256/10000, Prediction Accuracy = 65.13076923076923%, Loss = 0.007345379545138433
Epoch: 6256, Batch Gradient Norm: 4.52239853690781
Epoch: 6256, Batch Gradient Norm after: 4.52239853690781
Epoch 6257/10000, Prediction Accuracy = 65.3576923076923%, Loss = 0.007316638357364214
Epoch: 6257, Batch Gradient Norm: 4.707271739913281
Epoch: 6257, Batch Gradient Norm after: 4.707271739913281
Epoch 6258/10000, Prediction Accuracy = 65.32692307692308%, Loss = 0.0073779560267352145
Epoch: 6258, Batch Gradient Norm: 4.783896540109327
Epoch: 6258, Batch Gradient Norm after: 4.783896540109327
Epoch 6259/10000, Prediction Accuracy = 65.38461538461539%, Loss = 0.007399885986859982
Epoch: 6259, Batch Gradient Norm: 4.40579025130002
Epoch: 6259, Batch Gradient Norm after: 4.40579025130002
Epoch 6260/10000, Prediction Accuracy = 65.81153846153846%, Loss = 0.00719312377847158
Epoch: 6260, Batch Gradient Norm: 4.824785869569077
Epoch: 6260, Batch Gradient Norm after: 4.824785869569077
Epoch 6261/10000, Prediction Accuracy = 64.96923076923076%, Loss = 0.007456470245065598
Epoch: 6261, Batch Gradient Norm: 4.297299501851628
Epoch: 6261, Batch Gradient Norm after: 4.297299501851628
Epoch 6262/10000, Prediction Accuracy = 65.21538461538462%, Loss = 0.007250019026776919
Epoch: 6262, Batch Gradient Norm: 4.215263473354867
Epoch: 6262, Batch Gradient Norm after: 4.215263473354867
Epoch 6263/10000, Prediction Accuracy = 65.73076923076924%, Loss = 0.007118880247267393
Epoch: 6263, Batch Gradient Norm: 4.630693484891607
Epoch: 6263, Batch Gradient Norm after: 4.630693484891607
Epoch 6264/10000, Prediction Accuracy = 65.47692307692307%, Loss = 0.007304114361221974
Epoch: 6264, Batch Gradient Norm: 4.582879578217014
Epoch: 6264, Batch Gradient Norm after: 4.582879578217014
Epoch 6265/10000, Prediction Accuracy = 65.70384615384616%, Loss = 0.0072577593203347465
Epoch: 6265, Batch Gradient Norm: 4.554017615313488
Epoch: 6265, Batch Gradient Norm after: 4.554017615313488
Epoch 6266/10000, Prediction Accuracy = 65.03461538461538%, Loss = 0.007354860050747028
Epoch: 6266, Batch Gradient Norm: 4.356660257768223
Epoch: 6266, Batch Gradient Norm after: 4.356660257768223
Epoch 6267/10000, Prediction Accuracy = 65.61538461538461%, Loss = 0.007269345223903656
Epoch: 6267, Batch Gradient Norm: 4.421088495460233
Epoch: 6267, Batch Gradient Norm after: 4.421088495460233
Epoch 6268/10000, Prediction Accuracy = 65.58461538461539%, Loss = 0.007218704451448643
Epoch: 6268, Batch Gradient Norm: 4.4398974543897545
Epoch: 6268, Batch Gradient Norm after: 4.4398974543897545
Epoch 6269/10000, Prediction Accuracy = 65.71923076923076%, Loss = 0.007185106344807606
Epoch: 6269, Batch Gradient Norm: 4.45710874510667
Epoch: 6269, Batch Gradient Norm after: 4.45710874510667
Epoch 6270/10000, Prediction Accuracy = 65.62692307692308%, Loss = 0.0072735603182361675
Epoch: 6270, Batch Gradient Norm: 4.377504069997381
Epoch: 6270, Batch Gradient Norm after: 4.377504069997381
Epoch 6271/10000, Prediction Accuracy = 65.75769230769231%, Loss = 0.00721485407736439
Epoch: 6271, Batch Gradient Norm: 4.932953983994079
Epoch: 6271, Batch Gradient Norm after: 4.932953983994079
Epoch 6272/10000, Prediction Accuracy = 64.68846153846154%, Loss = 0.007541881802563484
Epoch: 6272, Batch Gradient Norm: 4.519919523002076
Epoch: 6272, Batch Gradient Norm after: 4.519919523002076
Epoch 6273/10000, Prediction Accuracy = 65.36923076923077%, Loss = 0.007353729138580652
Epoch: 6273, Batch Gradient Norm: 3.983652575822563
Epoch: 6273, Batch Gradient Norm after: 3.983652575822563
Epoch 6274/10000, Prediction Accuracy = 66.24615384615385%, Loss = 0.007031461582160913
Epoch: 6274, Batch Gradient Norm: 4.05727353987767
Epoch: 6274, Batch Gradient Norm after: 4.05727353987767
Epoch 6275/10000, Prediction Accuracy = 66.40769230769232%, Loss = 0.007051900279923127
Epoch: 6275, Batch Gradient Norm: 4.6236415972072376
Epoch: 6275, Batch Gradient Norm after: 4.6236415972072376
Epoch 6276/10000, Prediction Accuracy = 65.93846153846154%, Loss = 0.0072144255973398685
Epoch: 6276, Batch Gradient Norm: 4.697026987450076
Epoch: 6276, Batch Gradient Norm after: 4.697026987450076
Epoch 6277/10000, Prediction Accuracy = 65.51153846153846%, Loss = 0.007376924013862243
Epoch: 6277, Batch Gradient Norm: 4.9183268954943316
Epoch: 6277, Batch Gradient Norm after: 4.9183268954943316
Epoch 6278/10000, Prediction Accuracy = 64.38461538461537%, Loss = 0.0076248745004145
Epoch: 6278, Batch Gradient Norm: 4.551247799406451
Epoch: 6278, Batch Gradient Norm after: 4.551247799406451
Epoch 6279/10000, Prediction Accuracy = 64.59230769230768%, Loss = 0.007469128136737988
Epoch: 6279, Batch Gradient Norm: 4.367246183465761
Epoch: 6279, Batch Gradient Norm after: 4.367246183465761
Epoch 6280/10000, Prediction Accuracy = 65.34615384615384%, Loss = 0.0072301969003791995
Epoch: 6280, Batch Gradient Norm: 4.58168477673201
Epoch: 6280, Batch Gradient Norm after: 4.58168477673201
Epoch 6281/10000, Prediction Accuracy = 65.13076923076923%, Loss = 0.0073735688526469926
Epoch: 6281, Batch Gradient Norm: 4.098309408859655
Epoch: 6281, Batch Gradient Norm after: 4.098309408859655
Epoch 6282/10000, Prediction Accuracy = 66.3%, Loss = 0.006990838688440048
Epoch: 6282, Batch Gradient Norm: 3.9999508458232835
Epoch: 6282, Batch Gradient Norm after: 3.9999508458232835
Epoch 6283/10000, Prediction Accuracy = 65.91538461538461%, Loss = 0.0069957740175036285
Epoch: 6283, Batch Gradient Norm: 4.384396092084451
Epoch: 6283, Batch Gradient Norm after: 4.384396092084451
Epoch 6284/10000, Prediction Accuracy = 65.4846153846154%, Loss = 0.007227528052261243
Epoch: 6284, Batch Gradient Norm: 4.782536595853075
Epoch: 6284, Batch Gradient Norm after: 4.782536595853075
Epoch 6285/10000, Prediction Accuracy = 65.12307692307692%, Loss = 0.007361288791379103
Epoch: 6285, Batch Gradient Norm: 4.466433179461886
Epoch: 6285, Batch Gradient Norm after: 4.466433179461886
Epoch 6286/10000, Prediction Accuracy = 65.18846153846154%, Loss = 0.007368776768159408
Epoch: 6286, Batch Gradient Norm: 4.458404767855514
Epoch: 6286, Batch Gradient Norm after: 4.458404767855514
Epoch 6287/10000, Prediction Accuracy = 65.49230769230769%, Loss = 0.007346537752220264
Epoch: 6287, Batch Gradient Norm: 4.527207143934123
Epoch: 6287, Batch Gradient Norm after: 4.527207143934123
Epoch 6288/10000, Prediction Accuracy = 64.99230769230769%, Loss = 0.007460589484813122
Epoch: 6288, Batch Gradient Norm: 4.884773255940541
Epoch: 6288, Batch Gradient Norm after: 4.884773255940541
Epoch 6289/10000, Prediction Accuracy = 64.33076923076923%, Loss = 0.007617342464912396
Epoch: 6289, Batch Gradient Norm: 4.413634856357299
Epoch: 6289, Batch Gradient Norm after: 4.413634856357299
Epoch 6290/10000, Prediction Accuracy = 65.46538461538461%, Loss = 0.0072728358567334134
Epoch: 6290, Batch Gradient Norm: 3.955958285386919
Epoch: 6290, Batch Gradient Norm after: 3.955958285386919
Epoch 6291/10000, Prediction Accuracy = 66.47692307692309%, Loss = 0.006982720671938016
Epoch: 6291, Batch Gradient Norm: 4.098079875312124
Epoch: 6291, Batch Gradient Norm after: 4.098079875312124
Epoch 6292/10000, Prediction Accuracy = 66.34615384615384%, Loss = 0.0070324800550364535
Epoch: 6292, Batch Gradient Norm: 4.180549519610283
Epoch: 6292, Batch Gradient Norm after: 4.180549519610283
Epoch 6293/10000, Prediction Accuracy = 66.11923076923077%, Loss = 0.007078591626710617
Epoch: 6293, Batch Gradient Norm: 4.292717770909014
Epoch: 6293, Batch Gradient Norm after: 4.292717770909014
Epoch 6294/10000, Prediction Accuracy = 65.52692307692308%, Loss = 0.0071661264922183296
Epoch: 6294, Batch Gradient Norm: 4.386358623454681
Epoch: 6294, Batch Gradient Norm after: 4.386358623454681
Epoch 6295/10000, Prediction Accuracy = 65.44999999999999%, Loss = 0.007291509483296137
Epoch: 6295, Batch Gradient Norm: 4.024036125068075
Epoch: 6295, Batch Gradient Norm after: 4.024036125068075
Epoch 6296/10000, Prediction Accuracy = 65.78846153846153%, Loss = 0.007075726842651
Epoch: 6296, Batch Gradient Norm: 4.469441365356886
Epoch: 6296, Batch Gradient Norm after: 4.469441365356886
Epoch 6297/10000, Prediction Accuracy = 65.23846153846154%, Loss = 0.007271442060860304
Epoch: 6297, Batch Gradient Norm: 4.215000715072015
Epoch: 6297, Batch Gradient Norm after: 4.215000715072015
Epoch 6298/10000, Prediction Accuracy = 65.73076923076923%, Loss = 0.007154212154161472
Epoch: 6298, Batch Gradient Norm: 4.8047888406029315
Epoch: 6298, Batch Gradient Norm after: 4.8047888406029315
Epoch 6299/10000, Prediction Accuracy = 65.29230769230767%, Loss = 0.007418593642516778
Epoch: 6299, Batch Gradient Norm: 4.52764565171434
Epoch: 6299, Batch Gradient Norm after: 4.52764565171434
Epoch 6300/10000, Prediction Accuracy = 65.57692307692308%, Loss = 0.007276609325065062
Epoch: 6300, Batch Gradient Norm: 4.355413968771626
Epoch: 6300, Batch Gradient Norm after: 4.355413968771626
Epoch 6301/10000, Prediction Accuracy = 65.83461538461539%, Loss = 0.007152769141472303
Epoch: 6301, Batch Gradient Norm: 4.043122459188917
Epoch: 6301, Batch Gradient Norm after: 4.043122459188917
Epoch 6302/10000, Prediction Accuracy = 65.9%, Loss = 0.006963755971250625
Epoch: 6302, Batch Gradient Norm: 4.183625531196668
Epoch: 6302, Batch Gradient Norm after: 4.183625531196668
Epoch 6303/10000, Prediction Accuracy = 66.32307692307693%, Loss = 0.007087496109306812
Epoch: 6303, Batch Gradient Norm: 4.473780908460042
Epoch: 6303, Batch Gradient Norm after: 4.473780908460042
Epoch 6304/10000, Prediction Accuracy = 66.32692307692308%, Loss = 0.007124379348869507
Epoch: 6304, Batch Gradient Norm: 4.593718448213551
Epoch: 6304, Batch Gradient Norm after: 4.593718448213551
Epoch 6305/10000, Prediction Accuracy = 65.09230769230768%, Loss = 0.007376654503437189
Epoch: 6305, Batch Gradient Norm: 4.386106943941984
Epoch: 6305, Batch Gradient Norm after: 4.386106943941984
Epoch 6306/10000, Prediction Accuracy = 64.98076923076923%, Loss = 0.007301988115964027
Epoch: 6306, Batch Gradient Norm: 4.140234880339184
Epoch: 6306, Batch Gradient Norm after: 4.140234880339184
Epoch 6307/10000, Prediction Accuracy = 65.78076923076922%, Loss = 0.007072964969735879
Epoch: 6307, Batch Gradient Norm: 4.053082535911337
Epoch: 6307, Batch Gradient Norm after: 4.053082535911337
Epoch 6308/10000, Prediction Accuracy = 66.49230769230769%, Loss = 0.006945229027993404
Epoch: 6308, Batch Gradient Norm: 4.4788609232736
Epoch: 6308, Batch Gradient Norm after: 4.4788609232736
Epoch 6309/10000, Prediction Accuracy = 65.65384615384615%, Loss = 0.007148619454640608
Epoch: 6309, Batch Gradient Norm: 4.536475475269577
Epoch: 6309, Batch Gradient Norm after: 4.536475475269577
Epoch 6310/10000, Prediction Accuracy = 65.26538461538462%, Loss = 0.007202102623593349
Epoch: 6310, Batch Gradient Norm: 4.512066283011857
Epoch: 6310, Batch Gradient Norm after: 4.512066283011857
Epoch 6311/10000, Prediction Accuracy = 65.93461538461537%, Loss = 0.0072196305801089
Epoch: 6311, Batch Gradient Norm: 4.783366502007313
Epoch: 6311, Batch Gradient Norm after: 4.783366502007313
Epoch 6312/10000, Prediction Accuracy = 64.69230769230771%, Loss = 0.007382330162307391
Epoch: 6312, Batch Gradient Norm: 4.6091177281267415
Epoch: 6312, Batch Gradient Norm after: 4.6091177281267415
Epoch 6313/10000, Prediction Accuracy = 65.01923076923077%, Loss = 0.007388078679259007
Epoch: 6313, Batch Gradient Norm: 4.638328632502471
Epoch: 6313, Batch Gradient Norm after: 4.638328632502471
Epoch 6314/10000, Prediction Accuracy = 65.2%, Loss = 0.0073644189307322866
Epoch: 6314, Batch Gradient Norm: 4.713981840974199
Epoch: 6314, Batch Gradient Norm after: 4.713981840974199
Epoch 6315/10000, Prediction Accuracy = 64.75%, Loss = 0.007464266740358793
Epoch: 6315, Batch Gradient Norm: 4.648636392190126
Epoch: 6315, Batch Gradient Norm after: 4.648636392190126
Epoch 6316/10000, Prediction Accuracy = 65.13846153846154%, Loss = 0.007370978128165007
Epoch: 6316, Batch Gradient Norm: 4.2875353483432805
Epoch: 6316, Batch Gradient Norm after: 4.2875353483432805
Epoch 6317/10000, Prediction Accuracy = 65.31923076923076%, Loss = 0.007189063928448237
Epoch: 6317, Batch Gradient Norm: 4.590696959656615
Epoch: 6317, Batch Gradient Norm after: 4.590696959656615
Epoch 6318/10000, Prediction Accuracy = 65.14999999999999%, Loss = 0.007353196565348368
Epoch: 6318, Batch Gradient Norm: 4.503087847810648
Epoch: 6318, Batch Gradient Norm after: 4.503087847810648
Epoch 6319/10000, Prediction Accuracy = 65.44999999999999%, Loss = 0.007343995313231762
Epoch: 6319, Batch Gradient Norm: 4.7502249732951105
Epoch: 6319, Batch Gradient Norm after: 4.7502249732951105
Epoch 6320/10000, Prediction Accuracy = 64.80384615384615%, Loss = 0.007567024897210873
Epoch: 6320, Batch Gradient Norm: 4.57316708834178
Epoch: 6320, Batch Gradient Norm after: 4.57316708834178
Epoch 6321/10000, Prediction Accuracy = 65.43846153846154%, Loss = 0.007417000400332304
Epoch: 6321, Batch Gradient Norm: 4.300410747493382
Epoch: 6321, Batch Gradient Norm after: 4.300410747493382
Epoch 6322/10000, Prediction Accuracy = 65.36153846153846%, Loss = 0.007313443992573481
Epoch: 6322, Batch Gradient Norm: 4.155485885611797
Epoch: 6322, Batch Gradient Norm after: 4.155485885611797
Epoch 6323/10000, Prediction Accuracy = 65.81153846153846%, Loss = 0.007142515709766975
Epoch: 6323, Batch Gradient Norm: 4.718641355697961
Epoch: 6323, Batch Gradient Norm after: 4.718641355697961
Epoch 6324/10000, Prediction Accuracy = 65.16153846153847%, Loss = 0.007444385367517288
Epoch: 6324, Batch Gradient Norm: 4.410688483409425
Epoch: 6324, Batch Gradient Norm after: 4.410688483409425
Epoch 6325/10000, Prediction Accuracy = 65.45%, Loss = 0.007250240753189876
Epoch: 6325, Batch Gradient Norm: 4.362108841871632
Epoch: 6325, Batch Gradient Norm after: 4.362108841871632
Epoch 6326/10000, Prediction Accuracy = 65.77692307692308%, Loss = 0.00712049390690831
Epoch: 6326, Batch Gradient Norm: 4.518170599606339
Epoch: 6326, Batch Gradient Norm after: 4.518170599606339
Epoch 6327/10000, Prediction Accuracy = 65.61538461538461%, Loss = 0.007218451060068149
Epoch: 6327, Batch Gradient Norm: 4.1213866650179565
Epoch: 6327, Batch Gradient Norm after: 4.1213866650179565
Epoch 6328/10000, Prediction Accuracy = 65.9923076923077%, Loss = 0.007100204937160015
Epoch: 6328, Batch Gradient Norm: 4.373372457790539
Epoch: 6328, Batch Gradient Norm after: 4.373372457790539
Epoch 6329/10000, Prediction Accuracy = 65.76923076923077%, Loss = 0.007271323066491347
Epoch: 6329, Batch Gradient Norm: 4.180415358716848
Epoch: 6329, Batch Gradient Norm after: 4.180415358716848
Epoch 6330/10000, Prediction Accuracy = 65.88461538461537%, Loss = 0.0071311605592759755
Epoch: 6330, Batch Gradient Norm: 4.043590947934327
Epoch: 6330, Batch Gradient Norm after: 4.043590947934327
Epoch 6331/10000, Prediction Accuracy = 65.82307692307691%, Loss = 0.007121820038614364
Epoch: 6331, Batch Gradient Norm: 4.508313359194598
Epoch: 6331, Batch Gradient Norm after: 4.508313359194598
Epoch 6332/10000, Prediction Accuracy = 65.50384615384615%, Loss = 0.00724378708176888
Epoch: 6332, Batch Gradient Norm: 4.609004533090503
Epoch: 6332, Batch Gradient Norm after: 4.609004533090503
Epoch 6333/10000, Prediction Accuracy = 65.53076923076922%, Loss = 0.007240361677339444
Epoch: 6333, Batch Gradient Norm: 4.91963572207151
Epoch: 6333, Batch Gradient Norm after: 4.91963572207151
Epoch 6334/10000, Prediction Accuracy = 65.28076923076922%, Loss = 0.007361489169013042
Epoch: 6334, Batch Gradient Norm: 4.082287791876904
Epoch: 6334, Batch Gradient Norm after: 4.082287791876904
Epoch 6335/10000, Prediction Accuracy = 65.78461538461538%, Loss = 0.007052584694555173
Epoch: 6335, Batch Gradient Norm: 4.480933979976655
Epoch: 6335, Batch Gradient Norm after: 4.480933979976655
Epoch 6336/10000, Prediction Accuracy = 65.49230769230769%, Loss = 0.007252758655410547
Epoch: 6336, Batch Gradient Norm: 4.297164457028386
Epoch: 6336, Batch Gradient Norm after: 4.297164457028386
Epoch 6337/10000, Prediction Accuracy = 65.51153846153846%, Loss = 0.0072164456360042095
Epoch: 6337, Batch Gradient Norm: 4.575007807841786
Epoch: 6337, Batch Gradient Norm after: 4.575007807841786
Epoch 6338/10000, Prediction Accuracy = 65.64615384615384%, Loss = 0.00729074074815099
Epoch: 6338, Batch Gradient Norm: 4.384779372091656
Epoch: 6338, Batch Gradient Norm after: 4.384779372091656
Epoch 6339/10000, Prediction Accuracy = 65.86538461538463%, Loss = 0.007194994089122002
Epoch: 6339, Batch Gradient Norm: 4.982318906341797
Epoch: 6339, Batch Gradient Norm after: 4.982318906341797
Epoch 6340/10000, Prediction Accuracy = 64.56153846153846%, Loss = 0.007526384881482675
Epoch: 6340, Batch Gradient Norm: 5.064986520210904
Epoch: 6340, Batch Gradient Norm after: 5.064986520210904
Epoch 6341/10000, Prediction Accuracy = 64.82307692307693%, Loss = 0.007625434189461744
Epoch: 6341, Batch Gradient Norm: 4.68802444223784
Epoch: 6341, Batch Gradient Norm after: 4.68802444223784
Epoch 6342/10000, Prediction Accuracy = 64.69230769230768%, Loss = 0.0075022049176578336
Epoch: 6342, Batch Gradient Norm: 4.3549853453795055
Epoch: 6342, Batch Gradient Norm after: 4.3549853453795055
Epoch 6343/10000, Prediction Accuracy = 65.44615384615385%, Loss = 0.007244399426361689
Epoch: 6343, Batch Gradient Norm: 4.171643680912903
Epoch: 6343, Batch Gradient Norm after: 4.171643680912903
Epoch 6344/10000, Prediction Accuracy = 65.88461538461539%, Loss = 0.007182945998815389
Epoch: 6344, Batch Gradient Norm: 4.529100811142069
Epoch: 6344, Batch Gradient Norm after: 4.529100811142069
Epoch 6345/10000, Prediction Accuracy = 65.6423076923077%, Loss = 0.0073170367126854565
Epoch: 6345, Batch Gradient Norm: 3.98462494009506
Epoch: 6345, Batch Gradient Norm after: 3.98462494009506
Epoch 6346/10000, Prediction Accuracy = 66.42692307692309%, Loss = 0.00696788033327231
Epoch: 6346, Batch Gradient Norm: 4.651932228253716
Epoch: 6346, Batch Gradient Norm after: 4.651932228253716
Epoch 6347/10000, Prediction Accuracy = 65.25384615384615%, Loss = 0.007284729741513729
Epoch: 6347, Batch Gradient Norm: 4.817787408143137
Epoch: 6347, Batch Gradient Norm after: 4.817787408143137
Epoch 6348/10000, Prediction Accuracy = 64.59615384615384%, Loss = 0.007479236998523657
Epoch: 6348, Batch Gradient Norm: 4.701974702927647
Epoch: 6348, Batch Gradient Norm after: 4.701974702927647
Epoch 6349/10000, Prediction Accuracy = 65.11923076923077%, Loss = 0.007475640266560591
Epoch: 6349, Batch Gradient Norm: 4.564061392051914
Epoch: 6349, Batch Gradient Norm after: 4.564061392051914
Epoch 6350/10000, Prediction Accuracy = 65.3423076923077%, Loss = 0.007323867820489865
Epoch: 6350, Batch Gradient Norm: 4.539841621522704
Epoch: 6350, Batch Gradient Norm after: 4.539841621522704
Epoch 6351/10000, Prediction Accuracy = 65.48846153846154%, Loss = 0.0072362345929902335
Epoch: 6351, Batch Gradient Norm: 4.4282179423929415
Epoch: 6351, Batch Gradient Norm after: 4.4282179423929415
Epoch 6352/10000, Prediction Accuracy = 65.58461538461538%, Loss = 0.0071954743291896125
Epoch: 6352, Batch Gradient Norm: 4.072267837251804
Epoch: 6352, Batch Gradient Norm after: 4.072267837251804
Epoch 6353/10000, Prediction Accuracy = 66.46923076923076%, Loss = 0.007040548066680248
Epoch: 6353, Batch Gradient Norm: 4.177076654512039
Epoch: 6353, Batch Gradient Norm after: 4.177076654512039
Epoch 6354/10000, Prediction Accuracy = 66.08076923076922%, Loss = 0.0071420385502278805
Epoch: 6354, Batch Gradient Norm: 4.724644489491068
Epoch: 6354, Batch Gradient Norm after: 4.724644489491068
Epoch 6355/10000, Prediction Accuracy = 65.12692307692308%, Loss = 0.0074952436396135734
Epoch: 6355, Batch Gradient Norm: 4.304037318295195
Epoch: 6355, Batch Gradient Norm after: 4.304037318295195
Epoch 6356/10000, Prediction Accuracy = 66.02307692307694%, Loss = 0.007192253672446196
Epoch: 6356, Batch Gradient Norm: 4.159511995754148
Epoch: 6356, Batch Gradient Norm after: 4.159511995754148
Epoch 6357/10000, Prediction Accuracy = 65.78846153846153%, Loss = 0.0071569476993038105
Epoch: 6357, Batch Gradient Norm: 4.408044717168993
Epoch: 6357, Batch Gradient Norm after: 4.408044717168993
Epoch 6358/10000, Prediction Accuracy = 65.0423076923077%, Loss = 0.00729443752565063
Epoch: 6358, Batch Gradient Norm: 4.361801911246178
Epoch: 6358, Batch Gradient Norm after: 4.361801911246178
Epoch 6359/10000, Prediction Accuracy = 65.93461538461538%, Loss = 0.0072069898462639405
Epoch: 6359, Batch Gradient Norm: 4.397950112907054
Epoch: 6359, Batch Gradient Norm after: 4.397950112907054
Epoch 6360/10000, Prediction Accuracy = 65.77307692307694%, Loss = 0.007253212603525474
Epoch: 6360, Batch Gradient Norm: 4.375590761886839
Epoch: 6360, Batch Gradient Norm after: 4.375590761886839
Epoch 6361/10000, Prediction Accuracy = 65.9423076923077%, Loss = 0.00722739569699535
Epoch: 6361, Batch Gradient Norm: 4.247302414362863
Epoch: 6361, Batch Gradient Norm after: 4.247302414362863
Epoch 6362/10000, Prediction Accuracy = 65.43076923076923%, Loss = 0.007258021415999303
Epoch: 6362, Batch Gradient Norm: 4.295441928647471
Epoch: 6362, Batch Gradient Norm after: 4.295441928647471
Epoch 6363/10000, Prediction Accuracy = 65.96538461538462%, Loss = 0.007103438023477793
Epoch: 6363, Batch Gradient Norm: 4.136373752652508
Epoch: 6363, Batch Gradient Norm after: 4.136373752652508
Epoch 6364/10000, Prediction Accuracy = 66.33461538461539%, Loss = 0.0070420167623804165
Epoch: 6364, Batch Gradient Norm: 4.044932850564249
Epoch: 6364, Batch Gradient Norm after: 4.044932850564249
Epoch 6365/10000, Prediction Accuracy = 66.23076923076923%, Loss = 0.006986172798161323
Epoch: 6365, Batch Gradient Norm: 4.388303142301269
Epoch: 6365, Batch Gradient Norm after: 4.388303142301269
Epoch 6366/10000, Prediction Accuracy = 65.90384615384616%, Loss = 0.007174592572622574
Epoch: 6366, Batch Gradient Norm: 4.632621564685227
Epoch: 6366, Batch Gradient Norm after: 4.632621564685227
Epoch 6367/10000, Prediction Accuracy = 65.72307692307692%, Loss = 0.007242884236172988
Epoch: 6367, Batch Gradient Norm: 4.2852343543905755
Epoch: 6367, Batch Gradient Norm after: 4.2852343543905755
Epoch 6368/10000, Prediction Accuracy = 66.28461538461539%, Loss = 0.007044530652749997
Epoch: 6368, Batch Gradient Norm: 4.032050719055796
Epoch: 6368, Batch Gradient Norm after: 4.032050719055796
Epoch 6369/10000, Prediction Accuracy = 66.34615384615384%, Loss = 0.006996120970982771
Epoch: 6369, Batch Gradient Norm: 4.460275164405599
Epoch: 6369, Batch Gradient Norm after: 4.460275164405599
Epoch 6370/10000, Prediction Accuracy = 65.88461538461539%, Loss = 0.007137038028584077
Epoch: 6370, Batch Gradient Norm: 4.600719359131748
Epoch: 6370, Batch Gradient Norm after: 4.600719359131748
Epoch 6371/10000, Prediction Accuracy = 65.76153846153846%, Loss = 0.007172488571646122
Epoch: 6371, Batch Gradient Norm: 4.4013889028614885
Epoch: 6371, Batch Gradient Norm after: 4.4013889028614885
Epoch 6372/10000, Prediction Accuracy = 65.33846153846153%, Loss = 0.0071893023112072395
Epoch: 6372, Batch Gradient Norm: 4.207290518074595
Epoch: 6372, Batch Gradient Norm after: 4.207290518074595
Epoch 6373/10000, Prediction Accuracy = 65.9923076923077%, Loss = 0.007073998522873108
Epoch: 6373, Batch Gradient Norm: 4.401461386747329
Epoch: 6373, Batch Gradient Norm after: 4.401461386747329
Epoch 6374/10000, Prediction Accuracy = 65.44615384615385%, Loss = 0.007146859219154486
Epoch: 6374, Batch Gradient Norm: 4.3780860606419765
Epoch: 6374, Batch Gradient Norm after: 4.3780860606419765
Epoch 6375/10000, Prediction Accuracy = 65.90384615384616%, Loss = 0.007111505784380894
Epoch: 6375, Batch Gradient Norm: 4.93039959371648
Epoch: 6375, Batch Gradient Norm after: 4.93039959371648
Epoch 6376/10000, Prediction Accuracy = 64.99999999999999%, Loss = 0.007470404657606895
Epoch: 6376, Batch Gradient Norm: 4.438250797006132
Epoch: 6376, Batch Gradient Norm after: 4.438250797006132
Epoch 6377/10000, Prediction Accuracy = 65.86538461538461%, Loss = 0.007295705521335969
Epoch: 6377, Batch Gradient Norm: 4.436253078409705
Epoch: 6377, Batch Gradient Norm after: 4.436253078409705
Epoch 6378/10000, Prediction Accuracy = 65.35769230769232%, Loss = 0.007206302207822983
Epoch: 6378, Batch Gradient Norm: 4.590330131736674
Epoch: 6378, Batch Gradient Norm after: 4.590330131736674
Epoch 6379/10000, Prediction Accuracy = 65.51923076923077%, Loss = 0.007281340300463713
Epoch: 6379, Batch Gradient Norm: 4.865696843067531
Epoch: 6379, Batch Gradient Norm after: 4.865696843067531
Epoch 6380/10000, Prediction Accuracy = 65.15%, Loss = 0.007447088352189614
Epoch: 6380, Batch Gradient Norm: 4.732546873148092
Epoch: 6380, Batch Gradient Norm after: 4.732546873148092
Epoch 6381/10000, Prediction Accuracy = 65.45384615384616%, Loss = 0.0073723483902330585
Epoch: 6381, Batch Gradient Norm: 4.468397259372143
Epoch: 6381, Batch Gradient Norm after: 4.468397259372143
Epoch 6382/10000, Prediction Accuracy = 65.5576923076923%, Loss = 0.007146607976979935
Epoch: 6382, Batch Gradient Norm: 4.488563381045341
Epoch: 6382, Batch Gradient Norm after: 4.488563381045341
Epoch 6383/10000, Prediction Accuracy = 65.33076923076922%, Loss = 0.0072360910260333465
Epoch: 6383, Batch Gradient Norm: 4.469794752032587
Epoch: 6383, Batch Gradient Norm after: 4.469794752032587
Epoch 6384/10000, Prediction Accuracy = 65.42692307692309%, Loss = 0.007154161182160561
Epoch: 6384, Batch Gradient Norm: 4.204970872800966
Epoch: 6384, Batch Gradient Norm after: 4.204970872800966
Epoch 6385/10000, Prediction Accuracy = 66.00000000000001%, Loss = 0.007169987146671002
Epoch: 6385, Batch Gradient Norm: 4.1997189433632895
Epoch: 6385, Batch Gradient Norm after: 4.1997189433632895
Epoch 6386/10000, Prediction Accuracy = 65.95384615384617%, Loss = 0.007047157018230512
Epoch: 6386, Batch Gradient Norm: 4.7514798964040175
Epoch: 6386, Batch Gradient Norm after: 4.7514798964040175
Epoch 6387/10000, Prediction Accuracy = 65.26153846153846%, Loss = 0.007370357294208729
Epoch: 6387, Batch Gradient Norm: 4.565699294687415
Epoch: 6387, Batch Gradient Norm after: 4.565699294687415
Epoch 6388/10000, Prediction Accuracy = 65.38846153846153%, Loss = 0.007299042199380123
Epoch: 6388, Batch Gradient Norm: 4.980298972620525
Epoch: 6388, Batch Gradient Norm after: 4.980298972620525
Epoch 6389/10000, Prediction Accuracy = 65.31923076923077%, Loss = 0.007491613845699108
Epoch: 6389, Batch Gradient Norm: 4.906660300430765
Epoch: 6389, Batch Gradient Norm after: 4.906660300430765
Epoch 6390/10000, Prediction Accuracy = 64.61923076923077%, Loss = 0.007635019325579588
Epoch: 6390, Batch Gradient Norm: 4.237745807117556
Epoch: 6390, Batch Gradient Norm after: 4.237745807117556
Epoch 6391/10000, Prediction Accuracy = 65.61923076923077%, Loss = 0.007253420933221395
Epoch: 6391, Batch Gradient Norm: 4.493131074810087
Epoch: 6391, Batch Gradient Norm after: 4.493131074810087
Epoch 6392/10000, Prediction Accuracy = 65.20384615384616%, Loss = 0.007314599835528777
Epoch: 6392, Batch Gradient Norm: 4.690172256775713
Epoch: 6392, Batch Gradient Norm after: 4.690172256775713
Epoch 6393/10000, Prediction Accuracy = 65.0923076923077%, Loss = 0.007389668088692885
Epoch: 6393, Batch Gradient Norm: 4.318550718365174
Epoch: 6393, Batch Gradient Norm after: 4.318550718365174
Epoch 6394/10000, Prediction Accuracy = 65.5923076923077%, Loss = 0.007231590624612112
Epoch: 6394, Batch Gradient Norm: 4.293035003888342
Epoch: 6394, Batch Gradient Norm after: 4.293035003888342
Epoch 6395/10000, Prediction Accuracy = 65.16538461538462%, Loss = 0.007205574880712307
Epoch: 6395, Batch Gradient Norm: 3.85954197770525
Epoch: 6395, Batch Gradient Norm after: 3.85954197770525
Epoch 6396/10000, Prediction Accuracy = 66.37307692307692%, Loss = 0.006967572316240806
Epoch: 6396, Batch Gradient Norm: 4.047445622811296
Epoch: 6396, Batch Gradient Norm after: 4.047445622811296
Epoch 6397/10000, Prediction Accuracy = 65.92692307692307%, Loss = 0.007041507078191409
Epoch: 6397, Batch Gradient Norm: 4.844965604953298
Epoch: 6397, Batch Gradient Norm after: 4.844965604953298
Epoch 6398/10000, Prediction Accuracy = 64.71538461538462%, Loss = 0.007432667001222189
Epoch: 6398, Batch Gradient Norm: 4.861716842824423
Epoch: 6398, Batch Gradient Norm after: 4.861716842824423
Epoch 6399/10000, Prediction Accuracy = 64.63846153846154%, Loss = 0.007538143831949968
Epoch: 6399, Batch Gradient Norm: 4.199441745571654
Epoch: 6399, Batch Gradient Norm after: 4.199441745571654
Epoch 6400/10000, Prediction Accuracy = 65.79615384615386%, Loss = 0.007187771969116651
Epoch: 6400, Batch Gradient Norm: 4.474597386080493
Epoch: 6400, Batch Gradient Norm after: 4.474597386080493
Epoch 6401/10000, Prediction Accuracy = 65.73461538461538%, Loss = 0.007223898115066381
Epoch: 6401, Batch Gradient Norm: 4.135894099297658
Epoch: 6401, Batch Gradient Norm after: 4.135894099297658
Epoch 6402/10000, Prediction Accuracy = 66.00769230769231%, Loss = 0.0070970934958985215
Epoch: 6402, Batch Gradient Norm: 4.093076497612402
Epoch: 6402, Batch Gradient Norm after: 4.093076497612402
Epoch 6403/10000, Prediction Accuracy = 66.1576923076923%, Loss = 0.007030566330426014
Epoch: 6403, Batch Gradient Norm: 4.0723457267120295
Epoch: 6403, Batch Gradient Norm after: 4.0723457267120295
Epoch 6404/10000, Prediction Accuracy = 65.98076923076924%, Loss = 0.006923671561078384
Epoch: 6404, Batch Gradient Norm: 4.230190085773753
Epoch: 6404, Batch Gradient Norm after: 4.230190085773753
Epoch 6405/10000, Prediction Accuracy = 66.0153846153846%, Loss = 0.006975145509036688
Epoch: 6405, Batch Gradient Norm: 3.799908671030764
Epoch: 6405, Batch Gradient Norm after: 3.799908671030764
Epoch 6406/10000, Prediction Accuracy = 66.57307692307694%, Loss = 0.00681344516432056
Epoch: 6406, Batch Gradient Norm: 4.659509241419652
Epoch: 6406, Batch Gradient Norm after: 4.659509241419652
Epoch 6407/10000, Prediction Accuracy = 65.61153846153846%, Loss = 0.0072644917079462456
Epoch: 6407, Batch Gradient Norm: 4.673638037887773
Epoch: 6407, Batch Gradient Norm after: 4.673638037887773
Epoch 6408/10000, Prediction Accuracy = 65.49615384615385%, Loss = 0.007301545343719996
Epoch: 6408, Batch Gradient Norm: 4.568869806551558
Epoch: 6408, Batch Gradient Norm after: 4.568869806551558
Epoch 6409/10000, Prediction Accuracy = 65.91538461538461%, Loss = 0.0072914058915697615
Epoch: 6409, Batch Gradient Norm: 4.293889015118042
Epoch: 6409, Batch Gradient Norm after: 4.293889015118042
Epoch 6410/10000, Prediction Accuracy = 65.63076923076923%, Loss = 0.007179365457537083
Epoch: 6410, Batch Gradient Norm: 4.605249110383346
Epoch: 6410, Batch Gradient Norm after: 4.605249110383346
Epoch 6411/10000, Prediction Accuracy = 65.31538461538463%, Loss = 0.0073393359780311584
Epoch: 6411, Batch Gradient Norm: 4.994696753570978
Epoch: 6411, Batch Gradient Norm after: 4.994696753570978
Epoch 6412/10000, Prediction Accuracy = 64.89615384615385%, Loss = 0.007457194885668846
Epoch: 6412, Batch Gradient Norm: 4.456532083681702
Epoch: 6412, Batch Gradient Norm after: 4.456532083681702
Epoch 6413/10000, Prediction Accuracy = 65.43846153846152%, Loss = 0.007275651567257368
Epoch: 6413, Batch Gradient Norm: 4.241589967601728
Epoch: 6413, Batch Gradient Norm after: 4.241589967601728
Epoch 6414/10000, Prediction Accuracy = 65.88846153846154%, Loss = 0.007202370163912957
Epoch: 6414, Batch Gradient Norm: 4.394576418504755
Epoch: 6414, Batch Gradient Norm after: 4.394576418504755
Epoch 6415/10000, Prediction Accuracy = 65.61923076923077%, Loss = 0.0071818556708212085
Epoch: 6415, Batch Gradient Norm: 4.270887754616088
Epoch: 6415, Batch Gradient Norm after: 4.270887754616088
Epoch 6416/10000, Prediction Accuracy = 65.78461538461536%, Loss = 0.007119645078021746
Epoch: 6416, Batch Gradient Norm: 4.420027914900948
Epoch: 6416, Batch Gradient Norm after: 4.420027914900948
Epoch 6417/10000, Prediction Accuracy = 65.81923076923077%, Loss = 0.007127521022294576
Epoch: 6417, Batch Gradient Norm: 4.4798905837139795
Epoch: 6417, Batch Gradient Norm after: 4.4798905837139795
Epoch 6418/10000, Prediction Accuracy = 65.46923076923078%, Loss = 0.007214380929676386
Traceback (most recent call last):
  File "/Users/athmajanvivekananthan/WCE/JEPA - MARL/multi-agent/PPO/bert_marl/mode60-dqn/classify_rsmProp.py", line 162, in <module>
    outputs = clf(inputs)
              ^^^^^^^^^^^
  File "/Users/athmajanvivekananthan/WCE/JEPA - MARL/multi-agent/bertsekas-marl/spider/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/athmajanvivekananthan/WCE/JEPA - MARL/multi-agent/PPO/bert_marl/mode60-dqn/classify_rsmProp.py", line 64, in forward
    x = self.bn2(x)
        ^^^^^^^^^^^
  File "/Users/athmajanvivekananthan/WCE/JEPA - MARL/multi-agent/bertsekas-marl/spider/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/athmajanvivekananthan/WCE/JEPA - MARL/multi-agent/bertsekas-marl/spider/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/Users/athmajanvivekananthan/WCE/JEPA - MARL/multi-agent/bertsekas-marl/spider/lib/python3.11/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
KeyboardInterrupt