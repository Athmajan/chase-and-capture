Traceback (most recent call last):
  File "/Users/athmajanvivekananthan/WCE/JEPA - MARL/multi-agent/PPO/bert_marl/mode20-dqn/dqn_seq.py", line 272, in <module>
    action_id, action_distances = agent.act(obs, prev_actions=prev_actions)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/athmajanvivekananthan/WCE/JEPA - MARL/multi-agent/PPO/bert_marl/mode20-dqn/src/agent_seq_rollout.py", line 69, in act
    best_action, action_q_values = self.act_with_info(obs, prev_actions)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/athmajanvivekananthan/WCE/JEPA - MARL/multi-agent/PPO/bert_marl/mode20-dqn/src/agent_seq_rollout.py", line 127, in act_with_info
    res = self._simulate_action_par(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/athmajanvivekananthan/WCE/JEPA - MARL/multi-agent/PPO/bert_marl/mode20-dqn/src/agent_seq_rollout.py", line 231, in _simulate_action_par
    sim_obs_n, sim_reward_n, sim_done_n, sim_info = env_simulator.step(sim_act_n)
                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/athmajanvivekananthan/WCE/JEPA - MARL/multi-agent/bertsekas-marl/spider/lib/python3.11/site-packages/gym/wrappers/time_limit.py", line 18, in step
    observation, reward, done, info = self.env.step(action)
                                      ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/athmajanvivekananthan/WCE/JEPA - MARL/multi-agent/PPO/bert_marl/mode20-dqn/ma_gym/envs/predator_prey/predator_prey.py", line 350, in step
    self.__update_agent_pos(agent_i, action)
  File "/Users/athmajanvivekananthan/WCE/JEPA - MARL/multi-agent/PPO/bert_marl/mode20-dqn/ma_gym/envs/predator_prey/predator_prey.py", line 287, in __update_agent_pos
    curr_pos = copy.copy(self.agent_pos[agent_i])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/athmajanvivekananthan/miniconda3/lib/python3.11/copy.py", line 66, in copy
    def copy(x):
KeyboardInterrupt